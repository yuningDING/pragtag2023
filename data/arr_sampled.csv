essay_id,domain,label,text,prediction_string
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Do you have results on how the performance varies across different choices of λ, or alternatively, do you have an intuition on what types of target tasks might benefit more from larger instance- vs. task-information contributions?
",433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Todo,"
3) It's better to investigate whether the model really leverages document-level contexts correctly, probably refer to this paper: Do Context-Aware Translation Models Pay the Right Attention? ",553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Not sure if I need to register an account to get to the code. ,854 855 856 857 858 859 860 861 862 863 864 865 866 867
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,"On the other hand for protest-related data, we see a mixed performance, where Cont doing better in 2 out of 3 cases. ",721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo, ,
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"It seems that the hypothesis needs to consider a compact space for continuous prompts in order to build an approximate mapping to the discrete prompt space, as there is only a finite number of discrete prompts. ",488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"Line 22, ""Bert"" --> ""BERT"" ",620 621 622 623 624
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Todo," If it does rank poorly, it may reveal another important feature of NAR model. ",284 285 286 287 288 289 290 291 292 293 294 295 296 297
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,Typos ,529
f4d5395d46a0f2f0866fa4410edd21d000d1791f07ef488bea12fe58ae905b9bb44fd8d0b92f1da10bb6456a4dca4cf8ca35d0350654cb42b3a947b8edb49b7f,arr,Todo,"- Algorithm 1, line 11: the function s(·) should accept a single argument according to line 198.
",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo," At the very least, it would be prudent to include this in related work. ",718 719 720 721 722 723 724 725 726 727 728 729 730 731
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Todo,"- What hypothesis test are you using for computing the significance in table 2 and 3?
",380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,p.6 Are C_concat and C_average the same prompt similarity metrics used in Vu et al. 2021? ,817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,1. ,639
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,-Line 139: provide —> introduce/develop ,1383 1384 1385 1386 1387
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- Figure 2: It has not been useful at all, at least for me.
",698 699 700 701 702 703 704 705 706 707 708 709 710 711
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"You say your training data is 3.7B, but is that 3.7 B words? ",373 374 375 376 377 378 379 380 381 382 383 384 385
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"So, I’m not sure why the authors discuss this as a problem.
",272 273 274 275 276 277 278 279 280 281 282 283
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,BERT is a strong baseline model from Table 1. ,220 221 222 223 224 225 226 227 228
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"
How did you do it?
",634 635 636 637 638
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,Is it only using strict sentence string matching or semantic matching? ,422 423 424 425 426 427 428 429 430 431 432
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Todo,but I have not found this improvement in the current version (but I admit I might have simply overlooked it; all I am saying is I did not find it at the places where I would expect it). ,465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,General comments and suggestions: ,189 190 191 192
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo, ,
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,But this equation tells you do language modeling on the original text? ,319 320 321 322 323 324 325 326 327 328 329 330
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"In contrast, the numbers are 4.2 and 20.7 for improved language pairs”. ",336 337 338 339 340 341 342 343 344 345 346 347
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,Are there any ways (besides downstream BLEU) to how use of a contact language or same language family affects the model? ,290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,I fail to see how the ablation study of cross layer ensemble is relevant to this paper. ,983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,Did you try cosine distance instead of Euclidean? ,341 342 343 344 345 346 347 348
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo," In a way, it is therefore surprising that recent work using deep learning methods does not use this simple resource. ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"
are these cases normally split chronologically? ",179 180 181 182 183 184
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"It probably doesn't hurt if the number of sentences is not exactly identical for all language pairs, or does it?
",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,3.2  what does it mean articles cannot be violated? ,170 171 172 173 174 175 176 177 178
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo, It would be great to see if context boosting is still impactful versus more sophisticated approaches. ,231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"Because the models are predicting textual similarity, after all.
",738 739 740 741 742 743 744 745 746
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"Moreover, the effect of sentiment word detection and correction of SWRM should better be shown. ",384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Todo,"L. 135: "" linguistic law exists in many corpora"" --> probably  ""linguistic law is manifested in many corpora""? ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"	Table 1, what are the hardware used? ",147 148 149 150 151 152 153
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"l.267-270 This is possibly because, since HSK is an official Chinese proficiency test, candidates tend to use long sentences to show their ability in Chinese use ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,-L346: “apparently” weakens the point. ,465 466 467 468 469
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,Many such resources are not based on coreference resolution so may not be applicable. ,683 684 685 686 687 688 689 690 691 692 693 694 695 696
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On lines 066-067, remove "", and of course..."" to the end of the sentence.
",325 326 327 328 329 330 331 332 333 334 335 336 337 338
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,"-Line 631: similar, approaches -> similar approaches ",562 563 564 565 566 567 568
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Todo,"-For the full setting, AUC and precision improved a lot, but not F1. ",213 214 215 216 217 218 219 220 221 222 223 224 225
0717df21c948fc36edf5f14e8f8c15c7640e5a653f4dcc12c1c89a96aaa861c6aabcd3ec512d9dba6e71a5031f90b6cbf3411e7d555480e0e93fd160fbe0df95,arr,Todo,Similar issues also apply to the axes of the graph in Figure 5. ,274 275 276 277 278 279 280 281 282 283 284 285 286
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Q1. - ,761 762
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"
(2)	Why the Baseline outperforms Yu et al. (2020) on ACE 04 and ACE 05 greatly, but has comparable performance on OntoNotes 5 and CoNLL 2003? ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo," S4.1 Model design was elaborated into subsections, S5.2.1 adds an introduction to LED.
",546 547 548 549 550 551 552 553 554 555 556 557 558
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"Some introduction to the datasets might also be helpful, such as the size of each dataset. ",449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Todo,Livestreaming videos tend to have more word eros. ,430 431 432 433 434 435 436 437
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"At first, the authors state that two strategies are used: one extracting keywords from the references, and another using a sequence-to-sequence model to predict them from the source sentence. ",1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"
2. ",462
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,Please add more descriptions as the authors undergo the human annotation process. ,210 211 212 213 214 215 216 217 218 219 220 221
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"Here ""outperform"" --> ""outperforms"" 3. ""... ",155 156 157 158 159 160
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,about the collected corpus. ,306 307 308 309
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo," This does not seem to be visible in Table 1.
",477 478 479 480 481 482 483 484 485 486
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,"-line 080: incorrect use of quotation marks and repeated quotation marks.
",514 515 516 517 518 519 520 521 522 523 524
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,"
3. ",227
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Todo,"A general comment: For MMT task, it is already known that the vision model does not contribute much to the standard MMT task. ",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,-Table 2 is not colorblind-friendly (red-green is the most common type of colorblindness). ,650 651 652 653 654 655 656 657 658 659 660 661 662
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,"Although we can predict the same input sentence for different types one-by-one if a sentence contains multiple events of the same type, the same input (template and sentence) will correspond to various outputs. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,This is because the optimizer is focused on improving a single classifier’s loss (instead of many). ,632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,2) I feel like sentence segmentation and spellchecking & correction tasks do not fit well in the same benchmark alongside the other tasks that focus more on semantics. ,254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Todo,"It may be more often the case that a sentence corresponds somewhat to two or more moral foundations, and this might be better modelled as a score for each foundation. ",410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,Could you add an explanation? ,421 422 423 424 425
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"I am not sure it is adding anything to the motivation of the work, but it may rise concerns.
",514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-It would be helpful to mark the extended WEAT/WAT contributed by this paper using a modified label (eg WEAT*), in Table 2 and in text.
",1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Todo,"I urge the authors to release at least some part of the dataset to the wider public, or under some  end user-agreement.
",236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"Besides these, I also note some ethical issues in the ‘Ethical Concerns’ section. ",714 715 716 717 718 719 720 721 722 723 724 725 726
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,Comments: ,245
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Is there any added value to training the projector weights as opposed to just optimizing the projector's output (the prompt) directly? ,796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,Some of the explanations in the appendix could help to improve the readability of this section. ,148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"I recommend expanding on it once to clarify.
",648 649 650 651 652 653 654 655
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"This could be done in an unsupervised manner, or using a linear regression model, or something similarly simple -- maybe by deducting an ""average"" entity geographical distribution model, such that local characteristics become more prominent, or by computing (in an unsupervised manner) some weights that would downplay the contribution of entities from countries that are always represented (like a ""country tfidf"" maybe?). ",498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,"In the information extraction area, recently a lot of work has been explored to replace the traditional classification methods with the generative models. ",113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,Which is not the case. ,320 321 322 323 324
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Q3. ,840
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Is training layer 12 more important than training layer 4? ,1098 1099 1100 1101 1102 1103 1104 1105 1106 1107
0ac9820142b39e37945bfc25038d562d36d08e5407ab516a8f8eb18cc7a696601df7e15caa23159bf9ef420a1e65efadf3778d71d4aa95df26226ff49de26bb3,arr,Todo,"- How does \lambda influence the performances?
",214 215 216 217 218 219 220
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,  * Logic Trap 1: The point being made is obvious: ,505 506 507 508 509 510 511 512 513 514
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,2. ,300
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"- ""In this background"" - This phrase is used a couple of times and it's unclear what is meant. ",194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,I recommend using the strictest metric (such as RA) because it will clearly highlight the differences in performance. ,261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,"In particular, what is the meaning of the phrase “identical single task across both domain.” ",395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"1)	Many acronyms not defined, such as “IE” and “RNN” 2)	Missing references for some claims that are presented as if they are common knowledge. ",487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"
-I would add a bit more of a discussion on the nature of the data (fully open, consent, limitations for research/commercial purposes, etc.) ",512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"
3. ",829
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,Line 303: Missing citation of the Spacy library ,529 530 531 532 533 534 535 536
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,Can the authors provide more insight into this? ,542 543 544 545 546 547 548 549
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On lines 338-339, change ""with unanswerable examples too"" to ""that also contain unanswerable examples"".
",393 394 395 396 397 398 399 400 401 402 403 404 405 406
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"
(3)	According to the Table 4, the improvement of BS against LS is marginal. ",327 328 329 330 331 332 333 334 335 336 337 338 339 340
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"Multi-task Learning for Automated Essay Scoring with Sentiment Analysis"". ",346 347 348 349 350 351 352 353 354
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,Grouping the bars by domain instead of role might be better (because we can compare the shapes). ,794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Then the section can be ended with hypothesizing and limited exploration of model redundancy. ,1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-L265-268: I would move this paragraph to §3.3.2. ,230 231 232 233 234 235 236 237
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,l.569-71: I cannot parse this sentence ,247 248 249 250 251 252
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"In a summary, the authors have done a lot of exploration and experimentation, as well as using experiments to prove many of their conjectures, yet many of these conjectures can be directly summarized by previous work. ",761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,1. ,672
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Todo,NONE ,177
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Todo,> check reference ,207 208 209
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,"Maybe move MRPC to a separate figure and put it in the appendix?
",325 326 327 328 329 330 331 332 333 334 335 336 337
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"What I understand from this plot is that the MCC (which is a way of measuring the model's success) gets higher with the number of layers, and the entropy (which is an inverse measurement of how sure the model is of it's prediction) gets lower with the number of layers. ",747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo, ,
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,  ,
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Todo,"Syntactically controlled paraphrase generation:  Goyal et al., ACL2020, Neural Syntactic Preordering for Controlled Paraphrase Generation Sun et al. EMNLP2021, AESOP: Paraphrase Generation with Adaptive Syntactic Control  <-- this is a contemporaneous work, but would be nice to cite in next version. ",404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Todo,This time the presentation improves a lot and more details are added as attachment. ,105 106 107 108 109 110 111 112 113 114 115 116 117 118
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,The choice of H and W is not really explained. ,659 660 661 662 663 664 665 666 667 668
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"It might perform better in the end.
",349 350 351 352 353 354 355
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"Novikova, J., Dušek, O. and Rieser, V., 2018. ",634 635 636 637 638 639 640 641
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,I see the details of the datasets and I understand it. ,302 303 304 305 306 307 308 309 310 311 312
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Todo,"From Line.402-Line.405, the selection is selecting the one with lower MER from aggregation and post-edit. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Todo,"One previous decoding method used the combine similar outputs was to over-generate candidates, and then perform post-decoding clustering to group similar candidates together (Ippolito et al., 2019). ",459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,The proposed method is a model acceleration technique rather than model compression technique (which reduce the model parameters or size). ,247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,6. ,392
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Some are by necessity (because the available resources are incomplete), some by choice (the adjectives and historical figures). ",645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"-Also, it seems that all the rules change a one-token entity to a multi-token one or vice-versa. ",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,"If a table is added, it would be better to include relevant discussions. ",408 409 410 411 412 413 414 415 416 417 418 419 420
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,"It is explained in later paragraphs, but on first reading it is somewhat confusing ",172 173 174 175 176 177 178 179 180 181 182 183 184 185
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Also consider marking the best results in each column/row using boldface text. ,279 280 281 282 283 284 285 286 287 288 289 290
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] lines 89-94: Can you give examples of two different instances drawn from the same task that should be handled using different prompts? ,679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-**Lines 448-451:** For completeness, using multitask learning to leverage knowledge from heterogeneous resources has been already studied in SRL (Conia et al., 2021).
",814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,It's not clear what the highlighting in Table 1 shows (it is implicitly mentioned later in the text). ,963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"That is, the paper/system is motivated by there being a single knob to turn to control accuracy/computation tradeoffs, but this is two knobs, I think. ",864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,"- Line 232: The are surely sentences where not every bucket is represented, right? ",279 280 281 282 283 284 285 286 287 288 289 290 291 292
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"how do you control for it?
",398 399 400 401 402 403
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Todo,I believe that the paper would be made much stronger if the authors would keep the somewhat didactic attitude that characterizes the overview. ,283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"In this sense, Table 4 goes in this direction. ",591 592 593 594 595 596 597 598 599
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,What is used as ‘descriptions’ of entities in MedMentions? ,298 299 300 301 302 303 304 305 306
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,"Comparing with below methods will show generality of ideas proposed in the paper in a much better way.
",379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Todo,"Please revisit the following sentences for readability: line 137, 301, 498, 550 ",256 257 258 259 260 261 262 263 264 265 266 267
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-§3.2.1: I would have liked to see a discussion on the properties of these examples. ,156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Todo,- The hyperlink for footnote 3 and 4 do not seem to work. ,209 210 211 212 213 214 215 216 217 218 219 220 221
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 244 in Section 2.3 refers to $E_{gen}$ and $E_{rev}$ which have not been previously introduced. ,449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Todo,"The formulas in Line 310 are not described and embedded in the text, I think describing them in the neighbouring text would make clear why the formulas are there. ",350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"l123: ""graduation accumulation"" -> gradient accumulation ",517 518 519 520 521 522
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"mean?
",584
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"I would suggest changing the colors and/or specifying in the caption that the top number in each cell corresponds to chrF and the bottom one to COMET.
",663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,Is this because word2word and FastAlign fail for some language pairs or is this because there are few alignments between these language pairs? ,348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,Is it a new parameter? ,377 378 379 380 381
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"A better practice would be to have more than one checker for each problem, at least on a subset of the corpus, to measure the agreement between them and, in case of need, adjust the guidelines. ",302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"It's unclear what is meant.
",238 239 240 241 242
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Todo,"Figure 2 is a bit cluttered and the ""bold"" text is hard to see, perhaps another color or a bigger font could help in highlighting the human identified rationales better. ",249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"
5. ",196
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Todo,Is this true? ,520 521 522
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"-""The model shrinks character sequences into less hidden states"" -> ""fewer hidden states"" ",689 690 691 692 693 694 695 696 697 698 699 700 701
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,The statement above looks more like you intended to say discourages rather than encourages. ,795 796 797 798 799 800 801 802 803 804 805 806 807 808
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"245 The GAT is trained with the whole model?
",359 360 361 362 363 364 365 366 367
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"-330: Introduce SPMR, what does it stand for?
",414 415 416 417 418 419 420 421
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,-Code link seems to be expired. ,382 383 384 385 386 387
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"
Is there anything we, i.e. the trainers of the NNs, can do to make it easier for the NNs?
",522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,Other papers seem to go for the full SuperGLUE suite. ,235 236 237 238 239 240 241 242 243 244
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Todo,Did you check the disparity and fairness of data? ,92 93 94 95 96 97 98 99 100
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"What ""in-the-wild"" term means? ",142 143 144 145
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"2: Why did you discard the ""anatomy"" category?
",226 227 228 229 230 231 232 233
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] lines 128-134: Since this is a transfer setting that involved different levels of supervision from multiple tasks and domains (source vs. target datasets) it is not super clear what the “fully-supervised” and “few-shot settings” refer to. ,739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"This links to the second potential weakness, regarding the applicability of this method to newly collected datasets (which is the aim, right?). ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Todo,"the combination"" -> ""combine"" ",407 408 409 410
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo, ,
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,  ,
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"It's abs(p - q) to use the terminology of line (232), is that right? ",1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,The definition of diversity is unclear. ,304 305 306 307 308 309
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,This paper will be further strengthened if the effectiveness of the proposed method is shown even when large-scale encoders are employed. ,269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"Panitan Muangkammuen and Fumiyo Fukumoto. "" ",340 341 342 343 344 345
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"In line 257, it's strange that including the collected LIV-EN parallel data for finetuning actually makes the NMT system perform worse. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,-Could you show ablations on EPO and SEO? ,344 345 346 347 348 349 350 351
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
13. ",363
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,I didn't understand the paragraph 4.1 Cognitive Dataset. ,656 657 658 659 660 661 662 663
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Todo,"Also, including generation from baseline systems for the same examples would help illustrate the differences better. ",386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,	Section 2 “related work and background” is hard to understand. ,392 393 394 395 396 397 398 399 400 401
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"
L101: comprehensive experiment -> comprehensive experiments L231: This fine-tuning process incorporates a (..) discriminator will... -> which will L240: We hope the generator will have more perceiving to -> more perception power? ",496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Todo,"For the writing part, for example, Section 3 is mixed with the past tense and present tense. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"
(3) How to transit properly?
",210 211 212 213 214
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,- Figure 4 is not easy to interpret. ,387 388 389 390 391 392 393 394
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,Can you please provide a reason/explanation for this observation? ,861 862 863 864 865 866 867 868 869
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,Typos: consists in -> consists of (several times until section 5) pdf2dvju -> pdf2djvu described in Section ) avoid contractions like didn't and can't ,302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"In this sense, weakness 3) can be useful to solve all the others. ",498 499 500 501 502 503 504 505 506 507 508 509 510
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"However, it seems to me that a better upper bound would be the prediction based on true background articles. ",788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"While this ensures a lack of overlap, it seems possible that each court produces a slightly different distribution of decisions. ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Todo,"**Suggestions**: See above.
",280 281 282
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"Please check.
",613 614
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Questions ,801
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Todo,This is an important direction of research and I believe in the current state the paper can be accepted for publication. ,215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Todo,"-154: ""efficiently to compute"" -> ""efficient to compute"" ",280 281 282 283 284 285 286 287
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Todo,"[1] Ding, M., Zhou, C., Yang, H. and Tang, J., 2020. ",94 95 96 97 98 99 100 101 102 103 104
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"Should L910 be corrected accordingly?
",220 221 222 223 224
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Additionally, the terms “domain” and “datasets” are used interchangeably throughout the paper (i.e., “domain” is line 46 vs. “datasets” in lines 62). ",516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,This is something that could be checked. ,424 425 426 427 428 429 430
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"-How did you decide the number of classes (10 for coarse-grained and 104 for fine-grained) and how did you decide these classes?
",151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Todo,I like the use of the initial example throughout the paper. ,204 205 206 207 208 209 210 211 212 213 214
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Todo,"Glad to see that the ""full annotation data"" will be available, and I'm assuming that any other required data will also be available to other researchers as well. ",214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Todo,"Also, isn't there overlap between German and the other training languages? ",286 287 288 289 290 291 292 293 294 295 296
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 254: describe -> described ,503 504 505 506 507
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,"I didn’t follow the description of the sentence-level hash function from Line 324 to Line 328: If we use the sequence encoder (e.g., Sentence-BERT) as a hash function to directly map the instances to the exiting layer, why do we still need an internal classifier at that layer? ",572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"On why that is important, I would suggest reading **Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science** (Bender and Friedman, 2018) or https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/ ",760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,WMT@EMNLP 2021: 478-494 ,561 562 563
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,Table#1 in Figure 1: (C3-B3)/B3 -> (D3-C3)/C3 ,279 280 281 282 283 284 285
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,---------Suggestions---------   1. ,435 436
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Todo,"- Line 100: why is this a class of neural networks, and not a neural network?
",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"It might be good to address whether this is a concern.
",183 184 185 186 187 188 189 190 191 192 193
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"  In case the paper doesn't go through to your ideal *ACL venue, please address these issues before resubmitting and I'll be happy to continue as a reviewer of this paper. ",877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," If your original motivation is correct, I would expect a configuration like that to do better than your current best result, 0.5-0-0.5. ",627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,It would be interesting to see how they work compared to XLSR-53. ,494 495 496 497 498 499 500 501 502 503 504 505
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,Missing reference to Lukin et al. 2017 (EACL) ,173 174 175 176 177 178 179 180
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Todo,Paper is well written and organized. ,237 238 239 240 241 242
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,"-In Figure 4 bottom-left, the first sentence should remain the same (i.e., it should start with “He was” rather than “They are”) ",497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,3. ,313
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,"If possible, annotate more data. ",278 279 280 281 282
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Using only the speedup ratio for diagnosing the behavior of the model is lacking important information. ,670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo, Lines 301-328. ,1223 1224
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Todo,Table 5. ,354 355
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Todo,"misc{hsu2021robust,       title={Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training},        author={Wei-Ning Hsu and Anuroop Sriram and Alexei Baevski and Tatiana Likhomanenko and Qiantong Xu and Vineel Pratap and Jacob Kahn and Ann Lee and Ronan Collobert and Gabriel Synnaeve and Michael Auli},       year={2021},       eprint={2104.01027},       archivePrefix={arXiv},       primaryClass={cs. ",458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,"On line 395, ""refined for multiple years"" should be ""refined over multiple years"".
",357 358 359 360 361 362 363 364 365 366 367 368 369
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-Is it possible to compare to MCDropout? ,1437 1438 1439 1440 1441 1442 1443
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"The original annotation considered some sentences to be erroneous while your guidelines did not?
",408 409 410 411 412 413 414 415 416 417 418 419 420 421
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,It would be better to discuss the potential of language-agnostic templates (html tag). ,208 209 210 211 212 213 214 215 216 217 218 219 220
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Todo,"In my experience of GLUE, SST and MNLI are two of the most resourceful sentence classification tasks compared to other tasks in GLUE. ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,5) How much are these problems language-dependent? ,427 428 429 430 431 432 433
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"Is it even important for one model to be good at both?
",339 340 341 342 343 344 345 346 347 348 349 350
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"- In the abstract, what is ""increasing F1 by up to t points and precision @Top-K by a large margin of over 25%"" based on? ",357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,1. ,212
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"The proposed approach requires producing |L| finetuned models, one for each target language. ",186 187 188 189 190 191 192 193 194 195 196 197 198
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"A bit more insight into how these are reflected in dataset characteristics and how they impact the usefulness of the dataset would be very useful.
",809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Todo,"If not, could you please check a performance comparison with any attention mechanism? ",60 61 62 63 64 65 66 67 68 69 70 71 72
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,Typos: ,475
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Todo,"
2. ",733
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"
  I think it would be more appropriate to list the works or methods instead of noting the relative   abundance.
",1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Todo,"As shown in Table 1, the number of N + 1 is 3 for the GovReport dataset. ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,-The only kind of work I would add are proposals to learn an ideal segmentation (instead of fixing the segmentation before starting the training). ,502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"What's the size/computation of proposed IQ, compared to baselines? ",81 82 83 84 85 86 87 88 89
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"l.66 ""it will be taxing"" -> ""it will be difficult"" ",108 109 110 111 112 113 114 115 116 117
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo, ,
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"2) In Equation 1, the symbol $i$ is used for both the subscript and the superscript, such as $X^i_i$, which is a little bit confusing. ",589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Ln 41: I don’t think these works assume a generative framework. ,627 628 629 630 631 632 633 634 635 636 637
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,Are they shorter/longer than the sentences seen in the average MT training corpora? ,171 172 173 174 175 176 177 178 179 180 181 182 183
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"-313 - footnote 2: What's the postprocessing effort here, not clear. ",397 398 399 400 401 402 403 404 405 406 407
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Todo,I would talk about theorem 1 informally in the introduction. ,428 429 430 431 432 433 434 435 436 437
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Why not merge Table 1 and Table 2? ,222 223 224 225 226 227 228 229
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Todo,The font in Figure 1 is very small. ,216 217 218 219 220 221 222 223
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Todo,The most clear description of early exiting appears in line 338-345. ,119 120 121 122 123 124 125 126 127 128 129
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Todo,"Appendix B.3 is not referenced in the main paper.
",247 248 249 250 251 252 253 254 255
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"The example in Table 3 shows that the lexicon-based approach (VAD dataset) suffers from lack of context sensitivity (the word ""close"" in this example is just a marker of proximity). ",631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Todo,Which is the fourth dimension. ,469 470 471 472 473
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"Is there a reason why the 4 constructions used in Case Study 1 (_transitive, ditransitive, caused-motion, resultative_; L.165), are slightly different from Case Study 2 (_ditransitive, resultative, caused-motion, removal_; Table 2)?
",939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"
  2. ",549
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"For example, EMR is stated to ""randomly stor[e] a few examples of old classes"" (Line 254); one might therefore expect the performance of EMR to possibly improve (significantly), as the quantity of stored examples of old classes increases.
",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"For table-text reasoning, why NRP task + formula-based prompt improve this reasoning ability? ",153 154 155 156 157 158 159 160 161 162 163 164 165
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"For example, character-level FSTs for unsupervised translation between closely related languages (e.g. Serbian and Bosnian) perform very well [1]. ",475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"220 - ""intuition..."", this is good ",438 439 440 441 442 443
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"This doesn seem like isn't an ""ideal calibrator,"" it has nontrivial ECE still, right? ",888 889 890 891 892 893 894 895 896 897 898 899 900 901
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Todo,What exactly is the latter type? ,242 243 244 245 246 247
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 046: which nevertheless -> which are nevertheless ,694 695 696 697 698 699 700 701
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Todo,-I am willing to see other reviews of this paper and the response of the authors. ,397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,-More information about the annotators would be needed. ,692 693 694 695 696 697 698 699
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,(Question 4)  What is the precise definition of “error probability” of (10a)? ,265 266 267 268 269 270 271 272 273 274 275 276
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,Comments: ,189
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Todo,"This paper has done a solid work on Cross-Lingual Named Entity Recognition, however, some questions remain to be clarified.
",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,This paper is well written and easy to follow. ,170 171 172 173 174 175 176 177 178
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"This parallelism is questionable, as there are contrasting feelings and opinions about it. ",501 502 503 504 505 506 507 508 509 510 511 512 513
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Todo, ,
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"But for me, the two parts still seem a bit independent from each other. ",295 296 297 298 299 300 301 302 303 304 305 306 307 308
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,The geographical mapping presented is left to the subjective inspection of a human judge. ,414 415 416 417 418 419 420 421 422 423 424 425 426 427
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"-fix punctuation: l. 336, l. 433, l. 445, l. 534 ",283 284 285 286 287 288 289 290 291 292
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"
2. ",829
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,line 175 seems lacking of experimental results to support it. ,230 231 232 233 234 235 236 237 238 239
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,The claim may very well be true for specific type of data. ,589 590 591 592 593 594 595 596 597 598 599 600
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Todo,"It might be better to add more redundancy to that paragraph, using different ways to explain the same concept. ",490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Line 465: -> perform ,691 692 693 694
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-135: space before ( ,235 236 237 238
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,"-During training you sample 0-3 reference tokens as constraints, since the BPE is used, does it mean that it might be the case that only part of the word is considered as a constraint? ",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,"See (1) under Weaknesses for some notation inconsistencies that can be improved as well.
",556 557 558 559 560 561 562 563 564 565 566 567 568 569
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Todo,Line 414: it would be good to show the ratio of false negative examples that are filtered out. ,236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,-l.64 an-->a ,487 488
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[General Question] The final matching score between the instance x and prompt p_t requires setting a hyperparameter λ that defines the relevant contribution of the task- and instance-level information. ,374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,045 - Figure 1 does not seem to show that the attacks were successfully able to pick the persona consistently. ,234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,"Also, how do you select the patient population for the experiments? ",372 373 374 375 376 377 378 379 380 381 382
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,1. ,741
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"An introduction to these concepts may help readers with different background knowledge as I am.
",485 486 487 488 489 490 491 492 493 494 495 496 497 498 499
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,"Tables 1-6: I would recommend bolding the best performance numbers in these tables.
",375 376 377 378 379 380 381 382 383 384 385 386 387
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,"Domain adaptation with asymmetrically-relaxed distribution alignment."" ",523 524 525 526 527 528
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"Inspired by"" ",325 326
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Todo,N/A ,324
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,"Do they have linguistics background?
",706 707 708 709 710
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,-Lines 559-560: This is not entirely true. ,440 441 442 443 444 445 446
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Todo,"1) In Figure 1, what is the corpus that the authors use to sample sentence pairs? ",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,-	It would be interesting to know if there is a particularly reason that the authors frame the retrieval task (stage 1) as sentence retrieval rather than as document retrieval. ,393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,It may be unfair. ,276 277 278 279
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Line 123: “shotcut learning problem” -> “shortcut learning problem” ,791 792 793 794 795 796 797 798 799
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo, How is this score computed and what properties of MT training does it reflect? ,550 551 552 553 554 555 556 557 558 559 560 561 562 563
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"Currently ""Introduction"" section of the paper reads as 2-3 paragraphs of introduction, followed by 3 bullet points of related work and again a lot of introduction. ",198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,Regarding the proposed approach 1. ,181 182 183 184 185
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo, ,
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-Conia et al., 2021. ",937 938 939 940
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Todo,"-please clarify what is meant in line 375 by ""harmful"" and annotation bias in line 373 ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,I think of headlines and titles as fundamentally the same thing: short (one sentence) high-level descriptions of the article to come. ,845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Todo,- I am puzzled by a difference between the Dicta test set and the new test set: the difference between CHA and WOR for the Dicta test set is much bigger that the respective difference in the new test set (between 1.4 and 2.4 times bigger). ,192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	The fact that the claimant is included in the veracity prediction hints at the authors’ assumption that certain claimants are more or less likely to make true/false claims. ",633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"This must be corrected.
",787 788 789 790
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"
3. ",732
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," I've never heard of this metric before, so I don't really understand what it is or whether an improvement of 0.7 is meaningful. ",564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-163: This statement is unsupported ""First, the models went back to focusing on single-turn utterances, which..."" ",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"not that good at storing sentence encoding representations in the CLS token (see e.g., Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders (Liu et al 2021) or Condenser: a Pre-training Architecture for Dense Retrieval (Gao & Callan 2021), so difficult to conclude these baselines are particularly strong. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Todo,"-Comparison of Diverse Decoding Methods from Conditional Language Models (Ippolito et al., 2019) ",521 522 523 524 525 526 527 528 529 530 531 532 533
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"-The proposed method lies in the metric learning field; however, the authors do mention the related metric learning work in their section 5 (related work). ",405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo, ,
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Todo,"For example, would [AlterRep](https://arxiv.org/abs/2105.06965) automatically handle the issue of redundancy?
",546 547 548 549 550 551 552 553 554 555
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"[1]Cao, Jie, and Yi Zhang. "" ",411 412 413 414 415 416
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"I would suggest either weakening the phrasing or providing more models.
",727 728 729 730 731 732 733 734 735 736 737
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,What do you mean exactly? ,403 404 405 406 407
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,I'm not sure if the finding of Voita et al (2019) applies to the CLIP representations as no language modeling objective is used during CLIP training. ,381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"In NER datasets, it is better to state the size of the dataset with the number of sentences. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,I found several points where I was extremely confused. ,478 479 480 481 482 483 484 485 486
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"First, I fail to see how figure 1 demonstrates the problem at all. ",734 735 736 737 738 739 740 741 742 743 744 745 746
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"2 ""The opposing meanings help to avoid ambiguity in the correct answer, make the task intuitive for human annotators, and help prevent annotation artifacts that have plagued other NLI datasets."" ",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,-l. ,234
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Todo,I am not sure why the paper used a probability of 50% to sample a target sequence with less than five words (in line 318). ,285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"
I don't understand this part, I'm not able to reproduce you Corr column in Table 4 from the numbers in Table 2. ",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(42): works on -> works by ,544 545 546 547 548 549
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,I would recommend colour-coding the different types of bias and providing the details in the caption. ,981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"L280, there exists... ",641 642 643
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Todo,1. ,184
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Todo,"In line 300-301 ""{ d i,1−, . . . , ",213 214 215 216 217 218 219 220 221 222
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Comments ,626
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Todo,- the discussion of Arabic use of diacritization is not accurate. ,161 162 163 164 165 166 167 168 169 170 171
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Todo,"The sentence starting on line 279 (""Having considerable higher effectiveness on average signals the advantage of using the proposed dataset."") ",447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"In general, this paper presented a fairly good amount of work. ",830 831 832 833 834 835 836 837 838 839 840
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,"GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing, ICLR 2021. ",425 426 427 428 429 430 431 432 433
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Todo,line 47: model → model. ,244 245 246 247 248
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,169-182. ,576
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"There are stronger cascade systems (e.g. you cited Bentivogli et al., 2020, whose cascade scores 28.8).
",588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,Or all? ,614 615
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Line 209-211: I can understand what you mean but this part should be re-written. ,264 265 266 267 268 269 270 271 272 273 274 275 276 277
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,I suppose it should be Q_k instead. ,232 233 234 235 236 237 238
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Since the inputs are always one from each side (Section 3.2), are such stories filtered out of the dataset? ",396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,"-There is a significant drop in performance for MeSH terms when metadata are not available, leading to a worse performance than other methods (Ablations-d). ",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,Maybe expand on the hyperparameter choices a bit more. ,611 612 613 614 615 616 617 618 619
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,1. ,686
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,L237: Text-to-table -> text-to-table ,296 297 298 299
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo, ,
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"As mentioned above, I think that supplementary datasets are important for better comparing SWRM and baselines. ",368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,l.166-67: This should should seem ,193 194 195 196 197
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- There are some inconsistencies in the notation for AOPC and the k parameter with potential   related typos in its definition.
",1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-line 177: copes -> copies ,545 546 547 548 549
089fa4b7f0e4265532d65b1eea05ac48c8b82e01358b15feea59cf8855580971154b1b47fe6ad58eed10e64e8b2d89d6aa582d55e183b9fe28b3b25ec81b4fa8,arr,Todo,Nothing as such!! ,121 122 123
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Todo,"It seems to me that redundancy may only be a problem for the specific gradient-based representation alteration method you consider, rather than other ways of producing counterfactual interventions. ",518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Todo,"Consequently, earlier exists require -> exits Our method is easily.. orthogonal to many other existing methods (and later: To investigate the orthogonality of E-LANG with others)- I don't really get the meaning of 'orthogonal' and  'orthogonality' in this context. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"However, I believe the evaluation should focus on the performance of the stereotype detection task only because is the reference task for this paper. ",600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"-Ln 545: This is an excellent point, and if you choose to save this for future work, then you should acknowledge this limitation up front and hedge all claims about ASCs ",711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L352: “obtained” -> “obtains” ,647 648 649 650 651
057a3f73710f304801787e253e5ffc7e5d2eb9cf4570a5e3c6dc8edf75ebaadb324aff13a67e27a6057b12080f89cd80cc8d0f000bd23657daf14ff9c30856db,arr,Todo,Do you mean that you find erroneous sentences in unannotated data and then correct them by a strong ensemble to obtain the target sentence? ,158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Todo,"Keyword-controlled decoding strategies: Hokamp et al. ACL2017, Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search Post et al, NAACL 2018, Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation ",445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Todo,"If this task is for real applications, the other tags are also necessary, right? ",216 217 218 219 220 221 222 223 224 225 226 227 228 229
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"l.266-267 -> NLPCC18 has the shortest sentences, whereas CGED sentences are much longer.
",194 195 196 197 198 199 200 201 202 203 204 205 206
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Todo,"Given the limited space, there probably isn't much to be said, but it might be worth mentioning so that the readers are aware of this. ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Shouldn't the diagonal be 100 by definition? ,586 587 588 589 590 591 592
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,"In line 23, it should be: …on the three datasets…. ",411 412 413 414 415 416 417 418 419 420
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo, ,
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,Generation methods are more uncontrollable than span extraction and span classification methods for event extraction. ,277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,A.2 Table 9 is with or without tuning? ,605 606 607 608 609 610 611 612
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,Questions: ,304
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"so as to stress that the authors seem not to plan an open release of their resource.
",873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo, ,
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo, ,
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,2015. ,588
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Todo,The added significance tests ,374 375 376 377
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Todo,Typos: L504: Compared to* the baselines ,184 185 186 187 188 189
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Todo,Suppose the articulatory features are learned to be very similar to phoneme embedding. ,242 243 244 245 246 247 248 249 250 251 252 253 254
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,Are they the same as the formulas used in the dataset construction (Table 5)? ,410 411 412 413 414 415 416 417 418 419 420 421 422 423
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"Intuitively, can you simply give a simple example of the difficulties of cross-domain translation (such as vocabulary difference, grammar difference and technical terms) and show that cluster based methods are helpful for this cross-domain translation. ",402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Todo,- Equ. ( ,408 409 410
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-For the ZIP method, one thing unclear to me is how you combine multiple sequences by if they have different lengths of shared suffixes?
",225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,The grammar in the paper writing could be improved. ,360 361 362 363 364 365 366 367 368
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"As such, it would be beneficial for reproducibility to provide more details on how it was constructed. ",1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"
It is not clear what is meant by ""accuracy"" during the annotation stages.
",360 361 362 363 364 365 366 367 368 369 370 371 372
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"In Figure 2, It would be better to replace [ RANDOM …… TOKENS …… from …… VOCAB ] with an specific example. ",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Todo,We are also interested in whether entities from low-resourced languages are well aligned with the high-resourced ones. ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,https://arxiv.org/abs/1704.08424 ,687
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In Section 5.1 it would be useful to report the total number of sentences in the test set so that the reader has an idea of the difficulty of the retrieval task. ",735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,This is how the authors define the relevance for immediate downstream tasks. ,230 231 232 233 234 235 236 237 238 239 240 241
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,in other domains? ,397 398 399
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"How much effort would be involved in ontology definition and annotation?
",464 465 466 467 468 469 470 471 472 473 474
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo,"-How did you choose min/max threshold values, and what are these values? ",500 501 502 503 504 505 506 507 508 509 510 511
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Todo,"It seems DCLR is independent of the positive data augmentation strategy used.
",354 355 356 357 358 359 360 361 362 363 364 365
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Todo,"Also, can you provide more details about how you computed Krippendoff's alpha? ",474 475 476 477 478 479 480 481 482 483 484 485
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"
Should this be ""the adversary holds 3,753 dialogues with persona labels ranging from 0 to 3.""?
",1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,"Lines 207-208: Isn't this just mathematically equivalent to taking Binary Cross Entropy loss over the sigmoid?
",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Todo,1. ,218
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"Howcroft, David M., Anja Belz, Miruna-Adriana Clinciu, Dimitra Gkatzia, Sadid A. Hasan, Saad Mahamood, Simon Mille, Emiel van Miltenburg, Sashank Santhanam, and Verena Rieser. "" ",525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
9. ",293
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,Models with different random seeds could easily be ensembled and combined with this approach for routing. ,279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,Do you explain why DILR-BERT is stronger than BERT in detail? ,229 230 231 232 233 234 235 236 237 238 239
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Todo,1. ,352
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-250-252: what is the hypothesis? ,270 271 272 273 274
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"The caption of figure 1 mention some number but you do not explain what they are: are they the average improvement over all languages?
",349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Todo,"Line 338, ""..towards shifting the current culture into a hopefully more equitable one"". ",191 192 193 194 195 196 197 198 199 200 201 202 203
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,\mathbb{Q}_K^NN is defined at L899. ,151 152 153 154 155
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo,Possible Analyses / experiments: ,384 385 386 387
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"Page 3, Line 240-252: There are a few variations of LSTMs [1]. ",547 548 549 550 551 552 553 554 555 556 557 558
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,arXiv preprint arXiv:1909.03087. ,672 673 674
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Todo,Significance test might be needed. ,153 154 155 156 157
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-It would be helpful to have a listing of nationalities/racial identities/occupations included in the dataset (along with the adjectives used) as part of the paper, such as in supplementary tables.
",1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 1] lines 84-86: Can you provide some more context on whether/how the difficulty of transferring relates to the similarity/nature of the two tasks (i.e.,  source and target)? ",651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,"I guess it doesn’t have the stitching layer?
",488 489 490 491 492 493 494 495
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Todo,"In Table 3, the COMET score is added without enough explanation: why choose this metric and how it fits into this evaluation? ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"Beam search is a greedy algorithm that can recover the best output with high probability.
",210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo, ,
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-Figure 1, graph titles ""embembeddings"" ",1171 1172 1173 1174 1175
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"For example, at each step (1, 2, 2a, 3, 3a) are you sampling a different batch from S and T? ",136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Todo,"Could you highlight the necessary steps that can achieve discriminator-guided decoding?
",163 164 165 166 167 168 169 170 171 172 173
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"I thing it really suffices to say ""we are investigating the accuracy/latency tradeoff, motivated by the fact that some applications will require lower latency"" and leave it at that? ",974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo,Minor Suggestions:  ,407 408
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Todo,"Section 4.7: Consider reminding the reader what the age comparison task is -- I got a little confused here and had to search for the PDF for word ""age"". ",349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Questions: ,186
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Todo,2): double-check i vs. j in denominator ,411 412 413 414 415 416 417
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,https://arxiv.org/abs/1910.12554 ,690
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo," Is there something missing?
",523 524 525 526
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-Lines 458-460: I don't think that we can conclude anything based on experiments on one dataset.
",650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
6db5d3547297644e1a01b2dd191f13fced41cc86ff3a74d59ca05167091c7b4bbe9f67ec055106ee390fe9cdb497d99a303a97c2d53e008f5f89e93f722c3fbb,arr,Todo,Eleven pages of Appendix are an indication of a great effort that went into this paper. ,283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"How certain is it that the Johnson et al. paper reliably depicts Google's current production system?
",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Please don't leave this as an exercise for the user.
",558 559 560 561 562 563 564 565 566 567
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"Line 063: ""output the woman or king."" - ",884 885 886 887 888 889 890 891
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,So I guess the randomly generated n-grams would have distant different PPL value with the extant words. ,224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,1. ,571
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"
Which 40% of the training data is used? ",648 649 650 651 652 653 654 655
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 3] lines 224-227: Need to clarify: Are the source prompts learned jointly for all source tasks?
",855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,It would be interesting to analyze these three categories separately and see whether if there are differences in the models' performances. ,586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,Many typos: ,506 507
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Todo,      2. ,152
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Todo,"- Line 136-138: ""... we down-sample each category to align with the average PosRatio of the whole test set"". ",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Todo,"Advances in Neural Information Processing Systems, 33, pp.12792-12804. ",111 112 113 114 115 116 117 118
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Two concerns here: 1) the dataset used in this paper must be clarified – how do the authors get the exact same results?; ,682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 059: With the annotated -> With annotated ,702 703 704 705 706 707 708 709
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,Is this similar to other approaches? ,441 442 443 444 445 446
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,"
3. ",235
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Todo,Suggestions: ,309
3157d8a8980d26bab69c208803b2e28cfb897da55fe2f26c7bc2b13323adf33ac953adff54c60aa83ba1dc97c6fb586ddc58637cbcaedbd7899bfdc4c3c35021,arr,Todo,What is the purpose of your paragraphing in the abstract section? ,128 129 130 131 132 133 134 135 136 137 138
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"Other tasks has the connotation of other V&L tasks such as VQA, captioning, ...  2. ",661 662 663 664 665 666 667 668 669 670 671 672 673 674 675
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"
In any case, both of these two settings would be interesting to know, so I suggest, if it is possible, to include them in the comparison if it is possible.
",504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"I didn't see for what this is helpful.
",719 720 721 722 723 724 725 726
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Todo,"
+ Line 021 – less steps + Line 228 – Take … ",497 498 499 500 501 502 503 504 505 506 507 508
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"1. "" ",247 248
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"-Table 5: The three settings, I assume these are the hybrid approaches with BM25. ",598 599 600 601 602 603 604 605 606 607 608 609 610 611
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"I think it would be useful to mention to the reader that high scores are undesirable in the TRS metric (e.g., Table 1 and Figure 3).
",680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,"
2. ",363
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Todo,N/A ,129
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,The same with languages that cross many borders. ,801 802 803 804 805 806 807 808
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Todo,"
+ They can use the following paper: Knowledge Distillation from Internal Representations [Aguilar, AAAI20] ",147 148 149 150 151 152 153 154 155 156 157 158 159 160
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"-For the transitivity experiments, does 50% constitute a random baseline? ",597 598 599 600 601 602 603 604 605 606
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"But, in the rest of the paper, all the explanations were given on a word-basis. ",216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-do you have a proof of the sample-efficiency claim in line 317? ,1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Todo,Otherwise some clarification on the abbreviation would be good. ,262 263 264 265 266 267 268 269 270
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,FELIX generates frequently hallucinations that potentially are contradictory to the initial text. ,217 218 219 220 221 222 223 224 225 226 227 228
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,- How is the balance loss different from the one in Switch Transformer? ,345 346 347 348 349 350 351 352 353 354 355 356 357
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,  ,
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Todo,"
4. ",199
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Todo,"
  The feature attribution method based on attention could easily be the focus of the study, whether by using the method proposed by (Kobayashi et al., 2020, “Attention is Not Only a Weight:Analyzing Transformers with Vector Norms”) as a comparison point, by analysing attention heads separately the same way it is conducted per layer, etc. ",676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"Probably I am missing contextual knowledge, such as the meaning of PENÁĆ and who are the people named there. ",466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,al. 2021. ,266 267
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Todo,"L50: ""Furthermore, models that contain such biases may make surprising predictions when the bias is present, causing problems in critical systems."": ",348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,It is not clear which hyper-parameters are selected from. ,303 304 305 306 307 308 309 310 311
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo, ,
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,Some sentences are confusing. ,385 386 387 388
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,Any point in an unbounded space seems hard to be mapped with a certain accuracy into a discrete space with a finite number of points. ,524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Todo,"Abstract: “overhead” -> it’ll be great to elaborate what overhead you’re referring to (especially because this is the abstract).
",406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,5. ,465
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Questions to the authors (which also act as suggestions):  ,752 753 754 755 756 757 758 759 760
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,These texts were filtered for the whole corpus? ,478 479 480 481 482 483 484 485
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Todo,"First, many of the results (e.g. most of the results in Table 5) are not significantly better than the Transformer baseline. ",384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,I would suggest adding a summary of contributions in the last paragraph of Sec. 1 for clarity. ,335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Todo,How to ensure that the consecutive refined BEP tokens can be valid whole words after de-BPE operation? ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Todo,"
2. ",417
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"- I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig. 1. ",324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Todo,- Algorithm 1. ,395 396 397
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,== KL Loss == ,444 445 446 447
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Todo,"Line 207-2018 describes dense retrieval in the section about re-ranking, I think dense retrieval should be described beforehand and not in the section ""Reranking"" ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Todo,Add more figures to clarify the ideas. ,178 179 180 181 182 183 184
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"This is a very important, interesting, and valuable paper with many positives. ",144 145 146 147 148 149 150 151 152 153 154 155
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Lines 199-207. ,281 282
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo,"- ""Deep learning methods usually treat this task as a multi-label classification problem"": this is the case more generally of supervised machine learning methods, and is not specific to deep learning methods.
",390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,Line 190 - 191: define t1 < t2 as I suggested above and simplify the equation. ,376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"Learning a similarity metric discriminatively, with application to face verification."" ",508 509 510 511 512 513 514 515 516 517
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,"
2. ",222
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,Evaluation metrics can be explained in a few words (or a relevant reference can be provided). ,147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"> ""output woman or king"" Line 121: ""is sometimes not be able"" -> ""is sometimes not able"" Line 1271: ""the GPT-2"" -> ""GPT-2"" Line 235: ""multi-mode"" -> ""multimodal"" also line 263. ",892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Todo,-Could the authors use some specific examples to analyze why the constructed adversarial training sets can improve the robustness of the TM models? ,222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,Missing References: 1. ,337 338 339
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,I did not notice many typos. ,93 94 95 96 97 98
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"[3] Sylwia Ozdowska, and Andy Way. ",604 605 606 607 608 609
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"Li, M., Weston, J. and Roller, S., 2019. ",654 655 656 657 658 659 660 661
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,Can the authors explain why they selected this baseline? ,404 405 406 407 408 409 410 411 412
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"- 357: The text speaks of ""53"", but I believe the value ""52.9"" from Table 4 is meant. ",739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"GPT-3 mostly showed promise for Few-Shot evaluation, not that it get really good performance on downstream tasks. ",1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,"Not sure how much performance is made by the data itself, or the training mode itself?
",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,Please verify all variables and carefully review it all. ,549 550 551 552 553 554 555 556 557
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"If we want to estimate whether the object is large or small, we need to first calculate the similarity between ""large"" and the object, then ""small"" and the object, respectively. ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Line 363: no space before ""In"" ",651 652 653 654 655 656
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Todo,"I think it is not a normal expression.
",205 206 207 208 209 210 211 212
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,"-Malte Ostendorff, Terry Ruas, Till Blume, Bela Gipp, Georg Rehm. ",296 297 298 299 300 301 302 303 304 305
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,6. ,269
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,Generally: ,278
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Line 074: This sentence is confusing. ,2011 2012 2013 2014 2015 2016
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Concatenation? ,254
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"In lines 70-71, the authors state: “Since sentential exemplar are only available for testing, …”. ",914 915 916 917 918 919 920 921 922 923 924 925 926 927 928
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,Some detailed questions about model inference: ,173 174 175 176 177 178
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo, Just a minor thing you may want to consider :) ,387 388 389 390 391 392 393 394 395 396
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Consider clarifying what you mean by “this problem” in beginning of the  paragraph?
",638 639 640 641 642 643 644 645 646 647 648 649 650
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Todo,Do the heads of attention affect the model performance? ,204 205 206 207 208 209 210 211 212
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,Comments: ,303
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
14. ",376
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,"
4. ",392
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L305: “The size of this layer depends on the length of pseudo sentences”- This sentence is vague and not clear at all. ,612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.4 ""Considering RoBERTa can only predict a single token"" -- I'm not understanding why RoBERTa can't be used for extractive QA tasks. ",603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Todo,"In Table 4, I wonder whether ""the model probability"" is estimated using MC dropout. ",204 205 206 207 208 209 210 211 212 213 214 215 216 217
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Todo,"-After fine-tuning a LM pre-trained with conditioned token sampling (L456 ""useful inductive bias""), you could check if embeddings of L2 have interpretable topological relations, such as analogy. ",429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,The concepts selected by the authors in this paper are well-defined by the site owners. ,271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,The authors design an objective to build up a trade-off between the task accuracy and the prompt F1. ,550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"ERRANT computes P, R and F from M2 files containing span-level annotations. ",498 499 500 501 502 503 504 505 506 507 508 509
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"It would be better to show the mean and standard deviation of many samples, or at least clarify how exactly this result is produced.
",589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
11. ",316
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,Towards best experiment design for evaluating dialogue system output. ,585 586 587 588 589 590 591 592 593
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,Does it include time spent by the user waiting for the model to generate a response? ,444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Todo,-Is there any reason why the paper stresses on Masked Language Models in particular? ,332 333 334 335 336 337 338 339 340 341 342 343 344 345
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo, ,
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,Why no encoder-decoder models like T5? ,223 224 225 226 227 228
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Todo,"-In Figure 1, it would be better to compare the attribution map of GlobEnc with the attribution map of other comparable methods (e.g., N_{res}). ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,Can you expand on how you choose this parameter for each task? ,403 404 405 406 407 408 409 410 411 412 413 414
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,Paired t-test? ,1402 1403
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(136): abbreviations like ""MoCo"" should not appear in the section header, since a reader might not know what it means. ",625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,-The same for Figure 3. ,431 432 433 434 435
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,al) for example to help strengthen this some. ,447 448 449 450 451 452 453 454
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"-254: Oscar is introduced here but there is no description until line 276.
",384 385 386 387 388 389 390 391 392 393 394 395 396
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,"For instance, will the performance drop on the lengthy dialogues? ",243 244 245 246 247 248 249 250 251 252
19f388a29acd478e296a556b93da193a08c35983f08334eb804d61a3b42f687cf8b7a8ad0984b98d01112105066170a4441bd5a07e61e8179253006a3cd6aeff,arr,Todo,NA ,121
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,"However, I find the discussion of the first limitation somewhat incomplete and ending abruptly. ",433 434 435 436 437 438 439 440 441 442 443 444 445 446
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,"We don't have to carefully look around each equation to understand the meaning of each term.
",354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,It would be good to have more details about this study and how it drove the decisions in the rest of the paper. ,575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,"This is not a problem for other generation methods because they are trigger-driven (TANL, BART-GEN), or generate all extracted events in one step (Text2Event).
",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,-Footnote 1: Why use the representation of the first subword of a word? ,359 360 361 362 363 364 365 366 367 368 369 370 371
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-Line 051: extra ""is"" ",1176 1177 1178 1179
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"In the text, $q_\phi (Z^p | C, R)$ is not conditioned on $Z^k$ (lines 199, 207) ",340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Todo,"
3. ",239
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"And for this overall work on CQA, the language which is focused on should be mentioned early on in the introduction and ideally in the abstract itself. ",1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,- The standard deviation from the Appendix could be added to Table 1 at least for one metric. ,220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Todo,The paper could be further improved by including more discussion about interpretability as it difficult to explain the model's  behavior. ,210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,  * Logic Trap 3: The third point is known: ,773 774 775 776 777 778 779 780 781
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"-Ln 487: Why not also test BERT, miniBERTas, and non-English models?
",802 803 804 805 806 807 808 809 810 811 812
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Todo,"Overall, no other issues with the writing, which is excellent. ",210 211 212 213 214 215 216 217 218 219
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,"X is a city in Y', do the neurons still robustly show low activations?
",642 643 644 645 646 647 648 649 650 651 652 653 654 655
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Todo,It may be better to conduct more experiments across different models. ,169 170 171 172 173 174 175 176 177 178 179
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,- It would help a lot in terms of understanding if the indices are not shared. ,292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"However, these two tasks feel lower level than the other tasks probably better handled somewhat separately than others. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
64d426bdd2237b1a76367942d93054e27cbba57122d341c186e2724c64f32ea70276be64edd40415fcfa2a55ffb540f5d6e8d89acd4ac1bf95878ac359286fa7,arr,Todo,Lines 236-239 make me think they're used in addition. ,129 130 131 132 133 134 135 136 137
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Todo,Dynabench: Rethinking Benchmarking in NLP (https://arxiv.org/abs/2104.14337) 2. ,316 317 318 319 320 321 322
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,What is the impact of using two different swift models in this architecture. ,266 267 268 269 270 271 272 273 274 275 276 277 278
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"
5)	Grammatical error in “the two real news compliment each other”, “in the first news”, and “the two fake news contradict the real news with different details” ",709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Todo,A guide or summary table can be used to help readers better and more quickly understand past research works. ,152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"-Line (7) of alg 1's pseucode is referenced in the text but the fig doesn't have line numbers, is it possible to add them ""the achieved reduction in ECE as compared to all baselines is significant"" what does this mean? ",1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- The word ""context"" in the title of the paper could be more specified. ",301 302 303 304 305 306 307 308 309 310 311 312 313 314
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo, ,
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"Error analysis in 5.2 is crappy, more quantitive error analysis will help. ",293 294 295 296 297 298 299 300 301 302 303 304
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Todo,"
In the ""Carbon footprint"" section, the authors mention ""All emitted carbon dioxide has already been offset"". ",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"In figure 6, what are the models in the last two columns lan_model_p and lan_model? ",507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"While the out of domain experiment is pre-trained on other prompts, it is still fine-tuned during training on the target prompt essays. ",294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(252-55): Isn't it obvious that ""positive examples in SimCSE have the same length"", since SimCSE enocdes the same sentence differently as positive examples? ",699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,7. ,472
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,I would still keep my score to be 3. ,141 142 143 144 145 146 147 148 149
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Todo,Does the linguistics issues discussing in this paper applied only for the languages in South Asia? ,213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
42ae5ac0b6ebf8dbeb0aacafa17347e79484894bf3755dc74179c72dc37a6c50f1ec70fcebe4c3d99626a87a96b3c794fad2694e04ff203897c71a6b4e97a96e,arr,Todo,"In particular, situations where the names of functions involve multiple characters. ",233 234 235 236 237 238 239 240 241 242 243
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Todo,Suggestions in the previous submission have been addressed. ,549 550 551 552 553 554 555 556
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"1) The name of the ""Evaluation"" element can be changed to ""Metrics"" since 'evaluation' can have a more general meaning. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-**Lines 55-56:** references for the effectiveness of pretrained language models has been demonstrated by Shi and Lin (2019), Conia and Navigli (2020) and Paolini et al. (2021), among others.
",740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,"This can let the reader know whether the extra cost of MC dropout method comes with considerable benefits.
",446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,-Could the results of the Sentence Sorting be driven by the fact that sentence embeddings are obtained by averaging over word embeddings? ,730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Todo,"- As shown in Table 3 , MLS 212 achieves consistent improvement over the origi213 nal label smoothing in both the original and the 214 balanced multilingual translation dataset under all 215 translation directions -> Table 3, MLS ",246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,Thanks! ,262
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"For example, it is claimed that ""The performance drops with removing Lco (""w/o CO""). ",346 347 348 349 350 351 352 353 354 355 356 357 358 359
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"
8. ",280
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Todo,-MCTS is mainly used in RL since the state transition and reward function are probability distributions. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"Since based on this table, I am not sure why we shall rank your method to be higher than the other baselines. ",325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Todo,I guess the point is that it only relies on MT at training time and not at evaluation / inference. ,233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Todo,"When the method extracts commonsense, there is a hierarchy structure among concepts. ",163 164 165 166 167 168 169 170 171 172 173 174
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-440-441: Why don't you tune your lambda parameters on the dev test for fair comparison? ,430 431 432 433 434 435 436 437 438 439 440 441 442 443 444
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05). ,518 519 520 521 522 523 524 525 526 527 528 529
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Todo,Typos: Line 255 / Line 259:  p < .05 -->  p < 0.05 Line 266:  Correlations grouped by sentence length shows stable values around .6  (SST) and .4-.6 (Wikipedia) except for shorter sen-    tences where correlations fluctuate. -- ,260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Todo,"E.g., if all systems are ALSO fine-tuned on supervised data such as NLI, does the improvement over the baseline system still hold.
",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Todo,"D in the text body should be in italic, consistently. ",361 362 363 364 365 366 367 368 369 370
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,"Similarly, is there a reason why the effect of linguistic acceptability was not analyzed (Table 3 and Section 4.6)? ",450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"For the NeuS-Title model, does that order of the input matter? ",703 704 705 706 707 708 709 710 711 712 713
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Todo,"It would be helpful to be clearer about this distinction and clarify which analyses in the paper follow which approach.
",278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo, Have you thought of methods of aggregating or scaling the NPRM score to get around this drawback? ,274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,- Figure 6 is not useful. ,1099 1100 1101 1102 1103 1104
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Todo,Please mention which system/s are used to generate the summaries in Table 3 and 4. ,495 496 497 498 499 500 501 502 503 504 505 506 507 508 509
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Todo,The arXiv link misled me initially. ,200 201 202 203 204 205
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo, ,
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,"For e.g., Based on the extremely large values (>0.99) for all approaches in Table 4, I doubt the difference between NPRM’s 0.995 and Glove+SVMRank 0.992 for Avg. ",315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,"
2. ",172
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,2021. ,444
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Todo,NA ,307
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"So it seems to me that  the more layers the model has, the better it performs on both measurements, although it is possible that I am missing something. ",797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   * What layer are the plots in the top row in Figure 2 from? ,421 422 423 424 425 426 427 428 429 430 431 432 433 434
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Todo,"While I appreciate the efforts undertaken by the authors to test on a new task, the results, unfortunately, are not infavor of the proposed solution. ",320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"An unsupervised subword-level neural MT model for the same task tested demonstrates very poor results [2], but training the same model with character-level tokenization yields a great improvement [3].
",494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"### Typos/Style: Very well written paper, no remarks here. ",1304 1305 1306 1307 1308 1309 1310 1311 1312
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,"What is DNNs, in Section 1 Introduction ? ",168 169 170 171 172 173 174 175
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"-The notation of x1 and x2 vs. x = (xa, xb) in the compositionality section is a bit confusing, especially when x1 and x2 are already themselves pairs. ",623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Todo,-Do you think generative PLMs that are pretrained on biomedical texts could be more suitable for solving the multi-token problem? ,231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,"In lines 366-367, it's said the relative weights for combining CTC and seq2seq losses are different during training and decoding. ",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Todo,"
In addition, Table 4 would need more explanation which might really help classical humanities studies, e.g., why naive AnchiBERT only outperforms others on NER? ",327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,Why do they have such high error probabilities? ,317 318 319 320 321 322 323 324
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,"There is less evidence on how the method helps target languages, so it would be interesting to do some qualitative analysis to see how this method helps a specific language compared with the baseline sampling method. ",240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Todo,"I generally liked the paper, but I am not sure that the results (as presented) make a compelling argument to add another model to the transformer-based “pantheon of models.” ",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,What constraints/attributes are preserved? ,426 427 428 429
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,Be clear whether the language modeling task in section 4 is a causal model. ,421 422 423 424 425 426 427 428 429 430 431 432 433 434
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,Typos: 1. ,277 278
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Todo,"Why are there two “40%” in the figure?
",489 490 491 492 493 494 495 496
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-What were the correlations of the chosen attitudinal scale item for the breadth-of-posts study with the toxicity in the breadth-of-workers study?
",499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"Would also be interesting than to see how the curve of a jabberwocky verb compares to that of a sensical/prototypical verb (like _gave_): there is probably _some_ degree of argument structure already encoded in the word embedding there (as a lexicalist would argue), so I would expect probing performance for such verbs to be much higher at lower levels already. ",1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Todo,   also Section names - often they are just numbers (see 5.4 or see 4.2 ) - but these should be Section 5.4  and Section 4.2 ,381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,Is it possible to hightly the specific areas where DTW and CTW make errors? ,401 402 403 404 405 406 407 408 409 410 411 412 413 414
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,"   * Relevant to above point: how are ""similar semantics"" calculated? ",445 446 447 448 449 450 451 452 453 454
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,Questions: 1. ,233 234
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"
2. ",783
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,30th USENIX Security Symposium (USENIX Security 21). ,1213 1214 1215 1216 1217 1218 1219
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,Where are the results training on the parenthetical data in section 5? ,496 497 498 499 500 501 502 503 504 505 506 507
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,What are the implications of that? ,1340 1341 1342 1343 1344 1345
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,It is not easy to deduce what they mean since they are not explained until the next section. ,465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Q2. ,817
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"Even better, the corresponding sections can be removed and the metrics can be briefly mentioned along with the datasets or in the captions of the tables since most, if not all, of the metrics are well-known and used as standard practice. ",213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,I find the dataset description to be inadequate. ,575 576 577 578 579 580 581 582
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,"-Line 47: ""constitinga"" -> ""consisting"" ",370 371 372 373 374
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Todo,Please provide some statistics of three benchmarks as truncation has been used in both sentence length and sentence number for each instance. ,161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"I assume that P_g and P_r shared the same parameters, so their calculation varies only for the use of different masks. ",301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," (For example, if MLS makes the training last 25 percent more updates than the baseline, then is the increased performance partially due to the mere fact of training longer?)
",762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"For Distance Minimizing, does this mean you're training a perceptron on a single datapoint? ",724 725 726 727 728 729 730 731 732 733 734 735 736 737
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"I am a little confused about the test set performance on these GLUE datasets, are the labels to these sets not available to the public?
",495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,the motivation is missing ,286 287 288 289
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,"Please have a look.
",809 810 811 812
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Todo,"Overall, the work straightforwardly builds upon prior efforts like NLVR2 and represents a fair and interesting test for vision+language models. ",325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Todo,See the prior review. ,144 145 146 147
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Todo,"It is unclear why you need MCTS to do a search, why not just depth-first search, best-first search, A* search, or any heuristic search? ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"158 - ""Casual"", describe what casual means with language instead of math please. ",297 298 299 300 301 302 303 304 305 306 307 308 309
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Todo,- Footnote 1 (Page 7): For -> for ,290 291 292 293 294 295 296 297
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-Lines 97-98: Rephrase the sentence ""one that searches for ... objects"" as it is currently confusing ",317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo, ,
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Line 027: what did you mean by “plain dependency parsing”? ,343 344 345 346 347 348 349 350 351 352
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,For example (1) lines 7-11 sentence. ,389 390 391 392 393 394
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Todo,"In line ""544"", I still quite understand why using entity representations can reduce language bias. ",243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,Questions: 1. ,151 152
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Todo,-The added significance tests are questionable. ,378 379 380 381 382 383
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Lines 068 - 080 - Are these lines referring back to the QA idea or is this now a translation problem, how did translation become part of a QA problem? ",341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,2. ,657
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo, ,
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"In addition, could the authors provide more information about the size of the dictionary and the average number of natural sentences for each LCT? ",1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Todo,"Same for PCKMT = ""Pruned CKMT"", hope I get that right too. ",271 272 273 274 275 276 277 278 279 280 281 282
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Todo,"There are some recent and contemporary works that also deal with figurative language (Chakrabarty 2021, ""Figurative Language in RTE"", Poliak 2018, https://aclanthology.org/D18-1007/) the authors should be aware of: in my mind, this work provides a novel, high-quality dataset, they could benefit from clarifying how their work is distinct from these.
",472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Todo,The only minor comment I'll make here is that the baseline in Table 3 has been updated from 35.11 to 35.02 in this version. ,708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Todo,"
2. ",313
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Todo,Such examples can help the readers to better understand the influence of rationale lengths. ,367 368 369 370 371 372 373 374 375 376 377 378 379 380
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Using a country as a proxy for language is useful, but it may skew the data representation, as the authors themselves recognize. ",760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"Indeed, if I am not making a mistake, the explanation for the incorrect answer must highlight the differences w.r.t. ",555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,"For example, this could be ""if a points falls into region n with an angle of 30 degree, what is the numerical distance between this point and the anchor point?"" ",462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Todo,"If the authors have done any analysis on why the annotators might disagree with the writer, I would love to see it!
",342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Apart from that, nothing is said about the size of the resultant dictionary.
",685 686 687 688 689 690 691 692 693 694 695 696 697
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-In that line, Section 6 discusses perceptions of vulgarity, but there are too many confounds here. ",566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Todo,One of the biggest problems is that motivation is not convincing. ,152 153 154 155 156 157 158 159 160 161 162
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Todo,"I got garden pathed reading line 331 ""One could define other Z1 and Z2..."" ",383 384 385 386 387 388 389 390 391 392 393 394 395 396
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-Certain researcher choices and experiment design choices were not justified (for example, why were these particular scales used?)
",324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   * It is important to make distinction between `procedures' and 'patterns' ,409 410 411 412 413 414 415 416 417 418 419
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"So, was that second strategy from (Liu et al.,  2020a) actually used? ",1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"-Appendix, Table 2: What does the slash in Russian and Chinese mean? ",615 616 617 618 619 620 621 622 623 624 625 626
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Todo,This should be included in the main paper if accepted. ,259 260 261 262 263 264 265 266 267 268
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"In Cycle Consistency loss you can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes.
",447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,3) Are there any reasons behind the selected baselines? ,326 327 328 329 330 331 332 333 334
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,Can you clearly state what objective? ,197 198 199 200 201 202
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"If possible, you may use a shorter sentence.
",125 126 127 128 129 130 131 132
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Todo,"In other words, the positive gap label corresponds to the positive RTE label, or not? ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Todo,188: typo at “represented by within” ,585 586 587 588 589 590
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"In the ‘Jabberwocky’ setup one would expect that at the word embedding level construction information can’t be present yet, but as it is contextualised more and more in each layer the ASC information is likely to increase gradually. ",1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,-Line 130-131: check grammar ,359 360 361 362
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Todo,1. ,102
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"It would be helpful to show high/low Corr subjs (Table 11) for Single/Multi/Any subjects separately.
",640 641 642 643 644 645 646 647 648 649 650 651 652 653 654
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Todo,-Capitalization of subsection titles is inconsistent. ,259 260 261 262 263 264
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 203: This penalization token -> This penalizes token ,494 495 496 497 498 499 500 501 502
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Todo,"417: why is “as” included along with “were” and “are”?
",556 557 558 559 560 561 562 563 564 565
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,-Training Neural Machine Translation to Apply Terminology Constraints. ,227 228 229 230 231 232 233 234
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,== Defense Learning Strategies == ,396 397 398 399 400
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"Line 165: Remove ""remedy,"" ",2025 2026 2027 2028
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Todo,"An additional practice to avoid underclaiming is to define clearly, before conducting experiments, the desired behaviours of a model in order to properly evaluate if the model ""succeeds"" or ""fails"".
",233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo, ,
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"-Background section: ""...high fidelity thank to…"" -> ""...high fidelity thanks to…"" ",256 257 258 259 260 261 262 263 264 265 266
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Todo,"L404: It might be worth recalling the reader that k is the number of sentences at this point, given that this fact was introduced much earlier on and not used until then. ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
cae04ea5a5edc93df8355c570815cbecec45d18562b5e323e53d02cb9a95394dff757192c80981f891adf14462e54a81f0786e4017a672b721801666e52f162e,arr,Todo,"
2) It would be better to present a few case studies for readers. ",202 203 204 205 206 207 208 209 210 211 212 213 214
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"Please clarify the transformation.
",254 255 256 257
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Would that not work here? ,640 641 642 643 644
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Todo,The whole approach lacks the evidences to prove the usefulness. ,245 246 247 248 249 250 251 252 253 254
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"
3. ",108
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Is this the case or just a confusion?
",752 753 754 755 756 757 758 759
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Todo,"2) Potentially relevant but not cited work: Chu et al. 2021 (https://openreview.net/pdf?id=8smkJ2ekBRC), Wang et al. 2019 (https://aclanthology.org/P19-1132.pdf) ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,"Since a fixed batch size (B=128) is used, there is a chance that a document will be split into several batches, or a batch may contain mentions from very different documents. ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Todo,"
For example, why the results for LaPraDor (unsupervised and FT) are lower than Late interaction for some datasets (FEVER or CQADupStack) while they are better for others ? ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"Line 148: I think it would make sense to make a distinction between hard prompt work updates the frozen model (Schick and Schütez, etc) from ones that don't. ",1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo, ,
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"
4. ",189
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,Bridging the gap in multilingual semantic role labeling: a language-agnostic approach. ,925 926 927 928 929 930 931 932 933 934 935
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo, ,
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"-What is the set $\beta$ in line 311?
",1304 1305 1306 1307 1308 1309 1310 1311
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Todo,"
If the authors conduct a fair comparison, the authors should prepare strong methods for machine translation and summarization. ",481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Todo,"Does this affect the underestimation of the performances?
",223 224 225 226 227 228 229 230
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,"On the other hand, having too many unrelated words in the general-purpose data can act as noise for more domain-dependent tasks? ",795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,Semantic Role Labeling: an introduction to the special issue. ,895 896 897 898 899 900 901 902 903
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Todo,n/a ,229
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,"Have you thought about using  standardized metrics or a rank-based metric (e.g. Spearman correlation between vectors)?
",404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"If someone is interested to retrieve all the entities belonging to a concept, they can look at the top-20 retrieved entities, annotate them, and then get more seeds to train a model to retrieve more. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Todo,The authors could evaluate the proposed Triaffine mechanism on these tasks to make it more influential ,472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"-Also, when describing the contribution in the Introduction, using the word hypothesis/null hypothesis really made me think about statistical significance. ",263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Todo,More examples on section 4 in comparison to attention focus formulating efforts done in section 3 will add extra visibility and application to the entire research ,523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,"-In Section 2.3, Line 266 the description states $L$, $R$ are conditioned on $X$. Presumably it is meant to be $L$, $E$ since no $R$ is introduced anywhere.
",570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597
cae04ea5a5edc93df8355c570815cbecec45d18562b5e323e53d02cb9a95394dff757192c80981f891adf14462e54a81f0786e4017a672b721801666e52f162e,arr,Todo,"1) In Figure 2, please indicate STEP 1,2,3,4 in the corresponding places in the diagram for better illustration. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,"In EACL.
",361 362
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- Please, explain what do you mean by ""Intricate text"" in Table 8. ",458 459 460 461 462 463 464 465 466 467 468 469 470
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Todo,"-It would be valuable to investigate the reason behind the high impact of the LDND distance.
",306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Todo,The issues for the performance gap shall be investigated and solved. ,542 543 544 545 546 547 548 549 550 551 552
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,"- More evidences regarding the performance improvement, showing that it is not only due to the effect of ensembling.
",464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"For example, a by-class accuracy breakdown could answer some of these questions. ",447 448 449 450 451 452 453 454 455 456 457 458
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 5] line 558: You mentions that the drop is *significant*, did you employ significance testing for numbers presented in Table 5? ",1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 081 - The related work is a little long, you could mention the two types of transfer and cite some work in a few lines, not this many pages. ",387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo," How does Table 3 in this paper relate to Tables 2 of Zhang 2020b (re: DigloGPT,Beam 345 seems to perform better)? ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,"
3) The BART large model is used to train CMLM and MLM, and the entities are also generated by BART on XSUM. ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,https://arxiv.org/abs/1412.6623 ,686
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Todo,Remove italic conclusions to ensure better readability. ,288 289 290 291 292 293 294
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"References: [1] Gerdes, Karen E., Cynthia A. Lietz, and Elizabeth A. Segal. "" ",755 756 757 758 759 760 761 762 763 764 765 766 767
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"There are a couple of cases that it's written as ""Figure"", but meant for ""Table"", e.g. ""Figure 3"", ""Figure 5"". ",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"However, it is confusing, mainly for the test set. ",1242 1243 1244 1245 1246 1247 1248 1249 1250
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.3 ""In this work, we show that prompt transfer can remedy, improve the effectiveness to some extent with knowledge transfer, and empirically analyze the transferability of prompts across tasks and PLMs."" -- ",539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,-How are the trait  scores obtained for the prompts that did not have them in the original dataset? ,376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"== Experiment == --> Experiments?
",501 502 503 504 505
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Todo,This would strengthen the results vastly. ,240 241 242 243 244 245
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,Optimal Bilingual Data for French-English PB-SMT. ,610 611 612 613 614 615
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Todo,"- Generating informative and diverse conversational responses via adversarial information maximization (Zhang et al., 2018) ",506 507 508 509 510 511 512 513 514 515 516 517 518 519 520
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,224 comprising of the node -> that comprises the node ... ,348 349 350 351 352 353 354 355 356 357 358
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Todo,1. ,225
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,"This paper needs more examples of the kind of relation they are looking at, earlier in the paper as well as throughout the paper. ",354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,Line 070: Section 3.1 and then Section 3.2? ,349 350 351 352 353 354 355 356
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Todo,The equation aids in aligning instance with label embeddings but it does not contain any elements that encourages different instances to disperse. ,401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"-It would be great if we can see that the proposed method works for other pretrained models besides BERT as well.
",461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-267: focusd -> focused ,290 291 292 293
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Todo,I think you should include evaluation results with the AGA metric. ,238 239 240 241 242 243 244 245 246 247 248
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Todo,- L236: Acronym IRB was not introduced ,184 185 186 187 188 189 190
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-Dev et al 2019 and Nadeem et al 2020 references are missing publication information.
",1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,(Question 3) What is q_k in L911? ,225 226 227 228 229 230 231
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo,-Make this paper a closed loop. ,414 415 416 417 418 419
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"- I suggest to revise a bit the discussion, especially in the modeling section, which in its current form is not clear enough. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo, Should this be a separate paragraph? ,338 339 340 341 342 343
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"[2] He, Junxian, et al. ""A Probabilistic Formulation of Unsupervised Text Style Transfer."" ",719 720 721 722 723 724 725 726 727 728 729 730 731
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,- Equations 10 & 11 should be H_{abstract} instead of D_{abstract}? ,173 174 175 176 177 178 179 180 181 182 183
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,- The title of Tab. ,510 511 512 513 514
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,The soft prompt has nothing to do with the natural language that humans are accustomed to and can exist in any form. ,634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"
Are the guidelines used to train the annotators publicly available? ",274 275 276 277 278 279 280 281 282 283
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"2 “Dial.”, “ ",734 735 736
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"Specifically, the source of the data is not clearly mentioned. ",583 584 585 586 587 588 589 590 591 592
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Todo,What do that mean exactly? ,292 293 294 295 296
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Todo,The dominant pre-trained methods usually report the results and release the models with the different settings. ,218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,281 - 299 The paper takes on the idea of a game gotten from other work. ,464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Todo,"Line 21 -- what are ""the relations""?
",257 258 259 260 261 262 263
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo," Also, in the last sentence of your abstract, ""it is shown that"" should be ""we show that"".
",297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"7) Line 310: ""Since it is usually ..."" This is not a well-formed sentence. ",422 423 424 425 426 427 428 429 430 431 432 433 434 435
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,"In the past few years, I have repeatedly observed that a method that works well on small models has only a marginal impact on large models. ",243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-131: capable of learning ,231 232 233 234
db14eda600a57c45529a8ae7db67ef709b17efd9bc501459d16886267bb64db205b07db81311c17bd4e2bec40a9d83d6cff10898a7f5016d5b2799e8ccb4c73b,arr,Todo,"The example on the first page sounds like figurative use of the word ""to march"". ",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"ArXiv abs/1807.03748 (2018): n. pag.
",495 496 497 498 499
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"As it stands, it sounds as if you only kept the incorrect sentences without their corrections. ",462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,"-Section 5: Why did you not also compare against a pre-trained ResNet version, as you did for CLIP (image-only)?
",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"2021.
",1220
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"Also, it has a length of m+1 (please indicate whether the first token is the CLS). ",576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Vu et al. 2021 is mentioned as ""concurrent"", but was online 3 months before the ARR Jan deadline, so should be considered ""recent"", not concurrent. ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Todo,-The D.2 appendix mentions two human annotators. ,329 330 331 332 333 334 335
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,-Line 530: Use \citep not \citet ,775 776 777 778 779 780
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- l.182-195: According to this, it seems that the resulting CLIR system proposed by the authors would be also able to work not only with queries in the source-language (i.e. non-English), but also with queries in the target-language (i.e. English). ",712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,- It's great to have at least some statistical significance tests. ,406 407 408 409 410 411 412 413 414 415 416
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"Same with line 46, where the authors state “To obtain desirable surface forms..”. ",840 841 842 843 844 845 846 847 848 849 850 851 852
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"
5. ",151
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"- line 511ff: I can't follow why a higher performance of TinyBERT over BERT suggests that TinyBERT ""mak[es] sentence representations more relevant to individual tasks [through knowledge distillation] and hence result[s] in better task similarity estimation.""
",468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,1. ,82
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,The reader of the paper would struggle to understand why this is an issue if the top-1 rank is correct in the vast majority of cases. ,576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"Additionally, the authors should provide more details about the training regime and what is the effect of combining different tasks at once. ",476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo,1. ,249
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Lines 441 - 453 - I am not convinced that doing this really helps show the performance, it almost seems as if you are mining to find a difference. ",717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,al 2021 also use a discriminator at each time step to control generation for certain attributes ,270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,Is there a particular reason for this? ,801 802 803 804 805 806 807
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Todo,"-Alibaba QUAKE is sometimes spelled Alibaba KUAKE, is this on purpose? ",196 197 198 199 200 201 202 203 204 205 206
a6f83f54bd43db725bd0f67fc819f1c0b0bf631d8badf27f63f1eaca61865c0f943ea31260da63ebb8157c4b7131d3f08990bba93564e11293c433f2a1cd5109,arr,Todo,1. ,99
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo, ,
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo, This doesn't match figure 4 (at least as labeled). ,633 634 635 636 637 638 639 640 641
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,"For example, some sentences have two death events. ",229 230 231 232 233 234 235 236
ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42,arr,Todo,"
2 In terms of the automatic evaluation, can authors use more metrics except BLUE to verify the results? ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Todo," Especially given this is in the appendix, it would help to explain exactly why this is impossible. ",403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Todo,"Line 613: ""their comprehension of different visuo-linguistic"" -> visual-linguistic ",149 150 151 152 153 154 155 156 157
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"Twenty years of confusion in human evaluation: NLG needs evaluation sheets and standardised definitions."" ",550 551 552 553 554 555 556 557 558 559 560 561 562 563
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,Comments: 1. ,208 209
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"Most would not argue for multiple lexical entries for “sneeze”, but rather posit some kind of functional head or type shifter for introducing arguments.
",666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Todo,As the input (includes the tokens can be attended) is the same for every prediction at a position. ,246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"
Carlini, Nicholas, et al. ""Extracting training data from large language models."" ",1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,"For instance, if one uses lexical primes in a prompt not meant for the relation, e,g., 'capital. ",625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"Similarly, Figure 4 shows the dropping correlation as the model grows. ",1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841
0717df21c948fc36edf5f14e8f8c15c7640e5a653f4dcc12c1c89a96aaa861c6aabcd3ec512d9dba6e71a5031f90b6cbf3411e7d555480e0e93fd160fbe0df95,arr,Todo,"See above for my main comments.
",247 248 249 250 251 252
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-Line 113 (right column), will the lattice graph size explode? ",133 134 135 136 137 138 139 140 141 142
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Todo,I think the paper would benefit from another round of revisions to fix some typos. ,340 341 342 343 344 345 346 347 348 349 350 351 352 353 354
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Line 83: “cus via eliminating” -> “cues via eliminating” ,782 783 784 785 786 787 788 789 790
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"Based on the results, vanilla BERT outperforms FreeLB on all three datasets, yet the FreeLB paper claims they could surpass RoBERTa baseline on all GLUE datasets, which makes me wonder if there are some implementation issues. ",532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,"- Table 2 layout is current a bit difficult to read; consider adding additional row and column headers saying source/target, pivot vs multilingual vs finetuning, to make it easier to match results to experiments ",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"If pretraining on multi-centric data performs better than En-centric data (Table 1), seems the problem can be better solved by preparing more diverse and high quality data. ",250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,**Suggestions** ,244
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Line 193, redundant first “|”, {}|_{some conditions} is enough. ",820 821 822 823 824 825 826 827 828
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-The Ethical Statement is well written, but should be extended with some more concrete discussion of challenges not addressed in the dataset (eg gender beyond the binary, races other than Black, other sources of social bias).
",1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Todo,"In the introduction part, the authors have made this claim: “We believe that the extract-then-generate approach mimics how a person would handle long-input summarization: first identify important pieces of information in the text and then summarize them.” ",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"For example, the contrastive loss was first proposed by Chopra et al. (2005) and triplet loss (Weinberger et al., 2005; Schroff et al., 2015) is also quite relevant to this paper.
",430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,"
4) I wonder that since the author focused on factual hallucinations, why does the author always separate factual evaluation from hallucination evaluation? ( ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,1. ,487
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo,Putting together all the strengths and weaknesses I believe the authors proposed a new angle to study long-form QA and the NLP community will benefit from the annotated corpus. ,308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,-Fig. ,225
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"How many sentences does the dataset include?
",354 355 356 357 358 359 360
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Todo,Additional experiments to justify the the attention divergence loss can help the paper. ,243 244 245 246 247 248 249 250 251 252 253 254 255
7e23ee6e56ace10f42339e73b598425e2f2f0f8539fed8f42a514d3a80a537553522ece6eca40ded1d3e587222531371a27d268cbb3ba00f80c3ba8cb0bf286d,arr,Todo,"- The authors mention using `the latest WMT evaluation sets`, which currently would be from WMT2021, but if/when the paper is published the `latest` would already be different, so it would be good to specify the exact year.
",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,"Using vague terminology like ""purified representations"" (l.253) doesn't help this overall messiness, making the system very hard to understand.
",433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo, ,
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Am I missing something? ,979 980 981 982
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,-From Figure 3 it is not clear to me how ZX is the most similar domain to Source. ,776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Is this accurate?
",595 596 597
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,-Line 062: propose > proposes   ,651 652 653 654 655
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,Is precision more important or recall? ,406 407 408 409 410 411
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo,"
247-255: sounds more like future work or has to be rephrased to make clear that this is a motivation for using cross-cultural data 289: how was it translated? ",606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Todo,-Is there a way to take any clue from the video to create harder negatives. ,293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,The decoding algorithm mixing greedy and beam search should be added as pseudocode for clarity. ,283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,-Line 556-557: check grammar ,376 377 378 379
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Table 3 BertScore(sc) -> BertScore (src) ,546 547 548 549 550 551
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"Line 210, on what ET, EN, LV data is the Sentencepiece tokenizer obtained on? ",271 272 273 274 275 276 277 278 279 280 281 282 283 284
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,"In this case, how can predictions in the memory bank affect the current prediction? ",378 379 380 381 382 383 384 385 386 387 388 389 390 391
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"or ""is the intent to ask something related to gym?""
",443 444 445 446 447 448 449 450 451 452
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"
  Likewise Alvarez-Melis et al. (2018) point out that the non-robust artifacts in attributions they   discover are actually reasonable if faithfulness to model is the only goal of an attribution. ",832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,"-Line 216: ""classifies"" -> ""classify"" ",375 376 377 378 379
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,The next sentence immediately proceeds to the model description. ,493 494 495 496 497 498 499 500 501
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,Why did you introduce a parallelism between neural networks and the human brain in the introduction? ,485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Todo,"What is the concrete implementation of this idea when building an NLP model?
",216 217 218 219 220 221 222 223 224 225 226 227 228
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Todo,N/A ,391
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"Perfect balance?"" ",886 887
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"-Line 222: ""In total, we collected 1,446 human-machine con- versations and 15,059 question-answer pairs"" - suggestion: It could be reasserted here that this dataset will be released as this collection of conversations is an important resource and contribution and does not appear to have been highlighted as much as it could. ",1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Todo,"
line 420: the the -> the line 430: MOreover -> Moreover line 436: 5Our -> 5 Our ",231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,- The paper uses much analysis to justify that the information axis is a good tool to be applied. ,147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"What follows are some minor remarks, questions and comments: ",287 288 289 290 291 292 293 294 295
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Does the loss go to 0 in this case? ,738 739 740 741 742 743 744 745 746
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"\mathbb{Q}_K^NN must be a subclass of \mathbb{Q}_K, because the definition of \mathbb{Q}_K does not have any requirement on the functions q. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"In line490-492, the explanation of why CRL (w/o CR) will degrade performance seems to conflict with the reason why using knowledge differentiation(see line 341-346). ",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Todo,"
2. ",135
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,-The explanation of the creation of the breadth-of-posts was confusing. ,342 343 344 345 346 347 348 349 350 351
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,The authors might be interesting in this concurrent work (https://arxiv.org/abs/2104.04448) from the computer vision community  that studies the relationship between adversarial robustness and flatness. ,338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"    ""The decision-making process of neural networks is not equal to the decision-making      process of humans.""
",515 516 517 518 519 520 521 522 523 524 525 526 527 528 529
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Todo,"But RoBERTa has more than 2 layers; it is currently unclear what happens in the other layers.
",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,Aspect-based Document Similarity for Research Papers. ,306 307 308 309 310 311
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,== Problem Formulation = ,293 294 295 296
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 173 - borne --> born Line 171-175 - Is there a percentage amount that was observed previously? ",463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo,"- Conduct more in-depth or fine-grained analysis on the discourse structure of long-form answers, which hopefully would provide more insightful observations that can benefit the long-form QA community. ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-The description of the model architecture needs to be rephrased for clarity. ,544 545 546 547 548 549 550 551 552 553 554 555
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"However, this is only one of two components of the the proposed CogTaskonomy framework. ",616 617 618 619 620 621 622 623 624 625 626 627 628 629
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,OTHER TYPOS OR CONFUSION ,669 670 671 672
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] High-level comment: The problems of adaptation to (a) a new task vs. (b) a new domain are discussed in parallel. ,469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,"
2. ",122
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(310-314): I don't understand ""query"", ""key and value"". ",753 754 755 756 757 758 759 760
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,"You show results on the subsets of ParaNMT, but how does performance scale with the samples in ParaDetox?
",346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"It would be good to quantify this if possible, as a counterargument to that would be that not all stories are noteworthy enough to require such treatment (and not all stories will appear on all sides).
",332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,I believe the idea is not highly integrated with UMAP. ,287 288 289 290 291 292 293 294 295 296
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Todo,1. ,194
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Interleaving the words/phrases of the stimuli with a random word list ,500 501 502 503 504 505 506 507 508 509 510
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"Then we should calculate the difference between the two similarity instead of using the similarity between the object embedding and the difference between ""large"" and ""small"" embeddings. ",225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Todo," Cutting all of the material on different graph encodings in order to more clearly explain this issue in the body text (I found it hard to understand even after reading App A) would improve the paper.
",294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,  * Logic Trap 2: The second point made is a roundabout way of saying that ablation orders are     varied: ,662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,"
2. ",456
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,Now the authors are reporting in bold the results whose difference is statistical significant. ,479 480 481 482 483 484 485 486 487 488 489 490 491 492
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"Are they also separated by a [SEP] token among themselves?
",1064 1065 1066 1067 1068 1069 1070 1071 1072 1073
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Todo,Try using weighted example F1 to assign different weights to easier prediction labels like the century and harder ones like month and date. ,432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Todo, ,
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,1. ,339
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,What tests were performed to compare the two cases? ,855 856 857 858 859 860 861 862 863
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,The newly created space could be used to enter the missing details mentioned in the review. ,633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,"
3. ",441
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Table 2: what’s the difference between “SWCC w/o Prototype-based Clustering” and “BERT(InfoNCE)”? ,364 365 366 367 368 369 370 371 372 373 374 375
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,Did the state of the art work use real or fake training data? ,625 626 627 628 629 630 631 632 633 634 635 636 637
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,5. ,252
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,Will the code be made publicly available with an inference script? ,463 464 465 466 467 468 469 470 471 472 473
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Todo,"Several references are missing their venues / journals / arXiv identifiers, you can get the correct bib entries for papers from https://aclanthology.org, Google Scholar or arXiv. ",420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Todo,1. ,370
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Todo,"- it would help to report OOV rates; and performance on in-vocabulary vs OOV for your system.
",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,-Related Work section: a suggestion that could make this section but perhaps also the broader work stronger and more interesting to a broader audience is making the connection to how this work fits with other work looking at different NLP tasks that looks at failures of the popular automated evaluation strategy or metrics failing to capture or differing significantly from how humans would evaluate systems in a real-world setting. ,1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-017: jointly ,204 205
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,"-I suggest further experimenting with various hyperparameters and would the addition of NoisyTune be complimentary to hyperparameter tuning.
",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"The paper presents two well-thought out experiments and presents results in a clear manner which contain several important findings.
",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,"
4. ",359
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,"
2. ",413
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Though there is still a lot to improve, I believe that the authors are moving towards an impactful work. ",853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,"-Line 426: ""autometric"" ",373 374 375
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"8) Line 399: ""... and only use the erroneous part for training"" Do you mean you discard correct sentences? ",443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,Line 505-507: “... have pointed out that the feed-forward network module also matters to Transformer” needs a little elaboration -- matters in what way? ,679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"So you should be able to retrieve a translation from your five systems, change the target word, and have a quick manual check for agreement etc. ",471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Lines 320 - 330 - Now, it looks like we are combining tasks again, the other sections here, however, are good. ",650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"L351, why 0.4 epochs? ",644 645 646 647
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Todo,"[1] Jiang, et al ""Generalizing Natural Language Analysis through Span-relation Representations"" In ACL2020. ",488 489 490 491 492 493 494 495 496 497 498 499 500
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"
4. ",204
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Todo,"For each HMM with rank r, add a baseline smaller HMM with state size being r. ",729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
5. ",653
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Todo,"
Line 542: I assume Dutch and Finnish were removed to remove the phonemes that are also present in German, but it would be useful to say that explicitly. ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Line 119-120: please rewrite (a) ,457 458 459 460 461
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Todo,I think it is not appropriate to throw any examples from the test set. ,393 394 395 396 397 398 399 400 401 402 403 404 405 406
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- footnotes 3,4: When a reference to a footnote is inserted immediately before a punctuation mark, they should switch positions; e.g. ""(...) OPUS^3. ",953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(9-10): explore -> exploit ,540 541 542 543
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Todo,"-lines 528-529: should ""only improves the results significantly"" be ""insignificantly""?
",170 171 172 173 174 175 176 177 178 179
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"If I correctly understood, I recommend the authors to change the example to more clear-cut and non-ambiguous one.
",406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"I would suggest to revise this part.
",323 324 325 326 327 328 329
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-Line 377, is BFSZIP an existing work? ",249 250 251 252 253 254 255
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"I find it a bit odd to name a section “Baselines” and show the results, but this may be a personal opinion. ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Todo,"See comments/questions in the summary of weaknesses for ways to improve the paper.
",707 708 709 710 711 712 713 714 715 716 717 718 719
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Ln 139: This is an uncharitable misrepresentation of lexicalist theories. ,656 657 658 659 660 661 662 663 664 665
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"If without, then how much worse does the two-step method perform?
",639 640 641 642 643 644 645 646 647 648 649
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-L349-353: What is the connection of the Isabelle et al. paper with DeepL? ,301 302 303 304 305 306 307 308 309 310 311 312 313
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"This will make a better comparison with other models using external LM.
",172 173 174 175 176 177 178 179 180 181 182 183
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"This is common in structural priming experiments as well, and models are known to rely heavily on lexical heuristics. ,
",825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,"-Sect 4.3: The output of the BERSON decoder is simply the order, i.e., integer values (e.g., 0 and 1 in your case of sequences of 2?), ",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Todo,"But the training process still relies on MT, so this approach does still rely on MT, right? ",216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,So it would be better to show demonstrate results with other tools like T-SNE. ,297 298 299 300 301 302 303 304 305 306 307 308 309 310
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Todo,"Arabic ""dots"" are not optional in common use of Arabic; diacritical marks (vowels, nunation, gemination) are. ",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,Comments: ,601
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo, ,
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,3. ,330
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,-Line 577: the authors discuss about limited ImageNet data for pretraining. ,240 241 242 243 244 245 246 247 248 249 250
6c7386d38647d226e22fb6a21bec815d465a1023fc59c871b959b53ae367be17a28b2839533147dc589795577b8630217bf4ea6311ca501b3d89453b25741324,arr,Todo,- Including an example created by BERT and comparing them with one created by the proposed model may be helpful. ,181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
bd9e1f80c81f4619d7b93cff38f4ca9e4642566c30cfbbd2b934b29262b4770edd6afc39af1d95c895d124f3b8631b150c371e4af90609ab6780222f71ce8fdd,arr,Todo,fixed from last version ,50 51 52 53
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,-Did you consider different measures of similarity in the Jabberwocky experiment? ,845 846 847 848 849 850 851 852 853 854 855
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,"My suggestion would be to mention the connection to referring expressions somewhere in the paper and to think about refining the intro/notion of context a bit.
",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo," In particular, exploring the potential relationship between lexicalization and missing slot error would have made for a much stronger paper. ",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Todo,"
If you want to describe the training time, I encourage you to discuss it more. ",610 611 612 613 614 615 616 617 618 619 620 621 622 623 624
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Todo,"The authors may include some discussion on inter-annotator disagreements.
",402 403 404 405 406 407 408 409 410
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,-Table 4: Please also include bold numbers for the baselines of previous work. ,433 434 435 436 437 438 439 440 441 442 443 444 445
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,Is that right? ,1343 1344 1345
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,"A few citations on existing synthetic training: https://arxiv.org/pdf/2106.01044.pdf and https://cs.stanford.edu/~nfliu/papers/liu+levy+schwartz+tan+smith.repl4nlp2018.pdf both of which look at the inductive biases through synthetic training data.
",399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,"
2. ",322
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Todo,"Your attempt to train the retrieval and outcome prediction jointly seems unsuccessful, have you considered experimenting with different approaches, such as  Retrieval-Augmented Language Model pre-training and fine-tuning?
",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,"-In the paragraph on line 267, it is described that samples that the classifier scores above the threshold of 0.8 are included. ",378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,The performance difference between CGExpan and LM-Base (proposed by the authors) is striking even if the underlying techniques are very similar. ,521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo, ,
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-In my opinion, the perspective API experiment was interesting but rather shallow. ",598 599 600 601 602 603 604 605 606 607 608 609
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,al. 2020; as done in -  https://arxiv.org/pdf/2104.01624.pdf. ,538 539 540 541 542 543 544
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,"It is also not clear how the choice of $\mathbf{t}^{\prime}$ is being made.
",666 667 668 669 670 671 672 673 674 675 676 677 678
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,"Although these methods do not release the code, I think this comparison could strengthen the effectiveness of the proposed method. ",225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"- Line 031: ""has the promise to revolutionize"" - this should be substantiated further, seems quite vague. ",1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,I have a question regarding the schema expansion for the synthetic dataset. ,376 377 378 379 380 381 382 383 384 385 386 387
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,"Although, at a high level, tasks are well-motivated, what makes the authors think that other researchers will adhere to a challenge in this format?
",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Even then, we are missing any form of analysis of disagreements or low correlation cases that would help solidify the argument. ",456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,Compare the proposed approach with methods which uses domain knowledge in the form of grammar. ,364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,"Typos: 261: in the abve equation ""are"" used to guarantee that all ",267 268 269 270 271 272 273 274 275 276 277 278
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"- L96: There is an incorrect reference for the attention mechanism.
",551 552 553 554 555 556 557 558 559 560 561
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"Details cannot be in appendix.
",342 343 344 345 346
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo, ,
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-There is growing consensus to capitalize racial identifiers (certainly ""Black"", increasingly ""White"").
",969 970 971 972 973 974 975 976 977 978 979 980
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"
3. ",252
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,"
2. ",295
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"-Please describe more on MNLI corpus, on the reason why the dataset is utilized in the training of entailment system.
",509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"L166, theory.
",639 640
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"1) Additional reference regarding explainable NLP Datasets: ""Detecting and explaining unfairness in consumer contracts through memory networks"" (Ruggeri et al 2021) ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,3. ,680
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"If not, consider noting or discussing this somewhere in the paper as it helps with understanding the validity of human experiments) ",910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,"In the current paper, the comparison is between the whole pipeline and other baselines. ",117 118 119 120 121 122 123 124 125 126 127 128 129 130
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,"-[Minor] For Figure 4, preferable to have legends outside the plot.
",226 227 228 229 230 231 232 233 234 235 236
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Todo,"-As mentioned in Sec 5, there is another model named TaPEx, which is also designed to improve reasoning skills in table pre-training. ",210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Todo,"Fig 1 suggests the [CLS] token is at the end of the context, but line234 says the [CLS] token is at the beginning of the context. ",401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"If other contexts such as 'S1 is fat/poor' is not given, then the conversation between S1 and S2 seems quite natural. ",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo," I understand you want to preserve space to make up for the new additions into your manuscript, but the wider margins would help for legibility.
",509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,Questions to the authors: Would the knowledge-neurons remain robust when the words in a given relational prompt are mentioned but not in a knowledge-expressing manner? ,600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Todo,Maybe the paper would be better without it. ,348 349 350 351 352 353 354 355
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo, Is this related to equation 18 (from Appendix C)? ,506 507 508 509 510 511 512 513 514
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,Do the MISS percentages correlate with the accuracy figures? ,350 351 352 353 354 355 356 357 358
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Todo,"Under this setting, parsing F-1 might not be directly comparable, but perplexity can still be compared. ",712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"Dense representations can be produced without using any neural networks (for example, by applying SVD to PMI vectors).
",383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,"
  ",
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,  ,
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"-In several instances (167, 181, 460, etc.) ",1419 1420 1421 1422 1423 1424 1425
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"From my opinion, instead of correcting sentiment word errors from the ASR models, improving the performance of the ASR models is a thorough solution to guarantee the effect of the MSA models in practice. ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"-References: Please make sure that abbreviations and language names are capitalized.
",566 567 568 569 570 571 572 573 574 575 576
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,-signal earlier that the automatic metrics do not correlate with the human metrics. ,124 125 126 127 128 129 130 131 132 133 134 135 136
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Todo,"Just a conjecture, but I am a non-native and I am certain that I am worse than GPT in these tasks. ",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"- L464-L465: These are the asymptotic formulas, which are obviously not used for creating Fig 3. ",670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Todo,"
And if it only takes 24 hours, it seems acceptable. ",600 601 602 603 604 605 606 607 608 609
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"EMNLP 2017.
",717 718
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Line 69: “current” -> “currently” 3. ,198 199 200 201 202 203
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Todo,Another round of proofreading may be needed. ,778 779 780 781 782 783 784
9718a739d8caa017664be63a426c74dc7d8daff635c7dfdb44370137bf06fe6e6e1668afefb0860bc026efb02485979591635a255987a98fd6dfde30e4ab8f8c,arr,Todo,"Line 045: challening -> challenging Line 310: ""See Fig 2"" could be written in parentheses, instead of making it a separate sentence. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,Is the test set temporally split or split according to different patients? ,393 394 395 396 397 398 399 400 401 402 403 404
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Todo,1. ,673
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,1. ,554
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"Also, the term correlation is confusing (at least to me). ",308 309 310 311 312 313 314 315 316 317
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Todo,My intuition was that the top codes would be benefited less since we have enough training data for those codes. ,187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo, ,
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,4. ,270
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Is this correct? ,352 353 354
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Todo,"While I acknowledge the clear advantages of this, particularly related to sample size, I would encourage the authors to also include system-level scores in the leaderboard. ",273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo, ,
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"
4. ",853
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo, ,
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"
2. ",367
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Todo,"Since we know a stronger vision model helps image captioning, so it is foreseeable that a stronger vision model is helpful when visual information is missing. ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo, ,
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"
  Thus Logic Trap 3 does not seem to add anything beyond Opinion A. ",861 862 863 864 865 866 867 868 869 870 871 872 873
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo, ,
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,- Why are SST-2 and SICK-E chosen as representative tasks to show that the proposed method generalises to other few-shot settings? ,214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Todo,"
2- The text mention 2300 docs annotated. ",222 223 224 225 226 227 228
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"
2. ",146
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,There   is no single correct metric because there is no single interpretation. ,752 753 754 755 756 757 758 759 760 761 762 763
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo," If so, how are is each derived? ",252 253 254 255 256 257 258
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Lines 430 - 432 - Has this type of loss been proposed in the past for interpretability? ",696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Todo,"The whole statement is a bit strange: Zipf's law is well known to be manifested not ""in many corpora"", but in _all_ human languages, and thus, in any imaginable corpus of natural language texts. ",160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"
""The data-model alignment is a clear cause for MT performance."" ",383 384 385 386 387 388 389 390 391 392
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"using parallel corpus"" --> ""using parallel corpora"" ",161 162 163 164 165 166 167
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,Regarding the Ethical statement: Well... this is super weak argumentation: you rely on IBM's black box but at the same time claim only correct solution is to aim for being transparent to the user. ,188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
7e23ee6e56ace10f42339e73b598425e2f2f0f8539fed8f42a514d3a80a537553522ece6eca40ded1d3e587222531371a27d268cbb3ba00f80c3ba8cb0bf286d,arr,Todo,This part is unclear... ,287 288 289 290
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,https://arxiv.org/abs/1806.04313 ,689
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,The order of terms in L288-L290 should be aligned with Figure 2. ,222 223 224 225 226 227 228 229 230 231 232 233
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,"Appendix A: sometimes you write p-hat, and sometimes you write p-hat_MLE ",204 205 206 207 208 209 210 211 212 213 214
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,It will also be good for reproducibility if the authors can share the full set of hyperparameters as well. ,501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Todo,see above ,220 221
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"If so, you may want to separate it and show it better. ",553 554 555 556 557 558 559 560 561 562 563 564
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"-The abstract is written well and invokes intrigue early - could potentially be made even better if, for ""evaluating with gold answers is inconsistent with human evaluation"" - an example of the inconsistency, such as models get ranked differently is also given there. ",1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Todo,The line number on page 4 is missing. ,189 190 191 192 193 194 195 196
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Todo,"• The paper shows that machine translated data can be used as a proxy for human translated data, but only compare with post-editing approach which provides bias for the human editor.
",380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,Allsides.com sometimes includes more than one source from the same side -- e.g. https://www.allsides.com/story/jan-6-panel-reportedly-finds-gaps-trump-white-house-phone-records has two stories from Center publishers (CNBC and Reuters) and none from the right. ,368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Todo,"
line 216: subdividing -> subdivide? ",226 227 228 229 230
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,-The paper in general is very dense (and thus difficult to get through in parts). ,304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"In fact, ESE is a useful mechanism when a concept is complicated enough to be expressed as a query. ",252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,Are the results in Table 1 with decoder downsampling obtained with or without the two-step method? ,623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Todo,"If I understand correctly, in Line 283, there seem to be typos on the operators in the equation -F(x;f) < t = log(...). ",267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,How does (1) and the last part of (2) match? ,373 374 375 376 377 378 379 380 381 382
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,"Does this formulation cover the task of identifying the predicate(s), or are the predicates given by syntactic parsing results?
",757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,-Figure 1 caption:  middle -> midpoint ,756 757 758 759 760 761
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"
(1) How to capture the interaction between the two types of dialogs? ",191 192 193 194 195 196 197 198 199 200 201 202
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Todo,Minor: commas should follow “i.e.” ,425 426 427 428 429
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 185 - You are repeating some here. ",455 456 457 458 459 460 461 462
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,-Is it possible to generalize the application? ,147 148 149 150 151 152 153
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"More details would be helpful.
",669 670 671 672 673
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,Do not Rely on Relay Translations: Multilingual Parallel Direct Europarl. ,575 576 577 578 579 580 581 582 583 584
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,"-A few minor typos, proof reading should fix them. ",256 257 258 259 260 261 262 263 264
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,*Typos:* ,143
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Todo,See above ,194 195
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,3. ,293
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 5] Tables 1 & 2:  The first 4 rows of Tables 1 and 2 collapse to the same settings and are thus repeated. ,1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"Would it be possible to highlight in bold the best result in each group (0, 8, 64, 512) and with another symbol (maybe underline) the statistical significant ones? ",493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"-Author did not mention how the initial durations of phonemes are obtained.
",293 294 295 296 297 298 299 300 301 302 303 304
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"Positive or negative examples should have similar distribution of length and structure, so that they don't become a cue during inference. ",587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,"Lines 225-232: One limitation of the current ranking based approach is that while it's easier to compare across different datasets with potentially different label scales, running comparisons over multiple instances may be less efficient. ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Todo,"Though there is a accompanying repository, I still think it's worth talking about the model architecture, training hyperparameters, and the training loss.
",323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Todo,"-Positions of the figures are not fitting with the explanations, which makes the paper harder to read. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"If so, please cite. ",713 714 715 716
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"Doesn't your model need the ""char"" representation?
",462 463 464 465 466 467 468
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,"E.g. B_ij = subj_context_attn(S, C) ",287 288 289 290 291
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Todo,Did experiments not work out with an autoregressive LM? ,346 347 348 349 350 351 352 353 354
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Todo,Suggestions: 1. ,166 167
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Taking into account the length of the paper and the Appendix, a reduction of Sect.1 through the removal of unnecessary redundancies would provide space enough to move part of the appendix back to tha main paper, thus making it more complete and self-contained.
",585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Todo,It will be good to provide a reference for this claim. ,356 357 358 359 360 361 362 363 364 365 366
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Todo,1. ,388
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,"I’m not necessarily pushing it but maybe you should check.
",415 416 417 418 419 420 421 422 423 424
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo, ,
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,-Line 405: This last sentence seems a bit circular. ,722 723 724 725 726 727 728 729 730
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Table 3: lOur method -> Our method ,314 315 316 317 318 319 320
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,"[1] Lin, Hongyu, et al. ""A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained Model Lead to the Promised Land?."" ",824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,3. ,225
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,This information would be very useful to have a better view of the performance of the approach. ,810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,lines 216-20) ,467 468
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,---------------------------------------- Typos and other presentation comments: ,729 730 731 732 733 734
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,Are they similar in style/genre/domain? ,184 185 186 187 188
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"-Throughout the paper, the authors use the term NLU, however I'm not sure whether some of the lower level tasks count as NLU or syntactic tasks. ",358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,You’ve defined systematicity such that the geometric property is satisfied if and only if f is systematic. ,731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Todo,Towards Efficient NLP: A Standard Evaluation and A Strong Baseline (https://arxiv.org/abs/2110.07038) It would be better to include and discuss them. ,323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,-Figure 3 is a bit hard to read. ,317 318 319 320 321 322 323 324
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,- Please check the weaknesses section for suggestions on how to improve the work. ,426 427 428 429 430 431 432 433 434 435 436 437 438 439
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"### Minor issues I was slightly confused by the word ""headline"" to refer to the summary of the article. ",826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"== Experimental Setting == --> Experimental Settings?
",513 514 515 516 517 518 519
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"Second, depicting sentiment analysis, it does not align well with the main contribution of the paper, improvements on the WiC task. ",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Todo,"- This work may feel more ""at home"" at an IR conference -- I'm not sure how interesting this will be to a broader *CL audience. ",300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Todo,"One suggestion to the authors is to change the title to something that is less focused on BERT, captures some of the more noteworthy empirical findings, and avoid ""muppet"" as a generic term for transformer-based language models.
",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-Algorithm 1 step 4 and 5, you may need to give the detailed steps of *isRecomb* and *doRecomb* in the appendix.
",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
5055d6e9bee3c38f171f9a51c2cc9db4023bba622f8b471a60e20864e21b6e012403a4b741ecaf347e239448fde93bfbf299ec9f5ee6bf0091d4c33ee9b19ba0,arr,Todo,1. ,106
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-line 292: you could use \softmax to represent the symbol ,560 561 562 563 564 565 566 567 568 569
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"Could you provide more discussions/explanations on this?
",130 131 132 133 134 135 136
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,"- Sec 5 on related work is reasonable, although could include the most recent work from the image processing space, e.g. [CSG20].
",573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,Intent Classification? ,608 609
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Todo,Footnote marks should come after punctuation. ,342 343 344 345 346 347
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo, ,
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,[1]: Dynamic Early Exiting for Accelerating BERT Inference ,285 286 287 288 289 290 291 292
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"Did you classify the errors in the M2 files before feeding them into ERRANT?
",665 666 667 668 669 670 671 672 673 674 675 676 677 678
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,This would increase readability. ,655 656 657 658
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"Is this purely a data curation issue, or could this be due to some architectural changes? ",531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Todo,"3) Please fix the bibliography and cite published versions rather than arxiv versions (e.g., Loshchilov et al. 2017). ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"If there is no ground truth, how can it be   wrong for an attribution method to say anything?
",571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality. ,499 500 501 502 503 504 505 506 507 508 509 510 511 512
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Todo,"line 365: size larger than 50, should be defined on a reference image size since it could mean widely different things based on how big the image itself is. ",484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Todo,needs more explanation somewhere in the paper. ,193 194 195 196 197 198 199
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,Does it expand into t and s? ,545 546 547 548 549 550 551
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,"I think you should rename ""null hypothesis"" to something else, since ""null hypothesis"" could have a different meaning and is not specific to label verbalization. ",522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Todo,"-Do you assume you can naturally have every constraint as well as the corresponding discriminator?
",174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,then you jump into the tiny details. ,224 225 226 227 228 229 230
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,-Figure 2: It is a bit unintuitive and confusing to see the two y-axes with different ranges and interpret what it means for the different model evaluations. ,1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,Could you please elaborate more on that? ,520 521 522 523 524 525 526
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,2. ,319
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Todo,"I agree with the authors about the framing of the classification task, that it isn’t a realistic one. ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Todo,It is also unclear to me that why syllable segmentation could be useful for the annotation. ,211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"the output vector from the cross-attention?
",410 411 412 413 414 415
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,a word is missing here ,684 685 686 687 688
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Todo,1. ,204
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Additionally, I have the feeling that whatever is discussed in text in this paragraph could be more concisely presented in a Table. ",1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190
0943e5d2efbf75734b113861f9c2bb8ca031e0740fce519c60b9b17470dea2b0df56aa327e769a0e36e89ac92fa23086cd9ee85094e50a67d721965f0c3509f7,arr,Todo,"At least you should state why the standard evaluation metrics fail in this case, e.g., they cannot score plurals, i.e., split-antecedent references ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Lines 185-191 Question: Same question as in (2). ,259 260 261 262 263 264 265 266
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,What should we take from it? ,230 231 232 233 234 235
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Todo,- l222: *the* fully ,386 387 388 389
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,"- In Table 5, I would think that one intuitive configuration is to devalue the source vocabulary without shutting it off completely, via parameter settings like 0.5-0.5-0.25. ",600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"I would expect most readers would recognize this to be one of the central tradeoffs across the entire field and acknowledge that it's useful as an object of study.
",1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,"Specifically, how to process the example by Hierarchical Attentive Reader and Multi-hop Reasoner ? ",205 206 207 208 209 210 211 212 213 214 215 216 217 218
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"You can make such comparison only on the same data, thus I compare the number of erroneous sentences for NLPCC18(Orig) and MuCGEC(NLPCC18), but the number of correct sentences has increased only by about 80. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Todo,"- Line 183: it would be good to show what languages are used in the PLM pretraining and if there is a difference of the proposed method between the seen and unseen languages.
",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"Basically, it is difficult to confidently evaluate the superiority of the proposed CRN over prior methods, without taking into consideration the amount of data available to each of these methods. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"-Notations: (1) In line 247, the subscript $i$ (in $X_i$) is not defined. ( ",575 576 577 578 579 580 581 582 583 584 585 586 587 588
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,A clear description of how batches are constructed would be helpful. ,378 379 380 381 382 383 384 385 386 387 388
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,Is there any reason why 'Gold Reference' was not reported for Newsela? ,425 426 427 428 429 430 431 432 433 434 435 436
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Todo,A possible question: this work seems focused on starting with metaphors and getting literal interpretations. ,522 523 524 525 526 527 528 529 530 531 532 533 534 535 536
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,"-Other than UMAP, there are some other tools for analyzing the geometry of high-dimensional representations. ",272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
db14eda600a57c45529a8ae7db67ef709b17efd9bc501459d16886267bb64db205b07db81311c17bd4e2bec40a9d83d6cff10898a7f5016d5b2799e8ccb4c73b,arr,Todo,This is an important aspect of mismatched translations. ,219 220 221 222 223 224 225 226
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Todo,-missing section in line 492 ,252 253 254 255 256
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"In the contributions (line 110), the authors state that the ""CNM is able to learn stable task relations"" (line 128f). ",596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615
5055d6e9bee3c38f171f9a51c2cc9db4023bba622f8b471a60e20864e21b6e012403a4b741ecaf347e239448fde93bfbf299ec9f5ee6bf0091d4c33ee9b19ba0,arr,Todo,"If a country is located at the westernmost part of a specific time zone, there might be more than one hour difference between the sunrise/sunset with regard to the easternmost part. ",123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"
It is not clear how many problems are examined during the second round and the agreement between the authors is not reported. ",338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"-L006, as later written in the main text, ""thousands"" is not accurate here. ",543 544 545 546 547 548 549 550 551 552 553 554 555
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,"Why does it become a problem?
",651 652 653 654 655 656
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,"Lines 528 With no overlap between the two subsets, there is no way we can hypothesis the adversarial samples share similar model reasoning to the original samples.
",821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,The line is now unclear. ,616 617 618 619 620
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 178 - Please explain what you mean by ""losing"" their positional information during translation. ",481 482 483 484 485 486 487 488 489 490 491 492 493 494 495
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"### Other comments Even though the authors submitted a sample (120 sentences) of their dataset for reviewing purposes, I am choosing ""No usable datasets submitted."" ",848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Todo,It is best to use vector graphics in the paper. ,103 104 105 106 107 108 109 110 111 112
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Todo,The annotator disagreement might be interesting for the different punctuation marks. ,185 186 187 188 189 190 191 192 193 194 195
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Todo,I would strongly advise the authors to provide a discussion/comparison with respect to: https://aclanthology.org/2020.sigdial-1.2.pdf Consider improving the work with a more sophisticated human evaluation on the actual dialogue task. ,183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Todo,what BPE tokenizer? ,377 378 379
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"363 - PPL, this is not defined anywhere.
",525 526 527 528 529 530 531 532
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Todo,Ablation study in Section 4.1.3 should be conducted on validation sets instead of test sets (similar to Section 4.1.2). ,411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo, ,
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Todo,Please provide more details. ,227 228 229 230
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"It is precisely because of the great potential and impact of this paper, I think the current manuscript requires more consideration and fine-tuning before it can reach its final stage. ",225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Such detailed discussion is better suited for Sec 4.4 ,490 491 492 493 494 495 496 497 498
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Todo,"In their response to the previous reviews, the authors list the following improvement: ""We describe the Twitter data acquisition and cleanup process."", ",443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,What is the purpose of the average duration reported in Table 1? ,425 426 427 428 429 430 431 432 433 434 435 436
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-In Section 4.2, why does sentence length influence percentage of perturbed words? ",602 603 604 605 606 607 608 609 610 611 612 613
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,l.546: truncated sentence? ,215 216 217
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"In the experiments, I have some concerns: (1)	The paper uses RoBERTa for the experiments, while the baselines used BERT. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"Why does soft prompt tuning have such a huge effect on Color (~20-30) points but much less for the other attribute types?
",529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,"Medium, another seed for swift model size, etc. ",327 328 329 330 331 332 333 334
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"- Still in Table 4, the 3r column shouldn't be named ATE? ",349 350 351 352 353 354 355 356 357 358 359 360
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-Table 6: remove bold style on the number `39.2` since it is not the best one ,632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Todo,"- the dataset should be improved concerning the eastern country representativeness, as well as its impact on the structure of the arguments.
",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,Maybe it would be helpful to clarify that tin the Figure caption. ,1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-The toxicity experiment was intriguing but there was too little space to be meaningful.
",362 363 364 365 366 367 368 369 370 371 372 373 374 375
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"Using Optimal Transport (OT), or more specifically leveraging the Wasserstein Distance, in GAN is first seen in the Wasserstein GAN paper, i.e. WGAN (Arjovsky et al. ICML 2017). ",784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Todo,A case study with only one sample is insufficient for a competent paper in the dialogue area. ,297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,-Line 228: token -> tokens ,310 311 312 313 314
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,"Is the prediction a long span like in training?
",360 361 362 363 364 365 366 367 368
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"This is very important to note the contribution of this work.
",210 211 212 213 214 215 216 217 218 219 220
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,"Why does the designed QAG system extracts answer candidates from stories directly?
",509 510 511 512 513 514 515 516 517 518 519 520
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"arXiv preprint arXiv:2110.06800.
",469 470 471
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo," There is no mention in the draft of more powerful language models, such as N-gram (N>1), combined with various smoothing and back-off techniques, why? ",123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo," First of all, will the author release the dataset or will it remain private? ",260 261 262 263 264 265 266 267 268 269 270 271 272 273
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,Also why there are quite limit number of BLEU scores achieved by your “Ours method” higher than others? ,301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"Line 196: ""We noticed that the annotators are biased when evaluating the correctness of answers"" - are any statistics on this available? ",818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Todo,2. ,215
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo, ,
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Equation 12. ,299 300
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,"2) if indeed the experimental datasets are the same, I am not sure if it is okay to replicate the exact same table across papers.
",705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,1. ,281
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,How much does this affect the precision of the classifier? ,400 401 402 403 404 405 406 407 408 409
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,I think I needed to make my way until section 5.3 to get it. ,281 282 283 284 285 286 287 288 289 290 291 292 293 294
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"While this seems to be helpful in improving quality, it remains questionable how scalable this approach is, especially when extending the system to handle hundreds of languages. ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Todo,1) Why do you use uncased PLMs? ,250 251 252 253 254 255 256
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Todo,"It is suggested to add some case studies to clarify the problems you have solved, so as to clearly show your contribution. ",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,  The authors are rightly pointing out that numerous forms of attribution evaluation based on   ablation or reconstruction inputs have been used to motivate attribution methods. ,695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Todo,"6) The expression of ""fully unsupervised"" in Section 1 is a bit misleading, because an alternative standard dictionary containing complex definitions can be used for training.
",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,"I speculate that sentence embeddings learned by DiffCSE focus more on superficial information than SimCSE in order to solve replaced token detection, but the result is the opposite. ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo, ,
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Todo,This paper is well written and is elegant. ,213 214 215 216 217 218 219 220
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Todo,1. ,391
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Todo,Box plots like in Figure 4 and 5 would be better. ,579 580 581 582 583 584 585 586 587 588 589
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Todo,"- as shown in Table 6,7 for both BLEU 207 and chrF -> 6, 7 ",231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,"On line 005, insert ""many"" between ""by"" and ""Automatic"".
",286 287 288 289 290 291 292 293 294
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo,"Finally, as per https://2021.aclweb.org/ethics/Ethics-review-questions/, information about the compensation of annotators via Amazon Mechanical Turk has to be provided. ",980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,I think it would be correct to have one of their later citations on continually developed LM as the one that showed that. ,1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Todo,- ,187
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Todo,"Why FIN-BERT is much worse than SEC-BERT?
",196 197 198 199 200 201 202
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Todo,"Why do you think this happens?
",207 208 209 210 211 212
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Todo,The authors are encouraged to proofread the paper more carefully and explain their methods more clearly. ,258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Pointing out the that the _ON_ correlation for RoBERTA$_{\text{large}}$ would fit the tend of correlation vs model size (being between T5 Base and T5 Large) also strengths the argument but showing it isn't an artifact of _ON_ working poorly on encoder-decoder models. ,1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"For example, in line 78, ""the conversation starts without any speciﬁc goal"". ",239 240 241 242 243 244 245 246 247 248 249 250
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"I am not sure if I understand correctly but in the case of attach, the query concept is a (d, ss): definition, synonymns included in the synset. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Lines 99-100: rewrite more clearly using full sentences or more clear format (i.e., We define two requirements ...: (i) accessible with ... (ii) sharable format)  ",375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Todo,Related paper: Learning to Prompt for Vision-Language Models. ,310 311 312 313 314 315 316 317
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Todo,"- I might have missed the specific in the paper; hopefully, I get CKMT = ""Compact-network K-nearest-neighbor MT"" correct. ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Todo,"Comparing to ALP-KD, the improvement is not significant. ",255 256 257 258 259 260 261 262
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo,"-what types of errors do the feature attribution models find/miss, what do these models tell us about what sentence-level models are learning? ",388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Todo,"-line 499: corpus (David, 2020) ~~corpus~~ ",303 304 305 306 307 308
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"Sandeep Mathias, Rudra Murthy, Diptesh Kanojia, Abhijit Mishra, Pushpak Bhattacharyya. ",366 367 368 369 370 371 372 373 374 375
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,1. ,167
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"In line 505-512, the authors claim ""such systems is to only make entity recommendations instead of tasks..."". ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo, ,
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,Line 352: move label drift studies to the main text as they are helpful information. ,393 394 395 396 397 398 399 400 401 402 403 404 405 406 407
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"For example, the CoNLL-2012 shared task (Pradhan et al., 2012) included SRL annotations for English, Chinese and Arabic, if I am not mistaken.
",791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"In addition, the idea of effectively using boundary information has been proposed in Shen et al.(2021), which constructs soft examples for partially matched spans, and trains a boundary regressor with boundary-level Smooth L1 loss.
",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo, ,
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"The length of the manuscript is about right.
",88 89 90 91 92 93 94 95
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Todo,"The paper is generally well-written, but may benefit from an additional round of editing. ",467 468 469 470 471 472 473 474 475 476 477 478 479 480
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"This is confusing, since if a user has no specific goal, why does he or she chat with a salesperson? ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Todo,"Creation of synthetic datasets on large scale, by removing punctuation marks seems possible. ",261 262 263 264 265 266 267 268 269 270 271 272 273
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Todo,"**Questions**: In table 1, The MER indicators of +aggregation and +post-edit are both higher than 1.1, while the MER of +selection is very low. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,It seems that adjusting PABEE through the patience parameter still provides a useful range for the S/R tradeoff. ,953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"I suspect the forced-choice setting makes a significant difference to human interpreters, as suggested in ft. ",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"If possible, please show some examples in the Appendix for easy understanding. ",280 281 282 283 284 285 286 287 288 289 290 291
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,2. ,789
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,The usage of the momentum-based memory bank is confusing. ,327 328 329 330 331 332 333 334 335
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,Why is the pseudo knowledge label named {$P\bar}? ,587 588 589 590 591 592 593 594
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,"- This reviewer thinks that the indicator for adversary should be 'it' rather than he (line 374, 448).
",247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,T_1 + T_2 + ... + T6 + S (this is the version with all the datasets that is currently implemented in the evaluation) ,567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,what's the range of c? ,380 381 382 383 384
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,This way you wouldn’t run into the confounding issues that stem from using the contextualisation of ‘gave’. ,1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Todo,"-line 237, “an clipped” -> “a clipped” ",296 297 298 299 300 301 302
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,-Using p(x|y_<j) -- the source probability conditioned on the target prefix -- seems a strange choice. ,392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Todo,Though the dataset can be built to reproduce the results it would be better if authors can share the same publicly. ,221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-Shi and Lin, 2019. ",906 907 908 909
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Todo,-The paper says that computational linguists routinely cite Harris and Firth. ,651 652 653 654 655 656 657 658 659 660 661
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,"-Line 249: “Huge time costs” sounds very informal, maybe change to “considerable running time” or similar ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,8(3): 305-316 (2014). ,427 428 429
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Todo,1. ,124
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"L543: ""Pre-training"" and ""pretraining"" are not spelled consistently. ",411 412 413 414 415 416 417 418
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Todo,"Another flavor of related work to help motivate the approach (no fine-tuning, no optimization needed), could be around prompting, steering LMs without fine-tuning, etc.
",581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Ln 489: Using just the first subword embedding is just one arbitrary choice of several. ,599 600 601 602 603 604 605 606 607 608 609 610 611 612 613
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"While the paper can be easily read and understood, here I provide a few suggestions for replacing some words or phrases for clarity: ",1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"160 - The LM shown is the negative log of the probability, while that could be a typical training phase, how do you assume it is the ""casual"" one?
",310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"line 189), ""Golden"" -> ""Gold"" (lines 212, 220, 221, 317), ""sentence numbers"" -> ""number of sentences"" (Table 3 caption), ""numbers (proportion)"" -> ""number (proportion)"" (Table 3 caption), ""averaged character numbers"" -> ""average number of characters"" (Table 3 caption), ""averaged edit numbers"" -> ""average number of edits"" (Table 3 caption), ""averaged reference numbers"" -> ""average number of references"" (Table 3 caption), ""in the parenthesis of the..."" -> ""in parentheses in the..."" (Table 3 caption), ""previous"" -> ""original""? ( ",763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 264: two distribution -> two distributions ,745 746 747 748 749 750 751
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,3. ,158
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,Please add screenshots of the interface that was designed. ,371 372 373 374 375 376 377 378 379
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo, This new experiment will help to show how the interesting combination will help. ,398 399 400 401 402 403 404 405 406 407 408 409 410
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"Looking at Table 3, it does not appear anywhere either.
",1319 1320 1321 1322 1323 1324 1325 1326 1327 1328
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,Did you manage to measure the quality of the samples you collected using the proposed method? ,286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"Lines 360-364: ""We determine whether e∗_j = e_j by checking if F1(s∗_{j,1}, s_{j,1}) > 0 ....  .... as long as their first mentions have word overlap."" ",951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"- I might have missed it but the results section stated ""When translating without constraints, however, adding ACT does not bring consistent improvements as hard and soft constraints do, which could be attributed to the discrepancy between training and inference.""; ",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Todo,The authors addressed most of the reviewers' comments made for the previous submission. ,202 203 204 205 206 207 208 209 210 211 212 213 214
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"10) Table 5: ""For calculating the human performance, each submitted result is considered as a sample if an annotator submits multiple results."" ",564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"[1] Graves,A. et al. (2012) Supervised Sequence Labelling with Recurrent Neural Networks. ",653 654 655 656 657 658 659 660 661 662 663 664
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo, ,
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"If it’s the latter, please also highlight cells where the proposed approaches are significantly worse. ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Todo,Is it due to the quality of srs dataset or the XLSR model? ,311 312 313 314 315 316 317 318 319 320 321 322 323
97bd72cf67e40492696103ced9dcbd5066d8a3a52f3d2558764aa570e24ae2c7bedddf9ad226e624b1dabcced450f36d6bcd93ece5a871c74fa98b7e2d8145fc,arr,Todo,Was it just left for future work? ,226 227 228 229 230 231 232
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,Annual Conference of the European Association for Machine Translation EAMT (2009). ,616 617 618 619 620 621 622 623 624 625 626
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,Each annotator against the rest? ,599 600 601 602 603
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo,"E.g., care in moral foundation theory, Benevolence: caring in the dataset). ",617 618 619 620 621 622 623 624 625 626 627
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Todo,"-It would be good if Fig-QA is  built for  other languages as well.
",255 256 257 258 259 260 261 262 263 264 265 266 267
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"- ""These observations prove the efficacy of our method in maintaining a perfect balance between model performance and model uncertainity-a testimony of an ideal calibrator"" this is a pretty over-the-top claim! "" ",854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Todo,The equation (2) is inconsistent with the task definition described in Section 2. ,430 431 432 433 434 435 436 437 438 439 440 441 442
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Todo,"- Line 036 - ""probabilities of becoming the next word"" reads awkward to me ",207 208 209 210 211 212 213 214 215 216 217 218 219 220
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"I am not a vision expert, but it seems to me that the ratio between added parameters of a classification layer and convolutional layers is much less significant than that of a simple FC layer and a transformer. ",906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,- Lines 76-77: there lacks —> there is no ,1366 1367 1368 1369 1370 1371 1372 1373 1374
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,But isn't recall also important since you would otherwise miss out on reporting at-risk patients? ,426 427 428 429 430 431 432 433 434 435 436 437 438 439 440
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,1. ,229
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"I could imagine that in a BERT-like architecture the representation at the [CLS] position might serve as a sentence representation as well.
",778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Todo,1. ,296
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"
For example, data generation and data collection can be described in the same section. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,  The paper argues that black-box is not a worthwhile goal. ,937 938 939 940 941 942 943 944 945 946
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Todo,Is that because people tend to input short sequences in real-world situations? ,310 311 312 313 314 315 316 317 318 319 320 321
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,"This measure should be further explained for self-containedness.
",282 283 284 285 286 287 288 289
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Todo,"- The authors have taken into account all my previous comments, and plan to look into the correlation point above. ",362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"The proposed loss is similar to both NCE and InfoNCE, so changing either the citation or name of the method is fine. ",375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,How accurate is this invalid question detection strategy? ,1029 1030 1031 1032 1033 1034 1035 1036
5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec,arr,Todo,I think it will be better if the authors highlight their methodology as well. ,50 51 52 53 54 55 56 57 58 59 60 61 62 63
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,1. ,376
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,2. ,325
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"We need to know the impact of such processing constraints.
",663 664 665 666 667 668 669 670 671 672
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,How does that help in constructing a dictionary for the room type concept? ,192 193 194 195 196 197 198 199 200 201 202 203 204
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"Perhaps something like ""Thus"" over ""Hence only""? ",2017 2018 2019 2020 2021 2022 2023
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Which is not necessarily bad in itself, but as the more detailed maps in the appendix show, the characteristics of some datasets are very very similar (e.g. for European countries for example, or other geographically close countries). ",428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Todo,"Why the results are almost the same for Re-ranking, LaPraDoR unsupervised and FT while they are really differents for FEVER for example ? ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"The only evidence we have for the second insight are the results from the NeuS-Title system (compared to the NeuSFT model that doesn't explicitly look at the titles), but again, the comparison is not systematic enough (e.g. no ablation study) to give us concrete evidence to the validity of the claim.
",477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Todo,"In the introduction, the paper says ""reliance on ground truth data limits the quantity and quality of test cases we can produce"". ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,"For the major contribution of this work,  the special design of inputs and outputs could well capture the characteristics of the task. ",147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
21f74d3b60a2101f1630894856ba99180af6242a02b80070fe7274f02c867becdb7ff3d683a90f84d0f414d7b873d0fa2c18407c4bedd4e1bebb8dbcedc40de6,arr,Todo,This can be achieved by experimental setups which include or exclude other languages not in the test set. ,344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,T_1 + S 2. ,555 556 557 558
7f996fb9f31b45dea2339c0d4716c6c109c47c5b38feee689425e631026e454379762bebbea912d49f29530016a12a703c629819acd26de68018289115cb6bdd,arr,Todo,"- The samples of errors shown in Table 3 seem to often have the first, or few first characters right. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"In Appendix A.3, the GLEU metric is reference as GLUE.
",390 391 392 393 394 395 396 397 398 399
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Todo,The prediction of POS tagger mostly depends on the lexicons themselves. ,352 353 354 355 356 357 358 359 360 361 362
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo, ,
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,In this way it will be easier to spot the errors and validate the alignment result. ,415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430
0f595b4bd968ef5daacc88c4edb581bf7f683af30b6874ba157c6d2282aabead577041409b949924e4bc5ef54c543d85a10e962be8e70304dea65e1b18441bdb,arr,Todo,None. ,193
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-350: what exactly is a query? ,404 405 406 407 408 409
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,"
2. ",410
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Ideally, such a clusterings should be shown in the Tables and discussion in the results section as it seems there are multiple layers of comparisons made here. ",1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Todo,"Ultimately, in the other half of the leaderboard, metrics will be used to make system-level comparisons. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Line 559: “lower performance on Vikidia-Fr compared to Newsela-Es …” – Why? ,543 544 545 546 547 548 549 550 551 552 553 554
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,-Did you use pre-trained HiFi-GAN to synthesize speech from the predicted mel-spectrograms? ,420 421 422 423 424 425 426 427 428 429 430 431
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Todo,"Formatting of the paper could be improved, e.g. quotes in the title of section 5.1 are incorrect, several tables exceed the column width or are not centered.
",338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,418: s/is/are/ ,435 436
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Todo,"Second, it is better to compare with the best baseline model (e.g. the HMGD Transformer in Table 3) rather than the vanilla Transformer baseline. ",405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"
6. ",280
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,One other comment:  ,373 374 375
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Todo,The two-stage process is very related to [1]. ,240 241 242 243 244 245 246 247
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Todo,Missing Citations: ,504 505
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,"
3. ",138
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,Can the authors mention the dates during which the data was collected? ,231 232 233 234 235 236 237 238 239 240 241 242
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,Would it be then more correct to say that you have **approximately** 6x the data? ,293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"The clean accuracy on SST-2, QNLI and MRPC is also confusing. ",521 522 523 524 525 526 527 528 529 530 531
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo, Otherwise how are they different in practice… even the hyperparams from the appendix are largely the same. ,455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471
3cb226b0d8814a65b174a7d0cb90ebfa0748d404cd08981e4a84a2a794c22f90563f97eb4e66f87b1c5ec1921001d1baefeca833441161438617557155e84375,arr,Todo,The performance on KGQA with the complete KG setting should be provided. ,181 182 183 184 185 186 187 188 189 190 191 192
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"Semantic Role Labeling: An Introduction to the Special Issue"".
",731 732 733 734 735 736 737 738 739
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"- In the abstract and experiment section, expressions like ""5 points"" are confusing. "" ",335 336 337 338 339 340 341 342 343 344 345 346 347 348
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo, ,
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Line 450: L_{pc} or L_{cp}| in Eq. 7? ,355 356 357 358 359 360 361 362
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Todo,-Line 278: The word *the* is repeated ,457 458 459 460 461 462 463
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"-There is a mistake in rows ""MFS - Multi partition"" and ""MFS - Multi Input"" in Table 2. ",837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,What are your results on real data? ,638 639 640 641 642 643 644
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,== Ablation Study == ,598 599 600 601
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,Because attach considers candidate concept (that can be composed by a synonym set) ,335 336 337 338 339 340 341 342 343 344 345 346 347
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"However, it is not clear to me if it is the same for merge as it seems like the query concept is (d, ss) but ss is just the word that you are removing.
",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,I think readers unfamiliar with the area could appreciate more motivation for controllability in paraphrasing. ,790 791 792 793 794 795 796 797 798 799 800 801 802 803 804
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Todo,-line 207 - equation - should one of the L* have the t subscript? ,434 435 436 437 438 439 440 441 442 443 444 445 446 447
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"In Table 1, I think it is confusing that a deeper shade of red means better results. ",629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645
5055d6e9bee3c38f171f9a51c2cc9db4023bba622f8b471a60e20864e21b6e012403a4b741ecaf347e239448fde93bfbf299ec9f5ee6bf0091d4c33ee9b19ba0,arr,Todo,Have you thought of visualizing the data on a map? ,155 156 157 158 159 160 161 162 163 164
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,-There are many usages of 'casual' language modeling. ,343 344 345 346 347 348 349 350
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo, ,
ebfe58b10dee02a1cb830e85ec7993f381fa88e9d1e70ec9eba24417b92fdbe8d20ae561d42fbcbdb17d4380fde7845f5850c3fd769aa20c15003fe18fcdfbf0,arr,Todo,Line 473: missing word - “depending on the downstream task of interest” ,205 206 207 208 209 210 211 212 213 214 215 216
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"I understand your point in the definition but, still, when I read ""correlation"" I expect something between -1 and 1 that shows me how much two variables relate to each other.
",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
3a14a02b9c496d9bcd7b06aedeaa8d9c48fa003e7be1b23f9cb631571dd75d894c70b500313f5f1e5ca1c867cfb04c23cad117d1072ae2d0ebbb7964c16ccdf3,arr,Todo,"If you finetune XLM in the target language, do we get better results for MMA-XLM? ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Todo,"Since this is a text generation task and automatic metrics (such as rouge) are not very reliable, I was wondering if you had a human evaluation result? ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,"Yu, Licheng, et al. ""Modeling context in referring expressions."" ",281 282 283 284 285 286 287 288 289
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"-I think that the process of selecting the best-performing model in a smaller experiment and then evaluating it extensively is reasonable, but I am wondering if evaluating the two rejected models, CANINE and Charformer, in terms of robustness could have given other interesting insights. ",523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"12) Line 544: ""... we remove all extra references if a sentence has more than 2 gold-standard references"". ",679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- Typo/grammar near ""there are works (...) disprove"" ",1065 1066 1067 1068 1069 1070 1071 1072
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,"Besides, the information of reference (Merity et al., 2016) are incomplete. ",430 431 432 433 434 435 436 437 438 439 440
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-547: sharing 571: extra space before comma ,465 466 467 468 469 470 471
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"Could be clarified in the ""experiments"" writeup.
",889 890 891 892 893 894 895
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"But, I worry if ESE has application in such scenarios. ",242 243 244 245 246 247 248 249 250 251
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"In addition to the previous question, I cannot find the titles, any meta-information as stated in lines 187-189, nor VAD scores which I assumed would be included.
",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,"This was perhaps meant to be predicted labels and not the interpretations, unless the decoder here is generating the labels - this needs clarification or correction.
",618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,"-Line 130: Explain DM dataset.
",331 332 333 334 335
a09847ed94d9d36c62841908a6163e9cbb9e341099ac05ab01ec5a9c9de0e32dd33a5f044591d548fb961736b3ef91c5043ff5a59632d5bfa86eaf5303e5f438,arr,Todo,Maybe the authors can talk a bit about what the findings of this work imply from the perspective of the creator/maintainers of databases. ,153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 182: discirminate: discriminate ,490 491 492 493
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,RankME: Reliable human ratings for natural language generation. ,642 643 644 645 646 647 648 649
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"-Generally, I found the motivations somewhat contrived (the part about keeping up with high demand for flu queries via adaptively scaling back latency during flu season, for example, or sec 3.1 saying that the fact that there's a discontinuity in the PABEE latency-accuracy tradeoff curve, etc). ",896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-340 (and later): ""Data/Domain Setups"" -> ""Setups"" could either be ""Setup"", or ""Settings""/""Configurations""? ",481 482 483 484 485 486 487 488 489 490 491 492 493
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,"As far as I can say, this is the first investigation in the NLP literature of various entropy estimators, which makes the draft very valuable. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"- Figure 2 also shows where the BLEU is lost in the 10-30% bin, would it be possible to identify all terms in that bin and list them in the appendix with the (source, term) -> LevT vs LevT + ACT outputs? ",346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Todo,"I felt that this paper could do with more citations to the existing literature on morphological/character composition in neural models (e.g., https://aclanthology.org/P17-1184/) ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,Why no Precision-based metric is used? ,804 805 806 807 808 809
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,"Please see my comments above, additionally, 1. ",342 343 344 345 346 347 348
d420c861389d357cba32905a3ce5bdb49ac1f8cf4307e514dd57f7258c3fb92ed2ba9f8ed6236f98685df72905f399b55c3b1807531a2928752890bf72b2f7e1,arr,Todo,[2] https://aclanthology.org/2021.emnlp-main.701/ ,219 220
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo, ,
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Todo,How big is this new subset? ,382 383 384 385 386 387
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,"If that is the case, then how does it impact the efficiency of the model during inference? ",407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,7. ,420
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,	The caption of the table should be put on top. ,225 226 227 228 229 230 231 232 233 234
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Todo,Is this something that could be explored further? ,354 355 356 357 358 359 360 361
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"083 - this paragraph is really good, the explanation helps understand what is done later in the experiments ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,"-line 151: why the length of R is not equal to the one of U?
",525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,Section 2.4: can move data descriptions to the appendix or shorten them. ,358 359 360 361 362 363 364 365 366 367 368 369
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"Particularly, for empathy there are several scale items [1], so why choose the Interpersonal Reactivity Index?
",448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"The paper should further evaluate the boundary smoothing idea in several SOTA approaches.
",209 210 211 212 213 214 215 216 217 218 219 220 221
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,-line 265: concepts ,760 761 762
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,"
4. ",389
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Todo,"Clearly, given the large gap between human agreement and model performance, there's a long way to go with this task. ",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"221: How many query templates did you specify in total?
",235 236 237 238 239 240 241 242 243 244
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Todo,- [1] Compositional Generalization via Semantic Tagging ,269 270 271 272 273 274 275
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"If annotators could not come up with the correct words after 10 predictions probably it means the target word is not recoverable, right?
",668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,"-For Figure 1, I have another angle for explaining why randomly-generated n-grams are far away from the extant words: the characterBERT would explicitly maximize the probability of seen character sequence (implicitly minimize the probability of unseen character sequence). ",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,The paper will benefit from a more in-depth analysis and comparison of the datasets used against a more generic corpus. ,816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,Please do not use such hyperbole. ,777 778 779 780 781 782
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo,Many figures could be wider given the margins for the column. ,498 499 500 501 502 503 504 505 506 507 508
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In Section 4.2.2, is it correct that for each claim-true_sentence_from_review pair, n=number_of_claims incorrect sentences are chosen? ",567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In Section 4.3.3, how do you deal with the RoBERTa token limit? ",722 723 724 725 726 727 728 729 730 731 732 733 734
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,Maybe change the mean reduction to another letter such as M or N. ,1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Todo,what were the hyperparameters used to fine-tune BART?) ,380 381 382 383 384 385 386 387
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,"
Tables 2 to 4 look strange to me without lines.
",458 459 460 461 462 463 464 465 466 467
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Todo,I have nothing to mention here. ,401 402 403 404 405 406
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"
l158 block instead of black l159 ** same as l14 **  l189 ablation l331 missing “not”? ",1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,"line 323: \mathcal{L}(x, y, \tilde{S}, S] ==>\mathcal{L}(x, y, \tilde{S}, S)] ",359 360 361 362 363 364 365 366 367 368
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Lines 214-215: Are the same models trained for both normal language modeling and character-level language modeling without any architectural changes? ,582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,-Reading the Manual: Event Extraction as Definition Comprehension. ,331 332 333 334 335 336 337 338
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo,"-What does it mean to re-normalize class probability scores in Fig 3?
",478 479 480 481 482 483 484 485 486 487 488 489
9c42d14ccc84cf2e86bf494b4f4c72974fc1f55456a9cdd542f9d7654aaf3d5779eb6eac51a4cdb96a2edee8473bb8bdb525a43601d147fbac2e8d290269013a,arr,Todo,"- line 380: ""BIOSE"" --> ""BIOES"" (line 380) ",384 385 386 387 388 389 390 391
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,It is a bit hard to tell at first glance from figure 1 if your method is working or not. ,302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,1. ,320
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"Can some mechanism/layer be proposed to replace that alignment from GIZA?
",310 311 312 313 314 315 316 317 318 319 320
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"
- ",521
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"It is shown"" with ""uncertainty, and shows"". ",290 291 292 293 294 295 296
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo, ,
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"-It is stated that the dataset includes 4,894 documents. ",327 328 329 330 331 332 333 334 335
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-L182-188: an example would be welcome ,150 151 152 153 154 155
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Todo,"
2. ",200
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,I'm interested in the difference between the results of using usual relative position bias and gated relative position bias. ,266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,"In International Conference on Machine Learning, pp. ",529 530 531 532 533 534 535
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,Simple BERT models for relation extraction and semantic role labeling. ,910 911 912 913 914 915 916 917 918 919
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Todo, 2. ,243
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"Among them, the pair of /ch/ and /ah/ looks very different from each other. ",303 304 305 306 307 308 309 310 311 312 313 314 315 316
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Line 420: “the the span classification” ,815 816 817 818 819 820
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,There seems to be a related cross-lingual VLN dataset (English-Chinese) based on R2R -- https://arxiv.org/abs/1910.11301 . ,676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Todo,-Table 3 is labelled as Figure 3. ,211 212 213 214 215 216 217
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"While the manuscript acknowledges that, it does not mention the precise nature of the unfairness. ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,**Questions** ,308
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 233: to better inference -> to do better inference/to infer better ,733 734 735 736 737 738 739 740 741 742 743 744
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"Compared to the main text, I am personally more interested in the point brought up at L595. ",477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo, ,
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 5] lines 470-482: It is unclear what the exact experimental setting looks like for each of the “cross-task” and ‘cross-dataset“ sets of experiments. ,1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Todo,"If ancient Korean only wrote Hanja, why do we call it a 'language'? ",314 315 316 317 318 319 320 321 322 323 324 325 326
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Are these the same?
",489 490 491 492
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Todo,Line 277: “The may be attributed…” -> “This may be attributed… ,590 591 592 593 594 595 596 597 598 599 600
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,"
4. ",547
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Can you describe the two settings “supervised” and “few-shot” in the experimental setup before moving to the results discussion?
",1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Todo,- ,436
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,Is knowledge distillation really always effective? ,145 146 147 148 149 150
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"forbids = blocks, prevents, prohibits, impedes? ",1116 1117 1118 1119 1120 1121
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"I believe also that the choice to go for a short paper was penalizing the authors, as it seems clear that they cut out some information that could've been useful to better understand the paper (also given the 5 pages appendix).
",214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,Specifically for WMT17-WIKT the best result in terms of BLEU is actually in the baselines. ,446 447 448 449 450 451 452 453 454 455 456 457 458 459 460
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- References: They contain the usual missing-uppercases errors.
",945 946 947 948 949 950 951 952
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"- Table 4 (2): The table exceeds the page width; that needs to be fixed.
",659 660 661 662 663 664 665 666 667 668 669 670 671 672 673
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,3. ,436
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,It seems like this wouldn't change the calibration but allows us to estimate the ECE? ,1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(245-246): could be -> should be ,689 690 691 692 693 694
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,"- recently, [1] criticized the usage of standard similarity measures such as cosine and Euclidean distance with contextualized embeddings, given that such metrics might be dominated by a small number of outlier dimensions. ",362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,Some relevant papers includes: (1) Semi-supervised active learning for sequence labeling; (2) Rethinking deep active learning: Using unlabeled data at model training; (3) ATM:  An Active self-training framework for label-efficient text classification. ,279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Todo,Some typos: (1) counter measure --> countermeasure (2) relatively little efforts --> relatively few efforts (3) be harmful for --> be harmful to (4) detecting adversrial misspellings --> detecting adversarial misspellings (5) require training nor validation --> require training or validation ,410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"Maybe rephrase as, ""no standalone dataset to evaluate privacy of training data in a LM""? ",1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"
5. ",258
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"Dropping this, the other implications still hold well and get the point across - the different ranking of certain models, and Auto-Gold conveying a gap between two models where Human Eval does not. ",1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,-Figure-1 did not mention how the proposed CUC-VAE TTS system works in the inference time. ,314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On line 192, insert ""give"" between ""and"" and ""no"".
",359 360 361 362 363 364 365 366 367
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"l127:  ""graduation accumulation"" -> gradient accumulation ",523 524 525 526 527 528
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,-------------------------------- Comments on Structure -------------------------------- ,730 731 732 733 734
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,The paper also doesn’t present a concrete definition of either. ,407 408 409 410 411 412 413 414 415 416
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"Maybe reworking the figure to depict the WiC task would help with both problems.
",385 386 387 388 389 390 391 392 393 394 395 396 397 398
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   Style/typos: ,476
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"line 130, It is confusing why SGD dataset requires manually created dialog examples for prompts; But for MultiWOZ, it just chooses the example from the training set. ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,"Since some of the values between the baseline / gold standard are close to the method’s metrics, it would help solidify the claims. ",756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Todo,- Justify the differences from theoretical algorithm and practical implementation ,596 597 598 599 600 601 602 603 604 605
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,"I think the generator should be part of the joint model?
",610 611 612 613 614 615 616 617 618 619 620
534dd4d039e9277fd00d16e3f1cdf7b7ce3d9bf240f6b3db32d966ede32db1ff6121fa15bfe1ba49c20bf8fe510e0805c0d4cc63da74ec69523a1bab60678fa0,arr,Todo,An English-proofreading would significantly improve the readability of the paper. ,254 255 256 257 258 259 260 261 262 263
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,"This can be ambiguous, for instance you might have a transitive relationship between life events and health, thus the event types are not exclusive (as you mention this was part of your annotation design). ",486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo, ,
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Figure 6. ,1917 1918
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo," Also the level of specificity in Section 2 obscured the exact nature of the approach.
",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"IEEE, 2005.
",532 533
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Todo,Why only use single-pass in online learning? ,329 330 331 332 333 334 335
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"It would be good if the authors explained how the authors convert Levenshtein distance into similarity (I have checked the cited paper, and it does not provide any clue neither). ",432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,Proceedings of the IEEE conference on computer vision and pattern recognition. ,577 578 579 580 581 582 583 584 585 586 587
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,So you weren't but still did the study. ,222 223 224 225 226 227 228 229
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,- How the authors have resolved the possible doubts of the annotators while the annotating process in MTurk? ,364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Allsides.com is cited as (all, 2021) and (Sides, 2018); the year is missing for the citations on lines 110 and 369; Entman (1993) and (2002) are seemingly the same citation (and the 1993 is missing any publication details); various capitatlisation errors (e.g. ""us"" instead of ""US"" on line 716) ",914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Todo,I suggest using a consistent font for the caption and the main text. ,195 196 197 198 199 200 201 202 203 204 205 206 207
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Todo,(I provided full details in strengths and weaknesses above.) ,373 374 375 376 377 378 379 380 381
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"I'd be more interested to see a review on multilingual benchmarks and probing tasks, especially for morphologically rich languages. ",291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"While the error analysis is conducted in Appendix, there is no case study to make the improvement more concretely. ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
a2dbb4d1f528e4c6c48a51354adb882d3af65dffe69005a325d024c09982fd4dc72e38f8af529d3c0d8145db9095fa881f644d51f888c58b24b952fe51374be4,arr,Todo,See above ,220 221
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,minor: 1. ,187 188
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,-It would be interesting to see what human behavior is for these prompts/comparisons... ,1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,-Could the annotation scheme be easily scaled up to more domains? ,453 454 455 456 457 458 459 460 461 462 463
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,567: We -> we ,283 284 285 286
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,"For example, Line 313, the submission says “this work is among the first to introduce a span-based approach to Chinese NER tasks and establish SOTA results.”, ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"With regards to the model section, is there any particular reason that there was an emphasis on choosing retriever-based transformer models over generative models? ",461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"Why the human evaluations for the two languages were different?
",595 596 597 598 599 600 601 602 603 604
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Which layers are the ones actually being used? ,686 687 688 689 690 691 692 693
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,There is an error in bold T4 in the lower table of Table1. ,109 110 111 112 113 114 115 116 117 118 119 120 121
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation. ,546 547 548 549 550 551 552 553 554 555 556 557 558 559 560
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,-Line 229: most simple —> simplest ,1388 1389 1390 1391 1392 1393
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Todo,It would be very helpful to the reader for those to appear much ealier in the paper. ,130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," (Whereas I know quite well how much intuitive importance to give 0.7 BLEU.)
",587 588 589 590 591 592 593 594 595 596 597 598 599
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"In table 1, is there any particular reason for the reduction in pass rate % from free run 1 and free run2? ",402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Todo,Typo. ,201
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   * Lines 250-52: what does this mean? ,469 470 471 472 473 474 475
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo, ,
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,Interpretation of the results are offen missing. ,129 130 131 132 133 134 135
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Todo,"to trained the model"" => to train the model ",234 235 236 237 238 239 240 241 242
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Todo,As different communities would be interested in different aspects of this paper. ,276 277 278 279 280 281 282 283 284 285 286 287
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 520: prodduct -> product ,541 542 543 544 545
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"-How accurate are the automated classification in the breadth-of-posts experiment, i.e., how well does the states technique differentiate identity vs non-identity vulgarity or AAE language for that particular dataset. ",520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548
6bd292c3f083f1a278739bedb1db76eb53014bcfa286c850680811f20b8fe3f79ba1881809e4fd3532754f4e6344d24365f551e1c879292061577d5b3b70f0e6,arr,Todo, ,
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Todo,This paper shows KG link prediction performance from the proposed model trained on Wikidata5M in section 4.4. ,175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,- line 69: adversrial ,510 511 512 513
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,"c) How do you know that a row in a table is actually true? :)
",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,Do you choose a certain number of sentences or do you define a cut-off threshold? ,618 619 620 621 622 623 624 625 626 627 628 629 630 631 632
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,"Lines 088-092 Last, the over-belief in existing evaluation metrics encourages efforts to propose more accurate attribution methods, notwithstanding the evaluation system is unreliable.
",772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Todo,Is the proposed improvement also additive? ,339 340 341 342 343 344
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo, ,
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,The argument about the new metric MAP at gold-k is not solid. ,286 287 288 289 290 291 292 293 294 295 296 297
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Todo,Subramani et al. 2019) ,653 654 655 656
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,Finetuning a model on labeled training data for the target task is usually computationally not so costly and having more diverse supervised data almost always greatly helps. ,423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,There are at least three basic sub-problems. ,184 185 186 187 188 189 190
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,- I don’t quite see where p(x|c) fits into equation 1. ,221 222 223 224 225 226 227 228 229 230 231
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,The point is that both the resources and the process used to build the geographical maps of the datasets are incomplete. ,624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Todo,Such dispersion is only encouraged by considering hinge losses or using spread out regularization (e.g. by equation 6 in this paper). ,423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Todo,In ACL 2021. ,579 580 581
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Todo,"l. 331: ""same approach"" - which one? ",335 336 337 338 339 340 341
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,Why using RoBERTa as the baseline? ,258 259 260 261 262 263
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,-Lines 237-238 and Line 262: Why would you want to use the representation from the critic last layer? ,202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,Typos ,330
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,[1] Ravichander et al. 2021. ,348 349 350 351 352
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- When reading the first part of the article, the authors tend to associate the term ""CLIR"" mainly with theirs and similar approaches, in contrast with the classical MT+monolingual IR approach. ",523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Todo,N/A ,199
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"isn't simplification the point of this task?
",259 260 261 262 263 264 265
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"Similarly, for those tasks, why is Autoprompt chosen as the only reference approach to compare against? ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Todo,"The authors would better evaluate the performance of the defense method combined with the proposed detection model compared to existing defense methods.
",388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"2) Line 53: ""Because, obviously, there are usually multiple acceptable references with close meanings for an incorrect sentence, as illustrated by the example in Table 1."" ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo," For example, if we want to get an idea of the absolute readability for a new document compared to a set of S other documents that have ""already been scored"", we would have to re-run the NPRM over the S documents in your comparison basis. ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"  This section seems to be pointing out that attribution methods have a problem of domain   faithfulness in that they often internally apply a model to inputs that they have not been   trained on or don't expect to operate reliably on.
",885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,These assumedly interact and each of them contribute to the speedup. ,843 844 845 846 847 848 849 850 851 852 853
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- Grammar issue near ""achieve 86.4% accuracy"" ",1219 1220 1221 1222 1223 1224 1225
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,This sort of language not useful. ( ,460 461 462 463 464 465 466
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,"-In Section 4, it would be better if some paragraphs are split, and the meaning of results would be better presented if organized into a single table with the interpretation.
",300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"The   Figure is suggestive of it being a triviality.
",1132 1133 1134 1135 1136 1137 1138 1139 1140
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- The term ""logic traps"" is not define or explained. ",1014 1015 1016 1017 1018 1019 1020 1021 1022 1023
03cb8483ba66064a3c9b4a132af185e861b3dd292bf0b90105956dfbf7cc7e88e5bff423e0904e34b16baa401f61c0938331c4795c5fcfa86fdf99d4eb48c7af,arr,Todo,255-257: Can you please explain why this is the case? ,240 241 242 243 244 245 246 247 248 249
9f16d7fbb89be40b6fa6ff149aa34cfcad08f2a811b1bef57d6136992bef789a65da497e685cbeb4e29335b120aaf58d3d7240a775eb25c9fe8bec3fa6bf4ffc,arr,Todo,What’s the performance of the proposed method on the Yes/No answer which cannot be extracted from passage? ,156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,W.r.t. ,410
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,"It's a little confusing now since you mention mortality prediction and say precision@topK, which isn't a regular binary classification metric. ",517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,As mentioned above: ,425 426 427
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"L543: What is continuous pretraining?
",406 407 408 409 410
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,"The presentation can be improved, e.g., “To train word embeddings” (line 298) and “to obtain word embeddings” (line 301) are repetitive. ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,- The hyperparameter section is rather terse. ,296 297 298 299 300 301 302
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,2. ,208
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"- Maybe I'm reading too much into Table 4 results, the improvements clearly comes from the constraint training, esp. ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,2020. ,355
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Todo,AL in ML setting could be a line to pursue further. ,154 155 156 157 158 159 160 161 162 163 164
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,"-L228: I think the grammatical errors in questions in QA datasets are not necessarily problematic but rather important characteristics because a QA model is sometimes required to be robust to these errors in real-world applications as claimed by [1].
",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Todo,"Typo/gramma: Sentence starting on line 614: ""The proposed in this work method based on the Mahalanobis distance and spectral normalization of a weight matrix..."" ",250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"-A bit pedantic, but Jabberwocky words are non-existing nonce words, whereas the setup that the authors arrived at is only semantically nonsensical, yet still made up of existing words (a la ‘Colorless green ideas’). ",880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,"Additionally, they argue how this might not be the case for the CLIP [EOS] token. ",366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Todo,"
3. ",262
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-Do you have an idea/conjecture why DeepL is so much better? ,520 521 522 523 524 525 526 527 528 529 530
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Todo,- It will be interesting to drop the control sequences from the gold labels (or replace them with negative ones) one after one and see how the automatic metric changes. ,221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," Since they were added only after the first revision of the paper, I felt like they weren't fully integrated into the main text or all of the results tables (like Table 5). ",417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo,"
Why only 50 arguments from Africa but 100 from India and China? ",635 636 637 638 639 640 641 642 643 644 645 646
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 044: human -> humans ,689 690 691 692 693
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,-Line 400-401: check grammar ,369 370 371 372
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Todo,"This paper is a resubmission from ARR August, and it has not been significantly improved. ",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Todo,"Even if there is high instance-level correlation, there could be different patterns at the system-level, for example if a metric has a small but consistent bias for or against a particular system's outputs. ",315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,Typos: -	Line 259: “cotation” -	Line 285: Missing “.” ,314 315 316 317 318 319 320 321 322 323
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"
How does the gradient search algorithm decide on where to put the word vectors and hidden state vector? ",504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Todo,1. ,526
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"How does that inform future decisions when choosing the source tasks given a known target task?
",1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,7. ,1329
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,"In Table 14, the α and overall accuracy are especially low for India. ",377 378 379 380 381 382 383 384 385 386 387 388 389
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 5] Subsection Header: “Fully-Supervised Setting” is not self-explanatory. ,1098 1099 1100 1101 1102 1103 1104 1105 1106
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,**Typos:** ,255
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo,"
2. ",257
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"
2. ",95
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Todo,~L130 ,184
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Todo,I suggest the authors put all the tables and figures at the top of the pages. ,266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,What's the input and output of the minus operand (it has two outgoing arrows?); ,357 358 359 360 361 362 363 364 365 366 367 368 369 370
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,Here are some questions: 1. ,134 135 136 137 138
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"In a CLIR context, a more accurate translation (e.g. being able to translate one more term of the input query) allows new matchings, thus improving recall, regardless of the ranking position where the new documents are retrieved.
",908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L360: “is” -> “are” ,652 653 654 655 656
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L300: The presented sentence here is a series of numbers and not tokens. ,562 563 564 565 566 567 568 569 570 571 572 573 574 575
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"This could be stated more explicitly in subsecs 2.2 and 2.2.1 (I may have just missed it).
",1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"-060: how do you define a difficult word?
",206 207 208 209 210 211 212 213
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,Additional relevant literature: ,272 273 274
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Todo,Maybe it would be helpful to explain why you didn't choose answer accuracy. ,499 500 501 502 503 504 505 506 507 508 509 510 511
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,"COLING 2020.
",312 313
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,"-L350: The sentence about question-type utterances sounds detached from the paragraph.
",474 475 476 477 478 479 480 481 482 483 484
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Todo,"In general, the paper perhaps should also mention the line of work that treat alignments as latent variables, e.g., [2, 3] ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,Consider explaining the tasks and performance metrics when you call them out in the abstract in a little more detail. ,497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Todo,Can the authors elaborate on how significant the conclusion is and why we need such deliberately designed probing tasks? ,255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo, ,
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,"It would be better to maintain consistency.
",442 443 444 445 446 447 448
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,Part of the motivation is that scaling the production of neutral (all-sides) summaries is difficult. ,317 318 319 320 321 322 323 324 325 326 327 328 329 330 331
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,Detecting Adversarial Samples Using Influence Functions and Nearest Neighbors. ,603 604 605 606 607 608 609 610 611
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,1. ,187
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Todo,"-line 541: ""We observed that"" is repeated twice ",180 181 182 183 184 185 186 187
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Todo,"-Is the [MASK] token applied to the omitted characters in the insertion task?
",390 391 392 393 394 395 396 397 398 399 400 401 402
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On line 050, replace ""consistently observed"" with ""been used to create"".
",314 315 316 317 318 319 320 321 322 323 324
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,"For the case of Cont, are there any disadvantages for not using a general-purpose model/data? ",743 744 745 746 747 748 749 750 751 752 753 754 755 756 757
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"If available, it may be better to be incorporated.
",377 378 379 380 381 382 383 384 385
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,-Do you perform re-annotation for the expanded dataset as well? ,323 324 325 326 327 328 329 330 331 332
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo, ,
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"My guess is that for every sentence in the training set, its truncated LCT was obtained, and then a dictionary was created with these LCT being keys. ",1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"7) The explanation that must be generated for the query, the correct answer, and the incorrect answers could be slightly different. ",534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Todo,Typos: ,457
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,In Proceedings of the 2020 AACL-IJCNLP Main Conference. ,394 395 396 397 398 399 400 401
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo, ,
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Todo,"1) Relating to weakness 2), the authors need to properly measure gradients during training and validate their hypothesis about vanishing gradients, which would be easy to measure with norm of gradients. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Todo,Add more baselines including simpler ones as reference ,514 515 516 517 518 519 520 521
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,- I am a little unconvinced by the discussion in lines 477 to 486. ,185 186 187 188 189 190 191 192 193 194 195 196 197 198
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Todo,One suggestion is to mention in a footnote why it is difficult to present back-translation baselines (like you explain in your letter). ,150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,"In this field, it's typical to refer to learners' responses to questions as ""responses"" rather than ""submissions"". ",370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Todo,"- In section 6.1, it is unclear why and how negative sampling (DCLR) has to change. ",338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"- Section 4, lines 404-411. ",265 266 267 268 269
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,Some re-writing for clarity might help here. ,483 484 485 486 487 488 489
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"A Comparative Study on Schema-Guided Dialogue State Tracking."" ",417 418 419 420 421 422 423 424
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"-Line 107 data, -> data.
",257 258 259 260 261
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Todo,See above weakness section ,380 381 382 383
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Todo,Two typos that could be addressed: ,451 452 453 454 455 456
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-304: Don't you only have the corrupted text as the input for the reconstruction (also as shown in Fig 2)? ,299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,Some parts of the main text are duplicated (Section 6 is already found in pieces in previous sections) on the other hand some relevant information is ignored here. ,474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,"If this percentage is large, will that create a roadblock in the wider applicability of this language model? ",777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,"d) What hardware did you require?
",244 245 246 247 248 249
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,- Line 195: plane -> hyperplane ,750 751 752 753 754 755
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,"	For the end-to-end variant, are the retrieving and the reasoning also intertwined as in previous works? ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Todo,I thought the monotonic means the sequence h->s->r. ,174 175 176 177 178 179 180 181
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Todo,"I'm not against using WMT14 En-De, however, WMT13 En-Ru is rare in the research community recently. ",409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"This is argued based on the finding that ""with a small number of cognitive signals (voxels), TinyBERT for CNM can achieve a good task ranking score"" (line 566ff). ",557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"- The paper may discuss why use MeSH rather than other ontologies like UMLS, SNOMED, HPO etc.
",487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,- Causal effect results. ,369 370 371 372
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"The same for some of the historical entities that no longer exist, but some of which have corresponding GPS coordinates that could be used. ",600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"
l24 make achieve l29 have become or became l33 remove “and” l39 remove comma, add “and” l58 have no doubt (need a comma or without have) l65 much often (add more)  l81 drop “the” l89 process = handle, deal with? ",1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Todo,N/A ,327
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"May be, reposition Figures 1 and 2 to use the page space more efficiently?
",327 328 329 330 331 332 333 334 335 336 337 338 339 340
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"L337: It's not clear why the authors chose to use 41k pairs and not the full dataset.
",463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Todo,1. ,328
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,Do you think this could be affecting your results? ,395 396 397 398 399 400 401 402 403
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,Could you please elaborate more? ,457 458 459 460 461
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Todo,Does this selective attention only work on patch-based vision models? ,188 189 190 191 192 193 194 195 196 197
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Todo,-line 499-500 “a more strict experiments” ? ,303 304 305 306 307 308 309
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,319 - experimental setting --> experimental settings ,506 507 508 509 510 511 512
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 5] 493-509: For each of the paragraphs describing the results, can you add specific references to the Tables the reader should refer to? ",1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271
fcc2d390db2717ce8d77836ca10248ee73a8d94600bd9528cef5d26d16f18393f230b60463fae854e5f652936577b5b37ccc698e95ca831fa89d8e7a12079552,arr,Todo,"Many mistakes, for example Eq.6 does not have the summation. ",200 201 202 203 204 205 206 207 208 209
e41e88092bada9f75b4ce8778855411e128fea782712d728ff13b90f98386e6c97f5b383da31df5f5ad9aed07e2e3af42ad0fe8ce53e7dc9d81130c9d24a351e,arr,Todo,Typo; L653: release->released ,71 72 73
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Todo,"In the Target segmentation, it is not clear, what can we do when the number of sentences is lower than K ? ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Todo,None ,170
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"This contradicts with the claim that SkillSpan incorporates both hard and soft knowledge.
",349 350 351 352 353 354 355 356 357 358 359 360 361
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"In Proceedings of the 13th International Conference on Natural Language Generation, pp. ",564 565 566 567 568 569 570 571 572 573 574 575
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"However, the paper organization can be improved. ",99 100 101 102 103 104 105
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(180): same -> the same ,650 651 652 653 654
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 163: dataset annotated by human -> human-annotated dataset ,717 718 719 720 721 722 723 724 725
25ecf77df8e811b8c942cb9933c4bd14112d1de9ed3f8989adcb669076c94472a9497f9ae80d57e03ed8fcb031fa6f84877d8faf869d641e622e8ddebd622cca,arr,Todo,I would recommend revisiting strong assumptions being made in this paper. ,214 215 216 217 218 219 220 221 222 223 224
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,Why are the captions of table 3 and table 4 going above the figure and not below? ,674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.2 -- It's not clear what TPT stands for when the term is introduced.
",459 460 461 462 463 464 465 466 467 468 469 470 471 472
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,"
Is your dataset intersected with CLPsych 2019 dataset (Zirikly et al. 2019)? ",527 528 529 530 531 532 533 534 535 536 537 538
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Todo,As such the claim of uniformity should be removed from lines 225-228. ,444 445 446 447 448 449 450 451 452 453 454 455
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"Ln 346: This method for producing sentence embeddings is not immediately problematic, but still just one of many ways that could affect results. ",550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,3) Figures and presentation: ,613 614 615 616
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,Are they expected to process the same or similar levels of RC skills? ,484 485 486 487 488 489 490 491 492 493 494 495 496
dd23042b3a19ead6484687423764d8156f6ea40cec4ccceb6d27ccc6305223ed76957ad46eae750d95766cc378fb0b332d4fcd737dc810c4bee6e8823ca79884,arr,Todo,See Weaknesses ,179 180
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Todo,It might be possible to try to make this clearer. ,253 254 255 256 257 258 259 260 261 262
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Todo,"In line 165, you don't explain ""DP"", although it is recoverable through the context. ",289 290 291 292 293 294 295 296 297 298 299 300 301 302
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,"How do OOV words get generated under this formulation?
",461 462 463 464 465 466 467 468 469
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"-A nit but i might use something other than ""distance"" to describe $d$ in line 231, since it's not in general a valid distance metric, maybe ""calibration mismatch"" or something.
",1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
2. ",424
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Todo,"Typos: (Line 514) For each size, we sample and 5 different datasets and average over 2 training random seeds. ( ",315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
3a14a02b9c496d9bcd7b06aedeaa8d9c48fa003e7be1b23f9cb631571dd75d894c70b500313f5f1e5ca1c867cfb04c23cad117d1072ae2d0ebbb7964c16ccdf3,arr,Todo,Therefore we should expect the same thing when fine-tuning XLM in the target language. ,182 183 184 185 186 187 188 189 190 191 192 193 194 195
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Todo,The paper lacks adequate verification for the idea. ,172 173 174 175 176 177 178 179
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,You can probably do away with some repetitions of long sentences such as what is in the introduction as well as in the conclusion. “ ,856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Please clarify these points in the paper. ,331 332 333 334 335 336 337
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo, [Section 5] lines 448-449: Which PLM is used by your approach? ( ,1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,Could this improvement just be due to randomness? ,566 567 568 569 570 571 572 573
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Todo,1. ,215
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,- line 269: missing the right $|$. ,503 504 505 506 507 508 509
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Todo,The paper is well-presented. ,582 583 584 585
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"Since the colon has usually a different meaning in natural language, do they think it may have an impact?
",408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Todo,"Line 17: add a space ""datasets. ",252 253 254 255 256 257
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,"- For ""still uses original assignment scores as input, so the gate signal can also be learned in training stage 2"" (line 215 to 216), the routing strategy is fixed, so how the gate single could be also learned during stage 2? ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,This will make the reader's life much easier since []_{ij} would then always refer to the attention between the subject and context. ,332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,Can you provide some examples content/question/answer-choice triplets from ReClor? ,433 434 435 436 437 438 439 440 441
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"-Another related issue is, if the dataset was annotated on a syllable basis, how useful will be such an annotation for NLP tasks? ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Todo,"Given the training data sizes differ a lot, I would like to see an ablation that the model is trained on a mix of multilingual data with the same overall dataset size as the monolingual. ",542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Maybe simply state that better metrics are needed for ARA evaluation? ,479 480 481 482 483 484 485 486 487 488 489
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Annotating topical adjectives that indicate countries seems doable, based on the anchor texts of links pointing to countries, which are easy to obtain (for some languages). ",574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Todo,An auto Schema Extension method would be more exciting. ,305 306 307 308 309 310 311 312 313
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Todo,+ Performance of each teacher model should be shown in Table 1. ,135 136 137 138 139 140 141 142 143 144 145 146
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,"For example, Line 549 says, ""Figure 6(e) and 6(f) show the results"". ",409 410 411 412 413 414 415 416 417 418 419 420
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"l.260-265 ""most of the sentences are considered to contain grammatical errors in the previous annotation, but a considerable part of them are not corrected in our annotation"" ",118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,-can you include more details on the selection criteria for candidate examples from reddit (section 3.1). ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"How can a neural network depend on the length of the input?
",635 636 637 638 639 640 641 642 643 644 645 646
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Todo,"Referring BART as Transfermers in table 5 is misleading, could just write BART to indicate it is pretrained. ",124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,**Comments:** ,292
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Todo,"Page 6, line 542, compact --> complex ",162 163 164 165 166 167 168
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,"This is also important since the domain is computer networking which changes fairly rapidly.
",272 273 274 275 276 277 278 279 280 281 282 283 284 285
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Lines 138-145: The paragraph starts with talking about general language modeling and formulates it, and then claims this is only a special type of language modeling (i.e., autoregressive language modeling).
",480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Todo,A number of typos exist. ,734 735 736 737 738
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,line 304: \mathcal{X} \cdot \mathcal{Y} ==> \mathcal{X} \times \mathcal{Y} ,341 342 343 344 345 346 347 348 349
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"Moreover, in Fig. 2 the sentence starts with 1 and not with 0.
",592 593 594 595 596 597 598 599 600 601 602 603 604
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Appendex. ,261
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,"ACL/IJCNLP.
",295
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Todo,Potentially important citation ,207 208 209
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo, ,
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Todo,Comments:  1. ,223 224
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,-121: Not clear if you propose these tasks or only combine them into a pipeline? ,248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Todo,- Their model shows improvement in low resource setting. ,221 222 223 224 225 226 227 228 229
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,- There is missing work of Cheng et al. 2021 (Argument Pair Extraction via Attention guided Multi-Layer Multi-Cross Encoding) ,260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Todo,"the proposed LaPraDoR achieves relative low performance on MS-MARCO while relative high per- formance on BEIR, the inductive bias of the proposed pretrain method is worth exploring. ",393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"See the Citation section here: https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation ",398 399 400 401 402 403
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo,"- In the introduction you should give more credit to Myrossef et al. As far as I am aware they were the first who proposed to convert data-to-text generation to text-to-text generation (their model is not zero-shot, and you have enough of a contribution here to give them appropriate credit). ",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,-How many ASCs have been argued to exist (within English)? ,929 930 931 932 933 934 935 936 937 938
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"For instance, relation extraction, where we usually extract the NEs and the find relations between them. ",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"-""and thus relatively frequent occurrence of out-of-vocabulary tokens."" - ",675 676 677 678 679 680 681 682 683
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"ICLR 2019.
",732 733
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Moreover, which criteria is used to count the tokens? ",827 828 829 830 831 832 833 834 835
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,"For example, the generated span maybe not appear in the input sentence.
",292 293 294 295 296 297 298 299 300 301 302 303
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Todo,- I am curious about the number of total predictions to be made for a single input. ,231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Todo,"The number of BARTword + text smoothing and BARTspan + text smoothing on SST-2 in Table 3 should NOT be in bold as they cause degeneration of the performance.
",460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 4] lines 242-248: Does that imply that both source prompts and clustered prompts are included in the pool? ,872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,Proceedings of the IEEE conference on computer vision and pattern recognition. ,309 310 311 312 313 314 315 316 317 318 319
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,Here the   opposite conclusion to Opinion A is helpful. ,720 721 722 723 724 725 726 727 728
9718a739d8caa017664be63a426c74dc7d8daff635c7dfdb44370137bf06fe6e6e1668afefb0860bc026efb02485979591635a255987a98fd6dfde30e4ab8f8c,arr,Todo,"Some typos to correct.
",152 153 154 155
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,-l. ,245
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"In my opinion, every study that directly contributed to the 2 claims from the abstract, should be moved to the main paper. ",754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Todo,See above ,327 328
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"-Try to better align the figures with the text.
",274 275 276 277 278 279 280 281 282
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Todo,I think it would be better to have examples of different predictions using your text smoothing approach. ,163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"Maybe you mean ""To support GEC research/development/solutions""?
",244 245 246 247 248 249 250
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Todo,1. ,293
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"
    5b. ",1028
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"-Chopra, Sumit, Raia Hadsell, and Yann LeCun. "" ",500 501 502 503 504 505 506 507
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Todo,I think this paper is well-written and easy to follow. ,269 270 271 272 273 274 275 276 277 278
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,  ,
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,"It is useful to know where they come from.
",728 729 730 731 732 733 734 735 736
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Is cross-model prompt transfer something that would be useful in practice? ,269 270 271 272 273 274 275 276 277 278 279
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,"- Even without a formal significance test, can we have some intuition about this ECE score in Section 6.1 / Table 4? ",528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,-Line 426-Table4: What do you want to demonstrate here? ,412 413 414 415 416 417 418 419 420
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"
2. ",106
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,Currently this paper is okay but not novel enough. ,199 200 201 202 203 204 205 206 207
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,063-065 Though most of the existing studies consider the expansion a regression problem ... -> Missing a reference to support this statement ,115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Todo,"- Without looking at the Appendix, I found it difficult to interpret the different reasoning strategies mentioned in Section 3.6 and Table 5. ",228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,-Line 118: significant performances —> very good/high/strong performances ,1375 1376 1377 1378 1379 1380 1381 1382
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,"But it’s okay to use it as a coarse approximation of fluency.
",467 468 469 470 471 472 473 474 475 476 477 478
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"However, your rational for creating your own fake news is the lack of sufficient existent data. ",548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Todo,Questions: 1. ,345 346
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"(Question 2) In L908, Q_K and Q_K^NN are mentioned. ",201 202 203 204 205 206 207 208 209
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo,why? ( ,437 438
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,how there examples are selected? ,386 387 388 389 390
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Todo,"
The variables in formula 1 and 2 should be explained, for example, what is pair_asp. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
3398ca971c1ee00e7f56db6a5d9069a561805ba4bd33e4cc84ef6a4c1acf331a4d8c1a7e53ebf415d32cbefe4396b1808e031ddcef812a37768f40bde058252f,arr,Todo,-- some of the formal notations introduced in chapter 3 would probably be easier to understand if put in words -- but I realize that that would make the paper yet longer again ,149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,"40: ""... previous studies have shown the benefit..."" Citation?
",266 267 268 269 270 271 272 273 274
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- Several points in the paper use phrases like ""A lot of works ..."" or ""most existing methods ..."". ",1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo," Does this happen in the performed experiments?
",357 358 359 360 361 362 363
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"- There's two task-specific hyperparams to set to parameterize early stopping, aren't there, the $\tau$ param which binarizes the ""is this a low-entropy-enough"" decision, and the number of layers after which stopping occurs if the entropy's sufficiently low, I believe. ",803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"-Figure 3: Please, rephrase the caption of the errors bars (or explain it in the text). ",333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo,-do feature attribution approaches completely miss some types of word-level errors? ,449 450 451 452 453 454 455 456 457 458 459
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,1. ,492
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Todo,The methodology section needs re-working and ideas could be better presented. ,332 333 334 335 336 337 338 339 340 341 342
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Todo,This is true of textbooks and big review papers. ,662 663 664 665 666 667 668 669 670
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"  Finally, it is well understood that what is correct to a human may not be correct in a model as   per faithfulness vs. explainability discussion which is had alongside attribution evaluations in   literature and in Opinion A (some examples from cited works below).
",619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Line 217: “we can subdividing” -> “we can subdivide” ,800 801 802 803 804 805 806 807 808
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Todo,1. ,118
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"-""does not apply non-linearity"" -> ""does not apply a non-linearity"" ",702 703 704 705 706 707 708 709 710 711
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"In Table 2 it is non-intuitive that the first row is CHRF and the second row is COMET - and the table is quite hard to read.
",646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,"If so, is it possible to evaluate over annotated dataset? ( ",280 281 282 283 284 285 286 287 288 289 290
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,4. ,462
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo," Please highlight the difference in the description in Section 4.4.
",472 473 474 475 476 477 478 479 480 481
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"Same for ""core"", ""pseudo syntactic"". ",766 767 768 769 770
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,Doesn't really offer much insight. ,370 371 372 373 374
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"
2. ",352
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,9. ,499
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,--- ,890
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Todo,"L389, augment -> argument ",250 251 252 253
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,"Or am I misunderstanding something?
",308 309 310 311 312
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Todo,"I think there are also significant applications the other way, particularly in metaphor generation, where the literal interpretations can be used as input and the metaphors as output. ",537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,Questions:  ,409
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo, ,
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo, ,
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,  ,
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,"A1: Would you give some suggestions based on current results about which part can be discarded first if computational efforts are constrained?
",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Well, DVD-DST - what does DVD mean..... A better name is strongly suggested since ""DVD"" seems to distract readers from its real meaning. ",873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-For DocRED, did you consider the documents as an entire sentence? ",438 439 440 441 442 443 444 445 446 447 448
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"Can you explained more about the relationship of Memory, Memory Bank, Memory Knowledge and Embedding Knowledge in your paper? ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 4] lines 379-401: The ‘Model Discussion’ subsection seems more of an outline of the approach rather than an actual discussion. ,957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977
f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297,arr,Todo,"
2. ",124
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,Another workaround is to rephrase the motivation to make this paper focus more on the non-header part. ,514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,I understand that it probably isn't the case but the deep dive here is not warranted really in my opinion. ,758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Todo,Do the method extract grandpa nodes? ,185 186 187 188 189 190
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Todo,l. 287: serveral → several ,286 287 288 289 290
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"Furthermore, are these incorrect sentences chosen from one other review article or each sentence from a different review article? ",584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,Why does LM-base perform so well compared to CGExpan in user-generated datasets? ,550 551 552 553 554 555 556 557 558 559 560 561
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,Is this work using the original checkpoints? ,319 320 321 322 323 324 325
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Todo,Move the Appendix header to page 11 ,338 339 340 341 342 343 344
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,"I'm still not sure though, what Overall indicate in Table 7 ",164 165 166 167 168 169 170 171 172 173 174
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"-In the Audio-only model, what are the differences from Watanabe et al., 2017? ",197 198 199 200 201 202 203 204 205 206 207 208 209
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,Why does CRL (w/o KL) sometimes perform better than CRL in Table1? ,133 134 135 136 137 138 139 140 141 142 143 144
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"It would be interesting to rerun the same evaluation with different permutations (e.g. center first, or right first). ",714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,The paper mainly experiments with the biaffine dependency parser. ,301 302 303 304 305 306 307 308 309
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,"
2. ",263
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"Some typos and awkward/redundant/unnatural sentences such as lines 019, 041-043. ",773 774 775 776 777 778 779 780 781 782
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,When you decide to make small changes to the context? ,283 284 285 286 287 288 289 290 291 292
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,I would suggest adding one or more existing end-to-end MNMT models that enable XY translations into the baselines for comparison. ,298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Todo,"
2. ",148
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"Levenshtein is a distance metric (lower is better), not a similarity (higher is better) one afaik. ",416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,5. ,291
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Todo,"
		2) In addition to STS tasks, the authors could also explore a number of downstream tasks as implemented in SentEval to evaluate the quality of sentence representations. ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"
3. ",180
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Todo,"Citation should be formatted like so: ""The consensus points to BERT-like models having some capacity for syntactic understanding (Rogers et al., 2020)."" ",506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,"
2. ",484
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,The writing is not fluent enough. ,767 768 769 770 771 772
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Todo,I think the overall writing is clear and understandable however I thought it could be better organized in some sections: ,306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Related to the previous point, it's not clear what the case study mentioned in Section 4.2 actually involved. ",528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"Many…"" ",282
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 286 - Here the datasets point back to QA, but translation is covered, what is this paper about, QA? ",588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Todo,Figure 1 perhaps has space to make some of the text a bit larger ,415 416 417 418 419 420 421 422 423 424 425 426 427 428
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Typos: ,631
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"
-Add examples from the dataset and especially from the datasets on which the three proposed tasks are based on. ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Lester et al. 2021 found the original T5 checkpoints didn't work well for prompt tuning, and used LM-adapted checkpoints instead. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"In summary, the relationship between storage capacity (n, apparently maxing out at Upperbound in Figure 2) and performance appears an important factor to explore for the various memory-based models, since the memory-performance tradeoff is central to such models (as otherwise there appears no need to innovate if all old samples can just be stored). ",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo," Or are there particular applications you can see where this comparison problem as not being as much of an efficiency issue.
",291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,-l. ,275
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,The datasets utilized are based on topics. ,295 296 297 298 299 300 301
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,-Multi-events: Can DEGREE and DEGREE(ED) deal with multiple events of the same type in the same sentence? ,179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"Specifically, it's not intuitive to me why the voxels had to be randomly selected (line 400f).
",664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo, ,
1f3ed846cf117ae2eecd5e3d9d19a85c37510c11c3463afa9ded734ea9f7dc0569a0ad64808fed511202bc3a62103801e85b7e7d14a8617220cf2ec989190cb1,arr,Todo,n/a ,143
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"However, the second and third headlines don't make sense as stand-alone texts. ",259 260 261 262 263 264 265 266 267 268 269 270
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"This point should be clarified.
",253 254 255 256 257
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,1. ,305
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,- BertScore and BLEURT are inconsistently typeset through the paper (alternatively as Bertscore or Bleurt). ,427 428 429 430 431 432 433 434 435 436 437 438 439 440 441
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,Not clear how the perplexity is applied in the evaluation of the RetroGap challenge. ,268 269 270 271 272 273 274 275 276 277 278 279 280 281
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,VLDB Endow. ,425 426
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,Could you not show easily an f-score as you have already done? ,746 747 748 749 750 751 752 753 754 755 756 757
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo, ,
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"
In general the figures in the appendix could use more explanation (e.g. what are the color indices in Figures 8,9; what are the subjects in Figures 6,7). ",613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"Or, translation? ",612 613
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,is it learned during training without supervision and how? ,389 390 391 392 393 394 395 396 397
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"- It is great to see that confidence scores were reported for the obtained results, but how exactly are they calculated?
",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Todo,Theoretical analysis and evidences should be added in the paper in addition to experimental evidences. ,252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On line 466, insert ""and"" in front of ""only"".
",424 425 426 427 428 429 430 431 432
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Todo,"Organize the results in a more reasonable way, e.g., highlight what we can learn from each result. ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,-Are the Self-paced learning results all from another paper? ,362 363 364 365 366 367 368 369 370
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,"Did you try using the average of all the subwords?
",372 373 374 375 376 377 378 379 380 381
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,Uto et al. (2020)'s system reaches a QWK of 0.801 by using a set of hand-crafted features. ,259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,"line 520).
",476 477
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo, ,
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"From my point of view, there is considerable overlap between ""make entity recommendations"" and ""transferring from chit-chat to task-oriented dialogues and completing a task the user may want"". ",297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,Line 543-546: not understandable. ,816 817 818 819
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,"
2. ",357
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Todo,Some examples could help the audience to better understand the importance of length-control inference. ,139 140 141 142 143 144 145 146 147 148 149 150 151 152
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,We see that only 3 out of 9 problems are related to terrorism. ,695 696 697 698 699 700 701 702 703 704 705 706 707
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,I think this section should also be reordered to show that this drop is correlated with model size. ,1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Todo,"
3. ",375
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Todo,No questions. ,220 221
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Todo,L#538:  cases --> case L#540: works --> work ,342 343 344 345 346 347 348 349
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,"
2. ",297
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"- Line 559, the paper may discuss why the model does not perform well on LOS, why a high percentage of unhelpful literature are retrieved (even for correct predictions) and how such a high percentage of unhelpful literature impact the reliability of the model.
",443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,This table doesn't report results with different values for p. ,371 372 373 374 375 376 377 378 379 380
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Todo,I'm not sure why the authors describe pipeline methods in Table 1. ,406 407 408 409 410 411 412 413 414 415 416 417
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Consider sticking to one term throughout the paper?
",538 539 540 541 542 543 544 545
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Todo,"Is this something that has been considered?
",440 441 442 443 444 445 446
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,"L68-L70, Is there any further explanation of the statement ""the schemas for extraction are implicitly included in the training data""?
",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"
1. "" ",131 132
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo, Should Section 1.1 be Section 2.0 instead? ,250 251 252 253 254 255 256
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,The paper argues the need for a domain-specific language model for the area of political conflicts and violence. ,557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Todo,"- In line 122, triples denoted as $(e_1, r, e_2)$ would clearly show its tuple-like structure instead of sets.
",499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 135: method achieve -> method achieves ,710 711 712 713 714 715 716
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,2 Line 231-232: s/access/assess ,145 146 147 148
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Todo,Scatter plots in Figure 2 and 3 are not very suitable because it is hard to see how each run is distributed when they overlap. ,554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"
4. ",292
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"Maybe using Desc-ind/seq, Eg-ind,Demo-ind/seq? ",480 481 482 483
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   * Line 46 - hypothesize instead of `think' ,477 478 479 480 481 482 483 484
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,2. ,365
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo,"Otherwise, it might become yet another incremental reading comprehension dataset that might be addressed within a couple of months. ",457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"
In line 172, ""fout"" -> ""four"" In line 264 I guess a part of the sentence is missing: how is the contrastive loss computed? ",619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"On lines 074-076, you can remove everything prior to ""answer uncertainty"" and begin this sentence with ""Answer uncertainty"" for clarity.
",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- Please, mention the language you focus on to retrieve the Reddit posts. ",382 383 384 385 386 387 388 389 390 391 392 393 394
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"-Please be more specific on the 'Chain of Reasoning' section, especially line 276.
",496 497 498 499 500 501 502 503 504 505 506 507 508
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"If I understood correctly, the CS is created by the linguistic experts and it's used for evaluation purposes. ",361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Todo,"Many of the readers do not know Thai, so I think more explanation is necessary.
",227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"In addition, Sec. 2.2 can also be a new section talking about in-house training procedure and results. ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"Admittedly, the difference in performance to other approaches (at least for the SST-2 task) appears to not differ too much. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"l076: ""and .""
",508 509 510
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Todo,"-Line 280 - typo, ""there existS"" ",247 248 249 250 251 252
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"(in general) ""code"" is uncountable in English. ",483 484 485 486 487 488 489
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo,"- Modeling: BERT is multi-label, SVM multi-class. ",628 629 630 631 632 633 634
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Todo,"Line 302, right column. "" ",229 230 231 232 233
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Todo,It would be great to address the weaknesses above. ,238 239 240 241 242 243 244 245 246
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,It will good if the authors can learn the templates for schema expansion from source domain data. ,346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Todo,"First of all, “The phrase semantics are determined by their context.”. ",180 181 182 183 184 185 186 187 188 189 190
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Todo,"How to determine the value of such a parameter?
",154 155 156 157 158 159 160 161 162
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"These methods are great but iid performance on one dataset for a task does not suggest that we've outperformed expert humans on that task.
",783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 310 - A ""minimalist"" setup, you may want to remove some of the related work and expand this, how can your work be reproduced off of these settings? ",621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,-Line 018: near-soa > did you mean “near-state-of-the-art (sota)”? ,632 633 634 635 636 637 638 639 640
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Todo,"
+ Please avoid using words like ""friendly"" and FGM in the Abstract without further definition. ",482 483 484 485 486 487 488 489 490 491 492 493 494 495 496
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,-Levenshtein Transformer. ,259 260
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,Paper title is a bit overclaimed and also does not cover one of the main topics reporting bias. ,346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,"In appendix, there are many tables with very little description or even none. ",395 396 397 398 399 400 401 402 403 404 405 406 407
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"204 - ""simple LM training"", what is this, cite?
",401 402 403 404 405 406 407 408 409
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Todo,- Are there other tasks where temperature smoothing could be beneficial? ,396 397 398 399 400 401 402 403 404 405 406
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"It shows 5 out of 14, but the truth is not given in the figure.
",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
73837843c65a425ff419296a34871a445f1e2fee4cb8940431054c5ec0c1beb405f43cdd40fd27e52cf27aab7574eb4f160655995346c0889edc41328e588bdb,arr,Todo,"-It might be useful to provide the chance accuracy so that the readers can have a better idea of how well the baselines perform.
",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"
2. ",159
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,Typos ,1170
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Todo,As mentioned in the weakness. ,216 217 218 219 220
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,-Line 246-249: this sentence lacks the conclusion ,397 398 399 400 401 402 403
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,What are the templates used for the synthetic dataset? ,401 402 403 404 405 406 407 408 409
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,"
3) XLSR-53 is a pre-trained acoustic model which is trained in a self-supervised manner. ",466 467 468 469 470 471 472 473 474 475 476 477 478 479
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,2. ,359
883cec982be6ead1ee077df92d0d08618b52f2c4d4c39b923d78fb412dcf88496ff4894080de73f3c786310afcab26fa9e04cafe7020c5561b3835c375a0fd0c,arr,Todo,"- One question: x' is sampled within certain distance from x in the embedding space, does that mean they are semantically/syntactically similar? ",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Todo,This paper created a subset by filtering based on length of the positive/negative example pairs. ,367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"In addition, how are syntactic and lexical conditions combined before being concatenated to the source sentence? ",1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"vs ""For other language pairs, the data-model alignment can sometimes have a distinct positive impact and can also sometimes have a negative impact.""
",393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,It's of course quite frustrating to see that somebody has basically solved the problem but doesn't say how :) ,547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Todo,"In Line 492, the referred table number is incorrect. ",344 345 346 347 348 349 350 351 352
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Todo,1. ,266
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-You haven't defined calibration error but instantiate it via $\epsilon$ in line 254. ,1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-Line 181, Equations 4: $H^s$, $E^s$, $E^o$, etc are never explained.
",333 334 335 336 337 338 339 340 341 342 343
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Todo, ,
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
Missing References: 1. ",522 523 524
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Todo,1. ,338
6bd292c3f083f1a278739bedb1db76eb53014bcfa286c850680811f20b8fe3f79ba1881809e4fd3532754f4e6344d24365f551e1c879292061577d5b3b70f0e6,arr,Todo,"-As speech and texts are projected into the same latent space, it will be interesting to see an analysis of the joint embedding space to better understand how the model learns. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"I did not understand why Multiply option was selected for the experiments, when Concat+Dot clearly outperforms it in 4 cases, as shown in Table 3. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo,"I suppose by reporting three settings (inside, inside w/ self-training, inside + outside) you are doing a type of validation over hyperparams. ",437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"
In line 162, ""in"" -> ""into"". ",613 614 615 616 617 618
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,"I think the task is similar to any other discourse labeling and relation identification task, and there are a lot of open-source tools that can be used for such annotations.
",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,-Line 036: decision > decisions  ,646 647 648 649 650
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,Wouldn't there exist error propagation if the back translation is noisy? ,252 253 254 255 256 257 258 259 260 261 262
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"Also, following the work in Card et al (2020) (""With Little Power Comes Great Responsibility."") - ",878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"Can you first give references of using SP, LTP, HTP, and RP? ",289 290 291 292 293 294 295 296 297 298 299 300
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 5] Tables 3 & 4: It is very hard to read those Tables. ,1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"-Line 183: “we truncate the first convolutional layer in MoCo v2” -> why?
",184 185 186 187 188 189 190 191 192 193 194 195 196
6bd292c3f083f1a278739bedb1db76eb53014bcfa286c850680811f20b8fe3f79ba1881809e4fd3532754f4e6344d24365f551e1c879292061577d5b3b70f0e6,arr,Todo,"- Vased on what is written in this paper, it seems that the authors do not state any plans to release the code and the pre-trained weights. ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,Or do you get multiple vector representations and concatenate them? ,437 438 439 440 441 442 443 444 445 446
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Todo,Is it included using nearest neighbor search or not included at all? ,332 333 334 335 336 337 338 339 340 341 342 343
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,This could be made more clear ,236 237 238 239 240 241
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Todo,"I would suggest trying to come up with templates based on MAVEN types too, this will cover many more event types. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,-Are all the models re-trained on the same subset? ,447 448 449 450 451 452 453 454 455
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,The approach is based on events. ,289 290 291 292 293 294
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Todo,I wonder if perhaps there is some sort of compromise way to rank metrics that incorporates both instance-level and system-level scores. ,348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"More details are needed.
",605 606 607 608
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,Some of the typos/grammar issues found: ,353 354 355 356 357 358
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,"Given the input sentences, the supervision is comming from the delimiter term. ",401 402 403 404 405 406 407 408 409 410 411 412
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"-Missing references: (1) For Open Relation Extraction (in line 156), it might be better to cite the pioneering work, Bank et al. “Open Information Extraction from the Web” in Proc. ",476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,Suggestions: ,656
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"Common sources include tables with statistics and reports from governments, think tanks and other organisations, available online”. ",550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo, ,
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,"A3:  Based on the explanation, it seems that ND cannot be adapted to beam search, as it cannot achieve better performance. ",86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Todo,"Why is there no comparison with TaPEx in the experiment section?
",232 233 234 235 236 237 238 239 240 241 242
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo, ,
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Todo,"-Line 166 - typo, ""thoery"" ",230 231 232 233 234
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Todo,"
4) There is a recent work on unsupervised speech recognition at Neurips 2021 (https://arxiv.org/pdf/2105.11084.pdf) which does something similar but without the need for segmental acoustic models. ",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"These papers, although not 100% on-topic, might still be mentioned in the related work: https://aclanthology.org/W19-4713/ https://aclanthology.org/W19-4732/ ",401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"045 - This may be better attached to the previous sentence.
",223 224 225 226 227 228 229 230 231 232 233
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Todo,None ,243
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"The (...)"" --> ""(...) OPUS.^3 The (...)""  ",976 977 978 979 980 981 982
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,1) Suggestion for the general literature review: ,495 496 497 498 499 500 501
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,1. ,248
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Shuffling the words/phrases in the stimuli ,494 495 496 497 498 499
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," Doesn't the current result indicate that the source-side vocabulary is somehow quite helpful -- the opposite of your initial claim?
",649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"For Table 3, are the non-highlighted cells not significant or not significantly better? ",379 380 381 382 383 384 385 386 387 388 389 390 391
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"L425, the reference to Tab.2 in the main text happens after the reference to Tab. ",660 661 662 663 664 665 666 667 668 669 670 671 672 673 674
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo, The Figures and Tables can be moved on the top for better readability. ,465 466 467 468 469 470 471 472 473 474 475 476 477
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Todo,"Since ConfliBERT’s main gains seems to be from political conflict-relevant words in the vocabulary, how well will it generalize in a rapidly-evolving space? ",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo, ,
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Todo,Suggestions: 1. ,176 177
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,This should be noted (even if it is simply done randomly). ,830 831 832 833 834 835 836 837 838 839 840
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 434: Ma et al citation missing year ,519 520 521 522 523 524 525 526
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,Why would someone apply set expansion approaches to construct a dictionary from customer reviews? ,163 164 165 166 167 168 169 170 171 172 173 174 175 176
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"
7. ",298
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,Are there any reasons you can find for why finetuning is worse than pivoting? ,276 277 278 279 280 281 282 283 284 285 286 287 288 289
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Todo,"More discussions about dataset construction should be provided, e.g., the time range of data collection, preprocessing strategies and quality control.
",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,How to determine the number of output table(s)? ,253 254 255 256 257 258 259 260
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"Also, it seems the computation of $S_{epoch accd}$ depends on four summation loops if we replace $S_{batch accd}$ by its definition, what is the computation cost for $S_{epoch accd}$?
",353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"
3. ",217
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,"1- ""because events are more important to storytelling"": Do you have any investigation or reference for this? ",249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Todo,-consider adding into future work an error analysis of spurious  or missing mentions across all datasets especially - BC5CDR ,406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"[1] Pourdamghani, Nima, and Kevin Knight. "" ",707 708 709 710 711 712 713
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Todo,"Decoder are evaluated on Simple (from the OALD test set).
",329 330 331 332 333 334 335 336 337 338
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"-I suggest not phrasing the Jabberwocky experiment as “probing” (L.444 ‘method to probe LMs’, L.465 ‘probing strategy’, etc.), ",1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Todo,"Could a model trained for the RetroGap task contribute to better OCR?
",290 291 292 293 294 295 296 297 298 299 300 301
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"112-114 ""The taxonomy T is arranged in a hierarchical manner directed edges in E as shown in Figure 1."" - ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Todo,Details : some references have no venue -> please correct this. ,447 448 449 450 451 452 453 454 455 456 457
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,Did I overlook something? ,270 271 272 273
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,*General comments:* ,594 595
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"What strikes me as odd is that neither chose the center headline (the former is basically copying the Right headline, the latter has done some paraphrasing both mostly based on the Left headline). ",768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Consider, instead replacing those tables with graphs (with #of samples in the x axis) and present just one or two metrics in the main text (moving the rest to Appendix for completeness)?
",1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,The fairness of comparison against prior methods might be clarified. ,83 84 85 86 87 88 89 90 91 92
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"Facenet: A unified embedding for face recognition and clustering."" ",568 569 570 571 572 573 574 575 576
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"I am also interested in the results on QQP and RTE, but they are not reported here. ",568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Todo,I suggest Listening 1 to reflect the process of sending interpolated_repr into the task model to get the final representation ,490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"-What is ""Fraction unanswerable"" in Figure 5 and how is it obtained?
",322 323 324 325 326 327 328 329 330 331 332 333
71e7b95a72af9ac8519665285f1c20f8f8864dc212f5477ffd96c88ab2a42ae84a3e1a5eb93606189083f3c1271d360fde8eb2d0c0d81ef42c2692f8be1d897c,arr,Todo," For the Appendix H section, it should be reorganized which is difficult to follow. ",203 204 205 206 207 208 209 210 211 212 213 214 215 216
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Todo,More examples in case studies can better help in understanding the contributions. ,256 257 258 259 260 261 262 263 264 265 266 267
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,"Thus, I wonder about the performance of combining this method with other speedup ways, such as DeeBERT (dynamic early exiting). ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Todo,"
4- The reddit corpus could be compared to other event detection datasets that utilize user-generated text. ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,-Section 3.2: The amount of footnotes could be reduced. ,410 411 412 413 414 415 416 417 418
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Todo,"- Some crucial information is only presented in the appendix (most importantly the details on the evaluation metrics, which cannot be understood without reading the appendix). ",233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Todo,I am aware that this paper is a re-submission of a paper that I have reviewed before. ,88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,"- l. 25/26: ""... can benefit many downstream examples"" List/Cite some examples.
",253 254 255 256 257 258 259 260 261 262 263 264
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"- What is the training data for your probes in the compositionality and transitivity experiments?
",582 583 584 585 586 587 588 589 590 591 592 593 594 595 596
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,seems like a continuation of the previous statements. ,282 283 284 285 286 287 288 289
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Also there is a discrepancy between the input to the NeuS-Title model (lines 479-486) and the output shown in Table 3 (HEADLINE vs ARTICLE).
",886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Todo,Suggestions: ,453
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"Proceedings of the Workshop on Modelling Translation: Translatology in the Digital Age (MoTra21), pages 1-7, Iceland (online), May 2021.
",585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,-Do you intend to share non-detoxifiable samples? ,416 417 418 419 420 421 422
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,4. ,452
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Todo,"It would be interesting to see how relevant to word-level QE is the information encoded at different layers of the model without fine-tuning for sentence-level QE, by using simple classifiers as probes for instance. ",642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"If the overthinking problem did exist, I would expect the mcc to have a maximum at an intermediate layer. ",825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo,"Putting together all the strengths and weaknesses, I suggest this paper would benefit from another round of revision to address the above concerns before publishing. ",432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo,"- More synonyms probably increase the memory and time requirements: can you say more about the complexity of the method relative to the number of synonyms?
",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,The figures in Table 3 demonstrates that the performance on the synthetic dataset is much better than that on the repartitioned SQUALL. ,434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,I think this would give a better overview of the (massive) nature of the resource. ,310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Todo,"While the methods proposed in this paper are distinct, these methods should be mentioned in the related work.
",486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo,The work seems to be presented as an engineering task and provides limited insight into the fundaments of how decomposing the task help language models to consume meaning representations to generate text. ,169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"-Weinberger, Kilian Q., John Blitzer, and Lawrence Saul. "" ",534 535 536 537 538 539 540 541 542
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,The motivation behind experiment with clustering and interpretation of its results are missing/unclear. ,197 198 199 200 201 202 203 204 205 206 207 208 209
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Todo,"We"" --> ""datasets. ",258 259 260
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"Moreover, it is hard to understand the color schema followed in the Figure-1, there is no legend.
",329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Todo,I think this requires some elaboration. ,216 217 218 219 220 221
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,The are many works that leverage this technique for AL. ,269 270 271 272 273 274 275 276 277 278
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Todo,NA ,218
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo," I suggest adding the equation to the paper for clarity.
",239 240 241 242 243 244 245 246 247 248
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,Significance test can be conducted for the results of Tab. ,479 480 481 482 483 484 485 486 487 488
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo, ,
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"
3. ",240
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"Does model size/computation play a role in the performance difference shown in Tables 1, 3, 5? ",90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,Why not just leave that line empty? ,632 633 634 635 636 637 638
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Todo,I did not see a clear clarification until reading the conclusion. ,510 511 512 513 514 515 516 517 518 519 520
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo,"
typos: 155 (present*s*), 268 conclusion(s) ",647 648 649 650 651
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,Typos: ,316
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo, ,
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,should be escaped to avoid spacing issues ,1207 1208 1209 1210 1211 1212 1213
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Todo,"For instance,  why is Hanja an extinct 'language' instead of a 'script'? ",302 303 304 305 306 307 308 309 310 311 312 313
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,I do not agree with this takeaway because of the above statement. ,501 502 503 504 505 506 507 508 509 510 511 512
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,"- I'd like to see some discussion/visualization of learning curves, since the kind of differences in scores reported can be due to converged vs. non-converged models ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] lines 55-58: Is this the first work that framed generation tasks as language modeling by predicting the next token given previous tokens? ,553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297,arr,Todo,1. ,81
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,Model sizes? ,154 155
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,"My main concern is the experiment comparisons with similar approaches, such as centroid transformers and representation pooling. ",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Todo,"
2. ",235
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Todo,1. ,212
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,The paper not only accounts for demographic variables as done in previous work but other attitudinal covariates like attitude towards free speech that are well-chosen. ,181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"Second, I would expect the performance of the model to slightly increase when the speedup ratio is low (but not 0). ",844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-Please, add hyperlinks to the papers in the bibliography.
",839 840 841 842 843 844 845 846 847
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"In the related works, among the many multi-task frameworks the addition of the CTC loss is not cited.
",533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Since it is a Recall-based metric, the important thing is that you retrieve the document, regardless of its ranking. ",889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"-In line 303 the authors mention ""sentence transformers"". ",419 420 421 422 423 424 425 426
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,Do authors have more justifications on going with multi-modal for this task? ,171 172 173 174 175 176 177 178 179 180 181 182
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,2) Some aspects of the creation of the dataset are unclear and the authors must address them. ,243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Todo,"
I think the authors have polished the paper and achieved a good status. ",222 223 224 225 226 227 228 229 230 231 232 233 234
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Todo,"-Line 90, “constrastive learning” -> “contrastive learning” ",280 281 282 283 284 285 286
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(153): what is a ""key""?
",645 646 647 648 649
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,- the paragraph from l90 to l116 is very unclear. ,162 163 164 165 166 167 168 169 170 171
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"-line 551ff: ""RSA is able to be adapted to NLP task structure detection"" seems to be already argued with a single configuration where it outperforms random. ",504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,The automatic evaluation configuration section is little bit hard to follow. ,137 138 139 140 141 142 143 144 145 146 147
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Todo,There are too many references to the appendix in the paper. ,191 192 193 194 195 196 197 198 199 200 201
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,It would be very interesting and valuable if we have the ED annotations on that dataset to further push the performance of the risk assessment models with the use of the triggers. ,539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,"
3. ",469
a10d35763dca42f9e79c8e0caa0c46187df3879026bdd9c437fa21cb43f4713e871f77a5508c7aefe0c3ef70f3c71cddc20c64e692664edfc6ade6954ee36188,arr,Todo,Does it come from data points where syntactic constraints are violated? ,128 129 130 131 132 133 134 135 136 137 138
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-Spaces after non-terminal periods (""vs."", ""cf."") ",1201 1202 1203 1204 1205 1206
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"Section 4.2 (Elictation methods) includes paragraphs on soft promt tuning and knowledge distilation, which is confusing. ",655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Todo,Line 458: equally effected -> equally affected ,203 204 205 206 207 208 209
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo,"They are expected to vary across social groups, geographical locations, etc. ",670 671 672 673 674 675 676 677 678 679 680
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,does that mean all the +ACT results only have alignments constraints and prompting during training and no alignments prompting at inference? ,213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,Think this is a typo. ,351 352 353 354 355
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,== MI Loss == ,460 461 462 463
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"However, this is not substantiated with an analysis of performance on actual items with rare words. ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Todo,"Maybe it makes more sense to try out models pre-trained on conversations, e.g., text from Twitter or natural language conversations. ",301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Todo,l. 141 varies --> vary l. 466 datasts --> datasets ,370 371 372 373 374 375 376 377 378 379
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,3. ,332
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Todo,line 128: BN has never been defined. ,219 220 221 222 223 224 225
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,### Comments ,177 178
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Todo,What is the goal for section 6? ,180 181 182 183 184 185 186
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,Does this mean that the mean accuracy of DeepL is actually 40% instead of 60%? ,598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"
  Page 2, Line 098-100: The phrase ""latent semantics"" is unclear. ",572 573 574 575 576 577 578 579 580 581
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"-340: I'm very confused how the complexity ""c"". ",372 373 374 375 376 377 378 379
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,"-Sect 4.2.3: Maybe an illustration would help to explain this part, I found it hard to understand.
",302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,"L59-62: Add references here.
",476 477 478 479
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"The resulting accuracy greatly surpasses the that based on so-called “true” discrete prompts, this previous result already shows that the so-called “true” target prompt is not effective compared with the soft prompts.
",729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,-Line 255: Comma should not start the line. ,519 520 521 522 523 524 525 526
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Todo,"Therefore, the majority of reviewers' comments from ARR August still holds (I was one of the original reviewers). ",341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,-Which attack was used to compute accuracy under attack in Figure 2? ,280 281 282 283 284 285 286 287 288 289 290 291
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,Vid.”) ,737
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,2. ,280
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Todo,Why only one iteration? ,421 422 423 424
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Todo,"-Although the mixing ratio of the methods with Fixed Residual (W_ {FixedRes} and N_ {FixedRes}) is explained as 0.5, it is actually lower than 0.5 because attention also has the effect of preserving. ",476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,Abbreviations (Tab. ,732 733
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,"In table 3, for the proposed model, WER for the audio-visual setting vs. audio-only setting are close (2.6% vs. 2.7%). ",151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,"For example, an overly small perplexity may correspond to repeating common n-grams. ",455 456 457 458 459 460 461 462 463 464 465 466
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. ,425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,### Comments and questions ,317 318 319 320
44e7ab41a54cab53f17e79871feb2713cc16df873abd22f680ff5a4c0366953bb1c6c359fd3fd84fa68c262345dae767a3250a4249f7a0583a6569f44fdaa4d1,arr,Todo,"It would be helpful to compare BitFit with Adapter and Diff-Pruning base on other language models (e.g.,RoBERTa, T5). ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"A related question: Is the evaluation of T5 for classification tasks doing unconstrained generation, or is it a ""ranking"" approach, just scoring the likelihood of the legal labels?
",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"The fact that its percentage of the tokens in a sentence and not an absolute number should remove the dependence on sentence length, no?
",614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Todo,The paper is well organized and well written. ,236 237 238 239 240 241 242 243
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,A Globally Normalized Neural Model for Semantic Parsing ACl 2021 2. ,398 399 400 401 402 403 404 405 406 407 408
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"You'd better state clearly what idea hypothesis you want. "" ",297 298 299 300 301 302 303 304 305 306
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"
4)	Heuristics used as baseline for event-level detection seem valid. ",645 646 647 648 649 650 651 652 653 654
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"- In lines 198-220, explanation of $\phi$, $\psi$ and $\pi$ is not clear. ",302 303 304 305 306 307 308 309 310 311 312 313 314
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,Nor clear how the Bin:Control effect is computed. ,421 422 423 424 425 426 427 428
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Todo,"In Table 5, the performance of ""DESCRIPTION"" is very low. ",149 150 151 152 153 154 155 156 157 158
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,"What’s the relation between text-to-table task and vanilla summarization task?
",242 243 244 245 246 247 248 249 250 251
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Todo,"1)	As an abbreviation, PLM in line 67 should be defined first 2)	The authors should give some intuitive case about hypothesis, source and reference in experiments 3)	The introduction of Hard MRA need improvement. ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,The effect of the various losses towards their intended function has not been thoroughly covered. ,331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Todo,"Line no 84:- ""...may be..."" -> may have been 2. ",226 227 228 229 230 231 232 233 234 235
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Maybe some parameters that measure these issues more explicitly -- which seem more closely relevant to the process of textual collection building -- would provide better insights into data characteristics.
",730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,For instance focusing on: ,115 116 117 118
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Todo,Please reorganize the section of performance evaluation to highlight the strengths of the proposed methods. ,184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Q4. ,931
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Todo,1. ,220
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Todo,"-the abstract is too long and should be shortened.
",425 426 427 428 429 430 431 432 433
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Todo,"The dataset\task is nice, but it is not the main contribution in my opinion. ",341 342 343 344 345 346 347 348 349 350 351 352 353 354
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,Line 559-561: Do you think the drop in performance for Vikidia-Fr is because of the domain difference between Newsela and Vikidia? ,454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"
Having a single person responsible for the check at the end of the first round may introduce biases. ",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Todo,There is lot of content and tables. ,306 307 308 309 310 311 312
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"213 - 216 - The statement makes sense but do you have something to show that?
",422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Todo,"-299: ""We denote the encoder and decoder for encoding and generating source-language sentences as the source encoder and decoder"" - unclear ",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,p.5 The description of Distance Minimizing and Task Tuning could be clearer. ,693 694 695 696 697 698 699 700 701 702 703 704
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Todo,"There is a related work [1] performing similar experiments and analyses as in this work, but with more tasks and ranking features (though not using pre-trained models). ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,Try to move the latter to an appendix. ,397 398 399 400 401 402 403 404
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,2016. ,320
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Are they very far apart, or the underlying ""character"" of the dataset is still retrievable even in such imperfect conditions? ",372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"> It doesn't seem clear.
",184 185 186 187 188
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo,- How did you sample the synonyms when not all of them are selected: fully randomly? ,329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,You could write your contributions as bullet points. ,263 264 265 266 267 268 269 270
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,------------------------------------------ Suggestions: ,666 667
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,4. ,448
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Todo,- Tables 1&2: please add standard deviations since you anyway have already run each model at least three times ,218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"Line 048 - There is an assumption that it ""can"" be done based on non-relevant results. ",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,Is it simply a text corpus? ,525 526 527 528 529 530
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,SUGGESTIONS ,405
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,"From my understanding, RA is the strictest evaluation metric, and NPRM performs worse on RA when compared to the baselines (Table 4) where simpler approaches fare better. ",393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Todo,"-L411 ""train the model with one iteration over the corpus"". ",411 412 413 414 415 416 417 418 419 420
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,-Line 252: Not clear what is the subject of this sentence. ,437 438 439 440 441 442 443 444 445 446 447
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"It's interesting that the LV→EN model performs better than the ET→EN model, especially in section 2 authors mentioned that Livonian and Latvian languages are similar in many aspects. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,-L348: real-word -> real-world ,371 372 373 374
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,It would help if every term is clearly defined. ,253 254 255 256 257 258 259 260 261
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,"- The main results compare the training FLOPS, how about the total compute budget/costs for convergence? ",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Todo,Some typos for example:  Line 588 - “investigate the sensitivity“ Line 590 -  “as an search problem” Line 595 - “guarantees a better“ ,481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Experiments: what training data you use for pre-training? ,308 309 310 311 312 313 314 315
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Todo,N/A ,287
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"-Table 4: The heading ""w/o ICT (SimCSE 2021c)"" looks confusing, you would think that ICT was proposed by SimCSE 2021c) ",529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,"-while the contribution of the reinforcement agent is clear, it would be good to include a different baseline for ""selecting relevant examples"", in order to justify the use of RL in that setup over a simpler selection method ",240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,"-Line 248: This explanation, while plausible, could be relatively easy to check just by looking at the words themselves. ",313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"The expression ""donor model"" sounds weird to me (552), I would advice replacing with something different (pre-trained model, ..).
",576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Lester et al. 2021 may be a better reference for tuning prompts that only affect the input layer.
",521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Todo,Some typos: ,271 272
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,"
3. ",521
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"
4. ",566
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"Page 4, Line 287: I believe ""edges are implement MeSH hierarchies"" should be ""edges represent relationships in the MeSH hierarchy"" ",606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"More crucially, how sensitive are your results on the choice of this parameter per task and dataset choice? ",415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"[2] Kwabena Amponsah-Kaakyire, Daria Pylypenko, Cristina España-Bonet and Josef van Genabith. ",564 565 566 567 568 569 570 571 572 573 574
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,Some typos and grammatical errors. ,126 127 128 129 130
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,4. ,824
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,Section 3 (the Methods) is very difficult to follow. ,307 308 309 310 311 312 313 314 315
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Todo,N/A ,160
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-Lines 337, 338: Footnotes should appear after the period. ",817 818 819 820 821 822 823 824 825
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,"The text now says ""..and applying the same preprocessing"" (line 355) - this point can be made more clear.
",333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"-Alternatively, would it be possible to set up the sentence sorting experiment in such a way that the lexical overlap in between sentences is limited? ",800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo," Specific questions, comments, and typos: ",361 362 363 364 365
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"
Sections 2 and 4 (and even 5) could be merged as they are all data-related - this would also give a bit of structure to the paper, as now it has a concatenation of highly-related sections. ",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"E.g. first put the 8 SFII columns and then the 8 SPDI columns rather than alternating between them.
",421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"3 It feels odd to try to make only have english a desirable property of the benchmark, instead of a limitation ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo,- ,479
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Todo,Line no 218:- are the given references for the text encoding the first ones to use such encoding? ,236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,"
3. ",283
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"It would be really nice to see that comparison, but this isn't crucial. ",1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-166: Space after footnote 5.
",476 477 478 479 480
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,1. ,96
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Todo,An intro to this line of research can be found at https://huggingface.co/docs/transformers/bertology ,391 392 393 394 395 396 397 398 399 400 401 402
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,-Is it possible to add more evaluations about the synthetic data itself? ,105 106 107 108 109 110 111 112 113 114 115 116
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 238 - ""forms a positive pair"", how is this pair formed by the -log on cosine similarity, doubtful but please explain more. ",565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Todo,"Section 4 413: ""For evaluation, we use precision, recall and F1"" - since MUC and B3 measures also define P/R/F1, it's good to mention here that it's P/R/F1 on individual (coreference or bridging) links. ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Todo,"In Section 2.4, the authors argue that metrics should be ranked in terms of instance-level judgments. ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,-Spaces not needed between section symbol and number ,1193 1194 1195 1196 1197 1198 1199 1200
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"Are they fixed the same across the different setups?
",1122 1123 1124 1125 1126 1127 1128 1129 1130
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"ECE is usually given with the expectation randomness integrating over the simplex $D_K$ right, do we have to do that here? ",1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"With regards to the disconnect between the visualizations and the rest of the processing: the visualizations are based on geographical statistics for entities in a text, but these entities are already marked. ",291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Todo,"It is not clear how multiple discriminators can enforce constraints simultaneously.
",112 113 114 115 116 117 118 119 120 121 122
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,3. ,391
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-§4.7: I don't understand why and how you need manual annotation here. ,449 450 451 452 453 454 455 456 457 458 459 460
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-Lines 39-42: Point to figure 1 for this particular example.
",307 308 309 310 311 312 313 314 315 316
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Todo,So I insist on my previous positive rating. ,119 120 121 122 123 124 125 126
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"-Appendix: Figure 5 has a column ""%mistakes"", but the other figures have ""Accuracy"". ",585 586 587 588 589 590 591 592 593 594 595 596 597
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,Saying that CLIP uses GPT-2 as it's language model (line 84) might lead readers to assume it uses the pre-trained GPT-2. ,299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"The limits of machine translation"" - please see the AmericasNLP paper mentioned before and cite it as it is important; ""Finally, there were no substantial qualitative..."" - this paper does not show that really. ",813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"Sec 6.3 is titled ""Generalization to other V&L tasks"" -- this is misleading since both eval datasets are also VLN datasets. ",640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Todo,"The author's response to this was reasonable, and I would suggest that the include their reasoning in the paper as a potential limitation of the approach. ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
30aa157cc690ecbf3ee3034c035b2533e3c1a2e99c7ce2c797371c7c758de51b77204c36880a0163059bed31ff962c7a97d94be7c6d287e09e1c2e2a93ac4e1e,arr,Todo,I strongly suggest to improve the narrative of the paper. ,161 162 163 164 165 166 167 168 169 170
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"However, from En to Kk, the difference between +FA and mBART is -0.5 (1.3 vs 1.8) but this cell is not highlighted. ",431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,1. ,265
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Todo,"- For evaluation, the datasets that the authors use are pretty old datasets. ",396 397 398 399 400 401 402 403 404 405 406 407 408
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,"-Line 182: A bit confusing what the superscript p means.
",501 502 503 504 505 506 507 508 509 510
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,"Instead of model compression techniques, I believe other acceleration techniques such as [1-2] should be cited and discussed.
",267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"Why do you need to translate the entire sentence manually?
",497 498 499 500 501 502 503 504 505 506
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,Is it decided as explicit if the statement contains specific terms and offensive? ,477 478 479 480 481 482 483 484 485 486 487 488 489
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo,462 RoBERTa-base ,559 560
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"Line 220: is absent -> are absent; Line 259: in the training and testing phrases -> in the training and testing phases; Lines 310-311: k_i is defined as the number of sentiment words, but k_i is not used elsewhere; Line 352: Subsequently, We -> Subsequently, we. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"- Qualitative error analysis in the Appendix is great, but the manuscript so far lacks a more detailed analysis of the results. ",399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Line 173, cases ",472 473 474
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"-How is the annotation on Thai NER datasets, on a syllable-basis or word-basis, and why?
",312 313 314 315 316 317 318 319 320 321 322 323 324 325 326
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Todo,1. ,390
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"You might want to make this clearer.
",478 479 480 481 482 483 484
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Figure 3: The coloring of the PI group makes the text very hard to read in Black and White. ,1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo, ,
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,"The authors claim they took from another source, but understanding how they are created is relevant for this paper. ",394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,"For example using the KALDI ASPIRE model, or models built in Dalmia et. ",506 507 508 509 510 511 512 513 514 515 516 517 518
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,"I think a perfect fit of FairytaleQA's distribution of question types shows that the model can better overfit the FairytaleQA dataset, but this may hurt its generalizability to other datasets. ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Todo,The model is an energy-based model. ,345 346 347 348 349 350
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Todo,- The abstract part is lengthy so some background and comparisons with prior work can be elaborated in the introduction and related work. ,456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Todo,The LM objective is only used for pre-training these models and as far as I can see the paper does not try to evaluate this model as a LM. ,417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,"It is suggested that some quantitative analysis can be given, for example, the distance of inter-class. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,An advantage of prompt tuning is that the prompt is transformed by the models attention based on the value of the prompt. ,1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Todo,"[1] Matching the Blanks: Distributional Similarity for Relation Learning, Soares et. ",210 211 212 213 214 215 216 217 218 219 220
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,-Footnote 4: 'empirically helpful' - should have a cite or something to back that there. ,1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,-L407: PersonaChat dataset -> the PersonaChat dataset ,485 486 487 488 489 490 491
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Though the paper presented a fair amount of good work, the current presentation should be improved. ",687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-285-287: repeating the same sentence ,294 295 296 297 298
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Does this imply making two passes of the decoder? ,322 323 324 325 326 327 328 329 330
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,Explaining Relationships Between Scientific Documents. ,290 291 292 293 294
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo,That is to show the additional discourse structure information can benefit the long-form QA system in terms of either improving its performance or facilitating the evaluation of long-form answers. ,420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"Appropriate information should be added, at least in the appendix.
",312 313 314 315 316 317 318 319 320 321
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Todo,"I couldn't find any references to automatic or manual deduplication of the claims in your data, and this data clearly may contain different versions of the same claim fact-checked multiple times. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Todo,What is the point of the taxonomy when you have four punctuation marks? ,171 172 173 174 175 176 177 178 179 180 181 182 183
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,"-In PLASM, the authors propose to use pseudo labeling to mitigate the ASM problem. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,Your abstract is way too long. ,251 252 253 254 255 256
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,"~[1] Yifan Wu, Ezra Winston, Divyansh Kaushik, and Zachary Lipton. "" ",512 513 514 515 516 517 518 519 520 521 522
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,and how it will be shared. ,535 536 537 538 539 540
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo, ,
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
fd2caf0a98ac82aa472d008400f29ba5bd74e77d5471c83cb7634bca4d59d5c302b38774e1e7775d5f8bf1110a26d537ba5427a759506b0a0807bc3e3590493c,arr,Todo,"Why embedding based methods are better than other selection methods?
",122 123 124 125 126 127 128 129 130 131
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Todo,"But to me, the authors seem to miss a straightforward baseline, that is to firstly flat the table into a text sequence like Figure 7 and then train a text-based QA model on it. ",356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"Section 4.2.1 is titled ""Architecture choice"" but it seems more a literature review of the existing approaches than a description of the choices made in this work. ",500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"At line 264 the citation style should be ""(Kumar, 2017)"". ",442 443 444 445 446 447 448 449 450 451
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,Explain Distinct-1 and Distinct-2. ,1221 1222 1223 1224
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"Figure 2/451: I think the Vokenization model has the second highest correlation gap between wikipedia and coda, after BERT - if this is true (I didn't do the math), does this imply vokenisation doesn't work?
",551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"-433: The model is heavily based on MASS, but it is not described properly. ",416 417 418 419 420 421 422 423 424 425 426 427 428 429
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,2020. ,858
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,The paper would benefit from a comparison to (or at least mentioning) related work on integrating lexical constraints: ,196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,"
2. ",270
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,It is not clear to me why results in Table 2 and Table 1 are different for the pivot-based baselines. ,419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,Comments: 1. ,369 370
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Todo,"
This paper is well written and easy to read. ",190 191 192 193 194 195 196 197 198
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Todo,1) Kindly include the details of the expected entropy calculations in the main paper to make the paper self-contained. ,430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-It's not clear to me why step (3) of the algorithm should be necessary at all. ,1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Todo,"
In section 5.6, could you please provide the Kappa ? ",176 177 178 179 180 181 182 183 184 185
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Todo,See above. ,136 137
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Todo,"-I suggested for the previous version that the paper would be stronger if it also presented results on other knowledge-grounded benchmarks, e.g. DSTC9 and the Doc2Dial benchmark. ",346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Todo,"For explanations in Section 4.3, the authors should list each method for readability such as using \item. ",515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,"It would be better to add examples for each setting.
",223 224 225 226 227 228 229 230 231 232
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Todo,Most of my comments are given above. ,440 441 442 443 444 445 446
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Todo,"It deals with an important and not frequently discussed practical problem (making OpenIE triplets more useful for upstream tasks), the approach is interesting and the evaluation shows that the system produces triplets of the type the authors advocate more accurately than other systems (I think more can be done to convince that this style of queries is indeed optimal for upstream tasks, but still, this work seems like a step in the right direction).
",568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo, ,
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Vu et al. 2021 seems very similar: (1) investigates prompt transfer through initialization, (2) tests different transferability indicators, (3) discusses building a ""prompt warehouse"" for retrieving related tasks and improving prompt tuning. ",404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"She)_, and likewise for the other 2 constructions. ",1123 1124 1125 1126 1127 1128 1129 1130
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,"Please keep a separate ""Related Work"" section. ",191 192 193 194 195 196 197
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Todo,This paper has done a solid work on Multilingual Pretrained Language Models. ,178 179 180 181 182 183 184 185 186 187 188 189
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Todo,See Weaknesses ,262 263
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"- Table 4 (1): Always use the same number of decimal places, for example 61.90 instead of 61.9 to match the other values. ",632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,- What is the annotator agreement between the five annotators before employing MACE's method? ,334 335 336 337 338 339 340 341 342 343 344 345 346 347
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,How do the visualization using imperfect NER/EL resources and processing tools compare to the visualizations obtained on the annotated data? ,352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,What is the target KB size used for MedMentions in the experiments? ,263 264 265 266 267 268 269 270 271 272 273 274
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"Did you use some special off-loading?
",490 491 492 493 494 495
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Line 135: -> for each of the following ... ,471 472 473 474 475 476 477 478 479
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Todo,It would be interesting to show/compare some examples that are routed to the swift model by energy/softmax/entropy based approaches. ,235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,2. ,464
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Todo, ,
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"On a minor note, many important points are relegated to the appendix.
",312 313 314 315 316 317 318 319 320 321 322 323
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Todo,See the weaknesses section for suggestions. ,294 295 296 297 298 299
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,"
3. ",265
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"\mathbb{Q}_K is defined at L894 as a class of functions, while Q_K is the K-th code distribution in the codebook. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"-Limitations of NPRM - ""while"" --> ""why"" (or just get rid of ""while"") ",243 244 245 246 247 248 249 250 251 252 253 254 255
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Todo,N/A ,457
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,- I would recommend to clarify notation when it comes to GPT-2. ,277 278 279 280 281 282 283 284 285 286 287 288
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,There are many sentences that begin with “And …”. ,445 446 447 448 449 450 451 452 453
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Maybe the problem is actually non-existent in vision tasks? ,944 945 946 947 948 949 950 951 952
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Todo,All my suggestions in the previous version have been addressed. ,698 699 700 701 702 703 704 705 706 707
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Todo,- L100 “Zero-shot cross-lingual learning *is an” ,372 373 374 375 376 377 378
17895a29154ef932b798525a3fdd7daff03be79bde1e53998bfd0955be1720f0a3151d0ddc1d02683ccd1bdab897ee17ad96bd9cc0f54486f77e05bdcd142729,arr,Todo,No obvious errors of writing is noticed. ,97 98 99 100 101 102 103
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Todo,Additionally adding results for both QuantGPT and QuantBART for both the tasks for completeness. ,323 324 325 326 327 328 329 330 331 332 333 334 335 336
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,QUESTIONS: ,224
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
4. ",633
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Todo,I was wondering why the author believes that annotation limits the quality of the test cases. ,186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,"-Please indicate if f-score, precision or recall is used when ROUGE is mentioned ",261 262 263 264 265 266 267 268 269 270 271 272 273
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Todo,"- The paper now has an ablation study that supports each components efficacy, but it's presentation can be improved. ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,What is the correlation of the chosen scale item in the breadth-of-posts study?). ,299 300 301 302 303 304 305 306 307 308 309 310 311
53d0d9ae0394c4f59496513484fb9e9d625c0064283125135b8f81ec3a08afa63dc10427b9d929924d7cd1d29e9ad560df79372aa72a957bbe91a7acca6ea44c,arr,Todo,- Any idea about the difference in performance between using XLMR-base and XLMR-large? ,273 274 275 276 277 278 279 280 281 282 283 284 285
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Todo,## Comments Suggestions and Typos ,247 248 249 250 251
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Todo,1. ,384
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,- Related to the previous point: it makes a lot of sense to me that data-model alignment affects MT performance. ,416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"What about the last subword embedding, an average of all subword embeddings?
",614 615 616 617 618 619 620 621 622 623 624 625
73837843c65a425ff419296a34871a445f1e2fee4cb8940431054c5ec0c1beb405f43cdd40fd27e52cf27aab7574eb4f160655995346c0889edc41328e588bdb,arr,Todo,"Also, the time prediction seems to be completely off; the softmax classifier might be useful for diagnosing the problem. ",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo, ,
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Todo,"
3. ",257
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Todo,--NA-- ,400
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Line 100: what is 'sharable format'?
",400 401 402 403 404 405
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo,-Perhaps the following dataset is of use for your coreference replacement task: https://arxiv.org/abs/2102.05169 ,394 395 396 397 398 399 400 401 402 403 404 405 406
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Todo, Any thoughts on that? ,238 239 240 241
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Todo,- Introduce key concepts in the discussion of the theorem ,576 577 578 579 580 581 582 583 584 585
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Todo, ,
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,Why are the authors mentioning this? ,427 428 429 430 431 432
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,Is it due to the desire to show evidence that the aligner works? ,371 372 373 374 375 376 377 378 379 380 381 382 383
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,- Does the routing fluctuation problem exist in common MoE models or just the one compared (BASE Layer)? ,304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo,The 'task' for the ML model? ,600 601 602 603 604 605
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"You need to further explain why you are comparing PCEE-BERT to an ensemble model, and what insight did you gain from the results. ",1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,"- In Table 6, the header contains abbreviations. ",361 362 363 364 365 366 367 368
0943e5d2efbf75734b113861f9c2bb8ca031e0740fce519c60b9b17470dea2b0df56aa327e769a0e36e89ac92fa23086cd9ee85094e50a67d721965f0c3509f7,arr,Todo,"Can you please clarify/expand the evaluation methodology, e.g., given gold anaphors, you only evaluate the antecedents? ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
6bd292c3f083f1a278739bedb1db76eb53014bcfa286c850680811f20b8fe3f79ba1881809e4fd3532754f4e6344d24365f551e1c879292061577d5b3b70f0e6,arr,Todo,"If the authors can consider releasing the model, it will benefit more of the research community. ",292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Todo,The claim they make in lines 225-228 are partially true. ,391 392 393 394 395 396 397 398 399 400
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Todo,"(1) It's not clear why the author would use the phoneme embedding from a tacotron 2 model as gold data, which seems contradictory to the paper's statement. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,"Lines 078-079 / Line 08: For clarity, it would be better if the evaluation metric is mentioned here to better understand the scale of the improvement; this would also be helpful to understand the results reported in this paper for comparability: the expression “labelled F-measure scores (LF1) (including ROOT arcs)” was used in Fernández-González and Gómez-Rodríguez (2020). ",395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"-Line 161-162: this sentence is not clear.
",262 263 264 265 266 267 268
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 3] line 197: Another benefit of working with continuous prompts (that is also specific to your approach) is that it allows you to form prompt clusters, something that is not straightforward to do with discrete prompts. ",802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"
2. ",221
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"- How about comparing your proposed method with existing ones by using the standard F1 score?
",460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). ,845 846 847 848 849 850 851 852 853 854 855 856 857
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,The paper is clearly written. ,462 463 464 465 466
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,"This idea is interesting, and the motivation is reasonable. ",199 200 201 202 203 204 205 206 207
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In Section 4.2.2, it is unclear what the “top scoring” sentences (line 417) are. ",603 604 605 606 607 608 609 610 611 612 613 614 615 616 617
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,Should the section on the geometry of hypernyms possibly have a citation to http://proceedings.mlr.press/v97/allen19a/allen19a.pdf ? ,400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"
5. ",217
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,"Also, if this argument can be clarified, this sentence should be added to the paper.
",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Does this mean that such a combination is incorrect and thus not possible? ,561 562 563 564 565 566 567 568 569 570 571 572 573
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Todo,"Even if I take into account the convenience of fieldwork, there seems to be little need to compare training times. ",580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,"Figure 2a ""unifrom"" ",473 474 475
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Todo,"Please refer to the comments above.
",272 273 274 275 276 277
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,Can you simplify the paragraph? ,346 347 348 349 350
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,"- #55: Doesn't your attention-based approach also implicitly encodes relevant contexts into unnamed relations?
",220 221 222 223 224 225 226 227 228 229 230 231 232 233
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"-> ...because of the fact that HSK is ..., so candidates ",233 234 235 236 237 238 239 240 241 242 243
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Todo,"p.3 Casual Relationship --> Causal Relationship p.7/8 The human evaluation questions that are reported are 3  (readability, question relevancy, answer relevancy) but the intercoder reliability is evaluated on 4 dimensions. ",439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,"And also the inference speed is unclear.
",393 394 395 396 397 398 399
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"or is it a PCEE-BERT in which when a decision to exit has been made, the ensemble is used instead of the intermediate layer? ",1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"-Figure 2: I would find it more intuitive to report the MISS percentages in a table, analogously to Table 3. ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Todo,no major comments. ,606 607 608
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo,"
There are minor changes to the introduction section, lengthening the introduction and moving the related work section to the more traditional position, right after the introduction.
",425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,-Section 5.4 - What is really happening here? ,489 490 491 492 493 494 495 496
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,"The results section would be easier to read if there were bold-marked takeaways as paragraph headers, or at the beginning / end of each paragraph. ",548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,This is not a new discovery either. ,698 699 700 701 702 703 704
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"	Line 458, is “0.18 BLEU” a significant improvement? ",262 263 264 265 266 267 268 269
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"Whereas in Table-4 the baseline system show high MCD and FFE error than the baseline + fine-grained VAE and baseline + CVAE systems, why is it?
",384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"“We first select concepts for the seed by referring to the features on the corresponding websites, to ensure their relevance for immediate downstream tasks.” - ",205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"Could you elaborate a bit more about this?
",257 258 259 260 261 262 263 264
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"More concretely, ",376 377
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,-l. ,256
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"-Table 1: How did you choose the p=0.6?
",261 262 263 264 265 266 267 268
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,"I would suggest to you that the right thing to say is ""Table-based verification faces different challenges than unstructured-text-based...."" Text analysis has been around for quite a long time, while [web] table analysis for around 15 years.
",162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,"I guess some details on this process should be presented in the paper.
",348 349 350 351 352 353 354 355 356 357 358 359 360
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,- Algorithm 1 is not really explained. ,129 130 131 132 133 134 135
0805cef3514c6a8a408cb365fd19199aaee44bbc746bb7bc13c51afa2bd0cfdd0e9165c5a40142bf664015f97a59341d81ff0ce405993bbbbaeb8110390c3739,arr,Todo,Some grammar issues need to be reviewed. ,166 167 168 169 170 171 172
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,4. ,249
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Table 3:  the meaning of (tracking) should be clearly stated, or use another name like “w/ oracle bounding box labels”. ",783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Todo,"-Table 2: there are only three values of $\phi$ listed, and there are no difference between $\phi=0.5$ and $\phi=1$. It would be good to show more details on how $\phi$ affects the final performance.
",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,"missing baseline in table 5, 6: I would like to see the comparison including InfoXLM and XLM-Align. ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,It seems they are not directly comparable. ,324 325 326 327 328 329 330
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Todo,"First, it does not learn when the revisions are complete (having the system is Figure 2 is not very informative) and looking at the suggestions provided by the samples in the appendix, another concern may be raised. ",180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Ln 335: These models don’t really simulate nonnative English speakers. ,772 773 774 775 776 777 778 779 780 781
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-How many seeds did you use to report mean and stdev on the development set?
",423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Todo,It is unclear to me what's the input to the prior network. ,389 390 391 392 393 394 395 396 397 398 399 400
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,"If so, saying that such scenarios never happen in the training set could mean that it is likely to conceptually have such combinations exist, but it’s just that it’s not seen in the training data. ",574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo, ,
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,Have you done that? ,332 333 334 335
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,2. ,171
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Todo,"Some items in Table 2 and Table 3 have Spaces between accuracy and standard deviation, and some items don't, which affects beauty.
",437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,"hypothesise rather than hypothesis in the above sentence.
",848 849 850 851 852 853 854 855
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,2. ,322
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,-Line 389: You mention here you used different p values as in Table 1. ,357 358 359 360 361 362 363 364 365 366 367 368 369 370
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Todo, ,
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Todo,"
Also, Section 5.1 should indicate that complex definitions from Gen. Decoder are evaluated on Complex (from the OD test set) and simple definitions from Rec. ",304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,-It would be insightful to investigate the impact of the model size of the encoder. ,228 229 230 231 232 233 234 235 236 237 238 239 240 241 242
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Todo,I don’t understand what “0^nd” means in section 3.1.4  3. ,581 582 583 584 585 586 587 588 589 590
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Todo,"In line 047, ""consistinga"" should be ""consisting"". ",141 142 143 144 145 146 147
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,I list a few of the typos here. ,766 767 768 769 770 771 772 773
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Todo,None ,344
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] line 78: Can you expand on what the “soft prompts” are? ,577 578 579 580 581 582 583 584 585 586 587 588 589
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,line 309: |S| = \ell_j ==> |S_j| = \ell_j ,350 351 352 353 354 355 356 357 358
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- The link of the code is not available but the authors in a footnote affirm ""Code and data available at anonymous_GitHub_link"" ",403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"371 - Table 2, from random 0 to 37.59 is a stretch. ",533 534 535 536 537 538 539 540 541 542 543 544
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Todo,1. ,160
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"Why do you use BERT as the baseline method instead of RoBERTa, as RoBERTa outperforms BERT by a large margin in terms of clean accuracy on these datasets?
",466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo, And reference to Table 4 should be placed into Appendix C2. ,236 237 238 239 240 241 242 243 244 245 246
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,"-Just to be clear -- the different early-existing classifiers $f^{(i)}()$, for $i=1,\ldots,m$ each get the training label during fine-tuning right (that is to say, each of them is trained to predict the exact same label as the others, conditioned on a different intermediate vector)? ",1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"Different depths could be explored considering how much effort a user is interested to put in, but MAP at top-20 should never be ignored. ",453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,This paragraph would flow better if there were a sentence linking the two parts and making it explicit that the Transformer model is being used. ,502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"But, I suppose they should be \mathbb{Q}_K and \mathbb{Q}_K^NN instead. ",210 211 212 213 214 215 216 217 218 219
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"-Line 348: ""background 4, S∗ - latex styling suggestion, add footnote marker only right after the punctuation for that renders better with latex, so - ""background,\footnote{} ..."" in latex.
",1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,This is not exactly so. ,493 494 495 496 497
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L304: “the parameter” -> “each parameter” ,605 606 607 608 609 610 611
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(248): a -> another ,695 696 697 698
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,2. ,759
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,I would suggest that the technique focused on more high level ways of measuring for gains. ,865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,"
4. ",489
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,3 is the same as that of Tab. ,515 516 517 518 519 520 521 522
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,### Comments / Questions ,726 727 728 729
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"Seeing both possible answers makes the pragmatic scale on which the metaphor is being interpreted very explicit (for metaphor interpretation as structural mapping of conceptual domains, see eg Gentner and Bowdle 2008). ",198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,----------Typos----------   ,490
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"If not, it would be useful to explain why not.
",593 594 595 596 597 598 599 600 601 602
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"-On which data is fine-tuned the model for the ""Knowledge Distillation"" ",358 359 360 361 362 363 364 365 366 367 368
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,"
3. ",219
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Todo,"
3. ",329
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,2. ,378
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Todo,"- More clarification and novelty is needed for contributions in Sec 1.
",198 199 200 201 202 203 204 205 206 207 208 209
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"- Table 1: The reader must be able to easily identify which configuration described in the text corresponds with each raw, and this is not the case. ",760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,Is it the number of unique entities in the labeled partition (as shown in Table 2) or is it the entire UMLS? ,275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Todo,"The information about the passive voice checker in English is missing.
",518 519 520 521 522 523 524 525 526 527 528
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"If so it would be useful to mention this.
",833 834 835 836 837 838 839 840 841
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"- For Table 3, did you also evaluate against human answers (e.g. original response)? ",363 364 365 366 367 368 369 370 371 372 373 374 375 376
b1fb88206c3832e9f87e6f8115045f3478d45617776f8397f37664d4de722806db84bff9744f31328a47ad99443cf3b52355d950d9e6fa09b9747dbb3b9f4f21,arr,Todo,"It may be good to know if a better teacher model (BART-large, PEGASUS-large) produces better pseudo-labels for summarization distillation. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Todo,"
 - Can this approach be used with the ColBERT model, where the ranking scores are based only on the similarities within the last layer? ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,- PISP objective: I can see how patch-based swapping may help for learning a better intra-modal association in the case where the patches depict some objects the text refers to. ,242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Todo,-Might be interesting to expand on how the different VRM categories correlate with metrics like model engagingness ,268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo, ,
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"XLM-E substantially outperform XML on both tasks"". ",148 149 150 151 152 153 154
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- A dot is missing after the ""Label distribution and linguistic insights"" paragraph title.
",425 426 427 428 429 430 431 432 433 434 435 436 437 438
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"Just say Distinct-1 and Distinct-2 are the number of distinct unigrams and bigrams divided by total number of words.
",1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,*Additional questions:* ,216 217
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Todo,"If the authors do not have the resources to conduct this analysis in time, I suggest the authors to revise their claims on vanishing gradients as layer conductance does not measure that. ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"Since the systems have been build for pedagogical purposes, why not trying to use it as a teacher for machines as well in self-supervised trainings? ",391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,"A2: ""We believe any functions that first rise then decrease can also obtain similar results"" -> Do you have any other instantiation? ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
42ae5ac0b6ebf8dbeb0aacafa17347e79484894bf3755dc74179c72dc37a6c50f1ec70fcebe4c3d99626a87a96b3c794fad2694e04ff203897c71a6b4e97a96e,arr,Todo,Some of the LaTeX could be improved in the mathematical formulas. ,222 223 224 225 226 227 228 229 230 231 232
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Todo,Perhaps moving Related work higher might be useful for readers. ,313 314 315 316 317 318 319 320 321 322
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,Is the complete manual annotation or extracted by the named entity recognition tool? ,184 185 186 187 188 189 190 191 192 193 194 195 196
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,1. ,228
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"However, both of them are CLIR systems and this creates some confusion in the reader. ",554 555 556 557 558 559 560 561 562 563 564 565 566 567 568
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,"
4. ",322
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,f) What is the trigger-word set??? ,264 265 266 267 268 269
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,"
3. ",392
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Typos: 1. ,294 295
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Todo,"
2. ",343
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,"My feeling is that their method would address some of this, plus it's a stronger baseline regardless as it also takes label shift into consideration. ",479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"
In other words, ""even if greedy search is used, SPP is not a big deal, let alone that in reality we use beam search"", something like that.
",450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Todo,It would be great if the authors provided experimental analysis on the reason bi-encoders outperform cross-encoders when the encoders are pre-trained on their method. ,285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Todo,"Line 247 ""However, if two or more tokens are exact duplicates of each other, then one can easily remove the duplicates from the input and modify the self-attention appropriately to get the same CLS embedding at the top layer, and hence the same prediction.""
",476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Todo,seems incomplete? ,467 468
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"Table 1: It would be easier if you explain about ""Type of Skills"" in the caption. ",265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"For this reason, I would like to see the PCEE-BERT compared to smaller models (instead of a large model with budgeted exit). ",648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"The 'mask first token' methodology (Footnote 4) would lead to better MLM results for models that use finer-grained/shorter subwords, if tokenisation is not controlled for.
",504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"Due to the notation, the reduction where one C term (the constant in KL) is removed is unclear. ",1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"why is 5 anonymous, didn't understand?
",441 442 443 444 445 446
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] line 110: At this point of the paper it is unclear what “prompt clusters” referred to. ,721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Ln 221: Avoid factives (show that) when discussing experimental results ,762 763 764 765 766 767 768 769 770 771
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Todo,- Typo line 1: rational-centric → rationale-centric ,250 251 252 253 254 255 256
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,"Since quality is a 3 dimensional vector, is the complete covariance matrix approximated or a diagonal covariance matrix is assumed (which I guess won’t be a reasonable assumption for this problem)? ",709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,-L462: \citet should be used ,492 493 494 495 496
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Todo,"In domain adaptation, if the models are trained on the proposed dataset and tested on the existing dataset, does it perform better than the other way around? ",445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Todo,Figure 2 should be presented better. ,129 130 131 132 133 134
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,You seem to consider precision more important in order to not raise false alarms. ,412 413 414 415 416 417 418 419 420 421 422 423 424 425
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,"I reviewed the previous version of this paper, and most of the minor comments I mentioned have been addressed in this version. ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo,"- Please give us some statistics on the templates, how many they are per dataset, how they were developed (by one or several humans, was there an algorithm? ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Todo,Boldface in Table 3 doesn’t always refer to the best BLEU per column ,591 592 593 594 595 596 597 598 599 600 601 602 603
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,"In Section 3 (line 247-252), I am wondering tables are divided into three types. ",461 462 463 464 465 466 467 468 469 470 471 472 473 474
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,-The baseline with CharSVM seems disadvantaged. ,377 378 379 380 381 382
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Line 471: -> such as ,695 696 697 698 699
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Todo,"
Models trained on such synthetic datasets can also be compared on the human-annotated datasets. ",279 280 281 282 283 284 285 286 287 288 289 290 291 292
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"Is there a way to make this more intuitive?
",585 586 587 588 589 590 591 592 593
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,It might still be nice to include this in the camera ready. ,539 540 541 542 543 544 545 546 547 548 549 550
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- Please, move Table 1 to page 2. ",395 396 397 398 399 400 401 402
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo,"On line 154, ""detrimental for"" should be ""detrimental to"".
",315 316 317 318 319 320 321 322 323
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"This is okay but it probably should have been mentioned as the main premise for the work instead of a finding.
",480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"Then the authors say that they used three methods: TF-IDF, TextRank and KeyBERT. ",1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,I haven't seen any typos. ,457 458 459 460 461
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Todo,"I suggest the authors to focus their comparison on word2vec baselines (currently in appendix), instead of Sentence-BERT, as the latter does not show good performance on the short texts. ",260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Todo,"There are other typos that I did not mention, like parentheses starting right after the word without any space, more in general, the paper needs a good session of typos polishing. ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"NAACL.
",950
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Todo,especially important because the hNews and Twitter datasets are really small) ,343 344 345 346 347 348 349 350 351 352 353
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,There's the GPT-2 architecture and the GPT-2 pre-trained language model. ,289 290 291 292 293 294 295 296 297 298
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,PMLR ,536
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Todo,I'd like to see my doubt about the pretraining cleared up. ,191 192 193 194 195 196 197 198 199 200 201
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,So I'm just going to ignore this section completely. ,277 278 279 280 281 282 283 284 285
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," Since your experiments modify the kind of signal that the model receives during training, I was wondering if that has a confounding effect on the results. ",736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"-Line 430: You say that the batch size for each GPU is 4,096, so 16*4k = 64k in total for your server. ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,"The subsection organization seemed confusing.
",742 743 744 745 746
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"Minor grammatical/spelling concerns: (Line 97) ""Medica intent"" (Line 124) ""Contrastive Reply Networks"" (reply or replay?) ",394 395 396 397 398 399 400 401 402 403 404 405 406 407 408
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Todo,"Such as?
",369 370
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"Based on this iterative process, one can find all the relevant entities belonging to a concept. ",343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"196 - ""Machine Learning as a Service"" --> machine learning as a service (MLaaS) ",366 367 368 369 370 371 372 373 374 375 376 377 378 379
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Todo,"As BERT is incapable of processing very long texts (more than 512 tokens) like clinical records [1], other text representation methods should be considered.
",70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Todo,"
3. ",169
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"In the caption of table 2, what does strong mean? ",578 579 580 581 582 583 584 585 586 587
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,The Exemplar Dictionary plays a key role in generating training instances. ,1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085
5f9df67495c17db90e7bfcce611efe8b65edcb225b9fb603e5b7e3d30b198f39a36e0c38f66bc04a063129ecdaf2e387b1cb42291be7cf83de659b9fb091736c,arr,Todo,See weaknesses ,359 360
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,I believe what is really important to get out of those numbers is how metrics change in a relative manner when moving to fewer and fewer samples. ,1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,"-The way the multilingual model's vocabulary is chosen (25k units taken from imbalanced multilingual sources, size-wise) is likely to hurt performance on Livonian-English; it might make more sense to check to see what vocabulary granularity is being used for Livonian (if all or mostly characters, for example, that suggests the multilingual vocab is not appropriate, and perhaps a set of smaller BPE vocabs for each language should be created and then joined after) ",361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo,"- The basic principle of using multiple synonyms of ICD terms is quite common in earlier work: using the presence of ICD in the UMLS makes it straightforward to obtain more terms for the same ICD code, and terms can then be used to help concept extraction and normalization from text. ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"-Nit: In Def 2.2, is v a constant across all R, or can we pick a different v for each R? ",687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"They just acknowledge contrasts in acceptability (which are historically used as evidence in generative grammar…and in other frameworks).
",638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,"But this is an issue in the whole article.
",313 314 315 316 317 318 319 320 321
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Todo,Typo: L492: Sec ?? ,346 347 348 349
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"For example, the captions of tables and figures should contain necessary explanations of what are presented and what are the major findings that a reader should put focus on. ",703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Todo,"However, there are some problems that do not allow me to accept the current version. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,"
Mao, Junhua, et al. ""Generation and comprehension of unambiguous object descriptions."" ",298 299 300 301 302 303 304 305 306 307 308
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Todo,- (please see weaknesses) ,321 322 323 324
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Todo,See Weaknesses ,252 253
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,"If the language-agnostic templates could be applied to other structure prediction tasks with good improvements, the contribution could be larger. ",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"Would the method help more sequences with more triples?
",400 401 402 403 404 405 406 407 408
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,-Notation of BERT_\theta and BERT_\epsilon is confusing. ,244 245 246 247 248 249 250
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,Is the cross-lingual consistency a signal of something other than the general performance of NER/EL systems? ,872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Todo, It would be interesting to see more such analysis and discussion of the datasets. ,210 211 212 213 214 215 216 217 218 219 220 221 222 223
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,"Maybe I do not understand correctly, but using pseudo-labeling for AL is not a new concept. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,-line 557: more robust ,763 764 765 766
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Todo,"Was there any hierarchical annotation role?
",424 425 426 427 428 429
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In Table 3 the authors report the performance based on the review of a claim as the upper bound. ",768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Todo, ,
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,Other suggestions. ,227 228
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"    ""Using an attribution method as the ground truth to evaluate the target attribution method.""
",681 682 683 684 685 686 687 688 689 690 691 692 693 694
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,-What is the inference procedure for single-span (v1)? ,352 353 354 355 356 357 358 359
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Todo,"
On the contrary, I found it really difficult to draw any conclusion from a case study with two examples. ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,Could you add additional lines showing accuracy under attack against more than one method? ,292 293 294 295 296 297 298 299 300 301 302 303 304 305
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,   * Line 155 - representations ,492 493 494 495 496
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo, ,
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"
I have not been able to fully understand section 3.3, especially the second paragraph. ",452 453 454 455 456 457 458 459 460 461 462 463 464 465
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"Maybe delete the ""better"" at the end ",187 188 189 190 191 192 193
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,How is this variance estimated? ,689 690 691 692 693
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Todo,Checking the weakness will help. ,167 168 169 170 171
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Todo,SD} } ,504 505
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,"- Eq.(8) $c$ has not been defined.
",496 497 498 499 500 501 502
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Todo,"-Figure 1: The caption seems oddly placed being on the right-hand-side (presumably this was to fit the figure easily for review, but may not strictly be okay so something to check, I'm not sure).
",528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Todo,"It would have been useful if in Table 5, examples of the templates would have also been given. ",418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"-Adding to the previous point: probing in itself would not even be necessary to gain insight into the layerwise contextualisation; some of the current experiments could be conducted in such a fashion as well.
",1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"Weren't they free to correct the sentences in any way they wanted as you stated in lines 178-180?
",371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,"-“Separate model for each stage” is mentioned, but I am still not sure whether this means 2 (fine and coarse) or N models?
",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Todo,Is PPL a commonly-used metric for storytelling? ,457 458 459 460 461 462 463
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,I am not sure I understand the motivation of this step. ,446 447 448 449 450 451 452 453 454 455 456
97bd72cf67e40492696103ced9dcbd5066d8a3a52f3d2558764aa570e24ae2c7bedddf9ad226e624b1dabcced450f36d6bcd93ece5a871c74fa98b7e2d8145fc,arr,Todo,"- It took me a while to understand that ""sign"" and ""gloss"" refer to the same thing. ",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo,-the related work would be maybe put to better use after the introduction ,967 968 969 970 971 972 973 974 975 976 977 978 979
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,"But this paper if accepted needs better proofreading.
",774 775 776 777 778 779 780 781
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"227: What's the size of the set of knowledge candidates?
",246 247 248 249 250 251 252 253 254 255
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"-line 572ff: ""This is consistent with our previous finding in the main results that TinyBERT (with KD) captures more task-relevant knowledge than BERT for task relation detection."" ",530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"A detailed efficiency analysis in presented in Section 4.5"". ",133 134 135 136 137 138 139 140 141
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,-I don't believe it is fair to make the comparison in Table 4. ,334 335 336 337 338 339 340 341 342 343 344 345 346
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Todo,Why the best MER result is reduced to 0.14 after selection ,322 323 324 325 326 327 328 329 330 331 332
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,"Also, it will be interesting to see whether using the classification results on visual claim classes can help the classification performance on tertiary claim classes. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"For the ablation experiments in Table 2, it might be considered to include various (valid) combinations of exclusions (e.g. w/o PL and w/o FL); in particular, the performance for the baseline memory-based model (i.e. without any of the proposed extensions) would be important in benchmarking against the comparison models.
",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,1. ,239
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Todo,"We"" ",261
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Todo,"Line 517: typo - ""improveD"". ",253 254 255 256 257
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Syntactic dependency? ,353 354
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.2,3 -- In introducing ""soft prompts"" (p.2) and prompt tuning (section 3.1), the Li and Liang 2021 paper is presented as just tuning input embedding vectors. ",473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,"If you don’t have hypernym information for a particular word set, how will you be able to know whether they are maintaining the output property at all? ",505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,-It was stated in Section 3.1 that the data was annotated on a syllable-basis in order to avoid the automatic word segmentation problems. ,193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Todo,"
line 275: to the text → to the text as in ",249 250 251 252 253 254 255 256 257 258 259
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,384 - 52x --> 52 times? ,573 574 575 576 577 578
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"Did you have your own implementation, or directly use their released embeddings/code? ",342 343 344 345 346 347 348 349 350 351 352 353
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"### Main questions/comments Looking at the attached dataset files, I cannot work out whether the data is noisy or if I don't understand the format. ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Is there a specific reason for choosing 9 as the number of runs? ( ,610 611 612 613 614 615 616 617 618 619 620 621 622 623
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,"   * When investigating cosine similarity, authors should consider the work that    investigates MLM embedding spaces, namely    https://aclanthology.org/D19-1006.pdf and    https://aclanthology.org/2021.emnlp-main.372.pdf, which discuss the    anisotropy phenomenon. ",366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo, ,
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,2. ,300
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,  2. ,449
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,Line 122: we -> We 2. ,449 450 451 452 453 454
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Todo,It's better to also append the results of proposed weakly supervised pre-training method and unsupervised pre-training method  to the main table (Table 2). ,170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"Please provide more details for the sentence retrieval setup (how sentences are retrieved, from what corpus, is it the same/different to the setup in (Artetxe and Schwenk, 2019) ? ).
",282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,Proceedings of EMNLP. ,513 514 515
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Todo,"Also, it is interesting to see that summaries in Table 3 are very different from each other, while the same cannot be said for Table 4. ",510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Todo,"Otherwise, one can think that the improvements are in hundredths of a percent (very small).
",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"Similarly, ""She was as embarrassed as a kid who got an A"" might mean she is ashamed of being called a nerd, or proud of her academic success. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
a09847ed94d9d36c62841908a6163e9cbb9e341099ac05ab01ec5a9c9de0e32dd33a5f044591d548fb961736b3ef91c5043ff5a59632d5bfa86eaf5303e5f438,arr,Todo,"For example, are the template used for schema expansion helpful for creating a ""parsing-friendly"" schema? ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,550: Did you calculate the agreement between the annotators? ,257 258 259 260 261 262 263 264 265
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,"-In the name of reproducibility: What embeddings are used to compute the cosine similarity?
",364 365 366 367 368 369 370 371 372 373 374 375 376 377
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,Is it just s_i? ,232 233 234 235
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,"- Luu, K., Wu, X., Koncel-Kedziorski, R., Lo, K., Cachola, I., & Smith, N.A. (2021). ",275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"-L082, autoencoder ",582 583
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Some geographical indicators are disregarded, and that may have an impact on the visualizations. ",560 561 562 563 564 565 566 567 568 569 570 571 572 573
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,Table 1 in this paper corresponds exactly to Table 3 Vanilla Baseline in Lin et al. [1]. ,635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,Maybe having more text labels would help. ,357 358 359 360 361 362 363
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Any pooling? ,255 256
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Section 7 - The conclusion is weak as far as the results are concerned at a high level. ",847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
3. ",460
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,(Question 1) Should \hat{\theta} and \hat{q} of the left hand of Eq. (14) at L14 be \hat{\theta}_n and \hat{q}_n? ,177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,References ,532
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Todo,> 0.6  0.4 0.6 ,298 299 300 301
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"As far as I know, neither of those three are sequence to sequence models. ",1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,8. ,585
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Todo,"This would have been a nice positive to stress on.
",322 323 324 325 326 327 328 329 330 331
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,How was this two-parameter decision turned into a single-parameter speedup? ,854 855 856 857 858 859 860 861 862 863
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"actually affect calibration in expectation?
",1357 1358 1359 1360 1361
057a3f73710f304801787e253e5ffc7e5d2eb9cf4570a5e3c6dc8edf75ebaadb324aff13a67e27a6057b12080f89cd80cc8d0f000bd23657daf14ff9c30856db,arr,Todo,- Please explain better how knowledge distillation is performed. ,149 150 151 152 153 154 155 156 157
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,- L444: The SRL-guided data construction is not clear. ,657 658 659 660 661 662 663 664 665
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"
L298: same as above Eq. 8: c in the summation is not used anywhere in the terms. ",528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Todo,"Therefore, how to determine the head concept and tail concept? ",175 176 177 178 179 180 181 182 183 184
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Todo,"I would advise the authors to dedicate a bit more space on discussing the results and their significance for further work and applications, perhaps shortening the background sections slighlty. ",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,In line 956 there is a comma between the subject and the verb. ,605 606 607 608 609 610 611 612 613 614 615 616 617
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,Averaged across all of them? ,604 605 606 607 608
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Todo,1. ,436
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"2) For sequence labeling, Wiseman and Stratos “Label-Agnostic Sequence Labeling by Copying Nearest Neighbors” in Proc. ",519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"Distance metric learning for large margin nearest neighbor classification."" ",543 544 545 546 547 548 549 550 551
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,"In lines 370-374, the paper claims that MT performance is not affected, but there is no evidence of it in the paper: the MT results are missing.
",551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
12. ",354
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Todo,"- Perhaps this point is not explicitly mentioned, but it seems like BitFit also has the added advantage of *not* introducing any new parameters to the model. ",295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,"The rule is ""if A is in B and B is part of country C, then A is in country C"". ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,"And while sampling self-constrains, do you sample from the word buckets based on the sentence itself or do you consider ALL possible words (from all sentences) in the bucket? ",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"- Figure 2, it is not clear about ""merge target"". ",115 116 117 118 119 120 121 122 123 124
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo, ,
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,- 121: Deviding 1508 into 16*90 = 1440 cases cannot be fully correct. ,588 589 590 591 592 593 594 595 596 597 598 599 600
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,3. ,254
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"For example, in section 2 it would be nice to see a better formalization of the architecture. ",216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,5. ,868
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,They are two different metrics altogether and should probably not be compared in this manner. ,1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Todo, ,
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Table 2 caption:""mean average"" ?
",531 532 533 534 535
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"-Could the ‘priming’ aspect of Johnson and Goldberg (2013) in the Jabberwocky experiment perhaps be emulated more closely by framing it as a “Targeted Syntactic Evaluation” task (akin to Marvin & Linzen (2018), a.o.). ",1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"If LMs still rank altered sentences generated from the same template closer than sentences with the same verb, then it is clearly the function words, number of phrases of a certain type, or order of phrases that determines similarity.
",511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Todo,"-Have a strategy to filter out best quality question from the set of synthetically generated questions.
",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"Rewrite or attach to the previous one.
",436 437 438 439 440 441 442
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,Any reason you did not consider the other GLUE / SUPERGLUE tasks? ,509 510 511 512 513 514 515 516 517 518 519 520
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Todo,It seems that the four proposed resampling methods behave differently in different settings. ,125 126 127 128 129 130 131 132 133 134 135 136 137
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Todo,manually? ,634
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Todo,I'm not sure what has led to the change. ,732 733 734 735 736 737 738 739 740
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Todo,- l483: This *suggests* ,404 405 406 407
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,"Overall, the localization of Tables and Figures in the paper would be more optimal to ease the reading. ",440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"Can you add some details?
",353 354 355 356 357
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Todo,-Is there any deficiency/limitation of introducing these objectives? ,267 268 269 270 271 272 273 274
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"I guess this is why it's helpful to know exactly what $\beta$ is.
",1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Todo,"It seems that the proposed document augmentation approach is not mutually exclusive to other approaches such as query generation (QA, DA, AR in Table 1), and we should evaluate the combined performance of them with DAR. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,For “speed comparison”. ,156 157 158
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Todo,"
I guess that a non-native human cannot do well in these tasks, in general. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Todo,"-Table 9 in Appendix: what does “keyword emerged in gold summary” mean?
",309 310 311 312 313 314 315 316 317 318 319 320
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,A batch larger than 100 examples results usually in an out-of-memory error when using huggingface transformers with a distilbert model. ,470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"Santhanam, S., Karduni, A. and Shaikh, S., 2020, April. ",598 599 600 601 602 603 604 605 606
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Todo,"If you are using entire belief/predicted states for calculating T*, your metric is almost identical to the AGA. ",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"In the caption of figure 2 'Phone' is mentioned but it is not present in the picture.
",559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Lines 396-400: Do you remove the remaining 9% from the dataset? ,657 658 659 660 661 662 663 664 665 666 667
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Todo,"While defining the formal desiderata, probably for reasons of space, the authors do not provide enough intuitive description of what the target of the different principles is. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282
0943e5d2efbf75734b113861f9c2bb8ca031e0740fce519c60b9b17470dea2b0df56aa327e769a0e36e89ac92fa23086cd9ee85094e50a67d721965f0c3509f7,arr,Todo,Typo: line 513 'pretrained' ,102 103 104 105
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Todo,"-As mentioned in the previous section, it would be interesting if authors can discuss more details of each model (e.g: what error each model make and when should we use each model) ",348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,- It wasn't clear to me why the authors needed to build their own software for the annotation task. ,279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,"
2. ",267
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"
Because in reality, especially that many MT models are considered in the paper, greedy search is seldomly used. ",432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Todo,"> It applies for merge in most cases but it is not case for attach, right? ",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,"For example, it may be possible to compare the baseline with the proposed model trained on ROM+EU to see where the benefit comes from.
",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,-The definitions of usefulness and diversity seem quite intuitive. ,192 193 194 195 196 197 198 199 200
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,The user does not have any idea about gold-k and could only go to some pre-defined depth such as 20. ,433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Todo,None ,233
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"Using a segmenter or tokenizer?
",307 308 309 310 311
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo," I've never seen significance at p < 0.01 for such a tiny score change.
",514 515 516 517 518 519 520 521 522 523 524 525 526 527
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,"
2. ",247
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"Is this type of out of distribution evaluation intended?
",205 206 207 208 209 210 211 212 213
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,line 865). ,1006 1007
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,"Appendices C1 and C2:  I think at l.563 the reference should be to Table 3, not Table 4. ",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,"In OT,  earth mover's distance is more common. ",861 862 863 864 865 866 867 868
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Table 1: needs to include a random baseline to show the task difficulty 10. ,294 295 296 297 298 299 300 301 302 303 304 305 306 307
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Todo,"
Line 300-304: q and d are confusing ",420 421 422 423 424 425 426
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,It will be nice to see some examples of the system on actual texts (vs. other components & models). ,470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,-L.490: “we take the embedding of the first subword token as the verb embedding.” ,973 974 975 976 977 978 979 980 981 982 983 984 985 986
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,Your study or GEC in general? ,238 239 240 241 242 243
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Todo,See weaknesses ,180 181
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Todo,1. ,228
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"[a] - Wang et al. ""Interpreting Interpretations: Organizing Attribution Methods by Criteria"". ",1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Todo,"Without at least some human judgement, it is difficult to judge whether or not this holds. ",646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Todo,"
and are also applicable for encoder-decoder -> is also ",359 360 361 362 363 364 365 366 367
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Todo,This option should be explored. ,274 275 276 277 278
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,6. ,1222
262843a4c9c8009e43c652fd03dead78e120f32d62499d0826136d5c4e1204d19e1bcc09ae3b3c7a938f919e9e86262d824cc86c483e18e874e11562461a1524,arr,Todo,Could the authors please comment more on their decision of including only one comment for context? ,157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"Not sure if this is essential to get all the details precise here but probably it would be good to define what ""calibration error"" is at the least.
",1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Todo,Figure 2 is hidden in the text. ,259 260 261 262 263 264 265
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Reference should be put to ambiguous descriptions (e.g. refer Line 253,254 to Fig.2 such that examples of OBJ<class> can be well understood). ",744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,1. ,317
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Todo,"Line435-436: ""their weight initailiza-tions"" -> initailizations ",143 144 145 146 147 148
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,l.219: trigramma function > trigamma function ,198 199 200 201 202 203
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Todo,does this show that sentence level models aren't learning that information? ,460 461 462 463 464 465 466 467 468 469 470
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,"-Appendix C:  hard to understand how Figure 5 is produced, since CBMI values are calculated per token, not per sentence. ",565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Todo,"
2. ",549
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,Rephrasing: ,883
ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42,arr,Todo,1 The paper is well written and easy to follow. ,129 130 131 132 133 134 135 136 137 138
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-Line 28: ""However, recent studies..."" Which recent studies? ",807 808 809 810 811 812 813 814
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo, ,
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Todo,"It might be interesting to explore simpler models with static (cross-lingual) word embeddings, especially for the languages that are not included in the pre-training of XLM-R. ",363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,"Though strictly accurate evaluation metrics for attribution methods might be a “unicorn” which will likely never be found, we should not just ignore logic traps in existing evaluation methods and draw conclusions recklessly.” ",881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Other related work ,829 830 831
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,"In equation (12), there's a dependence on the vocabulary. ",452 453 454 455 456 457 458 459 460
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"A few possible reason that the model is finding it hard to learn that 10-30% bin, (i) term is mapped to too many multiple targets in training data or mapped to targets that's not in the constraint list of terms in a skewed manner, (ii) the translated outputs though not in the reference are valid translations though not the preferred one ",388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo,"My current score of 3.5 reflects these weaknesses + other unclear details that I've mentioned in ""Weaknesses"" above. ",859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,"How exactly do you formulate queries (378)?
",181 182 183 184 185 186 187
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,I wonder if there could be hyperparameters for CGExpan that are not well-tuned. ,562 563 564 565 566 567 568 569 570 571 572 573 574
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Todo,"On line 198 it is explained that the second layer has a task-specific prompt, while the first layer has an instance-specific prompt. ",342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
a6f83f54bd43db725bd0f67fc819f1c0b0bf631d8badf27f63f1eaca61865c0f943ea31260da63ebb8157c4b7131d3f08990bba93564e11293c433f2a1cd5109,arr,Todo,The reference of a related work (https://aclanthology.org/2020.wmt-1.53) is missing in this paper. ,100 101 102 103 104 105 106 107 108 109 110 111
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,"In the experiments of this paper, it is assumed that the golden topic entities are given (as indicated in lines 187-188). ",360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Todo,"- line 249: ""tuned"" -> ""tune"" ",130 131 132 133 134 135
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"3.
",675
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Todo,1. ,424
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo, ,
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,-Boosting Neural Machine Translation with Similar Translations. ,214 215 216 217 218 219 220
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Todo,"
Some important information such as the number of extracted oracle sentences should come directly under the experimental setup, not in the Appendix. ",343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,-What was the distribution of the annotator’s background with respect to the attitudes? ,464 465 466 467 468 469 470 471 472 473 474 475 476
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"The method of collection and distribution assumptions are questionable.
",589 590 591 592 593 594 595 596 597
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Todo,"The paper needs more innovation and comparison with past work.
",144 145 146 147 148 149 150 151 152 153
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Todo,How did you determine what questions you were going to ask the annotators? ,178 179 180 181 182 183 184 185 186 187 188 189 190
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,Why did the significant performance drop occur when using local entities in the experiments? ,271 272 273 274 275 276 277 278 279 280 281 282 283 284
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo," If you compared each annotation to the rest but the systems were compared to all the annotations, then I believe human evaluation is an underestimation. ",618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"- In paragraph 481, please show didactic examples where the ""Parent"" helps to identify the class of the ""Target"". ",439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,	Line 576: proves -> prove. ,247 248 249 250 251
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Todo,The amount of the training data and the model size are important for pre-training. ,204 205 206 207 208 209 210 211 212 213 214 215 216 217
64d426bdd2237b1a76367942d93054e27cbba57122d341c186e2724c64f32ea70276be64edd40415fcfa2a55ffb540f5d6e8d89acd4ac1bf95878ac359286fa7,arr,Todo,"That is, if we obtain token-level distributions by masking each token in the input in turn, and then use the resulting smoothed representations, is this better or worse for augmentation than the approximation the authors propose? ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"However, methods based on soft prompt were designed with these factors in mind when it was first introduced. ",616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,"
2) The author mentioned that calculating the inter-annotator agreement between annotators, so whether all 800 documents are double-annotated? ",205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,How does the performance change for the fine-tuning setting when pre-training was without SimCSE (i.e. just ICT pre-training followed by supervised MS MARCO training)? ,574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,The authors find that project to “true” target prompts is no more effective at solving the tasks. ,681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Todo,"
2. ",290
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"
This baseline seems to combine tasks of various different lengths – do you expect the same models to be good at both? ",317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,L.32: Choose only one between “since” and “however” ,468 469 470 471 472 473 474 475
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,"I recommend citing the UHop paper, which is closely related to the proposed SR method.
",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,p < 0.05? ,1404 1405 1406
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"MFS - Multi partition has 1 #P and 9 #I according to the table while Multi Input has 4 #P and 1 #I which does not make sense.
",855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Todo,Specific comments for improving the work: ,145 146 147 148 149 150
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Todo,"Please correct the punctuation errors and review the consistency of words (orthography with or without dashes, upper and lowercase letters). ",268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,How would this approach scale to batch size > 1? ,296 297 298 299 300 301 302 303 304 305
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo, ,
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,What is the source domain? ,430 431 432 433 434
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,Is there any explanation? ,390 391 392 393
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"For example, CRN implements memory by storing the top n (prototype) examples (Line 160) for each class - do the other methods such as EMR also have access to n examples?
",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Todo,"I suggest the authors do it, which will improve the influence of the work. ",234 235 236 237 238 239 240 241 242 243 244 245 246 247
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"In particular, I would suggest the authors take their `bert-base` classifier, and train using MTL with different dataset combinations. ",511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,The token selection algorithm used in the paper also reminds me of another way that combines the selective encoding method and Gumbel-Softmax for BERT. ,298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
555b9b4626e46bff6dcd1dd669cac930e4e3c587766a39059797b4d5100a130d8c7aa4ee67cb74e7ebc5a9126fed58d4b54ceab34144da5a84f5d402acdf18af,arr,Todo,It would be beneficial to the community to release the software and associated models along with exporting the models to an engine that can take advantage of lower precision for increased inference speed. ,155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,3. ,790
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,-096: typo: MLR -> MRL ,243 244 245 246 247
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,4. ,983
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,It is good to point out what do they mean. ,369 370 371 372 373 374 375 376 377 378
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,"For the other settings/models/modalities, the difference in effectiveness is comparably marginal. ",385 386 387 388 389 390 391 392 393 394 395
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,-I suggest to make a change to the tables. ,470 471 472 473 474 475 476 477 478
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Todo,Numbers in Tables 2 and 3 look more crowded. ,221 222 223 224 225 226 227 228 229
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Todo,There is no mention of making the built datasets publicly available. ,210 211 212 213 214 215 216 217 218 219 220
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"This wouldn't change much of the argument as from what I can tell from Figure 5, Implicit is still better than MAP with %UNANS of 25. ",454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,"
For RF-HEALTH event type, you mention that it is about mentions that directly affect the subject's health. ",469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Eq. 1: what is z_p 6. ,236 237 238 239 240 241
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"Maybe use this to explain/motivate why you opt for continuous prompts early on the problem formulation?
",839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,The paper completely ignores the bias term in the softmax. ,610 611 612 613 614 615 616 617 618 619
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo,- I think explicit and implicit questions might not be a good naming. ,409 410 411 412 413 414 415 416 417 418 419 420 421
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-017: You can hint at which components you refer to ,194 195 196 197 198 199 200 201 202 203
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Inconsistent use of uppercase / lowercase in the title: tasks > Task; boost > Boost ,744 745 746 747 748 749 750 751 752 753 754 755 756 757 758
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Todo,"
2. ",138
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Todo,[line 734] Ioana Hulpu? - ,202 203 204 205 206
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Todo,Lines 276 and 328 AOPC rather than APOC ,813 814 815 816 817 818 819 820
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Todo,What is that reason? ,159 160 161 162
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 509: exapmle -> example ,771 772 773 774 775
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,-l.294 spareness-->sparseness ,489 490
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-In line 906, it is clear from the previous papers that Beam search results lack diversity and increase the beam size does not work. ",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo,"In Table 2, can you clarify what ""Paper"" and ""Others"" are? ",407 408 409 410 411 412 413 414 415 416 417
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-188-191: why would you need to generate both of them? ,249 250 251 252 253 254 255 256 257 258
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Todo,"
3. ",205
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Todo,"As a result, Figure 4 should be Figure 3, etc.
",218 219 220 221 222 223 224 225 226 227
34a654d252d0bb72f0bd405e28bc8a2c52097ce0c2fc0293a544b3bd1929cfc5996e389971dc43791136d5d78b742372f89326f61ab0ae0fdb56d762335f5639,arr,Todo,****The authors have adequately answered most of the weaknesses mentioned in the previous review.***** ,154 155 156 157 158 159 160 161 162 163 164 165 166 167
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,"Section 5.3: One suggestion I had to make things a little easier to follow in this section is to add a table comparing the performance of the best models for each paradigm (classification, regression, pairwise-ranking) on the ranking metrics. ",312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,why the beam search algorithm is wrong? ,203 204 205 206 207 208 209
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Todo,How is the prompt token computed at inference time? ,323 324 325 326 327 328 329 330 331
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo," Currently, it's a little hard to follow the written results here because the reader has to check between multiple tables to make the comparison.
",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Todo," Or can you do more to tie it in with the preceding sentences?
",344 345 346 347 348 349 350 351 352 353 354 355 356
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo, ,
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,- The description of the BERT model is unclear. ,405 406 407 408 409 410 411 412 413
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo," Yet, based on Eq 7, the source probability factor is cancelled out anyway, so it doesn't really matter.
",418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Todo,"p. 3 first paragraph, ""should"" replicates just below formula (7). ",370 371 372 373 374 375 376 377 378 379
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"This is crucial, to understand why incorporating instance-level information is needed and can help motivate better your approach!
",703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Todo,"But, even in that case, I could not follow the transformation from L910 to L911. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"-Line 254: “is arguably a decoder” -> why arguably?
",231 232 233 234 235 236 237 238 239
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,I think maybe more data is needed to answer this. ,760 761 762 763 764 765 766 767 768 769
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo,"As a general comment, I find that this paper seems to be a bit scattered, or better, it alternatively shifts from a culturally-situated focus to the strive for “language-agnostic” approaches. ",812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"Adversarial examples can be highly confident and I suspect   means of incorporating confidence can themselves be subverted adversarially.
",1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Todo,How do you make sure that the false negatives in your dataset do not disturb your evaluation? ,368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Todo,"Line 136: “We find that as long as the student model is properly initialized, the vanilla KD can be as performant as those more sophisticated methods” <- it'll be great if the authors can elaborate. ",430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"- With regard to terminology and concepts, toxicity and hate speech may be related but are not the same thing. ",378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,"For example, in Figure 3, are h_i vectors or lists of vectors (with different layers) and if the latter, at what part are they aggregated? ",332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Todo,"- About ECE score: There should be an explanation from the paper.
",284 285 286 287 288 289 290 291 292 293 294 295
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-line 325: UIR -> IUR ,592 593 594 595 596
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo,"Also, how did you decide 1:10 ratio of constituents to distituents? ",512 513 514 515 516 517 518 519 520 521 522
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Each dataset (for the geographical mapping) is analyzed separately, so while cross-lingual consistency is indeed a problem, it is not clear how it is related to the problem of dataset mapping. ",841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,2. ,369
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"
2. ",1623
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,All of these sub-problems need to be treated more systematically and carefully. ,215 216 217 218 219 220 221 222 223 224 225 226
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-General comment: Specify upfront that when you say robustness, you mean robustness to adversarial perturbations and when you say accuracy, you mean accuracy on the original held out test set.
",735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"To me the loss curves for different algorithms are all smooth, how do you define a **smoother** loss in this scenario? ",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"It would have been useful to see how an end-to-end process performs: apply NER on the NER and QA datasets, and build the same visualizations as in section 3. ",323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Todo,-Line 214 - theorem 2 could benefit from providing an intuitive explanation ,235 236 237 238 239 240 241 242 243 244 245 246
21f74d3b60a2101f1630894856ba99180af6242a02b80070fe7274f02c867becdb7ff3d683a90f84d0f414d7b873d0fa2c18407c4bedd4e1bebb8dbcedc40de6,arr,Todo,"Apart from the concerns above, it is better to have some insights on how more other language pairs not in the test set correlates with increased performance. ",317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo, ,
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Todo,-Minaee et al. (2021) can be cited: Deep Learning–based Text Classification: A Comprehensive Review ,188 189 190 191 192 193 194 195 196 197 198 199 200 201
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,Some minor suggestions & questions:  ,242 243 244 245 246
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"	Lines 170 to 171, “unreliable neighbors” any examples of “unreliable neighbors”? ",250 251 252 253 254 255 256 257 258 259 260
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,"-In the results under ""Interpretation Promotion"", it is stated that ""most of the explanations generated by our method are reasonable even though the BLEU scores are low"". ",644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,Repetition of the word Tables in Line 549 3. ,381 382 383 384 385 386 387 388 389
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Todo,"-It will be useful explaining briefly the currently available NER datasets for the Thai language in the related works section.
",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation EMNP 2018 3. ,409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Todo,"Shedding more light on this might give us more hints on when we should use wav2vec and when we should refrain from using it.
",324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,"This would illustrate if the optimal flood level generalizes across attacks.
",306 307 308 309 310 311 312 313 314 315 316
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,He)_ to that of _P(gave | He cut it seasonal. ,1113 1114 1115 1116 1117 1118 1119 1120 1121 1122
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"[3] Ryskina, Maria, et al. ""Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction."" ",734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo, ,
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Todo,"  And with the observation of substantial difference in COMET and BLEU score, the author suggest that NAR models may rank poorly in human evaluation, why not add the human evaluation in the paper? ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Todo,"In experiment, it can also do fine-tuning on CLIP. ",284 285 286 287 288 289 290 291 292
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,"
3. ",285
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"-In Table 3, en-cs BPE to character results are missing the recall on lemmas/forms seen in training.
",690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706
80f0f27bae63d383650b5083d56d54d49670478d69ab16c333d994ebabdcc2558eff25814b0b8333c8a9865b96d20dc0e171383473a1e65de16556abe5eef90c,arr,Todo,"While I can see a detailed work in the paper, I would recommend the authors to address the points mentioned in the weaknesses. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Todo,The total number of summarization to be performed is N + 1 or N^2 + 1? ,265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,I did not understand the utility of presenting results in Table 2 and Table 3. ,349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"I am not sure of whether similar results apply to creative metaphors, especially out of context. ",398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Todo,How does the performance goes when we tune the parameter alpha in equation (6) and (7)? ,138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"What about the remaining 68 cases?
",601 602 603 604 605 606
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,### Questions to the Authors ,237 238 239 240 241
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,"Ferreira, et al., 2019. ",452 453 454 455
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Todo,More clarity on specific contributions of the paper. ,393 394 395 396 397 398 399 400
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,"-156: ""objective objectives"" sounds weird.
",271 272 273 274 275
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Todo,"
3) For the results in 5b, it would be good to add some models from the above work for comparison. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,The reasoning between line 448 ~ 452 is confusing. ,383 384 385 386 387 388 389 390 391
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Todo,1. ,397
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,	Line 53: the publication year is missing from the citation for WebQSP. ,212 213 214 215 216 217 218 219 220 221 222 223
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Todo,-Line 321-323: The text seems to indicate that $p_{\theta}(Z^{p})$ is shorthand for $p_{\theta}(Z^{p})$.  Should the second instance of this be something else? ,464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,"-Are different hyperparameters (e.g., drop out rate) explored? ",242 243 244 245 246 247 248 249
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Todo,"It would be more fair to either estimate %UNANS from the training data (i.e. 25%) or to split the DEV-mixed in half, use one half to estimate the best %UNANS threshhold and the other half to compare Implicit with the chosen threshhold to MAP. ",410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Todo,Do you consider generating or extracting contrastive pairs during model training and testing? ,168 169 170 171 172 173 174 175 176 177 178 179 180
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"[1] Tom Kocmi, Christian Federmann, Roman Grundkiewicz, Marcin Junczys-Dowmunt, Hitokazu Matsushita, Arul Menezes. ",533 534 535 536 537 538 539 540 541 542 543 544 545
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Todo,This is a very vague sentence without any proper basis. ,200 201 202 203 204 205 206 207 208 209
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Todo,"Please change to the concrete formulas, or at least state that. ",686 687 688 689 690 691 692 693 694 695 696
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo,-Typo: +0.55 -> 0.54 BLEU (line 473) ,482 483 484 485 486 487 488
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo, How are these priors calculated and used in training? ,497 498 499 500 501 502 503 504 505
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"Meaning, if these problems were perfectly translated into another language, would they remain valid? ",434 435 436 437 438 439 440 441 442 443 444 445 446 447
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Todo,Fine-tuning multilingual LMs enables good generalization for zero-shot cross-lingual transfer. ,169 170 171 172 173 174 175 176 177 178
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"line 165, finetuning T5-seq with prompt examples is meaningless given there are only #services new examples in prompt. ",361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,"2- The concepts ""topic"" and ""event"" are confusing as they are used in the paper. ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,Only the dependency data is there. ,508 509 510 511 512 513
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Todo,Not having to go to the Appendix for the results would make things easier for the reader. ,381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"-Table 2: The highlighting of the numbers does not correspond to the caption (""highest scores are in bold, second highest scores in italic"") ",293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,"If so, will this setting make the synthetic dataset easier? ",424 425 426 427 428 429 430 431 432 433
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"- In Figure 2, should the distilled distribution of $Z^p$ not be conditioned on $Z^k$? ",325 326 327 328 329 330 331 332 333 334 335 336 337 338 339
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,"Conventionally, 3, 5, or 10 are common). ",624 625 626 627 628 629 630
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo,"Note that this is more  more of an opinionated point of view (which could be discarded and I am thus not putting in the weaknesses section), but I think the paper should enhance the former, linguistically and culturally grounded perspective, which in my opinion is also the main strength of this work. ",901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"The same error also appears in line 94.
",397 398 399 400 401 402 403 404
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,why do you think sharing decoders among two tasks would help? ,275 276 277 278 279 280 281 282 283 284 285
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,- I think having a few points of comparison to your approach will give a better perspective for us as readers. ,413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-Figure 1 caption: ""In a realistic scenario, negative examples have the same length and structure, while positive examples act in the opposite way."" ",558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,Suggestions: 1. ,280 281
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Todo,1. ,541
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"It would be helpful to refer to longer text as a summary or a ""headline roundup"" as allsides.com calls it. ",866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Todo,The authors could add more analysis about the multilingual alignment of entity representations and it would be better to have visualizations or case studies for different types of languages such as language family. ,164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Todo,"Figure 1: although it is very intuitive to use one random example to demonstrate the distribution of false negative examples, it would also be good to show the statistics over the whole dataset or a particular slice of the dataset. ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Todo,"In Table 3, Column Color, Bert_L has the same values for Tune=N/Y. Is this a typo or a coincidence?
",586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Miscellaneous: 1. ,742 743
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,Other comments: 1. ,413 414 415
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,May also allow better comparison between models. ,713 714 715 716 717 718 719
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,	Line 435: a space is missing between “statement.” ,236 237 238 239 240 241 242 243
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,"It improves the readability and gives a clearer overall picture to the reader.
",449 450 451 452 453 454 455 456 457 458 459 460 461
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo, ,
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"
10. ",2010
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,However there are many large multilingual or english models available that can be fine-tuned. ,480 481 482 483 484 485 486 487 488 489 490 491 492 493
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"-2 Related Work - ""result in"" --> ""results in"" ",223 224 225 226 227 228 229 230 231
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo, ,
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,"- In Sec. 3, it is a bit confusing why there is a division of source domain and target domain. ",589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,I hope to see the authors' response in resubmission (if rejected) or clarifications in the camera-ready (if accepted) to remove my concern. ,877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,-428-448: I didn't understand how you feed the subword or token representation to a char-LSTM? ,447 448 449 450 451 452 453 454 455 456 457 458 459 460 461
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Todo,"-L104: Various structured prediction tasks have *been studied, ",379 380 381 382 383 384 385 386
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Todo,- ,265
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"To make understanding easier, I would start by outlining what the role of source prompts and cluster prompts is in the beginning of 4.1 and then expand on the more low-level details of how each of them is computed. ",918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,"- Studying more efficient and recent Bayesian approaches, such as: ",483 484 485 486 487 488 489 490 491 492
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,I will assume that it is better to replace the whole phrase instead of independent words. ,201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
dfd2ab193176f5966f14f5955687cf4e9b38cfdf5757e0cad23cca2bad60275ec30dfe3c06f55b0bf02741baed5b541ed734f52904675c5eaf7214f95f7a1ae3,arr,Todo,N/A ,164
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-Improvement still be observed with a better encoder, e.g. RoBERTa-base, instead of BERT?
",410 411 412 413 414 415 416 417 418 419 420 421 422
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,---------------- References ---------------- ,821 822 823
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"For example, from Kk to En, +FA is significantly better than mBART (14.4 vs 14.1, difference of 0.3) and thus the cell is highlighted. ",407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,Comments ,323
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,The introduction can be fleshed out a bit more to present the two problems separately and clarify/motivate how the proposed approach targets each of them. ,491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"Also, latest trends in mental disorder detection with attentive relation networks are missing. ",119 120 121 122 123 124 125 126 127 128 129 130 131
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo, ,
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,The only time a footnote should appear before a punctuation (if there is a punctuation right after where you want to place a footnote) is if the punctuation is a dash. ,826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,6. ,609
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Todo,"And, how much changes after the post-edit stage? ",262 263 264 265 266 267 268 269
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,Please separate the parameters for clarity. ,362 363 364 365 366 367
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Todo,"
2. ",300
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Todo,This paper is a differential review given that I previously reviewed the work in the Dec 2021 version submitted to ARR. ,404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Lines 173-174: What is a character language modeling dataset? ,536 537 538 539 540 541 542 543 544
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Todo,"Based on Fig 1(a), it seems like even Et-En and Si-En suffer with the problem of partial input bias when evaluated on DA scores. ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Todo,"
2) Consider adding an explicit related work section which also discusses work on out-of-distribution example detection, which is a closely related more general problem to the questions this paper aims to explore. ",449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Todo,This would definitely increase the value of this work among both NLP and language documentation communities. ,274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,-How was the train/dev/test split determined? ,824 825 826 827 828 829
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Todo,"
2. ",183
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo, ,
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Todo,"During the transition turn, did the process also check if the user is requesting for more information or a question before switching to TOD setting ? ",240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Todo,"If yes, what are the significant changes you observed between the two approaches? ",47 48 49 50 51 52 53 54 55 56 57 58 59
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Todo,"
I suggest changing all XY, EX, XE notations to X-Y, En-X, X-En, since they could be confusing. ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,The paper is clearly written and the claims are evaluated well using an extensive set of experiments. ,593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Todo,1. ,151
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"ideally be specific since, at this point in the paper, we do not know what is being measured, and 'extremely competitive' is also quite vague. ",1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Todo,This will show whether the control tokens really do contribute to the model’s performance. ,251 252 253 254 255 256 257 258 259 260 261 262 263 264
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Todo,The confusion mostly comes from the implementation details and the results. ,240 241 242 243 244 245 246 247 248 249 250
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,It seems Sec. 2.1 should be a standalone section discussing experimental setups and results. ,353 354 355 356 357 358 359 360 361 362 363 364 365 366
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,2) Questions: ,542 543
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,Does the x-axis represent the **inverse** frequency of constraint? ,173 174 175 176 177 178 179 180 181
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Todo,The authors have done a very good job at addressing the comments from the previous reviewing round. ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,Typos Line 409 we adopt BART-base for -> we adopt BART-base model for ,478 479 480 481 482 483 484 485 486 487 488 489 490
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"-Line 247: ""Where"" cannot be in a new sentence ",617 618 619 620 621 622 623 624 625
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Todo,1. ,75
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,"
2. ",740
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,“we developed a new RC dataset targeting students from kindergarten to eighth grade” Isn’t this range too broad? ,466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"For example, “given an anchor event, we generate 3 positive samples with different dropout masks.” ",278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,Entity Classification? ,610 611
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Todo,"However, in order to show the effectiveness of the suffix identification task task, the long-range Transformer model pretrained with the task need to have powerful performance on the downstream understanding tasks than vanilla language modeling. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Todo,How do you handle false negatives in your problem formulation? ,327 328 329 330 331 332 333 334 335 336
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,-l. ,282
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,Regarding experiments 1. ,295 296 297
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"For example, if you replace w_i, what happens with w_{i-1} and w_{i+1}. This could create incoherent text. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"
(2) How to determine the turning point? ",203 204 205 206 207 208 209
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-Footnote 6: As described in the weaknesses section, the authors should more explicitly describe these works and provide examples of how their work aims to improve on them.
",360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,- Sect. ,569 570
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"Provide citations.
",815 816
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,-Line 303: maximum the negative likelihood -> maximize the negative likelihood ,752 753 754 755 756 757 758 759 760 761 762
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"l 212:  ""the the issue"" ",529 530 531 532 533
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,-Line 344: with -> on ,646 647 648 649 650
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Todo,"As mentioned above, I would suggest including further baselines for the classification task. ",553 554 555 556 557 558 559 560 561 562 563 564 565
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo," You can shorten it starting at the sentence, ""This paper investigates both of these issues by making use of predictive uncertainty"", remove everything until you get to ""It is shown"", then replace ""uncertainty. ",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,References ,482
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"My reading of section F.1 is: We removed tanh because it worked better empirically (which sounds fine to me, provided it doesn't change the rankings of your proposed models and the baselines).
",805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836
5055d6e9bee3c38f171f9a51c2cc9db4023bba622f8b471a60e20864e21b6e012403a4b741ecaf347e239448fde93bfbf299ec9f5ee6bf0091d4c33ee9b19ba0,arr,Todo,This might be helpful for discovering some patterns in the data. ,165 166 167 168 169 170 171 172 173 174 175
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"  Regardless, no-one *expects* models to fully replicate the reasoning of a human. ",589 590 591 592 593 594 595 596 597 598 599 600
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,"One paper I think would make sense is: https://www.cl.uni-heidelberg.de/~sokolov/pubs/kreutzer18learning.pdf (also has character-level MT in the title).
",526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,"-Line 191: \cdot should be used instead of regular dot Section 2.1: It would be best to define the dimensionalities of everything.
",479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,Several typos exist in the paper. ,485 486 487 488 489 490
44e7ab41a54cab53f17e79871feb2713cc16df873abd22f680ff5a4c0366953bb1c6c359fd3fd84fa68c262345dae767a3250a4249f7a0583a6569f44fdaa4d1,arr,Todo,But current version is good enough for a short paper. ,111 112 113 114 115 116 117 118 119 120
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,What is the standard of defining the delimiter term? ,413 414 415 416 417 418 419 420 421
a08c0e0dafb5d74615009802dfc40b3801cc6a3f779b82e40b03a3f4c3f3bef3a4186e50fbbc8ec1a5364e61382882c08f2d7b7d4689d743a8b74728f99da313,arr,Todo,Please see my comments and questions in the core review. ,143 144 145 146 147 148 149 150 151 152
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,What is the required memory overhead to keep  4. ,307 308 309 310 311 312 313 314 315
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,"For me, one type (the column header) should work. ",475 476 477 478 479 480 481 482 483
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Todo,"The order of the Tables/Figures shown in the Appendices is somewhat confusing, having to jump back and forth across pages (although this may be due to their size and latex's automatic layout). ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,Detailed comments/questions: ,255 256
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo, ,
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Todo,"There should be enough horizontal space.
",238 239 240 241 242 243
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"This is explained later, in the appendix, but no clue is given to the reader at this point. ",644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Todo,- I also wonder why some numbers are missing from table 2-5? ,288 289 290 291 292 293 294 295 296 297 298 299
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,-L293: Do I understand correctly that as soon as a sentence fails in one of the 5 languages it is discarded? ,249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,-Line 097: biafine > biaffine  ,656 657 658 659 660
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Todo,Typos: Preposition is missing after models on line 276 ,571 572 573 574 575 576 577 578 579
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"As far as I understand, the refining mask is used only for training. ",339 340 341 342 343 344 345 346 347 348 349 350 351
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,SRR on NewsEla-EN is statistically significant. ,342 343 344 345 346 347
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,9. ,619
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,TYPOS AND MINOR ISSUES: ,472 473 474 475
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Todo,[2] Investigating Pretrained Language Models for Graph-to-Text Generation (https://github.com/UKPLab/plms-graph2text) ,340 341 342 343 344 345 346 347 348
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,-Subsubsection starting at 324: Would it make sense to use the lexicon information directly if available (which it is for some test conditions) and resort to automatic tools only if necessary? ,370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Todo,Do you have any observation or explanation for this? ,226 227 228 229 230 231 232 233 234
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"For example, if there are too few ‘free of speech’ annotators, then the results shown in Table 3, 4, etc are underpowered. ",477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"Also as 30 is rather small, the paper may discuss whether it is enough empirically.
",428 429 430 431 432 433 434 435 436 437 438 439 440 441 442
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"At this point, by looking at Figure 2, it would seem that more than one syntactic constraint can be concatenated at the time. ",1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"Do you join the text of all the snippets retrieved and, then, you count 5000 tokens?
",836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,"If not, when is H_{abstract} used? ",184 185 186 187 188 189
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-091-93: it just repeats the same sentence with no clarification. ,214 215 216 217 218 219 220 221 222 223
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"
Line 911: ""As in section 5"" -> ""As in Section 5"" ",923 924 925 926 927 928 929 930 931 932 933
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"Lines 264-265: ""The gap between HAM and ExCorD is significant in Auto-Gold"" - how is significance measured here?
",932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"Those in the 4-language parallel corpus?
",285 286 287 288 289 290
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Todo,Great writing. ,424 425
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,"For individual traits too, predicting the trait score instead of individual score, keeping rest of the set up same, may give you a quick comparison point, and make the paper more complete. ",464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Todo,"I think it is an important issue that is worth exploring.
",386 387 388 389 390 391 392 393 394 395 396
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,"If this is the case, I think this description can be revised, e.g. mentioning Li et al. (2019a) earlier, to make it clear and precise.
",667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"5% increase"" or ""0.05 increase"" would be clearer.
",349 350 351 352 353 354 355 356
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo," Also, the LM prior seems to give equivalent results to the ""prior selection"" and even to the full CBMI adaptive training method, why is this LM prior not compared to the LM prior in table 1?
",515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.6 For Task Tuning, training the projector directly on the training task examples seems very similar to prompt tuning itself. ",776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,"L432: ""No baseline can be applies to all four datasets"" is confusing.
",301 302 303 304 305 306 307 308 309 310 311 312
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Todo,-[2] Span-based semantic parsing for compositional generalization ,276 277 278 279 280 281 282
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Could you say why these two tasks were selected?
",684 685 686 687 688 689 690 691 692
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"One could wonder, for the WiC task, are the errors always due to models predicting ""matched"" for ""not matched"" GT? ",421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo, ,
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,-L47: consistinga of -> consisting of ,365 366 367 368 369 370
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Todo,Typos and Formatting Issues: 1. ,207 208 209 210 211
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,"Eva Hasler, Adrià de Gispert, Gonzalo Iglesias, Bill Byrne ",250 251 252 253 254 255 256 257 258
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,How do you deal with concepts (multiple entity mentions referring to the same entity)? ,449 450 451 452 453 454 455 456 457 458 459 460 461 462
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Todo,But my impression is that many in the ACL community do not engage with them at all. ,671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Todo,"From the paper, “We found that for en-kk, numbers of extracted word pairs per sentence by word2word and FastAlign are 1.0 and 2.2, respectively. ",312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,"Indeed, the SCR model performed better in all the tasks involving terrorism-related data. ",708 709 710 711 712 713 714 715 716 717 718 719 720
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(392): Remove ""In this subsection"" ",785 786 787 788 789
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"The manuscript, however, does not link well with recent literature on AI for mental health, e.g., see sentic computing for patient centered applications. ",96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"If so, it would be helpful to add some motivation for why this is an interesting problem to solve.
",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,You get the representations for the query-subject OR the candidate? ,414 415 416 417 418 419 420 421 422 423
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,There are many template methods for information extraction. ,304 305 306 307 308 309 310 311
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Todo,"Thus, the discussions from Line494 may be problematic.
",107 108 109 110 111 112 113 114
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,Can you also give speed/decoding comparison? ,319 320 321 322 323 324
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"1 ""Introduction"" contains too many redundancies with respect to the rest of the paper. ",571 572 573 574 575 576 577 578 579 580 581 582 583 584
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"9) ""... which does not need error-coded annotation"". ",485 486 487 488 489 490 491 492
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,-It would be even better to evaluate more datasets for text classification (e.g. SST-2 or TREC-6). ,223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"There is a big drop of from 46.94 to 46.03 of from “CKMT*” to “CKMT*+Ours”, any detailed analysis of this or any future work plan of this direction? ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Todo,"For instance, assuming that their reference task is S and the related tasks are T_1, T_2, ..., T_6, I would evaluate the following combinations: ",530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"Or, if it has been discussed elsewhere, provide citations. ",527 528 529 530 531 532 533 534 535
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Todo,"L237: question, I think you meant query here? ",441 442 443 444 445 446 447 448
5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec,arr,Todo,It will be better if the authors work on advanced AI algorithms such as deep learning. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Todo,-Was the notation in line 284 intentional? ,257 258 259 260 261 262 263
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo, ,
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,The instructions to the annotators seem to conflate both. ,398 399 400 401 402 403 404 405 406
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"e.g., line 92, 98).
",461 462 463 464
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Todo,"
3. ",306
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-**Lines 31-32:** one common reference for ""who did what to whom [...]"" is Marquez et al. (2008). "" ",713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,L. 390: in both corpora (no “the”) ,490 491 492 493 494 495 496
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Todo,"In Eq. 3, does T* include all the slots-values in gold and predicted belief states or just the predicted and gold slots-values in current turn?
",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,Some typos do not affect understanding: 1. ,442 443 444 445 446 447 448
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,What is the benefit of L2 distance? ,869 870 871 872 873 874 875
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"
2. ",249
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,Some citations have issues. ,910 911 912 913
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"Springer, Berlin. ",667 668
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"Hence, It seems that using the largest possible model would still yield the best results (as opposed to what is claimed in the overthinking problem).
",881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,"   * It would be interesting to see how the embedding spaces look like for BERT      out of the box.
",390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Todo,"For the analysis with varying homogeneity of training samples, would it help to look at performance on the romance and the outlier languages separately? ",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,"The same problem also appears in Line 1176.
",434 435 436 437 438 439 440 441
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo," This method may enhance the robustness of the proposed method, since it traverses more different combinations. ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo, ,
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 188 - Algorithm 1, line 25, gradients are explained and shown as a method call, but the main technique (CA) is not really in the algorithm, is the novel idea the logloss gradient transfer? ",518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,It makes the paper a little confusing to nest everything under Sec. 2. ,384 385 386 387 388 389 390 391 392 393 394 395 396
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Todo,"-L441: perhaps you meant Table 6, not Table 9? ",372 373 374 375 376 377 378 379 380
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"In particular, I would like to know if there were any counterexamples to the main points (e.g. are there titles that aren't representative of the type of bias displayed in the main article?).
",598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,Regarding paper organization: 1. ,331 332 333 334
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"
How should one decide on the number of softmaxes, input hidden states and partitions? ",620 621 622 623 624 625 626 627 628 629 630 631 632 633
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Todo,It seems quite artificial to me to create these probing tasks to draw conclusions for MMT. ,213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Todo,Were there any experiments performed to assess the efficacy of proposed methods for these languages as well ? ,371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,-225: in -> of ,266 267 268 269
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-Table 8: Some of the ""description-questions"" shown are ungrammatically, e.g., ""is the intent to ask about some refund?"", ",425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,Of the two major insights that form the basis of this work (polarity is a proxy for framing bias and titles are good indicators of framing bias) only first one is empirically tested with the human evaluation presented in Section 5.1.3. ,415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,"The paper addresses many times (Line 95-97, Line 308-310) that the consistency between training and inference can be easily satisfied due to the smoothness of neural models. ",658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,the soft constraint setup. ,293 294 295 296
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"-It is not clear the role of the dropout, as there is not specific experiment or comment on the impact of such technique. ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,-Line 138-144: Why the accuracy of predicting the number of heads is related to the observation that zero-head tokens are predicted too frequently. ,336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Todo,The assignment of a single moral label to a sentence seems quite definitive. ,397 398 399 400 401 402 403 404 405 406 407 408 409
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,"Any motivations to justify this definition, or is there any alternative form of definition? ",201 202 203 204 205 206 207 208 209 210 211 212 213 214
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,-Line 527: “randomly crop” -> randomly cropping ,293 294 295 296 297 298 299
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"-Background section: "" … Fang et al., 2019).Many…"" -> "" … Fang et al., 2019). ",267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,"l24 make achieve l58 have no doubt (need a comma or without have) l65 much often l158 black->block l159 number of, you already said it once, I understand what you mean, but it is not the numbers that you want enough of. ",1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo, ,
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Todo,"-Figure 4: if the y-axis is indeed in percents, then the ticks should be 0, 1, 2, etc. ",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Todo,"-I would recommend removing singletons from Figure 4.
",322 323 324 325 326 327 328 329
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,The citation of R^2 BERT in table 2 is incorrect. ,312 313 314 315 316 317 318 319 320 321
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Todo,See the { Summary } part. ,267 268 269 270 271 272
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"-Table 4: Should include other attempts at multi-intent datasets here (DSTC4, MixATIS, etc.).
",412 413 414 415 416 417 418 419 420 421 422 423 424
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,3. ,221
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,I would suggest changing this. ,651 652 653 654 655
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,I found ln616-632 excessively detailed for a conclusion paragraph. ,470 471 472 473 474 475 476 477 478
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"196 - ""can be directly.."", are you sure? ",380 381 382 383 384 385 386 387
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Todo,"Line118: SelfAtt_c => Cross Attention, the attention network over the encoder representations is generally called as cross attention.
",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Todo,"It is difficult to draw strong conclusions based only on automatic notions of factuality and quality, particularly when we are comparing the two. ",587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,8. ,469
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,"-Which is the impact of using different ratios of raw/augmented sentences for training?
",150 151 152 153 154 155 156 157 158 159 160 161 162
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,please explain more. ,277 278 279
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,1. ,1568
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Todo,"PMLR, 2019.~ ",537 538
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- Potential grammar issue near ""can be seen as an attribution"".
",1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"
2. ",229
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,4) Why have the authors decided to use the colon symbol rather than a more original and less common symbol? ,388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Todo," You might want to test CLEAR on this benchmark if possible -- I'm not sure how practical it is, so I've not included this under ""Weaknesses"". ",692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"
3. ",126
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,1. ,460
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"The insights gathered aren't particularly difficult to arrive at by reading the related literature and the examples in Table 1, while indicative of the arguments don't seem causally critical. ",546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,- #54: Min et al 2019 is a decomposition-based approach not a Neural Module Network ,205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"In figure 3, the test loss increases after some epoch, will the clean accuracy drop with the increased test loss? ",586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Todo,"-In terms of plug and play controlled generation methods that do not require fine-tuning of an LM, a citation is missing for Pascual et. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,"- In the setting where annotators were provided with both the question and answer prompts, doesn't this limit the example diversity? ",725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Todo,"It would take some time to implement your task for other corpora, which potentially use different programming languages, but it might be possible to still strengthen your results using bootstrapping. ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Table 2: Mentioning that the prompt used as cross model initialization is from _Task Tuning_ in the caption would make the table more self contained. ,1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,"- In Table 3(b), is it really the case that 23.19 BLEU for RO-EN is statistically better than 23.15, or is this a typo? ",490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Todo,"
2) I suggest the authors to add a brief discussion about how to pick learning rates in the “Smooth” variant; 3) Typo - line 440, “...from the all the joint…” -> “...from all the joint…” 4) Typo - line 561, “while MSLR while achieves…” -> “while MSLR achieves…” ",399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Todo,"This section might read more smoothly if you include an example question or a very short explanation for a few most popular types, such as ""Description"" or ""Symbolism"". ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Todo, ,
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"This point has been made   at least in [a].
",764 765 766 767 768 769 770 771 772
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Todo,And why use a single-head attention? ,198 199 200 201 202 203
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Todo,"It might help to add an example here to make this more convincing.
",671 672 673 674 675 676 677 678 679 680 681 682 683
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo, ,
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Todo,1- The ratio of RF-Other is too high (40%) in the corpus in comparison to other event types. ,198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Todo,"-Lines 26-27: Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.
",277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,- How do you decide when model training is over? ,701 702 703 704 705 706 707 708 709 710
25d81c5100d51b1e76e62a58136ddf202f0cd593dce3022314fa2faf872ce35425d15424a77e74592c2b856df0c9814c93b25c8d33ed6e03a9808afb71c740b5,arr,Todo,See review in Sept. ,31 32 33 34
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,- line 121: Should “a” begin a new sentence? ,514 515 516 517 518 519 520 521 522
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"Table 5, the models above the line are using slot descriptions, while the SDT-seq is using name only. ",306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"If yes, what is the data split you used? ",388 389 390 391 392 393 394 395 396
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,- l.266-268: The authors are surprised about the fact that the contribution of the KD with parallel corpus is greater than that of IR triples. ,852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Todo,Possibly split this into two sentences. ,556 557 558 559 560 561
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-Conia and Navigli, 2020. ",921 922 923 924
64d426bdd2237b1a76367942d93054e27cbba57122d341c186e2724c64f32ea70276be64edd40415fcfa2a55ffb540f5d6e8d89acd4ac1bf95878ac359286fa7,arr,Todo,"This is fine, but should be emphasized more explicitly.
",138 139 140 141 142 143 144 145 146
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Todo,Some examples may make it better to understand why partial input bias exists. ,234 235 236 237 238 239 240 241 242 243 244 245 246
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,"E.g if ""i"" refers to a token in the subject, don't use it to also refer to the index in the answer candidate later. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,"Since some of the sub-tasks, like dialogue state tracking, require a fixed format of the output, if the model generation is incomplete or in an incorrect format, how can we tackle this issue? ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Todo,Will the authors make the software available in a repository? ,327 328 329 330 331 332 333 334 335 336
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Todo,I appreciate authors' response. ,112 113 114 115
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Todo,"How is it related to what has been done in related research?
",191 192 193 194 195 196 197 198 199 200 201 202
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,would be good to put this into an appendix ,1428 1429 1430 1431 1432 1433 1434 1435 1436
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Todo,"-It would be better to define some notations and give a clear definition of the ""information axis"", ""word concreteness"" and also ""Markov chain information content"".
",247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Todo,"
 Why are the results varying so much on two different datasets? ",73 74 75 76 77 78 79 80 81 82 83
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,The original dataset contains source sentences and good+bad target words. ,461 462 463 464 465 466 467 468 469 470
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo,Can the authors elaborate on how this (paired with the skewed frequency coming with the high-granular dataset) affects the modeling? ,635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,I would move details on that in the Experimental Setup section and discuss only the results in this one. ,1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Todo,Grammar errors:  ,278 279
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"What happens with languages that occupy the same country-level geographical space, but are distinct, as happens with multi-lingual countries? ",782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Style ,742
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Todo,"Might want to check out work by Emily Morgan and Roger Levy on binomial pairs, predicting the ordering of items in a phrase like “peanut butter and jelly”. ",325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"-Line 409, could you cite the ""R2"" metric?
",276 277 278 279 280 281 282 283
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-Is the output of step (3) differentiable? ,1068 1069 1070 1071 1072 1073 1074
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,"Inconsistent intext citation styles:     - Lines 077-078 & 277-278: (Fernández-González and Gómez-Rodríguez, 2020) > Fernández-González and Gómez-Rodríguez (2020)     - Lines 276-277: (He and Choi, 2020) > He and Choi (2020) ",760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Todo," In Table 1 only the base results are flagged as such, but in table 6, it looks like both results are.
",371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Todo,"-Line 229: What’s t?
",511 512 513 514
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,-line 83f: clarify that these terms are introduced by the authors and are not pre-existing parts ,744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,"-Would not call 8.92 a ""very respectable BLEU score""; perhaps write that it is ""improved"" instead ",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Todo,NA ,484
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,- 091: I don't understand how this is relevant to the paper. ,213 214 215 216 217 218 219 220 221 222 223 224
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Todo,"Consider adding more samples and putting more highlights on the samples to show your superiority.
",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Todo,"-Line 248: ""... and is ..."" ",363 364 365 366 367 368
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,1. ,80
25ecf77df8e811b8c942cb9933c4bd14112d1de9ed3f8989adcb669076c94472a9497f9ae80d57e03ed8fcb031fa6f84877d8faf869d641e622e8ddebd622cca,arr,Todo,"No two sentences mean exactly the same thing, even before discounting noise from PPDB. ",225 226 227 228 229 230 231 232 233 234 235 236 237 238
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Todo,Seems that it is in the same direction with the general trends. ,347 348 349 350 351 352 353 354 355 356 357 358
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Todo,"If not, then please give the appropriate reference. ",254 255 256 257 258 259 260 261
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,I don’t understand how you are avoiding having any kind of ground truth labels for things like hypernymy? ,487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,What is      meant by `semantics'? ,455 456 457 458 459
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Table 1: do the baselines and the proposed method use the same training data for pre-training? ,317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,"For self-supervised pretraining, the authors are not limited to labeled images as in ImageNet. ",251 252 253 254 255 256 257 258 259 260 261 262 263 264
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Todo,Please update the citation for CronQuestions dataset to include the ACL 2021 paper link. ,186 187 188 189 190 191 192 193 194 195 196 197 198 199
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"it is a bit difficult to understand what are the “negative, positive, pivot” arrows in this figure. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"From Table 2, it looks like these methods are only training the projector on one task at a time? ",705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,"Globally, all metrics described in Section 5 would benefit from equations.
",429 430 431 432 433 434 435 436 437 438 439
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,--- ,970
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"Especially the third one which states ""Finally, borrowers will receive relief."" ",271 272 273 274 275 276 277 278 279 280 281
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,"given the connotation this term has with training small classifiers on top of a model’s hidden state representations.
",1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"Finally, check Ji et al.’s recent review of suicidal ideation detection.
",132 133 134 135 136 137 138 139 140 141 142
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"Rewrite or attach to the previous one.
",283 284 285 286 287 288 289
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Todo,Why is the font in tables so small? ,294 295 296 297 298 299 300 301
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Todo,"I suggest the authors replace it with ""Conversational context"", otherwise could be confused by the context of the sentence. ",315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,"-With the tuned threshold, how many MeSH terms are not selected during the dynamic masking on average in the different data splits? ",226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
747249d6df576d913b4dd001992510d9682657fee6f4ea775a23731979bf7af0362f975f45b8c27ae3b04e093fa81069cf32428adf42b4026a447055a6907e27,arr,Todo,Comparison with the adversarial training is necessary. ,170 171 172 173 174 175 176
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,"-In table 4, there is a spike in model performance in terms of annotation efficiency for likelihood sampling strategy in the Adversarial QA dataset. ",818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,Suggestions ,454
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 188 - Algorithm 1, line 14, while it may be obvious, ""y"" is never introduced or explained, is it the labels? ",496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,There is no explanation why the probability distribution of the top-k results in the softmax is an issue. ,558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Todo,"i.e., what if model A is performing better than model B in your task, but because model A is picking more on those false negatives and you only count performance based on true positives, you end up showing model B superior, where in reality model A is superior but your evaluation is noisy? ",385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"I may suggest that the work can focus on reporting bias *on top of* commonsense probing, i.e., commonsense probing can be just treated as an analysis tool to help you study the key reporting bias issues. ",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,SIGMORPHON 2021. ,751 752
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Todo,"Xia and van Durme has been published at EMNLP 2021 and can be cited as such.
",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Todo,"- What's the time complexity of Tracin operation?
",215 216 217 218 219 220 221 222
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,"They are both about the statistics of datasets used in experiments.
",230 231 232 233 234 235 236 237 238 239 240
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Line 360-367 are occupying too much space than needed. ,190 191 192 193 194 195 196 197 198
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo, ,
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"
4. ",1686
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Todo,l. 315: missing space ,291 292 293 294
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Todo,"Bilingual and pivot baselines are kind of weak in the multiway translation setup.
",318 319 320 321 322 323 324 325 326 327 328 329 330
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,1. ,246
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,"
5. ",496
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,It is a key column in your evaluation but is not explained at all. ,1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,"AAAI, 2020. ",367 368
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Todo,"Personally, I think of it more as *invariance*. (This point does not factor in to the final score since it's more of a personal take.) ",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Todo,Increasing the width of the line can help. ,138 139 140 141 142 143 144 145
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Todo,missing baseline in Fig.3 and Fig.4: I would like to see the comparison including InfoXLM an XLM-Align. ,230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	It would be interesting to also report or mention the class-wise F1 scores for veracity prediction and to analyse the confusion between the classes as a confusion between the True and False is much more severe than between True (or False) and the Partially True (False) labels. ",807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Todo,"Based on the author responses, that number should be four.
",336 337 338 339 340 341 342 343 344 345
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Todo,"- Can parameter counts/training time for graph-based models be provided?
",174 175 176 177 178 179 180 181 182 183
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Todo, ,
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,"If the word of S2 is to be decided as 'implicitly offensive', then one of the reasoning chain, such as 'you are fat/poor', should be provided as a context. ",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,The addressee may ask if bookclubs provide free food without offensive intention. ,365 366 367 368 369 370 371 372 373 374 375 376
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"Also, it is not recommendable to generate acronyms for multiword expressions that are shorter than 3 words, e.g., ED (unless they are universally recognized, e.g., AI). ",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"Also, the structure and writing should greatly improve. ",206 207 208 209 210 211 212 213
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"These different columns are all just very different sort of things, strange that they're presented next to each other ",936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Todo,Are they all native Chinese speakers? ,700 701 702 703 704 705
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Todo,"The theoretical analysis doesn’t provide much insight beyond that a loss computed on a held-out dataset (= the query set) is a better estimator of the expected loss than that computed on the training data, which is well known. ",503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,1. ,311
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo,"
Besides, this method seems to only fit downstream classification and ranking tasks. ",245 246 247 248 249 250 251 252 253 254 255 256
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Todo,"It should be noted that there are also lots of recent work on novel, challenging NLI sets, which the authors seem aware of. ",449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,"Nonetheless, I am slightly inclined to accept this work. ",233 234 235 236 237 238 239 240 241
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Todo," Does all the experiments keep the numbers of the parameters of the compared models the same?
",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"The soft prompt is only a sequence of ‘abstract pseudo tokens’ that can be understood by machines to assist the training of language models.
",656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Todo,What about the other XBRL tags that are not in the 139 tags? ,203 204 205 206 207 208 209 210 211 212 213 214 215
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,Why not simplify the presentation by selecting the best regression based and classification based approaches for each evaluation dataset and compare them against NPRM in Table 4 itself? ,364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Todo,Try incorporating more diverse and larger data sources to expand the data beyond NYT and also enhance it in size 3. ,463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Todo,"The authors frequently include numbered lists in the paragraphs that might be easier to read as actual lists instead of in paragraph form (where appropriate).
",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Todo,"Why is that?
",337 338 339
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Todo,-Converting generated results to events: Are there some generated results that cannot be parsed into events? ,261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Todo,"
2. ",185
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Todo,"Theorem 2 reads a bit abstract, so it would be much better to relate the theorem with the running, queen-king-woman-man example.
",447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"Consider rephrasing, e.g. ""With this background"", ""Given this background"", etc.
",213 214 215 216 217 218 219 220 221 222
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Todo,Factual detail questions and inductive questions might be more clear? ,422 423 424 425 426 427 428 429 430 431
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Todo,line 083: use colon instead of period. ,184 185 186 187 188 189 190
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,how is it defined? ,385 386 387 388
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"
2. ",166
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,QUESTIONS FOR THE AUTHORS ,358 359 360 361
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Todo,- How is P@10 calculated for spans of length 2+? ,376 377 378 379 380 381 382 383 384 385
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,- 006-007: The sentence sounds weird. ,181 182 183 184 185 186
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,"I believe you cannot say ""codes"". ",490 491 492 493 494 495
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,A better evaluation of the output produced by the proposed method would be beneficial for the reader. ,98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,-Constructions in MLMs: https://aclanthology.org/2020.conll-1.13/ ,832 833 834 835
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"1) Line 29: ""To support the GEC study..."". ",230 231 232 233 234 235 236 237
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Todo,-An additional experiment that might be interesting to explore is by probing for construction type across layers at the position of the verb. ,1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Todo,"- The authors can mention Geva et al. (EMNLP 2021) to justify excluding the Feed-Forward layer.
",460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Todo,are they hyperparams? ,1101 1102 1103
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Todo,"
3. ",399
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,CVPR. ,613
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"For example, a customer might mention that the room type of a hotel is small. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,"
-	In addition to the two datasets mentioned in the “Weakness” section there are others that could be useful to compare against, see e.g. “Automated fact-checking: A survey” by Zeng et al. 2021 or “A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking” by Hanselowski et al. 2019 for further references. ",457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,ON_ could be pushed farther. ,1956 1957 1958 1959 1960
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Todo,"Also, it might also be helpful to consider the typological distance between different language genera. ",294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,Will this bring some further improvement? ,221 222 223 224 225 226
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"For a larger dataset, it may impossible to just get the lattice graph, am I right? ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,1. ,766
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Todo,"-Are durations of phonemes predicted in frames or seconds?
",305 306 307 308 309 310 311 312 313
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Todo,- #277: What is i and j here refer to? ,234 235 236 237 238 239 240 241 242 243
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"
-I was a bit confused by Section 9. ",456 457 458 459 460 461 462 463
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"That’s why we should not disregard MAP at top-20, but we can explore the performance of a method at gold-k for reference. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"line 72), ""both formal/informal"" -> ""both formal and informal"" (line 81), ""supplement"" -> ""supply""? ( ",711 712 713 714 715 716 717 718 719 720 721 722 723 724 725
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"For future work, it may be worth considering adding cross-lingual contrastive learning to the training.
",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Line 058 - The intro here talks about alignment but then there seems to be a reference to Question Answering (QA), I understand that the case is not that but the writing here seems to be a little convoluted. ",302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"-Ln 78: “Neural reality” sounds vague and sensationalist (also confusing, as it sounds like it’s about the human brain) ",743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Todo,"
4. ",150
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Todo,- ,187
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Todo,"Space permitting, it may be beneficial to move the finding of Appendix B to the main paper as I found this interesting. ",527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,COVID-19 misinformation detection via identification claims and within-document events and entities.) ,672 673 674 675 676 677 678 679 680 681 682
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,5. ,348
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Todo,"
3. ",429
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,"e.g., isn't T5 also suitable?
",244 245 246 247 248
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Todo,See comments above. ,271 272 273
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Todo,"
2. ",728
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"034 - ""Unfortunately, large 035 language models tend to memorize training data"", cite or explain more... ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,1. ,189
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Todo,Dark colors in tables tend to make the numbers difficult to read. ,529 530 531 532 533 534 535 536 537 538 539 540
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,- Why don't the numbers at the top of Table 5 (for baseline label smoothing) match the scores given in Table 3 for LS? ,673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"5.2: feels a bit hard to say that your result clearly favors the legal models -- 13 total results, 6 of which the legal models do the best Why is there no “overall” score reported, like there is with GLUE? ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,"For instance, why the Haded attention- RNN and Adaptive transformer instead of more traditional LSTMs and normal encoder-decoder transformers (or decoder only transformers like GPT models)?
",335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"How should you handle that case?
",159 160 161 162 163 164
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo,- line 456-458: Maybe the reason FGWS works best on PWWS is that they’re closely aligned: both use word-based notions of weighted frequency-related characteristics. ,527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,#### Minor comments: ,306 307 308
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"In case this has not already been measured, perhaps a sample of instances where predicted history invalidates questions via unresolved coreference (marked by humans) can be used to then detect if the automated method catches these instances accurately. ",1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Todo,- Please put the equation in section 4.3 on separate lines for better readability ,245 246 247 248 249 250 251 252 253 254 255 256 257 258
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"
4. ",345
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Todo,"The reference (El-Kishky et al., 2014) had been published at Proc. ",414 415 416 417 418 419 420 421 422 423 424
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Todo,See weaknesses 2 and 3. ,234 235 236 237 238
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,For example TACRED or FewRel?) ,291 292 293 294 295
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"Soft skills are referred as attitudes (L180) but this work seems to only consider ""skill"" and ""knowledge"" (L181-183 and Figure 1)? ",328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,I'd rather see more details of the other Hebrew models. ,310 311 312 313 314 315 316 317 318 319
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,How is the performance only for the dense retrievers without BM25? ,612 613 614 615 616 617 618 619 620 621 622
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Todo,8 annotators were used but only the roles of 6 annotators are described. ,411 412 413 414 415 416 417 418 419 420 421 422 423
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Todo,How does this metric correlate with the Average Goal Metric proposed in Rastogi et al. (2020b)? ,204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,Just remove the ‘and’ and rewrite. ( ,454 455 456 457 458 459 460
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 5] line 468: I would replace the term “cross-dataset” with “within-task” to make it clear that the setting is constrained on datasets of the same nature (cross-tasks might as well refer to two datasets from different tasks).
",1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,"For contrastive learning in NLP, there are some existing studies. ( ",508 509 510 511 512 513 514 515 516 517 518
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Todo,I raised my score. ,116 117 118 119
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"I think it would help to briefly explain why this happens, or to link the reader to the section of the paper where this is explained.
",957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"The following are points where i would like to see further clarifications: (NB: I do not have access to the forum/comments of the previous submission so some of my comments might have been addressed earlier.)
",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Todo,"For Table 1, where examples are shown, why is the % not aligned as well for the 1st example (to E3/G3) while is is aligned for the 3rd (where proportion aligns to E3, shouldn't this be G3)? ",268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Todo,"In general, I think this is a great pioneering work and could be fed into a much more interesting resources in the future. ",260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,and why is it weighted? ,1093 1094 1095 1096 1097
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Todo,"Missing citation: BERTScore: Evaluating Text Generation with BERT (Zhang et al. 2020) For other suggestions, please refer to the weakness section. ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,"What about the CRA?
",630 631 632 633
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,"
2) Have you considered using a phone based model like Li et. ",438 439 440 441 442 443 444 445 446 447 448 449
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Line 248-268, Standard BERT description could be avoided to make space for discussing points more specific to your contribution.
",568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Todo,Typos: ,369
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"In addition, besides cluster based methods, can you also briefly summarize the major directions of dealing with “domain adaption for NMT”? ",437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] line 63: In the previous paragraph you refer to the problems of adapting to a new task and datasets. ,599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"These instances might be addressed.
",389 390 391 392 393
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"p.5 ""a larger and heterogeneous target PLM"" -- I'm not sure what heterogeneous means here.
",655 656 657 658 659 660 661 662 663 664 665 666 667 668 669
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,"Or do you handle such a situation in some way?
",252 253 254 255 256 257 258 259 260 261
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Todo,It will be good to see some results and analysis on the lengthy dialogue samples. ,228 229 230 231 232 233 234 235 236 237 238 239 240 241 242
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"3) Additional metrics that may be used to evaluate text generation: METEOR (http://dx.doi.org/10.3115/v1/W14-3348), SIM(ile) (http://dx.doi.org/10.18653/v1/P19-1427).
",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,This is referring to the drawbacks of generative models mentioned in the introduction section. ,746 747 748 749 750 751 752 753 754 755 756 757 758 759
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Todo,"From the examples shared in Table 3, it appears that both the NeuSFT and NeuS-Title models stay close to a single target article. ",745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Todo,It would be good if you expand on the importance of the order of wh-words used for question generation. ,294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,[Section 1] line 39: “corpus” -> “corpora” ,546 547 548 549 550 551 552
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,"And considering all the instances can be hashed by the pre-trained sequence encoder in advance before training (and early exiting), the appearance of label imbalance should not cause any actual harm? ",620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,I strongly recommend to explicitly state from the beginning of the paper the language that is being studied. ,742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"	Lines 088 to 089, hard to understand why it is “intuitively” since the figure 1 is a 2D description of high-dimension features/distributions, do you have any detailed data/experiments to support this “intuitively”? ",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Todo,"in Figure 4, the blue line and orange line are almost overlapping, it is difficult to distinguish. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"
Lines 381 - 410 - The gains here do not represent a major novelty, in several cases there are losses, which is fine but discouraging. ",671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Todo,"According to the experimental results, it is possible to achieve ≥ 94% prompt F1 when projecting the soft prompt to task-unrelated instructions with under 2% drop in accuracy. ",568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Todo,"Deciphering related languages."" ",714 715 716
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,"If the latter, will cascading errors be introduced? ",197 198 199 200 201 202 203 204
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,"Were the annotators authors of the paper?
",266 267 268 269 270 271 272
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,"
[2] Data-to-text with content content selection and planning. ",456 457 458 459 460 461 462 463
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Todo,"Similarly, the figure is supposed to help to understand the problem better, but I find it confusing in two ways: First, the figure is too abstract for me. ",329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"- Line 231: DaPI was concurrently also proposed by Liu et al (which they call Mirror-BERT https://arxiv.org/abs/2104.08027, published April 16; SimCSE was published April 18) ",409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Can you justify the reason? ,396 397 398 399 400
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Todo,I appreciate the authors taking the time to improve upon the paper. ,216 217 218 219 220 221 222 223 224 225 226 227
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,-Line 326: “publicly AVSR” -> publicly available AVSR ,285 286 287 288 289 290 291 292
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Todo,"L70-71, researches ... focus ... make -> research ... focuses ... makes 2. ",237 238 239 240 241 242 243 244 245 246 247 248 249
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Todo,"
3. ",491
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Content: 1. ,341 342
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Todo,"Page 6, Line 416-417: I believe the phrase "", and we converted all words are lowercased"" Should be "", and we converted all words to lowercase"" ",626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Todo,"
Zhu et al., 2019 indicated that end-to-end methods achieved better performance than pipeline methods. ",418 419 420 421 422 423 424 425 426 427 428 429 430 431
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,Vol. ,530
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo, ,
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Todo,"- You mention that you only select 10 answers from all correct answers, why do you do this? ",205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"A little introduction of 'Formula', 'Sketch', 'Range', 'table hierarchies' in session2 will lead to better understanding, which are often used in the latter part. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"Is there any specific reason why the authors decided to use the training set and not a perhaps bigger dataset that would provide more variability to the exemplars?
",1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,Does this count as an advantage of the proposed model? ,275 276 277 278 279 280 281 282 283 284
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Todo,"Line 334: “static results” -> statistic?
",809 810 811 812 813 814
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,1. ,375
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"It is interesting to analyze the correlation between socio-economic factors, but how does that impact the construction or characteristics of the datasets? ",673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,6. ,494
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,Q5. ,950
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Todo,"If not, can you mention the accuracy here? ",492 493 494 495 496 497 498 499
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Todo,"In section 2.3, it is assumed that the variance of the distribution p(q|s) is sentence independent. ",673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Todo,Can you recruit volunteer patients? ,212 213 214 215 216
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Todo,"Missing reference for ""First there is no existing data that can be used to quantify how much private information is revealed by a LM"". ",1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Todo,"- Are ""slugs"" restricted to being only in either test/train for the cross-validation experiments? ",157 158 159 160 161 162 163 164 165 166 167 168 169 170
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,AUCROC seems pretty high in other models in literature. ,487 488 489 490 491 492 493 494 495
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,Organization of the paper is good and the proposed method is quite novel. ,75 76 77 78 79 80 81 82 83 84 85 86 87
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,What is the percentage of vocabulary that is present in the general dataset but not in the domain-specific data? ,758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,1. ,94
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,Do not understand if it is “impressive result” or not. ,270 271 272 273 274 275 276 277 278 279
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Todo,"It would be really helpful for the dialog community if authors open their experiment script, especially their script to do automatic augmentation (Sec. 3.2.) ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Todo,- I don't understand what Figure 1 shows. ,249 250 251 252 253 254 255 256
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,arXiv preprint arXiv:1803.05928. ,650 651 652
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Todo,"In Figure 2, how does the ""average"" likely affect the sentiment analysis label?
",180 181 182 183 184 185 186 187 188 189 190 191 192
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"-Lines 250-252: ""the absolute numbers of human evaluation are much higher than those of automatic evaluations"" - saying this seems a bit suspect - what does absolute accuracy numbers being higher than F1 scores mean? ",1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"[Section 5] Tables 1 & 2: Apart from discussing the results of Table 1 and 2 in isolation, could you also add a small discussion on how your approach yields similar performances across the “cross-task” and “cross-dataset” settings? ",1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Todo,"a near-optimal model score"" this sentence is unclear to me, could you explain in detail?
",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"If so, I believe it is better to move this section to the data preparation sections, as it is an integral part of the whole preparation. ",486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,Although I saw authors trying to build relationship between the two topics. ,283 284 285 286 287 288 289 290 291 292 293 294
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,Please explain the dataset collection with examples of how knowledge and memory is compiled. ,598 599 600 601 602 603 604 605 606 607 608 609 610 611
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,The paper may discuss how representative these 30 EHRs are to MIMIC-III EHRs. ,415 416 417 418 419 420 421 422 423 424 425 426 427
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,  ,
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,"If an ESE approach returns a ranked list of entities, at which depth a user should go to find all the relevant entities? ",410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-line 329: what does it mean for `the joint model and the generator`? ,597 598 599 600 601 602 603 604 605 606 607 608 609
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"I presume the paths are supposed to be indicative of model behaviour but   as mentioned in earlier comments, defining it is a crucial problem in explanation work. ",1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Todo,1. ,523
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Todo,"It would also be helpful to the readers to know the specifics of the various experiments conducted (e.g., what embeddings were used? ",355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,"What exactly is the reason for that, for simplicity (like assumptions made by Abnar and Zuidema (2020))?
",302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,"-What is the standard deviation across multiple runs for e.g., Table 1 and Figure 2? ",267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"- Table 3: Right-align the numeric columns.
",625 626 627 628 629 630 631
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Todo,- The LayerNorm approximation seems to have a non-negligible impact on the performances for several tasks. ,370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo, ,
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Todo, ,
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,Unifying cross-lingual semantic role labeling with heterogeneous linguistic inventories. ,941 942 943 944 945 946 947 948 949
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo, ,
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Todo,To what degree does TILT actually differ from model stitching https://arxiv.org/abs/2106.07682 procedures? ,476 477 478 479 480 481 482 483 484 485 486 487
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Todo, ,
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 449: describedd -> described ,527 528 529 530 531
f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297,arr,Todo,"In Figure 1, given experimental dataset have paired amateur and professional recordings from the same singer, what are the main rationals for (a) Having a separate timbre encoder module (b) SADTW takes outputs of content encoder (and not timbre encoder) as input? ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Todo,"If you don’t have any further geometric analysis, it’s not clear to me that section 4.2 adds any information, as it seems to just be a set of definitions that are not later used.
",425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Todo,"
Section 6 555: ""Table 4 shows ..."" - the structure of Table 3 and Table 4 isn't very intuitive, since there is partial overlap in conditions and metrics but essentially it's one big collection of results (baseline, +joint, +transfer, +joint+transfer). ",324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,What do they mean here? ,761 762 763 764 765
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,-Table 3: The english transcriptions are needed ,426 427 428 429 430 431 432
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Todo,"- Line 079: Explain ID and OOD.
",324 325 326 327 328 329 330
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,I’d like to see more discussion on this in the updated paper. ,400 401 402 403 404 405 406 407 408 409 410 411
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,"Springer, Cham, 2016. ",295 296 297
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Todo,See the weakness 2. ,159 160 161 162
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Todo,"Such a trend was not seen for question prompts only setting, for both standard and adversarial data collection processes. ",842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Todo,-Figure 1: I am confused by frequency buckets. ,165 166 167 168 169 170 171 172
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Todo,It would be useful here to investigate this relationship between claimant and veracity as well as to exclude the claimant from the prediction (only use claim and evidence) to figure out what the weight of the claimant in this prediction is (maybe the model does not actually learn to predict the veracity from the evidence but rather from the claimant). ,662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,"In Proceedings of the 37th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. ",512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Todo,Comments: ,365
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo, My main concern is that entropy results are provided limited to the unigram distribution. ,92 93 94 95 96 97 98 99 100 101 102 103 104 105
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Todo,"Actually, it'll be kind of tough to do alignment prompting at inference anyways because should the prompting at every iteration or the first iteration of the decoder? ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Todo,It makes them hard to understand. ,353 354 355 356 357 358
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Todo,"Line 386 (of appendix) - ""it is impossible"" -- I don't understand why. ",390 391 392 393 394 395 396 397 398 399 400 401 402
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Todo,"The following papers, which consider the multi-dimensional evaluation in NLP, should be closely related to this work: 1. ",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,"The authors should move that part back to the main paper or, at least, indicate that those data are provided in the Appendix. ",662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,It might be better to use different symbols. ( ,614 615 616 617 618 619 620 621 622
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"-Figure 3: If the red bars are parts of the grey bars, you could stack them instead of having two separate bars.
",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"
3. ",872
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"-Table 1: row=ARAE, column=POLITICAL-FL It seems this value should be the one in bold.
",269 270 271 272 273 274 275 276 277 278 279 280 281 282
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Todo," It would be interesting to know if FGWS still works best against a version of PWWS that doesn’t align quite so closely.
",551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,“Existing evaluation metrics tend to overestimate the real-world performance of ESE methods and may be unreliable for evaluating concepts with large entity sets.” — ,477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Todo,- l.166-181: No data are given here about the parallel corpus used for the term-level alignment. ,628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,- I believe the method of Xu et al. can be compared against in the experiments of 5.1. ,428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Todo,See the Summary of Weaknesses ,274 275 276 277 278
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Todo,"Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks. ",501 502 503 504 505 506 507 508 509 510 511
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,It seems not reasonable to me for the formula in Adjective Projection part. ,182 183 184 185 186 187 188 189 190 191 192 193 194
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Todo,"- In Equation 6, it would be better to note what γ and ⊙ (element-wise product) represent.
",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"Finally, double-check both definition and usage of acronyms: every acronym, e.g., CNN, should be defined only once (at the first occurrence) and always used afterwards (except for abstract and section titles). ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"-Provide a greater discussion of why almost all defense techniques work similarly well against BAE on SST-2, and how a vanilla DeBERTa base outperforms adversarially trained methods against BAE on SST-2.
",698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Todo,"It's not clear to me why the ""overall"" figure isn't computed based on the separate baseline classifiers ",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Todo,See above. ,369 370
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Todo,"-001: ""The latent variables"" -> ""Latent variables"" ",273 274 275 276 277 278 279
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Todo,"Line 52-57, how this lossy conversion causes problems seems crucial to the paper's central thesis (it is avoiding this intermediate step that is hypothesized to improve performance in this paper). ",264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,There are some missing references in this paper. ,433 434 435 436 437 438 439 440
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"Also, please cite.
",457 458 459
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Todo,You cannot refer to appendix figures in the main paper (line 497). ,442 443 444 445 446 447 448 449 450 451 452 453
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Todo,"While a brief exploration is provided in Figure 3 in the Appendix, it is against a single model on a single dataset, and only up to a relatively limited range of storage (i.e. n=200) ",246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Todo,"-L010, be predicted ",562 563 564
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"But how do you get a batch of 4,096 on a single 32GB GPU? ",456 457 458 459 460 461 462 463 464 465 466 467 468 469
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Todo,Typo: Should “BRET” in line 65 be “BERT”? ,265 266 267 268 269 270 271 272
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"Arxiv.
",920
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Todo,-l. ,265
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Todo,"Line 255: typo, ""perform performed"" ",292 293 294 295 296
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Todo,2020. ,376
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Todo,"Additional comments about these aspects would be beneficial for future works, cross-lingual transfers, and multi-lingual settings.
",453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Todo,"Here ""in"" --> ""is"" 2. "" ",142 143 144 145 146 147
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo,-Why Aleph? ,475 476
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Todo,"In Table 2, the ablation experiment has a setting only add ""local Constraint"" but without ""Refinement Mask"". ",219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,Questions/Comments: ,157
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"At this point, there seems to be a lack of important details that prevent me from fully gauging the paper’s findings and claims. ",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo,The effectiveness of ensemble approaches is not surprising. ,513 514 515 516 517 518 519 520
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Todo,N/A ,435
3a14a02b9c496d9bcd7b06aedeaa8d9c48fa003e7be1b23f9cb631571dd75d894c70b500313f5f1e5ca1c867cfb04c23cad117d1072ae2d0ebbb7964c16ccdf3,arr,Todo,The high accuracy of SLM is because of its training on in-domain data. ,169 170 171 172 173 174 175 176 177 178 179 180 181
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Todo,"For instance, the text says ""Multilingual BERT is the model with the lowest degree of bias, with a score of 53 for English and 50.17 for French,"" but the table says 52.9 for English, so why the difference in significant figures?
",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo, It is well-known that unigram distribution is a very poor model for sentence distributions in natural language. ,106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Line 047: it would be better and more explicit if the task and/or dataset is mentioned as part of the “achieve state-of-the-art results” statement. ,370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Todo,Is your model biased on a particular data? ,84 85 86 87 88 89 90 91
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo, ,
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Todo,l. 264 LSTMS --> LSTMs l. 301 is most similar --> is the most similar ,476 477 478 479 480 481 482 483 484 485 486 487 488 489 490
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Todo,1. ,168
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,"-can you include agreement statistics for the corpus in section 3.1 or 3.2?
",227 228 229 230 231 232 233 234 235 236 237 238 239
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,Line 197 Question: What it means the “0”? ,250 251 252 253 254 255 256 257
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,- Are those 8 categories in Appendix I mutually exclusive? ,504 505 506 507 508 509 510 511 512 513
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
4. ",506
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Todo,"The introduction claims that the downside of existing prompt-tuning methods is that they are ""incompatible with the traditional LM objective"". ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Todo,"If so, it would be better to explain the reasons. ",322 323 324 325 326 327 328 329 330 331
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"If so, do you have any potential explanation why models are so substantially undershooting random guessing?
",607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Todo,Is W^s the same as W^{hourglass}? ,371 372 373 374 375 376
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,"But what is the assumption regarding the benefit of general patch-based (as in CLIP-ViL) swapping for the sequencing task (general intra-modal understanding is already the motivation for SMRM, isn't it?)?
",272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,You should restructure this a bit (maybe with one or two additional sections) to make clearer what you are doing and why/. ,484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"In Table 2, the authors use “B-R” (BLEU-R), shouldn’t it be BLEU-4?
",1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Todo,"I would highly encourage the authors to make the code, datasets and sample extractions public, as it can really increase the impact of this work, allow others to consume and evaluate the outputs in real-world tasks, etc. ",642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Todo,"- Make it clear that the paper focuses on zero-shot model transfer through fine-tuning instead of generalizing the findings on cross-lingual transfer.
",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"Computational Linguistics.
",904 905
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Todo,-line 205: `the` next section ,555 556 557 558 559
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Todo,"Besides the fact that I am having some doubt as to whether such approaches grant the definition of language-independent method (it does not seem to be very effective on all languages, it largely relies on *English* data and concepts, e.g. noon), I think that such shifts bring the paper out of focus at times and may affect its narrative. ",842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Todo,MINOR: ,273
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"-Lines 349-353: It seems you're comparing results for ARAE + CONTRA, ARAE + CLF and ARAE + CONTRA + CL with respect to simple ARAE, while in the text you mention only ARAE + CONTRA and ARAE + CLF.
",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Todo, ,
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"
3)	You state that you improve upon current state of the art work by 7 points. ",609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"Natural examples of creative metaphors with unexpected scalar mappings are not hard to find (for instance, the American F4 Phantom jet was nicknamed the ""Flying Brick""; while as a conventional metaphor, ""flies like a brick"" means ""cannot fly at all"", the intended meaning is that the Phantom was unaerodynamic but had a very powerful engine).
",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Todo,"
10. ",391
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Todo,I wonder if the authors plan to extend the proposed approach to LRS3? ,191 192 193 194 195 196 197 198 199 200 201 202 203
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Todo,"Knowing when something can’t be detoxified isn’t something that can be inherently modeled by the proposed models.
",437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo, ,
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Todo,"May be, it is better to call them insertion and deletion errors? ",270 271 272 273 274 275 276 277 278 279 280 281
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Todo,"
2. ",181
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,Typos ,192
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Todo,The paper should elaborate on OT in both the introduction and the methodology parts and should provide more details and justifications for OT. ,830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,Suggestions: 1. ,195 196
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,Or perhaps you just require $f$ to be Borel-measurable and deterministic or something. ( ,1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,NoiseQA: Challenge Set Evaluation for User-Centric Question Answering. ,353 354 355 356 357 358 359 360
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,3.7MB? ,386
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo, ,
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,Comments 1. ,178 179
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Todo,Typo Line 516 ,353 354 355
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Todo,1. ,431
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Todo,"It will be helpful to include ethical concerns, detailing the limitations of the approach regarding practical, clinical application. ",226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Todo,Comments incorporated into strengths/weaknesses above ,558 559 560 561 562
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"Is it possible to add a citation?
",433 434 435 436 437 438 439
fd2caf0a98ac82aa472d008400f29ba5bd74e77d5471c83cb7634bca4d59d5c302b38774e1e7775d5f8bf1110a26d537ba5427a759506b0a0807bc3e3590493c,arr,Todo,Can you provide more insights about why loss embedding based data selection is better for sequential labeling task while gradient embedding is better for classification task? ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"Also, the fact that there is ""no"" knowledge is probably not a fair comparison. ",545 546 547 548 549 550 551 552 553 554 555 556 557 558
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Todo,#### Typos: ,363 364
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,8. ,1342
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,- Tables 4+5 (2): What's the idea of showing the run-time? ,708 709 710 711 712 713 714 715 716 717 718
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"
7. ",1768
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(186-198): I feel that this is a better paragraph describing existing issue and motivation than (63-76). ,655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,Line 271: “question generation module (QG) module” ,522 523 524 525 526 527 528
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,This assumption seems to be the opposite of the observations made previously. ,290 291 292 293 294 295 296 297 298 299 300 301
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,This is confusing. ,359 360 361
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Todo,-Section 5: How would you explain the gap of the effectiveness in the Image-Only setting on WikiHow vs. RecipeQA? ,366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Todo,"- Typo/word choice near ""with none word overlap"".
",1057 1058 1059 1060 1061 1062 1063 1064
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,-Line 573: which use for -> which are used for  ,552 553 554 555 556 557 558 559 560 561
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Todo,Nothing major. ,265 266
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,"Line 205, “Auxiliary task” This is later called a dual task in line 336. ",475 476 477 478 479 480 481 482 483 484 485 486 487 488
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"If not, consider smoothing out the text and maybe just quantify the drops. ",1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Todo,They validate this claim by showing how such a language model can improve downstream tasks in this area. ,575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,arXiv preprint arXiv:1909.10122. ,594 595 596
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Todo,"a) ""Table-based verification is more challenging than unstructured-text-based"" ",154 155 156 157 158 159 160 161
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Todo," Which papers do these come from?
",418 419 420 421 422 423
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,-There are a couple of footnotes referring to wikipedia. ,440 441 442 443 444 445 446 447 448
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Todo,European Conference on Computer Vision. ,290 291 292 293 294
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Todo,My major suggestion is to have some analysis on the effect of model size for data augmentation. ,243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Todo,"-Dataset characteristics discussed  (line 359-376) can be combined with Table 2.
",202 203 204 205 206 207 208 209 210 211 212
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"L527: Is there any justification as to why you suspected that domain-adaptive pre-raining lead to longer spans?
",389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Todo, Two questions: ,247 248
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Todo,"In my opinion, ground truth data will increase the quality of the test cases. ",172 173 174 175 176 177 178 179 180 181 182 183 184 185
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo,"Some little typos: were => where (almost everywhere ""were"" appears) then => than (line 319) ",888 889 890 891 892 893 894 895 896 897 898 899 900 901 902
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,I.e. do you use 512 word pieces or do you pre-train on shorter paragraphs? ,515 516 517 518 519 520 521 522 523 524 525 526 527 528
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Todo,Typos/grammar/etc (not exhaustive): ,480 481 482
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Todo,Will there be a certain correlation between them that caused the improvement? ,245 246 247 248 249 250 251 252 253 254 255 256
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Todo,I suggest to conduct more experiments using more QE models on a wider range of language pairs. ,216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"I would suggest moving it to the Intro, and just briefly re-mention the issue here in Related Work. ",671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Todo,I would suggest giving more explanations on this. ,685 686 687 688 689 690 691 692
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"In my view, such rounding makes understanding harder rather than helping.
",757 758 759 760 761 762 763 764 765 766 767
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Todo,"3- How is the entire doc used to create the knowledge graph in the subsection ""KG representation""?
",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Todo,"Results: Overall, did you run any significance tests when making comparisons between two different models? ",388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,Add the abbreviation “LF” after “labeled Fscore” on Line 245 so that the use of “LF” later can be attributed to. ,869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"MUSHRA may need a reference (line 504).
",552 553 554 555 556 557 558
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"While it might seem redundant or trivial, the wording to annotators plays an important role and can confound the results presented here.
",417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Todo,  ,
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo, ,
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Todo,- It would be nice if the boundary between explicit and implicit offensive texts is stated clearly. ,460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"If so, it might be interesting to comment on why they might be working well here but not there. ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Todo,"- Page 1: ""set of value"" -> ""set of values"" ""For instance, Orlanski and Gittens (2021) fine-tunes BART"" -> ""fine-tune"" ",458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Todo,"-Only one dataset is used for evaluation, is there anything more?
",94 95 96 97 98 99 100 101 102 103 104
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Todo,I think it would be more clear if you can introduce sense embeddings a bit before introducing the bias measuring procedures. ,712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Todo,"This would complete the work in my opinion.
",416 417 418 419 420 421 422 423
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Todo,Questions:      1. ,327 328
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"If I understood correctly, the Label Embeddings are external parameters; instead, the figure is a bit misleading, as it seems that the Label Embeddings are the output of the encoder.
",233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo, ,
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"An example could help.
",445 446 447 448
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"lines 89, 867), ""from total"" -> ""from *the* total"" (line 127), ""Finally, we have obtained 7,137 sentences"" -> ""In the end, we obtained 7,137 sentences"" (line 138), ""suffers from"" -> ""poses"" (line 155), ""illustration"" -> ""annotation""? ( ",726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,"Could you say more about how many datapoints you're training on and how many steps of optimization you do?
",757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Todo,"- Based on Appendix B, the bi-encoder is trained on TREC 2016 with 30 EHRs. ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,-The KL divergence is introduced here but mentioned before. ,448 449 450 451 452 453 454 455 456
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Todo, ,
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Todo,"-Line 376: Dathathri et al. (2020) -> (Dathathri et al, 2020) ",508 509 510 511 512 513 514 515 516 517 518
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"-It is not clear how the categories in WEAT (Table 2) are associated with the social biases this paper is framed around.
",1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Todo,"The experiment baselines include Hash Layer and Switch Transformer, but the paper only reports the token-to-expert assignment changes for the BASE Layer model. ",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(7): semantics-aware or semantically-aware ,536 537 538 539
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,The way you present your results do not sell them very well. ,290 291 292 293 294 295 296 297 298 299 300 301
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Todo,How to solve the example by DILR? ,198 199 200 201 202 203 204
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Todo,"For example, ""He hustles like he's a billionaire's son"" (Table 1) might be interpreted as a description of how he gets things done (by using his contacts and social privilege) or of how hard he works (not hard because he doesn't need to). ",230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Todo,"In Table 2, what about the result of  SpreadsheetCoder under 20% train set? ",167 168 169 170 171 172 173 174 175 176 177 178 179
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,How did you get the results for the baselines? ,333 334 335 336 337 338 339 340 341
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Todo,In line 152 the citation format is not correct. ,604 605 606 607 608 609 610 611 612
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Todo,Typos: ,521
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Todo,"Same thing for HMT, between N=10^2 and N=10^3. ",184 185 186 187 188 189 190 191
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,4.2 Why are all of the models tested encoder-only? ,214 215 216 217 218 219 220 221 222
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Todo,-Lines 229-240: Are the differences between the topics statistically significant? ,354 355 356 357 358 359 360 361 362 363
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,Suggestions ,246
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Todo,"
How is it decided?
",656 657 658 659
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"Table 4's caption helps a bit, but I think the explanation here is not clear enough. ",292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo,The terms s_x and v_x are not clearly defined. ,236 237 238 239 240 241 242 243 244
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Todo,"Also, it could be integrated with the previous one. ",425 426 427 428 429 430 431 432 433
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Todo,"For each PCFG with rank r, add a baseline smaller PCFG with state size being r, but where $H, I, J, K, L$ are directly parameterized as learned matrices of $\mathcal{R}^{r \times r}$, $\mathcal{R}^{r \times o}$, $\mathcal{R}^{r}$, etc. ",674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,-Table 1: are these all the rules you defined? ,269 270 271 272 273 274 275 276 277
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Todo,I believe this work would definitely facilitate the documentation process whether in progress or as a post-processing step. ,228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Todo,Is this possible? ,602 603 604
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,How do the authors form clusters for tokens in Figure 1? ,306 307 308 309 310 311 312 313 314 315 316
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Todo,"- Did you try to marry FiD with your reranking framework, thus eliminating the need for expensive cross-attention in the decoder (by lowering the number of retrieved passages fed to FiD)? ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Todo,"-Since the motivation of this paper is avoiding overfitting during fine-tuning, I would be very curious to see NoisyTune in few-shot settings, where overfitting is more of an issue.
",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,"For example, BAMNet, GraftNet, and PullNet use entity linking results on WebQSP, according to original paper.
",420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
d420c861389d357cba32905a3ce5bdb49ac1f8cf4307e514dd57f7258c3fb92ed2ba9f8ed6236f98685df72905f399b55c3b1807531a2928752890bf72b2f7e1,arr,Todo,"- Textual matching is also relevant for evaluation metrics [2], where similar biases (e.g., lexical overlap) are discovered. ",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,-(376): It might worth mentioning SimCSE is the state-of-the-art method mention in the Abstract. ,771 772 773 774 775 776 777 778 779 780 781 782 783 784
8b6c32570a76bc3f912c81ca56238483b90d063a4358c30dd7ad577ec4d175db6ca56f62d02e938949fbb3e9f837a2feff5a1e97203beeef39e212d3bea306b1,arr,Todo,I would suggest adding some qualitative analysis to explain the title of the paper in later version. ,149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"It is fine, but I think the authors can find a better citation for the Frobenius norm and the Welch test.
",449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"Instead, for the combination of using description + example, could you simply append those example-based prompt after description-based prompt. ",379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Todo,- Do you think that validation using performance on the dev set (using early stopping or hyperparam selection) would be helpful? ,378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Todo,"So it is better that you mark whether the baseline models use golden topic entities or entity linking results in the result table, which is a variable need to be controlled when we compare the performance of KBQA models. ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Todo,"Is this simply because the Estonian model performs slightly better than the Latvian before pivoting, and have nothing to do with the appropriateness of contact language vs typologically related language? ",246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Todo,My understanding is that the goal of this work is to show that methods such as the one presented here can improve factuality and factuality in hallucination without significantly damaging the quality of the summarization model. ,610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645
d1921e5f5febc1efa6ccd005802a9c3efc66b8840ed104fdcade7b07f9f498a3eee437ee46bfdde58663ee7bf9cdaab4873670ba950b1a71a31bdc9388fbba99,arr,Todo,N/A ,178
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"To conclude, while my rating might seem quite harsh, I believe this work has great potential and I hope to see it enriched with the required experimental details.
",727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Todo,"-Line 263: It would be better to use l_i.
",361 362 363 364 365 366 367 368 369
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Todo,Ironically there are also quite a few grammatical errors. ,365 366 367 368 369 370 371 372 373
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,The bias term could change the orderings of the of the output layer and potentially ameliorate (or deteriorate) the issue. ,620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Todo, ,
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"-Don't think you define what the Platt-scaling set $G$ is ranged over by the argmin in step 1.
",1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Todo,1. ,124
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Todo,1. ,711
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Todo,None ,181
c1af730b370c44b11d64851ee9d2f5ea9eb336b8c04301c2681c8d1bfdf213c74db334a970ae2b248018ee30be7a033c695c8c021292d26e3f53ccac0f23ec28,arr,Todo, ,
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,It's important for readers to replicate your results as the results are provided in PER and PER is also directly dependent on the ground truth phonemes generated by the g2p rule. ,407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"Can you provide an analysis on the impact of the number of augmented samples (e.g., z_{a1}, z_{a2}) here? ",402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Todo,"Why?
",227
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,"-How grammatical are the ""filled gaps"" proposed by the model given that in principle the model does not modifies human constraints?
",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"
(2) This paper is highly related to dialog recommendation. ",271 272 273 274 275 276 277 278 279
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Todo,"-Cite Pires et al., 2019 in the 2nd paragraph in the introduction. ",337 338 339 340 341 342 343 344 345 346 347 348
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Todo,"line 121, the paper lacks details for how to design and use prompts for dialog with multi-domains/services. ",241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Todo,"- l224f: *the* low-resource, *the* train data, *set* the size ",390 391 392 393 394 395 396 397 398 399
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Todo,All pitch contours are mixed together. ,395 396 397 398 399 400
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo, ,
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,-What is Fig 2's dataset? ,955 956 957 958 959
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Todo,"l. 066: ""phonology: Inspired by"" --> ""phonology. ",318 319 320 321 322 323 324
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Todo,1. ,155
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"For example, when you decide to add ""and her team"" as in the last example of Table 1? ",293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Todo,N/A ,156
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Todo,"
On the other hand, I think the ethical statement section is mostly non-sense anyway, and I wouldn't know what to write here myself, if I were the author. ",236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Todo,"-The definition of perfect calibration in the info is perhaps a bit confusing as-is (namely, $P$ has to be a joint over the covariates $x$ and the predictions $f$ right so you need some sort of metric over both, is that right? ",969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Todo,"- The WLS parameters ""1-1-0"" in Section 4.2 (line 175) directly contradict the claim in Section 4.1 (line 150) that these three values must sum to 1. ",791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Todo,"It would make the whole passage more readable.
",292 293 294 295 296 297 298 299
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Todo,-Table 3: which PLM is used in this experiment? ,240 241 242 243 244 245 246 247 248
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Todo,"It's recommended to report the overall energy reduction of the full model, conduct experiments on more language pairs and with the big setting on a few of them. ",358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Todo,As the transformer has positional embedding and the self-attention layer is multi-head. ,523 524 525 526 527 528 529 530 531 532 533 534
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Todo,"
8. ",338
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Todo,The paper does not refer to the table 3 when discussing the results in section 4. ,333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Todo,"it would be better to show the KG link prediction performance from KGT5 after finetuning for QA, and showing performance on KG link prediction and KGQA with multi-task setting is also a good choice. ",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Todo,They can use any image for pretraining. ,265 266 267 268 269 270 271
00b1d8296a836fe8f6dda3d7c4b42674cca6f332f0c1865c4dc68f83e4c18995ed83391dbadb2f207e1f0ecfd02e512dba8c30173297edb4d698ee7451fbd19c,arr,Todo,"The manuscript presents some bad English constructions, grammar mistakes, and misuse of articles: a professional language editing service (e.g., the ones offered by IEEE, Elsevier, or Springer) is strongly recommended in order to sufficiently improve the paper's presentation quality for meeting the high standards of ARR.
",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Todo, Each token predicts the probability of surviving at each layer and adopt the Gumbel-Softmax to obtain the final token that feeds to the next layer. ,322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Todo,As mentioned by weaknesses above. ,198 199 200 201 202
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Todo,-Line 172: an argument level -> on argument level ,222 223 224 225 226 227 228 229 230
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Todo," Are these slots and value bindings, respectively? ",245 246 247 248 249 250 251
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Todo,"Then, the only difference lies is complete the task, which is not the focus of this paper. ",343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo,"It becomes clearer later on in the experimentation section that those terms refer to target sets, but it would be better to clarify early on. ",777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801
6de4c24feda039f610f2f5499017edf441c88aa4ccfcd935c5311e14cb3a538507eae0a124803d5f1852a085fc55e85971be82ce03f925c776ba7dcb86604511,arr,Todo,Please include a more recent big datasets for evaluation. ,127 128 129 130 131 132 133 134 135
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,    5a. ,981
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,I don't think that lemmas with only 2 senses are too easy... ,218 219 220 221 222 223 224 225 226 227 228 229
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"In Eq 13 around line 300: The summation is over $i$ and $j$ but they do not appear in $S_{batch accd}$, should they be $s$ and $t$? ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Todo,It is not clear to me why hard negatives and semi-hard negatives are generated from the positive sentence rather than the original sentence. ,229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Todo,"If not, maybe a line or two should be added that there exists no solution for this, and it is an open (hard) problem. ",425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"Measuring empathy in the 21st century: Development of an empathy index rooted in social cognitive neuroscience and social justice."" ",768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Todo,"In sum, I would keep my earlier scores unchanged. ",311 312 313 314 315 316 317 318 319
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Todo,"It might also be worth denoting number of sentences for your dataset, as Jia et al (2018) looks larger than SkillSpan at a first glance.
",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"The fact that it does not always happen couldn't be the effect of more ""others"" in Eq.3 besides length and content?
",436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,"Furthermore, it would be nice to also see some examples of friendly adversarial data, before and after they cross the decision boundary.
",676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo, ,
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Todo,"
2. ",508
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Todo,"- 305/310: Marie/Mary >> I think these should be written the same.
",727 728 729 730 731 732 733 734 735 736 737 738
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"-Paolini et al., 2021. ",951 952 953 954
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Todo,"As a followup work, it would be insightful to conduct a similar study on different CQA datasets ",251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Todo,It is better if the authors can relate the discussion points with the more general context. ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,"It will be helpful if the authors are more explicit and consistent when referring to the CLIP language encoder.
",325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Todo,"
3. ",597
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Todo,Can this not be done in real time? ,971 972 973 974 975 976 977 978
6695a2d16cadbaadac9a6a13d88ce4c37d0b78386799e141932cd2f36abca22fd324255f8bb1cae45c1f5eb66a945e0fcde3221c9e5cfabbde0339e17e30bebd,arr,Todo,"- L400: citation for ""for evaluating ranking or information-retrieval tasks in literature""?
",148 149 150 151 152 153 154 155 156 157 158 159
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,the word “besides” should be replaced by “also” or “in addition”. ,1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Todo,Btw what you call templates in the Appendix should be facts (which you get by application of your templates in the input). ,322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Todo,"In Table (5b), there is a big improvement of PER for IQ. ",107 108 109 110 111 112 113 114 115 116 117 118
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Todo,"@inproceedings{Sung:ACL2020,     title = ""Biomedical Entity Representations with Synonym Marginalization"",     author = ""Sung, Mujeen  and       Jeon, Hwisang  and       Lee, Jinhyuk  and       Kang, Jaewoo"",     booktitle = ""Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"",     month = jul,     year = 2020,     address = ""Online"",     publisher = ""Association for Computational Linguistics"",     url = ""https://aclanthology.org/2020.acl-main.335"",     doi = ""10.18653/v1/2020.acl-main.335"",     pages = ""3641--3650"" } ",487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Todo,"- There were too many missing details (for example, what is the distribution of people with ‘free off speech’ attitudes? ",279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Todo,"For example, as shown in Line 268, if $f(x; \theta^t)=[0.05,0.95]$, and $m_t$ in Eq. (10) is larger than $m_L$ (suppose to be 0.8), then the score of class 1 in $g(x;\theta^t)$ is larger than 0.8 times 0.95, which is larger than 0.5. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Table 1: Including the fact that the prompt used for initialization is the one that performed best in direct transfer in the caption as well as the prose would make the table more self contained. ,1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Todo,"Line 506-509, use the formal names instead of only citations for these models. ",803 804 805 806 807 808 809 810 811 812 813 814 815
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Todo,"173 - ""The goal"", why did you choose this goal, is there evidence that by correctly choosing a persona you are able to get more personal information?
",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,Lines 211-214: The authors indicate that the conditions are concatenated to the source sentences via the [SEP] token. ,984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Todo,"Nonnative English speakers are fluent in a non-English language, while the miniBERTas are not fully trained on their “L1”.
",782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Todo,- Figure 3: The illustration is not clear to me. ,479 480 481 482 483 484 485 486 487 488
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Todo,"-Table 4: Adding SimCSE to pre-training appears to bring little effect, performance improves from 43.4 -> 43.8. ",549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Todo,"E.g.: what are the topics, what are the stereotype targets, what kind of filtering do you apply?
",210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
5. ",235
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Todo,-L307: AMR-to-Text model -> the AMR-to-Text model ,458 459 460 461 462 463 464
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Todo,"
For example, initializing each model with mBART and fine-tuning them on training data of each task.
",499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Todo,"The current order suggests that §3.3.1 is done manually as well.
",238 239 240 241 242 243 244 245 246 247 248
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Todo,"
  - Tuan et al. Capturing Greater Context for Question Generation. ",357 358 359 360 361 362 363 364 365 366
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Todo,10. ,542
ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42,arr,Todo,"
3 Please do the significance test for all results. ",157 158 159 160 161 162 163 164 165
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Todo,L. 480: repetition of “language”’. ,497 498 499 500 501
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Todo, ,
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Todo,2. ,459
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Todo, ,
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Todo,"In general, hierarchical modeling seems to be its own task area, where both different pretraining techniques might produce better sentence encodings and different methods of hierarchical modeling may produce better overall results. ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Todo,-May be design a curriculum learning paradigm for pre-training so that the batch sampling is done in a manner that helps the pre-training learn from easy to complex questions. ,233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Todo,-I believe that the color scheme in tables is confusing at times. ,617 618 619 620 621 622 623 624 625 626 627 628
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Todo,It is hard to read numbers in Figure-3 and Figure-5 with a printed copy. ,329 330 331 332 333 334 335 336 337 338 339 340 341 342
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"In the case of Chinese, you did this yourself. ",530 531 532 533 534 535 536 537 538
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Todo,"
15. ",401
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Todo,"- In the introduction, the authors mention something about annotators' training and calibration process, but this wasn't elaborated upon later. ",328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Todo,"This should be mentioned.
",386 387 388 389
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Todo,is missing after “g” in “e.g” - only pointed this out as a typo as you used “e.g.” throughout the paper as in Lines 157 / 225 / 230 / 231  ,665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Todo,"For example, it is claimed that “conspiracy theories tend to be closely related to each other and convey highly similar information because they share the same biases or aim to manipulate readers in the same way.” ",512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Todo,1. ,262
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"l254: ""Table 1""  -> I think this should be Table 2 ",534 535 536 537 538 539 540 541 542 543 544
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Todo,1) Could you provide the source of the g2p rules. ,397 398 399 400 401 402 403 404 405 406
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Todo,"Missing reference: The main point of theorem 1 has been discovered several times in history: See Cover(1967) and I.J. Good & T.N. Tideman(1977) who counted the number of possible rankings given N and d. See https://rangevoting.org/WilsonOrder.html for a comprehensive discussion of the multiple discoveries.
",706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,Line 038: They state that GPT-3 showed extremely large LM can give remarkable improvements. ,1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Todo,Would it need to be retrained as different political groups and organizations emerge? ,258 259 260 261 262 263 264 265 266 267 268 269 270
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Todo,   I know what they are but the paper should be self contained and acronyms when introduced first should be elaborated on. ,347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Todo,"Gutmann and Hyvärinen (2010) propose NCE, but InfoNCE is proposed by Oord et al. (2018). ",360 361 362 363 364 365 366 367 368 369 370 371 372 373 374
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"However, by looking at the Experiments section, that’s not the case. ",1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Todo,"-(99): the first mention of ""momentum-encoder"" in the paper body should immediately come with citation or explanation. ",608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Todo,"According to my understanding,  Table 2 shows the templates used for the SQUALL. ",388 389 390 391 392 393 394 395 396 397 398 399 400
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Todo,Typos: ,340
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Todo,"The authors can give more results about that, following previous works (Big-Bird or Longformer)? ",228 229 230 231 232 233 234 235 236 237 238 239 240 241
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,3. ,382
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Todo, ,
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Todo,*Typos:*  ,738
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Todo,Highlight the best numbers in table 7. ,210 211 212 213 214 215 216
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,### Suggested additional references ,709 710 711 712
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Todo,"Also, you may want to mention the latest low-resource XLM transfer findings from AmericasNLP (Mager et. ",431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Todo,"For example, in lines 87-90 the authors introduce the hypothesis patterns (in contrast to the null hypothesis) referring to the way of representing the input labels, and they mention ""no significant"" difference, which instead is referring to the statistical significance. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Todo,"-Line 253: The formula doesn't depend on p, so why the premise is ""if p=100% of the eligible example""?
",418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Todo,"For instance, in lines 43-44, the authors state that “lacking control might result in undesirable results”. ",805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Todo,Please consider adding new human evaluation results and baselines as mentioned in weaknesses. ,215 216 217 218 219 220 221 222 223 224 225 226 227
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Todo,of ACL2020. ,555 556
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Todo,This will help us understand the sensitivity of the model to the data split or order of training etc. ,396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,  ,
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Todo,"
Below are some detailed comments/questions:  1. ",136 137 138 139 140 141
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Todo,"a smoother loss"" in line 184. ",249 250 251 252 253 254
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Todo,"The other occupation/action words are commonly used and could reasonably be measured, but very few texts (for embedding training) will use carpenter as a verb, and many native speakers will not recognize it as correct.
",934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968
0e30497ecba61ed356a72b0213bc87e06347be6b0164284ff6f25182bf1e310ac082f086cd5e0d6455085d4bf4025289c6f66bb8555e953606e080663f2aa9c1,arr,Todo,Refer to Summary Of Weaknesses ,194 195 196 197 198
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Todo,"-Line 048: ""extremely competitive performance of"" - what is 'performance' for these systems? ",1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Todo,"
[1] Neural data-to-text generation: A comparison between pipeline and end-to-end architectures. ",441 442 443 444 445 446 447 448 449 450 451
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Todo,"COLING.
",936
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Todo,"line 262), ""use"" (delete, line 270), ""in *the* re-annotated"" (line 271), ""twice of that"" -> ""twice that"" (line 273), ""edit number"" -> ""number of edits"" (line 281), ""the sentence length"" -> ""sentence length"" (line 282), ""numbers"" -> ""number"" (lines 283, 297), ""numbers"" -> ""the number"" (line 295), ""Same"" -> ""Identical"" (line 298), ""calculated"" -> ""counted"" (line 299), ""the different"" -> ""different"" (Figure 1 caption), ""reference number"" -> ""number of references"" (line 305), ""for"" -> ""to"" (line 307), ""the descending"" -> ""descending"" (line 326), ""sentence numbers"" -> ""number of sentences"" (line 327), ""It"" -> ""This"" (line 331), ""annotate"" -> ""annotated"" (Figure 2 caption), ""limitation"" -> ""limitations"" (line 343), ""SOTA"" -> ""state-of-the-art (SOTA)"" (line 353), ""these"" -> ""this"" (line 369), ""where"" -> ""on which"" (line 393), ""hugging face"" -> ""Hugging Face"" (431), ""these"" -> ""this"" (line 464), ""The"" -> ""A"" (line 466), ""reference number"" -> ""the number of references"" (Figure 3 caption), ""start"" -> ""have started"" (line 571), ""will be"" -> ""are"" (line 863), ""false"" -> ""incorrect""? ( ",840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Todo,-Please specify the maximum sentence length kept for BERT/RoBERTa/DeBERTa in Section 4.4 ,638 639 640 641 642 643 644 645 646 647 648 649
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Todo,"Comparison between LSTM and BERT is good, but not enough, as  this topic still has a dominant approach of combining some linguistic features with neural models, for modeling overall score. ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Todo,"
2) There is still a large performance gap compared to Voita et al. (2019) in linguistic evaluations, while BLEU may not be able to reflect these document-level phenomena and linguistic evaluations are important. ",509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Todo,Line 393-395: Having an example here would be nice. ,657 658 659 660 661 662 663 664 665
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Todo,Overall in the manuscript for random variables and equations it will be better to avoid brevity and be explicit with all variables being conditioned on. ( ,493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Todo,"If this is all you mean, I think the sentence could be clarified, but currently, it seems like it may be making a stronger claim than this. ",748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Todo,"Did you find the same (or similar) gains on the other language pairs?
",183 184 185 186 187 188 189 190 191 192 193 194 195
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Todo,4. ,241
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Todo,"It is not clear what do you mean.
",349 350 351 352 353 354 355 356
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Todo,"
For instance, I found Appendix E1 especially interesting as the performance quality of method used to find topic and length equivalents might affect the final quality of the generated corpora.
",502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Todo,"How is this defined, esp. ",392 393 394 395 396
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Todo,"You mention doing some preliminary experiments showing that ""complete many-to-many training is still as challenging as one-to-many"". ",390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Todo,"
Section 2 explains that the pinyin sequence starts from n+1 but the equation (2) uses pinyin sequence from 1 to n. To solve this inconsistency, the authors should prepare another variable such as N instead of using n+k in the equation (2). ",443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Todo,"So mutual information with the input might be higher for all tokens, not just the [EOS] token. ",407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Todo,"Without having an input to the model, the prompts activations are most likely dissimilar to the kind of activations one would expect when actually using the prompt. ",1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Todo,p.4 I'm confused why Fig 3b laptop => laptop is 99. ,575 576 577 578 579 580 581 582 583 584 585
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,There are some questions: ,27 28 29 30
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Weakness,"Considering the `hard` labeling method seems to just pick overlapped words between the incomplete utterances and the rewritten utterances, the nolvety of the proposed method seems smaller.
",452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"I suspect this will be the least used of the new foils, but I don't have a concrete proposal how it could be improved to really be a captioning task. ",406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"Specifically, why not also calculate perplexity of an MLM encoder on an NL L2? ",414 415 416 417 418 419 420 421 422 423 424 425 426 427
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Weakness,"For a more systematic description of MTL approaches for Deep learning models, please refer to https://arxiv.org/abs/1706.05098. ",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Weakness,"Since BM25 has strong zero-shot capability, it seems that the combination of the BM25 serves mainly to enhance the zero-shot capability of the model. ",130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Weakness,"If you don't have enough space, I would encourage you to add details on the appendix. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,The former definitely considers its role for modeling and the latter incorporates it in the annotation phase. ,179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,it would be very interesting to see how the dialogs can be improved by using domain ontologies from the SGD dataset. ,195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness,"Then, the regularity-agnostic models are not used during inference? ",221 222 223 224 225 226 227 228 229
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"In Line 342, it claims that the ""texts were broken down into small sections based on their semantic content by our annotators."" ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"This is a lot  smaller than the suggested learning rate of $0.3$ in [Lester et al (2021)](https://aclanthology.org/2021.emnlp-main.243/), it would have been better to see if a larger learning rate would have closed this gap. ",874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,"To overcome the large computational complexity, the authors propose to (1) prune span, which is often used. ( ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Weakness,"
2. ",177
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"In Related Work (Sec 2), other datasets/methods for V&L with multilinguality are mentioned (VQA, captioning, retrieval...) -- is your method inspired by/related to any of these methods? ",606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,Is this just model retrain noise from starting off at different initial model params? ,664 665 666 667 668 669 670 671 672 673 674 675 676 677
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Weakness,Not a lot to say here as I think the researchers have done a thorough job. ,295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Weakness,"For the fine-tuned model, they add LayerNorm approximation and d distill knowledge from original LN layers. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Weakness," At the very least, if this is a compelling problem, the paper should spend some time on error analysis and insight. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Weakness,"If ambiguity is supposed to cause issues in task-oriented dialog models it would be important to measure end-to-end metrics like success rate, inform rate, as well as preference tracking and dialog policy learning (all metrics used in the base MultiWOZ/SGD settings) to demonstrate whether the proposed database result disambiguation task helps in the downstream dialog task and the end goal of the system. ",467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529
25ecf77df8e811b8c942cb9933c4bd14112d1de9ed3f8989adcb669076c94472a9497f9ae80d57e03ed8fcb031fa6f84877d8faf869d641e622e8ddebd622cca,arr,Weakness,"For example, ""are mad"" and ""'re out of your mind"" can and often do have different meanings. ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Weakness,"I am also wondering why only 5 of 11 existing datasets of the KILT leaderboard are selected, I would be interested why you exactly choose these datasets. ",279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,The paper mentions [2] as related work that focused on uncertainty for summarization. ,298 299 300 301 302 303 304 305 306 307 308 309 310
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Weakness,The novelty is in the generative implementation and the scope of the claim should be reduced. ,185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Weakness,"-If I understand correctly, only the wav2vec is fine-tuned but the other 3 models are trained from scratch, therefore the comparison across the 4 models might not be very meaningful as it is easy to guess that the fine-tuned one would perform best.
",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Weakness,"
3) If using pre-trained is it better to use pre-trained model on many languages or just 1 language but multiple speakers is enough. ",329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Weakness,So the contribution seems a bit incremental. ,166 167 168 169 170 171 172
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,It would also be better if the authors can elaborate more on the relationship between this new scheme and previous ones. ,553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"Similarly, a comparison of which cognitive data is used might be interesting as well (i.e., fMRI vs. eyetracking data, for instance).
",305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,"
    * For the “Item Specificity” test, the authors wrote “For the worst output, we randomly select an item i, and we take one if its assignments (i, c).” ",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Weakness,"Since their approach ends up solving a Many-to-Many translation problem with N Many-to-One models, it greatly drops the deployment efficiency provided by Multilingual NMT, and scales linearly to the number of languages. ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Weakness,- The approach was applied to a sequence level representation defined in the end of text token in GPT-2. ,1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Weakness, ,
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,"How do these results vary when we sample a different set of ""K"" samples from the dataset? ",483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Weakness,Less experimental improvement. ,57 58 59
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness, ,
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,"An empirical analysis with the method proposed in this work over their dataset or at least a dataset using their OOV synthesis methodology would be very interesting to have particularly on this problem of OOV NER.
",544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,"From what I can tell, most of the analysis is performed on the results of one optimised model (ensemble), on one dataset (ReClor). ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness, It is true that they show some actual examples their method solved in Appendix (Figure 6). ,221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Weakness," CoLA is a quite different task, and the authors also report the correlation without this task, which becomes much smaller. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Weakness,"- The unsupervised translation tasks are all quite superficial, taking existing datasets of similar languages (e.g. En-De Multi30k, En-Fr WMT) and editing them to an unsupervised MT corpus.
",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Weakness,"-From table 3, it looks like using GAA with adversarial data collection hurts out-of-domain generalization, as seen by the dip in performance on MRQA dataset.
",543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Weakness,"
2) it only compares with some weak baselines in Tables 3, 4 and 6. ",383 384 385 386 387 388 389 390 391 392 393 394 395 396
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Weakness, ,
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,"maybe typo (line 171) '...predicting latent variables unavoidable sacrifice the overall decoding efficiency.'
",349 350 351 352 353 354 355 356 357 358 359 360 361
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Weakness,maybe the poor performance is due to annotation variance not model capability (line 546-548 v.s. line 553-558). ,290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,"-It appears (Table 3) the strongest improvement come from Lexicon-Enhanced Dense Retrieval, i.e. combining the dense sim score with a BM25 score. ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Weakness,"-The work suggests that hallucinations can be described by hallucinated entities, which may be factual or not. ",440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"While the method seems to stem from Papadimitriou and Jurafsky (2020), it's desirable to explain a bit more for self-containment. ",332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Weakness,-Relies on supplemental space to contain the paper. ,265 266 267 268 269 270 271 272
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Weakness,Are you smarter than a sixth grader? ,190 191 192 193 194 195 196
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Weakness,"- The proposed approach is not fully automatic, and still requires human annotations for identifying rationales and correcting errors from the static semi-factual generation phase. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Weakness,It would be much better if the authors could add some brief introductions for each baseline model. ,230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,"Readers would appreciate if the authors could provide quantitative results for supporting the claim.
",272 273 274 275 276 277 278 279 280 281 282 283 284 285
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Weakness,"It would be great if they can add an additional ""from scratch"" vs ""from pretrained"" results for each of the model choices. ",375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Weakness,"-To further evaluate the effectiveness of the proposed method, experiments on other tasks (e.g. cell type classification, table type classification) compared to TUTA should be conducted. ",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Weakness,This is very confusing. ,119 120 121 122
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Weakness,-There are still some methodological flaws that should be addressed. ,197 198 199 200 201 202 203 204 205 206
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"It next states that, “For each event cluster, we add a node to represent the overall information of the real-world complex event corresponding to the cluster.” ",272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Weakness,"
2. ",141
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Weakness,"- The work appears to be incremental: As mentioned in the paper, Kobayashi et al. (2020, 2021) proposed the analysis method leveraging attention block. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Weakness,The primary contribution of this paper is to integrate the existed strategies into a unified framework. ,188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,---------------- References ---------------- ,597 598 599
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"The paper does cite different sources which explain the problem in more depth, but I don’t think there’s a consensus that the type of compact extractions the authors promote is the ideal solution for the problem. ",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"In my understanding, this paper doesn't contain any novel findings essentially. ",139 140 141 142 143 144 145 146 147 148 149
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,The comparable supervised models should also be hybrid retrievers. ,155 156 157 158 159 160 161 162 163
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Weakness,"
2) It will be interesting to how this method scales with respect to more complex mathematical questions. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Weakness,3) Briefly discussing what kinds of data augmentation techniques  ( ♥ )  other works use in Table 4 would be great (and maybe why not used in this paper). ,223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,These details may impact your final results. ,323 324 325 326 327 328 329
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,Biases towards different languages/nationalities are different. ,518 519 520 521 522 523
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Weakness,"While I appreciate their effort in building pre-trained models for long sequences, I do have the following concerns: ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Weakness,2. ,247
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,"Card"" in this case could be considered more like a slot and maintain a similar level of genericness. ",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"-In Section 3.2.2, I would appreciate more intuition behind the ""Random walk"" language. ",352 353 354 355 356 357 358 359 360 361 362 363 364
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,Would that be a valid way to present these results? ,439 440 441 442 443 444 445 446 447 448
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,The difference between NoisyTune and above-mentioned paper is using masking or noisy to perturb parameters. ,163 164 165 166 167 168 169 170 171 172 173 174 175 176 177
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Weakness,The authors also say that improvement does exist and automatic schema expansion is worth future study. ,328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,"Thus, I feel the description on POMDP could be removed. ",135 136 137 138 139 140 141 142 143 144
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Weakness,"
2. ",324
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,"It would be important to include ALEBRT-ft + calibration regularizer in the ablation study to make sure that the observed improvements do not stem from the calibration regularizer.
",362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,  The paper indicates that only gold cue information is used for scope resolution (I. 219). ,120 121 122 123 124 125 126 127 128 129 130 131 132 133 134
4825eb030d8afb393c246a33e9d8a1f793b90ea88cb57ce09e675891f7d509d82c4b6cc50d7f8dc386a279b6854b3692285cbe651def3090bb02344787ef1b3f,arr,Weakness,"The attack effectiveness of the proposed models seems to be limited, with no more than 50%. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,But I think there should be some thought given to make sure the work is well evaluated. ,634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Weakness,Why is that? ,185 186 187
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Weakness,Why did you stick to a linear shape? ,292 293 294 295 296 297 298 299
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Weakness,The paper presents inconclusive negative results: it is unclear what the results would look like had millions of additional words that are *automatically diacritized* using Dicta are added in Nakdimon's training. ,75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Weakness,i.i.d. ,291
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Weakness,This is a revision of a previously submitted paper. ,110 111 112 113 114 115 116 117 118
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,A Globally Normalized Neural Model for Semantic Parsing ACl 2021 2. ,309 310 311 312 313 314 315 316 317 318 319
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Weakness, ,
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,It is not clear what the impact could be of measuring bias in sense embeddings or of debiasing sense embeddings. ,815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,__4. ,330
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Weakness,"The interpretability of the soft rules could be a potential benefit of the DILR approach, but it is still limited (no interpretation on relations, mostly attention-based entity chains) ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness,    ,
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Weakness, Is the BPE vocabulary of the LM fixed to the same vocab as the NMT model? ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Weakness,"The inference speed comparisons are also missing.
",267 268 269 270 271 272 273
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Weakness,"-The one design decision evaluated in the experiments is which graph encoding to use (node-centric, labeled-edge, and opinion-tuple). ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Weakness,"Although entailment models can be applied to estimate the probability of a given step in the reasoning chain, the paper does not really propose a full model that would apply such steps one by one, using some type of decoding process. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Weakness,1. ,143
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Weakness,"- Given this research topic, my first question would be: what is the upper bound / oracle performance for ""Select"", say, at the 3X speed up. ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Weakness,1. ,183
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Weakness,In section 3.3: what was the process of the manual annotation? ,297 298 299 300 301 302 303 304 305 306 307
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Weakness,I would recommend to add experimental contributions to the third point. ,491 492 493 494 495 496 497 498 499 500 501
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,1. ,223
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,Was any coreference spot-checked? ,260 261 262 263
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"More baselines should be included (e.g. Li et al., (2020), Gong et al., (2021a, b) as mentioned in the paper).
",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Weakness,- It is hard to follow what are the opinion piece the authors want to share with the readers through this paper. ,151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Weakness,"It would be interesting to see how this compares to directly tuning a late-fusion model with separate LR for each modality, especially with a similar or less compute budget. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,"For the loss functions, the authors should either give references to existing work which proposes these losses (for any task) or explicitly indicate that it is their contribution. ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Weakness,"The languages in CoNLL dataset are some rich-resourced languages indeed, the authors need to test MTMT model on some low-resourced languages.
",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,"Seeing in this light, the results in table 1 do not convey anything significant.
",597 598 599 600 601 602 603 604 605 606 607 608 609 610
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Weakness,W4: An analysis of the difficulty of the annotators in identifying each class is not presented. ,241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Weakness,"In doing that, this paper can certainly contribute to the growing literature on model vulnerability and robustness. ",450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,-I'd like to know why the authors perform different experiments on language models with CLM (causal) and MLM (masked) objectives. ,394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,Some of the work I'm talking about are: ,201 202 203 204 205 206 207 208
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,3. ,288
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Weakness,"Templates exacerbate this problem by presenting a relatively invariant sentence string structure.
",267 268 269 270 271 272 273 274 275 276 277 278
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Weakness,The paper should include results using the GCPG model without pre-trained initializations. ,226 227 228 229 230 231 232 233 234 235 236 237
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Weakness,"And also, it seems that the DILR-BERT doesn't fine-tune the BERT parameters? ",259 260 261 262 263 264 265 266 267 268 269 270
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Weakness,1. ,86
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness,"Otherwise, the authors need to present why the addressed issue of the proposed model appears in Chinese NER task, not in other English NER tasks, . ",295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Weakness,"W1: Considering that E2E model benefits from mostly training over pseudo-labels (“distillation”), the resulting model actually represents another pipeline, which requires the text-NER. ",107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Weakness,"-The previous report of SciBERT were removed, but this somewhat exacerbates the earlier problem in v1 where the analyses of the outcomes of the models was too cursory and unsupported by deeper analyses. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,Making the contribution more pronounced and how this specifically connects to the results and future opportunities might help with this. ,395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Weakness,"arXiv preprint arXiv:2012.15674, 2020. ",231 232 233 234
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,It seems additional cues are collected only from a biomedical domain. ,174 175 176 177 178 179 180 181 182 183 184
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,The authors did not justify why Optimal Transport (OT) is used and did not elaborate on what are OT's advantages. ,447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,"More generally, a comparison with state of the art on the used datasets is missing.
",441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Weakness,"I suggest at least discussing the following:   - Intuitively why relying on semantic roles is better than work like CLEAR   - What SRL model you use   - What the sequence ""[ARG0, PRED, ARGM − NEG, ARG1]"" mean, and what these PropBank labels mean   - What is your reason of using this sequence as opposed to alternatives ",446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,"The trainable SR module is based on RoBERTa, while NSM and GraftNet do not employ large pretrained language models. ",213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,__1. ,206
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Weakness,"Also, it is better for authors to include textCNN/LSTM (1 of them is enough) for text classification, which can show whether non-pretrained models can be used under PLASM.
",167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Weakness,Would this removal make conversational models less interesting or engaging? ,179 180 181 182 183 184 185 186 187 188
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Weakness,-The general idea is well described but several details are not clear in the paper (refer to comments for details). ,119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Weakness,"-In general, there are quite a few things missing -- details provided in comments section. ",240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,"
Therefore, the experiment results cannot support the claim made by authors.
",446 447 448 449 450 451 452 453 454 455 456
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,1. ,248
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Weakness,The contexts explored in this work are very specific distractor-like types of contexts where an image appears in combination with extremely similar images. ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,This can result in differences that are not comparable. ,517 518 519 520 521 522 523 524 525
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,A critical weakness of the paper is the lack of novelty and incremental nature of work. ,168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Weakness,"Its essence is the ""pilot update"" mechanism, which basically applies the inner loop of MAML twice, once to update the teacher, and once to update the student.
",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Weakness,"Some concerns remain over the empirical evaluation, as detailed in the comments. ",70 71 72 73 74 75 76 77 78 79 80 81
5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec,arr,Weakness,"From the title of this manuscript, it seems that the authors mainly contributed to the dataset. ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
6de4c24feda039f610f2f5499017edf441c88aa4ccfcd935c5311e14cb3a538507eae0a124803d5f1852a085fc55e85971be82ce03f925c776ba7dcb86604511,arr,Weakness,Evaluation is done on very old WMT datasets. ,46 47 48 49 50 51 52 53
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,Probing for sentence structure in contextualized word representations. ,441 442 443 444 445 446 447 448
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,"
5. ",317
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,"To better justify the claims in this paper, additional experiments or more in-depth analysis seem necessary.
",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Weakness,"
2) Details about the model training and dataset is missing. ",160 161 162 163 164 165 166 167 168 169
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Weakness,"Would be important to see in which cases the annotators do not agree and why.
",257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Weakness,One could also make the argument that the language itself is fairly artificial in the sense that these are not the sort of descriptions that would appear in any use case directly. ,237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness,"2] show that a hybrid retriever over DPR and BM25 is actually able to improve over both.
",147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Weakness," But on the other hand, the results so far are clearly making a lot of mistakes. ",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"Are there any higher-level tasks such as NLI, QA, SRL, etc.? ",558 559 560 561 562 563 564 565 566 567 568
74644b8c9ecdd5fa9ec1f11bf74bb24a859379bf32c3d6cbacd875a97578143afd0288863fc70dd959eddb1a9aabaf66d9ae02d6c1917377dd7d9427c44bde88,arr,Weakness,-Not quite clear how semantically related events are defined and prototype for cluster defined ,163 164 165 166 167 168 169 170 171 172 173 174 175 176
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,Would a transformer/attention mechanism be better suited for learning longer sequences? ,588 589 590 591 592 593 594 595 596 597 598
a6f83f54bd43db725bd0f67fc819f1c0b0bf631d8badf27f63f1eaca61865c0f943ea31260da63ebb8157c4b7131d3f08990bba93564e11293c433f2a1cd5109,arr,Weakness,It appears that innovation of this paper is less. ,90 91 92 93 94 95 96 97 98
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Weakness, The current work does not solve the problem of QA in education. ,337 338 339 340 341 342 343 344 345 346 347 348
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Weakness,Could a model pretrained on a larger and more diverse dataset be less prone to structural bias? ,319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,DExperts: Decoding-time controlled text generation with experts and anti-experts (Liu et al. 2021) Plug and Play Autoencoders for Conditional Text Generation (Mai et al 2020) Sentence Bottleneck Autoencoders from Transformer Language Models (Montero et al. 2021) A distributional approach to controlled text generation (Khalifa et al. 2020) GeDi (Kruase et al. 2020) DAPT (Gururangan et al. 2020) CTRL (Keskar et al. 2019) FUDGE (Yang and Klein 2021) ,209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Weakness,-detailed comparison and analysis across models are not shown (e.g: what errors does each model make? ,247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,More tasks ,316 317
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Weakness,"
2. ",255
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Weakness,For example one can use an F-measure like metric on all the words in the test set. ,411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Weakness,The claim of high cognitive demand question generation can not convince me. ,43 44 45 46 47 48 49 50 51 52 53 54
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,"-The ontology definition and annotation scheme itself is glossed over in this paper, although it is a major contribution. ",263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Weakness,"-The newly added results for the SGCP baseline look very different from the numbers reported in Kumar et al., 2020. ",293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Weakness,That can easily be addressed given an extra page. ,219 220 221 222 223 224 225 226 227
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Weakness,The dataset contains only extreme speech - it seems that the authors filtered out somehow the neutral text (or ones that don't require moderation according to their definitions). ,337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
747249d6df576d913b4dd001992510d9682657fee6f4ea775a23731979bf7af0362f975f45b8c27ae3b04e093fa81069cf32428adf42b4026a447055a6907e27,arr,Weakness,They release a benchmark for adversarial example detection on 4  attack methods across 4 models and 3 datasets. ,131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Weakness,"
3. ",142
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"To me, my main takeaway is that question decomposition is helpful, which has been studied in previous works like BREAK (Wolfson el at + 2020). ",418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Weakness,"It looks like for the most part, human responses are close to perfect. ",186 187 188 189 190 191 192 193 194 195 196 197 198
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Weakness,"However, it might be better to show the performances of these methods on the MedLAMA dataset, in order to show the validity of the MedLAMA dataset.
",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249
262843a4c9c8009e43c652fd03dead78e120f32d62499d0826136d5c4e1204d19e1bcc09ae3b3c7a938f919e9e86262d824cc86c483e18e874e11562461a1524,arr,Weakness,"Regarding the dataset construction: the approach is generally sound, but the purposive (i.e., keyword-search oriented) method regarding representative keywords potentially provides a heavy bias. ",111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Weakness,Several more such features can be thought of that would identify the template. ,388 389 390 391 392 393 394 395 396 397 398 399 400
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,"For example, the second paragraph of section 5.1 should be rewritten and divided into more than one paragraph. ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Weakness,How will such unhelpful literature impact patient outcomes? ,242 243 244 245 246 247 248 249
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Weakness,"There might be improvement in model calibration, but with the current paper it is not clear from Table 4 the improvement means big thing or not. ",202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,A comment about the architecture: There is neither intuition nor motivation as to why a single same attention layer should be used for both stages of obtaining the sentence embedding (Eq. 1 and 3). ,369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,https://arxiv.org/pdf/2011.05268.pdf ,237
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Weakness,"-Multilingual coverage could of course be better, but the current limitation is understandable and acceptable given the large amount of manual work involved ",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Weakness,"""We adopt sentence-level modeling [over between-sentences] because we would like to focus on the learning of sentence structures and also simplify the task setting."" ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Weakness,I can not understand why you concatenate all questions into one sentence. ,98 99 100 101 102 103 104 105 106 107 108 109
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Weakness,"The paper begins with the famous ""king, man, queen, women"" example and motivates the work by saying the proper next word following the ""After debating whether to bow to the woman or the king first, the jester decided on the"" context should be ""woman"" and ""king"", instead of ""queen"" and ""king"". ",303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,"I would suggest that the authors calculate the token-level difficulty of the model before and after using the hash function, and perform more analysis on this basis. ",413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439
5f9df67495c17db90e7bfcce611efe8b65edcb225b9fb603e5b7e3d30b198f39a36e0c38f66bc04a063129ecdaf2e387b1cb42291be7cf83de659b9fb091736c,arr,Weakness,"
    - Again, additional experiments in Section 4.5 is an overly detailed piece of information and is not super relevant to rest of the writing. ",335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Weakness, ,
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness,"The motivation of paper is not very tightly related to the proposed regularity-aware models, i.e. how it can be seen as an alternative model of the previous lexicon-based models? ",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Weakness,1. ,201
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Weakness,"- Given the nature of the work, evaluation is important. ",147 148 149 150 151 152 153 154 155 156
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,"Random selection might not be the best option here.
",175 176 177 178 179 180 181 182 183
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Weakness,"This information is important for understanding and reproducibility, and it is necessary for properly reviewing the work. ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,This point should be highlighted and explained further: Where does this become especially relevant and to what extent does it matter? ,201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,Percentage preference through majority voting is reported for the human evaluation. ,403 404 405 406 407 408 409 410 411 412 413
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,"Farhad Nooralahzadeh, Giannis Bekoulis, Johannes Bjerva, Isabelle Augenstein. ",242 243 244 245 246 247 248 249
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness,Soundness of this paper ,198 199 200 201
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Weakness,"Due to the difficulty to build a corpus as employed in this study, the amount of data used to train the machine translation systems is relatively small when compared to publicly available corpora used for the same language pairs by the research community. ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Weakness,And the discussion of the impact of different tasks in this paper is not sufficiently informative and does not fit well with other sections. ,128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,"-Gold-standard human explanation datasets are necessary, given the objective in line 307. ",246 247 248 249 250 251 252 253 254 255 256 257
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Weakness,"Can you please elaborate on this?
",202 203 204 205 206 207
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Weakness,"
  * If multiple answer spans for a question often exist within one sentence consecutively as shown in Table 2, just extracting the whole sentence as a single-span answer may be enough to answer a question and easier to model than the proposed multi-span setting. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Weakness,"The author adopted the ROUGE-L metric for evaluation, but there is no justification that this metric is reliable in the addressed task: How likely a QA-pair with high ROUGE score can faithfully evaluate children’s RC skills? ",306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness, ,
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Weakness,"-there is a disconnect between the visualizations and the rest of the processing.
",164 165 166 167 168 169 170 171 172 173 174 175 176
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"Line 118 claims `embedding distances of prompts do not well indicate prompt transferability` but Table 4 shows that C$_{\text{average}}$ is not far behind _ON_. This claim seems over-reaching and should instead be something like ""our novel method of measuring prompt similarity via model activations is better correlated with transfer performance than embedding distance based measures"" ",1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,[2] A Cross-Task Analysis of Text Span Representations. ,452 453 454 455 456 457 458 459
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Weakness,"In my opinion, this is the most disheartening weakness of this work in general (beyond the paper itself). ",560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Weakness,I had a few small technical/presentation suggestions: ,278 279 280 281 282 283 284
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,"The problem you are highlighting is more linked to ranking rather than perplexity.
",372 373 374 375 376 377 378 379 380 381 382 383 384
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,3. “ ,435 436
b1fb88206c3832e9f87e6f8115045f3478d45617776f8397f37664d4de722806db84bff9744f31328a47ad99443cf3b52355d950d9e6fa09b9747dbb3b9f4f21,arr,Weakness,"Given that this paper focuses on sequence distillation, wondering how the beam size, length penalty of the teacher model will affect the sequence distillation results? ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Weakness,"Testing what BERT knows about metaphors"" by Pedinotti et al, Blackbox NLP 21, should be cited here if possible. ",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Weakness, But it does not explain all results (like Bert small better than large even after intermediate training). ,553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Weakness,"Without this     information, it is difficult to ascertain if the out-of-the-box models'     probing performance is at all good, or if it pales in comparison to simple     supervised baselines. ",259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Weakness,"After all, if training with the additional information actually damaged performance, the authors would not have concluded that the model doesn’t use the information or that the information was somehow harmful or misleading. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Weakness,My main concern was the reasoning behind the conclusions: It is very tricky to reach clear conclusions between reading and listening from two such different datasets. ,148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,"So what would be the results of TAS-B+LEDR?
",207 208 209 210 211 212 213 214
dfd2ab193176f5966f14f5955687cf4e9b38cfdf5757e0cad23cca2bad60275ec30dfe3c06f55b0bf02741baed5b541ed734f52904675c5eaf7214f95f7a1ae3,arr,Weakness,-I would expect an analysis such as this to have at least 3 runs with varying random seeds per model to give greater confidence in the model's abilities. ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,2. ,388
30aa157cc690ecbf3ee3034c035b2533e3c1a2e99c7ce2c797371c7c758de51b77204c36880a0163059bed31ff962c7a97d94be7c6d287e09e1c2e2a93ac4e1e,arr,Weakness,"
• The logic flow of the paper needs to be improved. ",114 115 116 117 118 119 120 121 122 123 124
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Weakness,"On the other hand, the authors assume that multi-task learning is going to work without putting much effort into studying how each task affects the others. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,"Thus, the results presented are insufficient to prove the benefits of the proposed methods. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Weakness,- Training is performed on each dataset separately. ,211 212 213 214 215 216 217 218
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,"In terms of the three metrics, the state-of-the-art method, ZS-BERT, is inferior to other methods, such as Att-BiLSTM, which surprises many readers. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Weakness,"
2. ",205
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Weakness, Readers might be inclined to decide that the techniques aren't worth trying. ,393 394 395 396 397 398 399 400 401 402 403 404
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"While references are provided, no mention of validation of such manipulation is provided to satisfy a reader as to the of created fake news nor is mention made as to the heterogeneity or homogeneity of created fake news. ",441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,This pipeline seems to be fully automated. ,199 200 201 202 203 204 205
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,"If so, how many augmented samples are synthesized for each original sample? ",424 425 426 427 428 429 430 431 432 433 434 435
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Weakness,There is a slight imbalance between the background and the description and discussion of results in the paper. ,107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Weakness,Can you provide more information about the amount of parameters and inference speed towards other baselines？ ,154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Weakness,"For *Agent Summary Completeness Analysis*, some details are missing, how to judge agent summaries need to be integrated? ",171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Weakness,"Moreover, the improvements on YelpRev, DBPedia, QNLI, and QQP are always less than 1. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Weakness,1. ,266
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,It is better to show more results such as the convergence analysis. ,163 164 165 166 167 168 169 170 171 172 173 174
68c709e853fc85c4a51a2bf31e9323929a8768c91c3f21e30970ee38b5a6ecfa7ccb0abbc60c80205f631bbbaa1a83fdcb50ce32cdd591a45dfbf3dbe31d5180,arr,Weakness,"Unfortunately, in this paper, the authors reduced the  procedure to initializing the weights of the language model at random. ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"For instance, in lines 246-249, ""This difference in the composition of bias types explains why the bias score of BERT is higher in CrowS-Pairs, while the same is higher for SenseBERT in StereoSet."" ",354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Weakness,"Therefore, I don't see many technical contributions from this paper. ",171 172 173 174 175 176 177 178 179 180
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Weakness,1. ,128
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,"When applied to the target language, does it mean that we directly input the target sample into the teacher model to get the teacher distribution? ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,"It would be interesting to see the connection between the arguments of the current paper and such papers.
",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,It is hard to convince the effectiveness of DILR. ,133 134 135 136 137 138 139 140 141
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,Do p(s) and p(t) here the ones calculated and updated in equation (6-7) in lines 369-370? ,375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Weakness,- The case study section is also not very informative. ,112 113 114 115 116 117 118 119 120 121
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Weakness,The authors did not perform further experiments to show whether a long-form QA system can benefit from that discourse-level information to generate better answers. ,192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,Do you provide the ground truth context without distractors? ,596 597 598 599 600 601 602 603 604
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,NAACL’19 ,342
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Weakness,The evaluation section could benefit from further motivation for the three experiments shown; were other considered? ,155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness," First, I do not think boundary tokens are heterogeneous to inside tokens. ",225 226 227 228 229 230 231 232 233 234 235 236
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,1. ,111
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Weakness,I would have liked to see more discussion and empirical analysis of how typological differences between languages affect the relative performance of subword- and character-level models. ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,"In addition, all the comparisons in the result section (and the delta numbers in Table 1) are made against a baseline vanilla Transformer model. ",362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Weakness,"The paper has incremental or limited novelty as the question generation from passages using BART is already a known, Bi-encoder for QA already exists. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Weakness,"- Although the authors showed consistent improvement with proposed DDNET approach over the baselines, it is difficult to interpret how good the results are. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Weakness,heuristic multi-task group dropout” (HMGD) captures most of the improvements between Transformer vs proposed LaMGD with a 0.5 BLEU difference between HMGD and LaMGD - It is worth making a case that the simpler approach HMGD is also a win 3. ,431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"The current form is a bit messy in Line 409-436, 461-509. ",478 479 480 481 482 483 484 485 486 487 488
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Weakness,"	While the proposed method is more effective than the previous methods, the efficiency (e.g. training and inference speed) is not compared. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Weakness,"It would be better if the paper address this (even simply pointing out that it’s not an issue).
",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Weakness,"For a paper focused on determining what actually matters in building a text to code system, I think it is important to be precise on these details. ",346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"Kikuchi et al., 16: Controlling Output Length in Neural Encoder-Decoders.
",409 410 411 412 413 414 415 416 417 418
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness,"For tips, please see the previous litterature. ",363 364 365 366 367 368 369
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Weakness,"One way of achieving this would be, for instance, by commenting on an example, which would also serve as an introduction to the concept of discourse coherence. ",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Weakness,"Thus, I cannot judge whether the proposed training strategy improves the performance or sharing parameters improves the performance (or other reasons for improvements). ",302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Weakness,"
4. ",320
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Weakness,Lines 308-319 are quite confused to me. ,303 304 305 306 307 308 309
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Weakness,This is not a new discovery either. ,388 389 390 391 392 393 394
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Weakness,"- There approach may have limitations w/r/t to model scale (e.g., \alpha approaching zero in Figure 2) -- although the approach is still additive on GPT-3 (one of the largest language models available) in Table 1. ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,2. ,330
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Weakness,I think the proposed model is a special case of collective entity linking. ,200 201 202 203 204 205 206 207 208 209 210 211 212
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Weakness,"-Datasets are not new, but just aggregated from other people ",172 173 174 175 176 177 178 179 180 181
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Weakness,"Though it is important to validate them in the moral value applications (which is limited),  it will be better if the paper clarifies what its core contributions are and how it varies from other general approaches/findings in domain adaptation or multi-task learning methods. ",350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Weakness,"One of my concerns is that though it's nice to have results over such a large number of language pairs, only looking at the overall trend might not be enough to reveal certain interesting patterns. ",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Weakness,"-In general, it seems the authors want to propose a way of create a challenging set. ",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness, ,
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Weakness, ,
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Weakness,Need to design a more sophisticated reward. ,248 249 250 251 252 253 254
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Weakness,"Section 2.1 line 188-203, it is understandable to use special tokens as input for encoding, but the paper does not clarify which token is used as the representation of a mention span (is it [SATART] or [END]?), ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
7f996fb9f31b45dea2339c0d4716c6c109c47c5b38feee689425e631026e454379762bebbea912d49f29530016a12a703c629819acd26de68018289115cb6bdd,arr,Weakness,"- The results given by the probe are a little difficult to interpret; as, while there is a control experiment where the probe has no information, it would be very useful to have an idea of what the probe can do when fed with embeddings that we know contain orthographic information. ",296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Weakness,"
So I think the paper would be better to appear in related workshop, rather than a ACL long paper. ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,At the end we don't learn much about the models. ,401 402 403 404 405 406 407 408 409 410
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Weakness,"The question would be, is the machine translation system able to model the direction and potentially abstract from train-test or data-model alignment mismatch. ",461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,The novelty of the proposed method is also very limited. ,194 195 196 197 198 199 200 201 202 203
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,I suspect that there might be a big overlap. ,190 191 192 193 194 195 196 197 198
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Weakness,2. ,184
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,"Furthermore, under the current setting, this problem sounds more like another type of machine reading that the model is asked to fill in the table as the schema is easy to predict. ",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,This architectural choice should be justified. ,599 600 601 602 603 604
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,Did you normalize the vector norms? ,394 395 396 397 398 399
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Weakness,"- I am admittedly not that familiar with the standards in dataset and tasks for this domain, but most of the tasks presented in this paper seem to be based on question type/similarity (knowledge point classification, question relation, question recommendation). ",225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Weakness,Which will make this work accessible to a smaller set of research community. ,170 171 172 173 174 175 176 177 178 179 180 181 182
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"According to F3, the NL questions to the text agent and the table agent look pretty similar (e.g. [table] What movies has #1 written? ",458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Weakness,"Indeed, this has been pointed out in Chris Bishop's seminal paper, Mixture Density Networks. ",320 321 322 323 324 325 326 327 328 329 330 331 332 333
d0adbc683b1920556f2f658448daf2792434b209a9960622144d3cf741857c04c0854fce75bf2591fe5e861afaa3a58b2593abb0ea1927e3b4e1168cb2175c86,arr,Weakness,It would be interesting to observe whether the gains would remain as steep if trained on a fraction of the original dataset. ,149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Weakness,"
I guess what I mean to say here is that the problem is of limited interest to me (which says nothing about a broader audience) because the results agree very well with my expectations. ",358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Weakness,"For example, the authors commented in the response pdf to one of the reviewers that performance difference across traits is due to topical variation. ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Weakness,"- The comparative analysis in Table 2 shows that, with significantly more computational costs than the two compared baselines (PKD and ProKT), the model achieves a modest performance gain of about 0.5 absolute F1 points. ",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Weakness,1. ,121
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,"More details should be there for the approach ""negation-focused data collection"" approach. ",162 163 164 165 166 167 168 169 170 171 172 173
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"It is worth noting that the maximum pairwise similarity approach used in WAT calculation runs counter to this assumption of disjoint senses.)
",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,"In this case, `torch.topk` is called in the code, and only K numbers are sorted. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Weakness,"This phenomenon should be investigated further, for instance by replacing the random baseline by a frequency based classifier, as a starting point. ",493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,-A large contribution of the author is the proposal of a new pre-training approach that combines ICT + SimCSE with a large negative cache (ICoL) ,217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Weakness,1. ,191
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,The authors claim that the alpha entmax is slow because it requires sorting. ,104 105 106 107 108 109 110 111 112 113 114 115 116
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Weakness,"GenBERT is a very relevant baseline but I think other methods that enhance LM with external knowledge (e.g., KBERT, KnowBERT) should also be compared.
",194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Weakness,"
	2. ",231
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Weakness,"Also, see concurrent work [2] on training a self-supervised audio-visual representation from scratch for AVSR. ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Weakness,"I think if this paper couched itself as more of a 'analysis/experimental' type of paper, expanding its analysis even further (and maybe expanding its scope to other tasks besides just abstractive summarization), it could be solid contribution. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Weakness, ,
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Weakness,"Besides the above, the contribution part (line 99-111) is not well structured. ",479 480 481 482 483 484 485 486 487 488 489 490
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Weakness,"I suggest authors better address the causal nature of generating counterfactual examples, and try to analyze the sensitivity of their method to the type of attacks generated by SHARP. ",421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,ACL. ,239
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Weakness,It is unclear to me why the affinity weights should be defined as Eq.2? ,165 166 167 168 169 170 171 172 173 174 175 176 177 178
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Weakness,This brings out the concern that whether the main question discussed in this work can really stand for the trend of current works on this task. ,281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,"It has potentially wide-ranging downstream impact, so including one to highlight potential harms and effects is important. ",501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Weakness,"- Regarding the regression experiments that the authors discuss in their response, these results can perhaps be mentioned for readers' reference if space permits. ",488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Weakness,"Previous studies find that the mis-calibration problem is closely related with model size (Guo et al., 2019; Wang et al., 2020). ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Weakness,"
3. ",223
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,"experiments were performed on 3 language pairs with the base setting, I wonder whether the approach can perform well in challenging settings (Transformer Big and deep Transformers). ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"For example, the authors write about a “dictionary”, and a “memory bank” without providing further explanations about how they use them and how they are composed. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"Some major points of criticism, however still stand: ",230 231 232 233 234 235 236 237
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Weakness,"- As a recent trend is pre-training Transformer on large-scale corpora and larger models also show greater capabilities for context representative, I am wondering if the larger model performs poorly on context-dependent types.
",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Weakness,See comments below ,323 324 325
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Weakness,The methods are not novel as they are largely borrowing from existing work. ,98 99 100 101 102 103 104 105 106 107 108 109 110
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Weakness," Line 363 says that MLE denotes the technique of Lee et al (2018) from image processing, but I don’t know which technique from that paper, and I don’t know how it’s adapted for the tasks in this paper. ",396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,I suggest conducting experiments on more datasets to make a more comprehensive evaluation of the proposed method. ,297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,Why was there no discussion on non-autoregressive models? ,308 309 310 311 312 313 314 315
0805cef3514c6a8a408cb365fd19199aaee44bbc746bb7bc13c51afa2bd0cfdd0e9165c5a40142bf664015f97a59341d81ff0ce405993bbbbaeb8110390c3739,arr,Weakness,Note: the WER can exceed 100% in some cases. ,157 158 159 160 161 162 163 164 165
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Weakness,-The writing of this paper can benefit by some work (see more below). ,311 312 313 314 315 316 317 318 319 320 321 322 323
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Weakness,Why does the architecture or the pre-training make the model underperform? ,223 224 225 226 227 228 229 230 231 232 233
fb8abed24b895c60af95d65f500024e37b39c870800b09362cb415350eecdb493573e965cb693012ce459c254f4446514a17effdbceccb50b7ce870bb3bc6119,arr,Weakness,"Training with incorporating of another commonsense view is somewhat incremental and very similar to the referred JOIE in this paper, especially in the inference stage. ",89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,- One major concern is that the contribution of this paper to the QA and NLP community seems mediocre. ,145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Weakness,1. ,84
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness," Thus all attention weights are put on that key.
",307 308 309 310 311 312 313 314 315
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Weakness,"
2. ",121
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"In my view, the paper would benefit from refocusing on exploring its main contributions. ",122 123 124 125 126 127 128 129 130 131 132 133 134 135
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,"Namely, provided that Vrank also has error, the best possible automatic protocol would include only Vrank or be complemented with other metrics? ",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Weakness,"
2. ",346
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Weakness,"Thus, the conclusions drawn by the authors might be limited to low or average data settings.
",394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,These would all be helpful to know. ,287 288 289 290 291 292 293
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness,"  -- If I understand correctly, Y_i in eq 1 is the sentence embedding induced by BERT model. ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,"And while claims are related to 3 topics, they are still limited. ",176 177 178 179 180 181 182 183 184 185 186 187
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,It will be nice if you can provide some examples for s(_i) and a(_j) 5. ,631 632 633 634 635 636 637 638 639 640 641 642 643 644 645
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"How were two input sentences for qualitative analysis (Sec 4.5.5, Figure 1) determined? ",356 357 358 359 360 361 362 363 364 365 366 367 368
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,1. ,133
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Weakness,Can we eliminate the data leak through filtering with publishing time. ,193 194 195 196 197 198 199 200 201 202 203
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Weakness,Please see the detailed comments below. ,101 102 103 104 105 106
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Weakness,"Lacking the evaluation of sentiment word detection and correction: since the key ideas of SWRM are the detection and correction of possible sentiment word errors, I think it is necessary to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,"I see from the experiments that the TED model doesn't generalize well to Behance, but is that because of the nature of the conversations or the domain (design)? ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,"You are already very close to the ceiling, and it should be hard to see any benefit of the intervention.
",415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Weakness,"Moreover, it shows that prompt-based finetuning with BitFit can achieve comparable or even better performance, with memory efficiency introduced. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,What are the circumstances that DEAM fails? ,353 354 355 356 357 358 359
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,I also didn’t see this baseline exists. ,161 162 163 164 165 166 167
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Weakness,So I'm not sure whether repartitioning the SQUALL is the best choice or any other resources are also available. ,356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374
71e7b95a72af9ac8519665285f1c20f8f8864dc212f5477ffd96c88ab2a42ae84a3e1a5eb93606189083f3c1271d360fde8eb2d0c0d81ef42c2692f8be1d897c,arr,Weakness,There are two main concerns from me . ,126 127 128 129 130 131 132 133
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Weakness,"The amount of background provided can be reduced, and consists of quite a few detailed descriptions of topics and experiments that are not directly related to the experiments of the paper (e.g. the Priming paragraph at L210, Novel verbs paragraph at L224). ",545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Weakness,Even the Adapters baseline is very similar to the Transformer baseline. ,530 531 532 533 534 535 536 537 538 539 540
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,"If for some practical reason, the baseline of (Lin et al., 2020) can’t be used, it needs to be explained clearly.
",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Weakness,-Lack of clarity in how datasets were curated prevents one from assessing their validity ,120 121 122 123 124 125 126 127 128 129 130 131 132 133
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Weakness,Another weakness is that the conclusion of superiority of feature attribution methods is somewhat unreliable given that they hold for RoEn and NeEn but not EsEn (using AP as indicated in the paper). ,573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Weakness,1. ,98
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Weakness,Will this affect the evaluation results? ,381 382 383 384 385 386
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Weakness,"For example, ""What songs were in Parade"" could be answered without history information. ",177 178 179 180 181 182 183 184 185 186 187 188 189
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Weakness,-I don't understand why the results on RoBERTa and DeBERTa are restricted to only SST-2. ,468 469 470 471 472 473 474 475 476 477 478 479 480 481 482
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Weakness,"However, the authors only analyzed 52 examples. ",286 287 288 289 290 291 292
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"In general, this section 2.2.2 is the one I have found less clear)  ",397 398 399 400 401 402 403 404 405 406 407 408 409
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Weakness,"The ""baseline"" may not be appropriate. ",94 95 96 97 98 99
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"Compacter: Efficient Low-Rank Hypercomplex Adapter Layers."" ",406 407 408 409 410 411
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,-Line 187: It’s best to treat Emb as a function. ,416 417 418 419 420 421 422 423 424 425
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Weakness," The arguments here seemed all to have the same direction -- all in favor, all against, but with different moral bases. ",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Weakness,The paper only presents an evaluation on German and may or may not work in the actual low-resource settings. ,202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,LeBenchmark). ,323
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,"I’ll mention one other thing, which isn’t really a weakness but is more of a meta-concern: One potential pitfall of submitting and publishing this kind of work in an ACL venue is that the reviewers (like me) and audience are not necessarily going to be experts in this methodology and so care should be taken to make sure it is well reviewed by people who have the relevant expertise. ",436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness, ,
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Weakness,"However, the results reported in the updated draft have reinforced my concerns regarding the effectiveness of the learned job title representations. ",203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Weakness,For example: 1) Setting the vector dimension to 10 can make the entire conditional token distribution close to the Zipfian distribution. ,164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,Why is the decoder called 'mix-' decoder? ,312 313 314 315 316 317 318
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"-Circling back to the motivation of this work, which is the fact that ""an encoder only pretrained on L1 can be transferred to L2 without any parameter updates"". ",519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Weakness,The proposed model lacks a comparison with baseline(s) from the literature. ,226 227 228 229 230 231 232 233 234 235 236
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Weakness,-It is not clear if the benefit of the method is just performance-wise. ,226 227 228 229 230 231 232 233 234 235 236 237 238
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Weakness,Some qualitative analysis of the results and/or error analysis will be useful to understand these type of cases better. ,142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Weakness,"3- Measurement of the performance maybe highly affected by the way the evaluation dataset is created.
",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Weakness,"At alpha=.49 inter-annotator agreement is low, which is not unexpected given the complexity of the task. ",169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Weakness,The human evaluation part is quite confusing. ,331 332 333 334 335 336 337
fcc2d390db2717ce8d77836ca10248ee73a8d94600bd9528cef5d26d16f18393f230b60463fae854e5f652936577b5b37ccc698e95ca831fa89d8e7a12079552,arr,Weakness,"If lambda is too small, perhaps the model will always produce c_t = 0 to peak the ground truth. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,-The proposed method is not so new. ,374 375 376 377 378 379 380
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Weakness,"I would assume French and Spanish are included here, so claiming that this does well cross-linguistically assumes that too, right? ",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Weakness,"It seems that the main focus in the experiment is ""gender-ness"" of words (e.g., he, she, etc.) ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,arXiv preprint arXiv:2005.01655. ,259 260 261
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Weakness,"al., 2017), there are models that explicitly do data to text generation with copy mechanism (attention based) that could serve as a slightly more intelligent way of performing copying baseline with selection of what to copy. ",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Weakness,[1] https://www.nature.com/articles/s41597-019-0103-9 [2] https://arxiv.org/abs/2107.11665 ,331 332 333 334
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Weakness,"The binary reward from user feedback is weak due to the large search space for EQA, resulting in the incapability of providing precise supervisory signals. ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Weakness,I'm also a bit confusing about why the authors choose MSCOCO as the caption dataset instead of the larger Conceptual Captions. ,186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Weakness,1. ,81
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,Hope the author can explain this! ,168 169 170 171 172 173
9f16d7fbb89be40b6fa6ff149aa34cfcad08f2a811b1bef57d6136992bef789a65da497e685cbeb4e29335b120aaf58d3d7240a775eb25c9fe8bec3fa6bf4ffc,arr,Weakness,"Applying the copy mechanism in the point generator paper on transformer model has been studied in many papers.
",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,Many of those combine some blackbox methods in different ways. ,178 179 180 181 182 183 184 185 186 187
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Weakness,- it is not clear what's the goal of the paper. ,85 86 87 88 89 90 91 92 93 94 95
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,See below). ,209 210
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Weakness,1. ,126
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,"While calculating the speedups, the authors are showing the FLOPs in the figures. ",158 159 160 161 162 163 164 165 166 167 168 169 170
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Weakness,1. ,78
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Weakness,  * L292: Which BPE tokenizer are you referring to? ,241 242 243 244 245 246 247 248 249
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,"Though this work performs analysis of corpus and model to study the role of the context, the claim of being the first work to establish the importance of context may be a little stretched. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Weakness,The authors argue that a better understanding of the discourse structure of long-form answers can benefit the long-form QA systems or the evaluation of long-form answers. ,156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,"This may suggest that the baseline, and other baselines,  might overfit to the training data. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,"Since RoBERTa is generally considered more powerful than LSTM and MLP, it is likely that the high performance largely results from RoBERTa rather than the trainable SR strategy itself. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Weakness,- Human evaluation suggests that the proposed methods underperforms in fluency. ,241 242 243 244 245 246 247 248 249 250 251
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Weakness,Some of the references are provided in the comments section. ,351 352 353 354 355 356 357 358 359 360
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Weakness,"- much of the approach  is based on combining existing published work with respect to the dictionary construction and candidate generation so it makes it difficult to assess how much contribution has been made by the authors.
",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness, ,
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Weakness,"Multi-task learning generally struggles when tasks of different complexities are combined together (e.g., see GradNorm for a possible solution: https://arxiv.org/abs/1711.02257). ",356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,The paper does not lay down its claims concretely or can be confusing at times. ,326 327 328 329 330 331 332 333 334 335 336 337 338 339 340
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Weakness,"The authors only conduct experiments using one QE model, making the results less convincing. ",154 155 156 157 158 159 160 161 162 163 164 165 166 167
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,https://arxiv.org/abs/2101.00190 ,381
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Weakness,-The paper also lacks analysis or an intuitive explanation as to why the proposed model outperforms large pre-trained models like Frozen. ,247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Weakness,"But one question is how to measure the correctness of the divided group, not only from the perspective of intuitions but experimental evidence.
",118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Weakness,-~The experimental results seem to be missing significance testing. ,385 386 387 388 389 390 391 392 393
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,1. ,131
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"That is, it would be nice to have more model comparisons (aside from BART and PEGASUS and including state-of-the-art models), more datasets (different domains, multi-document vs single-document, etc.), ",160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Weakness,"Despite its strengths, there are also several areas that offer opportunities for improvement in future revisions: ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Weakness,The write-up has many typos and some formulas/explanations are confusing. ,114 115 116 117 118 119 120 121 122 123
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Weakness,3) The method is entirely based on written signal (spelling). ,278 279 280 281 282 283 284 285 286 287
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Weakness,"The baselines presented, however, are rather strong -- with DistilBERT achieving 0.390 MRR@10 on MS MARCO (compared to Nogueria & Cho's 0.365 using BERT-large). ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Weakness,Why do the authors use regularization for label embeddings but not for instance embeddings? ,349 350 351 352 353 354 355 356 357 358 359 360 361 362
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Weakness,It is not stated whether the dataset will be publicly released. ,211 212 213 214 215 216 217 218 219 220 221
d0adbc683b1920556f2f658448daf2792434b209a9960622144d3cf741857c04c0854fce75bf2591fe5e861afaa3a58b2593abb0ea1927e3b4e1168cb2175c86,arr,Weakness,No visible weakness. ,105 106 107
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"For example, the google search agent and the Alexa shopping agent described in the introduction make such a case. ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Weakness,"
2. ",109
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Weakness,"This could include for training: # of training datapoints, batch size, steps, and for evaluation: specifying whether reported numbers are on dev or test sets.
",200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,3. ,458
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Weakness,"Furthermore, the two difficult problems (implicit intent detection and transition utterance generation) deserve a more closer study. ",116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,I’m confused. ,286 287
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness, ,
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Weakness,"
2. ",180
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Weakness,"
The authors can also do a better job at explaining why starting with a Gaussian negatives and optimizing equation (3) and (4) can lead to negatives sampled from non-uniform semantic space. ",275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Weakness,I have read the author response and the new version of the paper. ,119 120 121 122 123 124 125 126 127 128 129 130 131
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"To be fair, I did not try for very long (< 15 minutes), and I also did not have access to a GPU so I tried to run it on a CPU. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"Eg Scandinavian nationalities are very unlikely to be considered disadvantaged.)
",805 806 807 808 809 810 811 812 813 814
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Weakness,"For the human evaluation, the authors used only 25 samples but the number of samples are too small. ",375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"
    - methods/models. ",217 218
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,"Almost no information about the reliability of the translations and the annotations is given (except for the result of the translation checking in line 285), which seems unsatisfying to me. ",456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Weakness,The authors have addressed some of the weaknesses highlighted in the previous review. ,300 301 302 303 304 305 306 307 308 309 310 311 312
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,"
4. ",254
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,-Did authors tried using BlenderBot vs 2.0 with incorporated knowledge? ,185 186 187 188 189 190 191 192 193 194
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,There is a serious issue of missing related work. ,458 459 460 461 462 463 464 465 466
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Weakness,"Some examples include Linformer, Reformer, Synthesizer, Performer, etc. ",257 258 259 260 261 262 263 264
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Weakness," Also, DISP as a key baseline for the FGWS work.
",345 346 347 348 349 350 351 352 353 354
4825eb030d8afb393c246a33e9d8a1f793b90ea88cb57ce09e675891f7d509d82c4b6cc50d7f8dc386a279b6854b3692285cbe651def3090bb02344787ef1b3f,arr,Weakness,The authors only compare the proposed model with UAT. ,99 100 101 102 103 104 105 106 107
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,This idea has been explored in Intermediate-Task Transfer Learning. ,233 234 235 236 237 238 239 240 241
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Weakness,"-It take some while for me to understand the auxiliary tasks, so I suggest adding a SDP graph examples and have the description of auxiliary tasks based on the example.
",113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,"However, it is a delicate topic, so the approach adopted by the paper is reasonable. ",313 314 315 316 317 318 319 320 321 322 323 324 325 326 327
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Weakness,1. ,50
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Weakness,"
3) MSLR requires knowing the unimodal optimal learning rates in advance - which means we have to spend resources to tune unimodal models and discard them in the end. ",278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,The authors should help quantify the effort required and comment on the feasibility of scaling their high-quality annotation to other domains. ,282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302
80f0f27bae63d383650b5083d56d54d49670478d69ab16c333d994ebabdcc2558eff25814b0b8333c8a9865b96d20dc0e171383473a1e65de16556abe5eef90c,arr,Weakness,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). ,285 286 287 288 289 290 291 292 293 294 295 296 297
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Weakness,1. ,158
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"[1] Lifu Huang, Heng Ji, Kyunghyun Cho, Ido Dagan, Sebastian Riedel, and Clare Voss. ",332 333 334 335 336 337 338 339 340 341 342 343 344 345
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Weakness,The  proposed weakly supervised pre-training method and unsupervised pre-training method seem not very related to the main contribution of the paper. ,149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Weakness,"Did the authors do a thorough analysis to confirm that hypothesis?
",381 382 383 384 385 386 387 388 389 390 391
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Weakness,The novelty of the approach is limited. ,121 122 123 124 125 126 127
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,"-I suggest the authors make the weights publically available (can be anonymous during double-blind reviewing) so the results can be easily verified by the community.
",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,It is simply not well optimized yet. ,400 401 402 403 404 405 406
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,The experiments are not convincing. ,98 99 100 101 102
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Weakness,But the text in 4.4 states that the adapter-based method in Table 3 is actually the Compacter. ,303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,"But, to be a bit pedantic, it doesn’t have to be syntactic information; if $D$ is highly correlated with something non-syntactic, then that property could be expressed redundantly, and the MI would still be high. ",467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,Prompt similarities are evaluated based on correlation with zero-shot performance for direct prompt transfer. ,1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Weakness,"and 3.2., ",109 110
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,"The experiments on the full dataset instead of that in the low-resource regime are also encouraged.
",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Weakness,-Some of the design choices are not explained well (e.g. why IDF-weighting) ,146 147 148 149 150 151 152 153 154 155 156 157
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Weakness,The length of meaningful rationales may largely depend on the density of the information related to the task. ,202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
73837843c65a425ff419296a34871a445f1e2fee4cb8940431054c5ec0c1beb405f43cdd40fd27e52cf27aab7574eb4f160655995346c0889edc41328e588bdb,arr,Weakness,"In the abstract it is briefly mentioned that the proposed task helps with subsequent tasks, but the authors did not provide further discussions and references. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Weakness,I would argue that using similarity score alone could not identify false negatives. ,228 229 230 231 232 233 234 235 236 237 238 239 240
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,"Applying all neutral words to a full dataset can make the whole pipeline of Figure 6 not feasible, or maybe I missed anything? ",368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Weakness," In particular, I’d characterise the differences with respect to FGWS – at a high level they have the similar idea of detecting low frequency samples (Fig 1 caption of present paper), but the approach is quite different. ",308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Weakness,"For instance, a valuable analysis would be to compare the performance per label with the annotation challenges. ",409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness, This analysis may point to interesting observations on which language combination is more effective. ,280 281 282 283 284 285 286 287 288 289 290 291 292 293
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"
     * In *Models with Access to Agent Knowledge*, how do you construct the context? ",537 538 539 540 541 542 543 544 545 546 547 548 549 550
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,1.Adding the random selection is not a new idea. ,142 143 144 145 146 147 148 149 150
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Weakness,- The number of questions with multi-span answers in the proposed dataset is small. ,236 237 238 239 240 241 242 243 244 245 246 247 248 249
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,1. ,236
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Weakness,"In human evaluation, the inter-annotator agreement on the sentiment task and the AGNews 482 task is only 0.39 and 0.30 in Fleiss’ κ, which is low to guarantee a high quality of the evaluation data. ",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Weakness,- It seems that how to choose the set of auxiliary tasks for French and English are based on empirical results. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"It seems that if I understood the instructions in the readme properly, there were a few __init__ files missing. ",300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Weakness,How can section 3.2 be grounded among such theory? ,171 172 173 174 175 176 177 178 179
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,"I also try to find the definition of evaluation metrics in Section 4, but finally, they are in the caption of Table 2. ",405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"
5. ",1113
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,There are many counter examples where perplexity can be very high but the model ranks the vocabulary correctly. ,385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Weakness,"the authors have covered these aspects, but briefly). ",233 234 235 236 237 238 239 240
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,"- If the 5 new tasks are indeed assessing different properties than the 10 superb tasks do, they are not all well justified. ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Weakness,"For example, BERT for learning question type distribution, BART for summary generation, and question generation. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Weakness,"Limited novelty: utilizing self-supervised speech representations for LRS has been conducted in [1], in which PASE is used instead of wav2vec 2. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Weakness,"While I have a generally favorable opinion of this paper, I have two issues with it that if addressed would improve the paper in my opinion.
",130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Weakness,"In addition, source-target vocabulary overlapping may be another important factor to look at. ",293 294 295 296 297 298 299 300 301 302 303 304 305
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,"
2. ",248
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Weakness,"
2) If LSTM/Transformer models are trained with a causal (auto-regressive) LM loss, then they should be decoders, not encoders. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Weakness,"If the authors feel like the related work should be discussed earlier, I suggest moving Section 6 to after the introduction.
",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Weakness,"The authors manually validate a small subset of the dataset but, for a high quality dataset, it would be better to validate all of it. ",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Weakness,"arXiv preprint arXiv:2110.08151, 2021. ",207 208 209 210
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Weakness,The resulting expressions may be called discriminative descriptions/unambiguous references or something along these lines. ,241 242 243 244 245 246 247 248 249 250 251 252 253 254
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"[1] Lin et al., Learning Language-Specific Sub-network for Multilingual Machine Translation, ACL 2021. ",350 351 352 353 354 355 356 357 358 359 360 361 362
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,-Motivation of the methods is less persuasive. ,157 158 159 160 161 162 163
30aa157cc690ecbf3ee3034c035b2533e3c1a2e99c7ce2c797371c7c758de51b77204c36880a0163059bed31ff962c7a97d94be7c6d287e09e1c2e2a93ac4e1e,arr,Weakness,"
• Not sure why the proposed model work for the experimental datasets, since those datasets do not have such textual supervision as co-citing sentences. ",125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"In my opinion, the paper should steer away from making arguments that these examples are deeply linguistic, beyond, involving nouns, counting, verbs, and coreference. ",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Weakness,"Also, I've seen the authors have addressed the questions of other reviewers. ",236 237 238 239 240 241 242 243 244 245 246 247
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"- Some descriptions of the experiment setting are somewhat vague, and therefore it is not super clear whether the comparisons are fair. ",503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Weakness,-The paper is hard to understand. ,114 115 116 117 118 119
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"Also, the related work is presented as more of a description of previous studies rather than a critical “mapping”. ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"Were humans involved at any level and were automatic annotations, such as coreference resolution, subjected to human sanity checks? ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Weakness,Dataset size is a little limited for the use of the more recent and heavy multimodal models which might be needed to reason over a vast amount of open ended data and visual images 4. ,369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,"
4. ",449
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Weakness,"Equivalence testing (e.g., TOST) could be used instead to strengthen the statistical claims. ",269 270 271 272 273 274 275 276 277 278 279 280 281
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"Although, the experimental results unanimously show that for problems related to this domain ConfliBERT is a better choice but it is not clear which version of ConfliBERT is better, SCR or Cont. ",437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Weakness,"For example, is there any overlap of claims, background documents, or (more generally) topics between the claims extracted from the various different sources? ",370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Weakness,"And probably as a result, it also becomes unclear why two sets of encoder/decoder are needed. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Weakness,Have examples been provided to the annotators? ,294 295 296 297 298 299 300
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,-I would change the wording to be more careful about describing the MBR results. ,365 366 367 368 369 370 371 372 373 374 375 376 377 378
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,ON_ as an improvement over the Cosine similarities which are also present in Vu et al) it seems this section should be expanded considering how much overlap there is. ,1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Weakness,The proposed ICoL is mainly an integration of some existing methods. ,154 155 156 157 158 159 160 161 162 163 164
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Weakness,"
  2. ",239
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Weakness,"However, I think the innovation of this paper is general. ",155 156 157 158 159 160 161 162 163 164
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,The dataset has conflicts in annotated data. ,200 201 202 203 204 205 206
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Weakness,"
They did not compare their search strategy to others, such as genetic algorithm (Alzantot et al., 2018). ",383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Weakness,The authors have addressed all my comments on the previous version of their paper! ,133 134 135 136 137 138 139 140 141 142 143 144 145 146
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Weakness,[1] Improved inference for unlexicalized parsing [2] Structured Prediction Cascades ,225 226 227 228 229 230 231 232 233 234
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Weakness,"If (b) is used, it seems like this would have trouble distinguishing between inside and outside. ",342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,1. ,323
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Weakness,"Zero-Shot Hybrid Retrieval Models"") or combining the scores with a linear combination of the BM25 and DPR score (see Karpuhkin et al. ""Dense passage retrieval for open-domain question answering"") ",250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,"For example, I did not understand as to why finetuning T5 helps in mitigating distribution shifts? ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Weakness,"The proposed method seems to be only useful for ""N-1"" and ""1-N"" relation types. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,1. ,200
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Weakness,   * The model seems to make very close use of relations (e.g. RelatedTo) that have been identified by previous work as being somewhat arbitrary and noisy. ,130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Weakness,ICLR 2020 ,213 214
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Weakness,"but others are more common (specifically "":). ",111 112 113 114 115 116 117
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Weakness,   * I assume that character-level MT would be more beneficial for languages with logographic writing systems (e.g. Chinese) than the ones that use alphabets. ,246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,The paper claims that it exploits unlabelled target language data. ,179 180 181 182 183 184 185 186 187 188
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Weakness,How many tests were run? ,407 408 409 410 411
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Weakness,"- In the related work, you cite several approaches - It would be fair to compare the SummN results with the implementation of the reported approaches. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Weakness,Or in another language? ,289 290 291 292
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Weakness,One problem I can notice is the scalability issue of the proposed method. ,191 192 193 194 195 196 197 198 199 200 201 202 203
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Weakness,- Creating/Selecting a dialogue containing all slots is not easy when the dialogue is especially in multi-domains. ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,"But compared to that, the gain obtained from the proposed method is marginal (Table 5). ",445 446 447 448 449 450 451 452 453 454 455 456 457 458 459
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Weakness,The only new effort is to take similar ideas and apply it on video-text models. ,190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,3. ,274
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Weakness,"In addition, details of annotations are missing in this paper. ",112 113 114 115 116 117 118 119 120 121
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,No details on the. ,262 263 264 265
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Weakness,rephrasing the paragraph along with its pseudo-code can add clarity. ,111 112 113 114 115 116 117 118 119 120
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Weakness,-The motivation of the three experimental settings is relatively weak. ,140 141 142 143 144 145 146 147 148 149
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Weakness,3. ,195
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Weakness,- Missing baselines for lexically controlled paraphrasing: The paper does not compare with any lexically constrained decoding methods (see references below). ,238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Weakness,"The transformation is all based on intuitions and without human validation,  it's hard to determine whether it will be valid and therefore we do not know whether the satisfy value is indeed meaningful. ",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,"3) Readers unfamiliar with the softmax bottleneck problem will struggle to understand the parallelogram example, or understanding theorem 2. ",441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459
883cec982be6ead1ee077df92d0d08618b52f2c4d4c39b923d78fb412dcf88496ff4894080de73f3c786310afcab26fa9e04cafe7020c5561b3835c375a0fd0c,arr,Weakness,"- It would be nice to show more experimental results of the proposed method from more aspects such as an ablation study or parameter analysis.
",128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Weakness,"
This isn’t entirely clear. ",258 259 260 261
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,"Additionally, this could serve as guidance to collect extra annotations to mitigate those mistakes. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Weakness,The fact that the contextualised embeddings of verbs in the same syntactic configuration is highly similar isn’t that surprising in itself (as is noted by the authors as well). ,653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,"For example, how are those hyperparameters ($t$, $p$, $\lambda_1$, etc.) ",375 376 377 378 379 380 381 382 383 384
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Weakness,1. ,233
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Weakness,"	More examples are preferred to understand the motivations, the novel part of the proposed method and the baselines (see “detailed questions and comments”); 2. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Weakness,"
They claim that their attack method does not need to know the training dataset used by the victim models. ",333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Weakness,"-In the future version, if space allows,    * please add examples of each category (table 2) so the reader can better understand the difficulty of each category. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Weakness,"However, they are evaluated only on one dataset. ",182 183 184 185 186 187 188 189
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,-Line 296: L and E should be defined in the immediate vicinity. ,391 392 393 394 395 396 397 398 399 400 401 402
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,1. ,296
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Weakness,It means that we only apply this method in the downstream tasks. ,139 140 141 142 143 144 145 146 147 148 149 150
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,"Lines 183-185 Moreover, we analyze the model confidence change in these unchanged samples, where the probability on the predicted label is used as the confidence score.
",533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Weakness,It is not clear whether baselines participating in the comparison are built on the same datasets that are used to build XLM-E. ,72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Weakness,"
3. ",115
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Weakness,"-For the cross-linguistic analyses, multilingual BERT is used. ",129 130 131 132 133 134 135 136
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Weakness," It would be made stronger if the authors could test their metric in one or two further domains, and extend the pool of evaluated classifiers to architecture in which the distribution of labels in the development set also plays a role. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Weakness,Do the authors think their hypothesis generalizes to other methods of discretely interpreting prompts? ,503 504 505 506 507 508 509 510 511 512 513 514 515 516
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Weakness,1. ,158
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Weakness, ,
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Weakness,It would be useful to add a discussion as to whether the reported improvement was within expectation given the effort for annotating a specialized dataset. ,384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"(being a previous reviewer R BWRg, I will respond to previously identified weakness) ",168 169 170 171 172 173 174 175 176 177 178 179 180
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,All these simple substitutes are probably super-efficient and quicker to compute than OT. ,529 530 531 532 533 534 535 536 537 538 539 540 541
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Weakness,[1]Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks ,224 225 226 227 228 229 230 231 232 233
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Weakness,"
-The authors overgeneralize when making claims about the problem they solve in many places. ",313 314 315 316 317 318 319 320 321 322 323 324 325 326
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Weakness,For example:     - GATE: Graph Attention Transformer Encoder for Cross-lingual Relation and Event Extraction     - Cross-lingual Structure Transfer for Relation and Event Extraction ,207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"Overall, I found the paper slightly difficult to follow. ",386 387 388 389 390 391 392 393 394
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Weakness,"How many masks have been generated?
",179 180 181 182 183 184
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,"For example, parsers utilizing the SQL grammar to generate the output SQL can use these templates to add new rules that can be used while generating the output. ",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"This may be asking a lot, but the paper would be significantly improved if the last page were almost entirely made of examples from the appendix. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Weakness,"For example, the model weights $\mathbf{w}$ are important optimization variables, but they are totally omitted in the derivation. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,-Bag-of-Vectors Autoencoders for Unsupervised Conditional Text Generation (Mai and Henderson 2021) ,320 321 322 323 324 325 326 327 328 329 330
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Weakness,The main findings are limited to applying to QE a set of existing interpretability oriented methods already applied generally to NLP tasks. ,405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Weakness,"
2. ",103
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness, ,
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,My main question is how factual knowledge is provided to each model? ,525 526 527 528 529 530 531 532 533 534 535 536
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,"The latter option would have to be written   from the perspective that faithfulness is an apriori goal.
",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,"
3. ",207
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"
7. ",1431
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"
    - it doesn't quite make sense to me to train on future data and test on the past. ",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Weakness,"Currently, most baselines are in the same technical line of kNN-MT which is too narrow to reflect the strength of the proposed algorithms/networks. ",119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Weakness, ,
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,They might mean removing assignments with a probability X but I cannot tell for sure if my understanding is correct from the statement. ,227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249
308a3dae511df165c5bafdb5ac87fa3882179218cd92d71a17954ba8f255214d06c106ec2341c49613479511484a01359e8b2cacb280fe807ffa5b2449a80c72,arr,Weakness,"Otherwise, this paper would not be as useful and would be hard to compare against. ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Weakness,"In other cases (e.g. in the specific case (EN-RO - Table 5)), the improvement is +0.04 (from 23.15 to 23.19), which I would say it does not imply anything that is particularly meaningful. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,Lack of significance test:__      I'm glad to see the paper reports the standard deviation of accuracy among 15 runs. ,207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Weakness,"From the results in Table 2, it shows that in ALBERT, with null prompt, the performance largely decreases (from 8 #Wins to 1), which raises the question of the necessity and robustness of null prompting. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Weakness,"If so, the performance would be very unstable due to the variance of BI, which makes this type of method not applicable to real-world problems. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Weakness, ,
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,"-Line 273: having X in the equation without defining it is a bit weird; should there be an expectation over X?
",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
The authors split the data 9:1 between training and testing, but for example, with 90 minutes of data, there are only 10 minutes of test data. ",310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,"	More baselines should be contained such XLM, XLMR, mBART. ",175 176 177 178 179 180 181 182 183
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Weakness,"Further, it is not clear how including those other operations will affect the quality and performance of the system. ",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Weakness,"I would like to see the justification of this change and experimental results that support it.
",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Weakness,"Although the authors mentioned three challenges in the introduction, it seems that they are not well-reflected in the experiments. ",273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,FADA should be defined formally in Section 3.1. ,371 372 373 374 375 376 377 378
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Weakness,"    * The empirical evaluation on the WMT dataset is also only performed on European languages (English, German, and Czech). ",347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Weakness,"For example, a BiLSTM-CRF could yield a 91.03 F1-score and a BERT-base could achieve 92.8. ",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,Serial or Parallel? ,389 390 391
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Weakness,I wish the distinction between these two concepts would be more clear throughout the paper. ,270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,"Many of these methods compare favorably against PPLM, so they could be stronger baselines against which your work could be compared to.
",331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,The authors argue that one major motivation of this paper is to learn schema in a data-driven way other than laborious manual schema engineering. ,249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness,2) A central argument of the paper is that encoding passages simultaneously is helpful. ,182 183 184 185 186 187 188 189 190 191 192 193 194 195
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Weakness,"-Supervised prompting methods were excluded from the evaluation, but they might provide interesting points of comparison ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
9f16d7fbb89be40b6fa6ff149aa34cfcad08f2a811b1bef57d6136992bef789a65da497e685cbeb4e29335b120aaf58d3d7240a775eb25c9fe8bec3fa6bf4ffc,arr,Weakness,The experimental results are not convincing enough. ,131 132 133 134 135 136 137
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Weakness,"So, while this is indeed a solution, the manual schema expansion method is not exciting. ",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,It's very hard to imagine the foils from the descriptions alone. ,288 289 290 291 292 293 294 295 296 297 298
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"Then, at lines 195-99, the extractive approach is defined as to infer *non-overlapping* time ranges. ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"However, their method cannot take this into account, and thus the method is not very flexible.
",266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Weakness,"However, they follow the work of Han et al. (2020) and train the reference models on the same dataset used by the victim model (at least for the dependency parsing task). ",352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Weakness,"In other words, it is still unclear where the improvements of HiStruct+ (Roberta-base) vs. BERTSUMEXT are coming from? ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Weakness,There are a lot potential baselines are missing in the experiments. ,285 286 287 288 289 290 291 292 293 294 295
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,To Reviewer2.3**: Sorry for the confusion. ,279 280 281 282 283 284
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Weakness,For leave-one-out-task experiments it's unclear why the numbers are much lower than Table 3. ,260 261 262 263 264 265 266 267 268 269 270 271 272 273
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Weakness," * Hyperparameters weren't mentioned to replicate experiments for fine-tuning BART.
",310 311 312 313 314 315 316 317 318 319
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Weakness,"For example, if I understood correctly and the models are indeed trained on the adversarial data, what are the resulting training data size for the baseline and different augmentation methods? ",460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"if not, this could be an idea to improve the quality of the dataset. ",447 448 449 450 451 452 453 454 455 456 457 458 459 460
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Weakness,"Morpheme-based tasks are more relevant to multilingual probing literature (e.g., LINSPECTOR: Multilingual Probing Tasks for Word Representations) which are not mentioned throughout the paper. ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,"Akula, A. R., Gella, S., Al-Onaizan, Y., Zhu, S. C., & Reddy, S. (2020). ",231 232 233 234 235 236 237 238 239 240 241 242 243 244
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"Although the additional annotations about reading skills could be counted as one highlight, this categorization is still coarse-grained to me since it seems nothing more than question types (I assume the categorization might be easily inferred from the question surface form, e.g., ""How did ... feel?"" ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,"Are “other relations” randomly selected?
",406 407 408 409 410
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,The flexibility of their approach ,222 223 224 225 226
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,The randomness of the layer selection could cause the unstable of performance. ,151 152 153 154 155 156 157 158 159 160 161 162
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,The improvements under some settings are not significant. ,189 190 191 192 193 194 195 196
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Weakness,"Thus, I have raised my overall score. ",428 429 430 431 432 433 434
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Weakness,"The improvement of the proposed method over baselines (row 6-9 in Table 2) may come from using a better backbone model, ProphetNet.
",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,tuned? ,385
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Weakness,"
4. ",168
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Weakness,-It is not clear why CUC-VAE TTS system with L=1 performed worse than baseline system -- an appropriate reason or further analysis may be required to validate this. ,212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness, ,
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,[3] A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation. ,482 483 484 485 486 487 488 489 490 491 492
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"If there is a different pseudo sentence per sentence, then the mapping strategy is missing from the paper.
",323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Weakness,"The results on WebNLG seem only marginally better compared to the second best model by Li et al [1] (BLEU-4 61.88 -> 61.90, Chrf++ 79.1 -> 79.7, CIDEr score is lower). ",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Weakness,"-The semi-factual generation on model generated rationale in the first step: the replacement could be done on missing rationales, This will remove the correct rationales form the example. ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness, ,
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Weakness,"Compositionality typically means something like “the meaning of a full expression can be computed recursively as a function of its parts, where the structure of the recursion is modulated by the syntactic structure.” ",385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,9. ,656
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Weakness,I am still a little concerned about the Figure 2. ,183 184 185 186 187 188 189 190 191 192
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Weakness,Given that the goal is improving uniformity - they should have at least considered using (spread out) regularization for instance embeddings too (ref: eq 6 in https://arxiv.org/pdf/1708.06320.pdf) ,363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"If automatically, what was the reliability of the nodes themselves? ",306 307 308 309 310 311 312 313 314 315
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,It would be interesting to understand the effect of having multiple-speaker training sets. ,243 244 245 246 247 248 249 250 251 252 253 254 255
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"The former is a standard (straightforward) way, and the latter uses the idea in previous studies. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Weakness,"Where is the classic testing that you would contrast this with to check whether this issue shows up?
",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,This section could be more clear with a simpler notation. ,420 421 422 423 424 425 426 427 428 429
ce67bb03e40a4cb585035890d55be2d05240f7adac74d42a128163bf2da6fb5aaa06f54690655904e48dfa3e8e8d52de6d2b888a1a626b9b87ecb5f9584ab004,arr,Weakness,"My suspicion is that BLEU-4 is often zero for some stories, which leads to many ties of 0 vs 0. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Weakness,"The amount of material (in particular, mathematical proofs) presented goes beoynd an 8-page *ACL paper, in my opinion.
",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Weakness,"This hurts the main arguments favoring the E2E approach over the pipeline model.
",130 131 132 133 134 135 136 137 138 139 140 141 142
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,  ,
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,"It should be noted that the NLG model is only a part of the dialogue system of the pipeline structure, and time efficiency also needs to be taken into consideration. ",160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Weakness, ,
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,"More concrete questions/concerns are given in ""comments"" below, written as I read the presentation.
",596 597 598 599 600 601 602 603 604 605 606 607 608 609
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Weakness,The negative pairs used for training the dense passage retrieval model appear to be selected at random. ,242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Weakness,"
2. ",239
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Weakness,"Some of the issues were described in the first paragraph of Section 3, which could be viewed as implicitly motivating the use of the auxiliary tasks, but it still seems not very sufficient: the jump from problem description to “Hence the idea of using auxiliary tasks taking into account all the heads'' seems abrupt. ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,"It is very similar to the UHop model in [1], which also adopts an iterative style to extract reasoning path until reaching the END, and updates question representation with historical expanded relations. ",180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Weakness,"suggestion] Is it possible to do a manual analysis of cases where BERT misclassifies a text and ConfliBERT does it correctly, or both models still struggle? ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"There are several further issues with the precision of the language used in the paper that are important to address when discussing a sensitive topic such as social bias measurement.
",465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Weakness,- the writing of the paper can be improved in some sections (Introduction/Related work) to accommodate readers that are not experts on the task ,131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,"So, readers would be happy if the authors specify which parts are their original extensions more clearly. ",427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"
2) Various baselines are missing. ",306 307 308 309 310
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Weakness,"The choice of baselines covers related work, but it doesn't cover possible variations of the model, such as a non-BERT ranking baseline. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"The selling point of this paper is unsupervised pretrained dense retriever(LaPraDoR) can per- form on par with supervised dense retriever, but actually, LaPraDoR is a hybrid retriever rather than a pure dense retriever. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Weakness,"It is possible to make Figure 2,6 smaller to save some space. ",168 169 170 171 172 173 174 175 176 177 178 179
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Weakness,-Each component of the framework is based on existing works. ,146 147 148 149 150 151 152 153 154 155
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,Section 4.4 goes in the right direction by showing that models trained using GCPG suffer less from he copying problem and are able to generate more diverse ngrams than simply using ProphetNet or ParafraGPT. ,368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Weakness,A discussion of these works and comparisons would really strengthen the paper greatly. ,188 189 190 191 192 193 194 195 196 197 198 199 200
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Weakness,"If the oracle performance is 80%, then we know a performance drop is inevitable, and this ""Select"" problem is fully solved by this paper. ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Weakness,"	Innovation is weak, only the modification of existing methods. ",82 83 84 85 86 87 88 89 90
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Weakness,"
+ They should explain why the proposed model can deal with a causal abstraction. ",99 100 101 102 103 104 105 106 107 108 109 110 111 112
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Weakness,"The paper does this very well qualitatively and with careful human analysis, but not the sort of quantitative comparison I was expecting - I think this would be an exciting area for future work.
",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,-The method requires a fixed number of nodes to be activated at each layer for all the tasks. ,227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Weakness,"If the proportion is very small, it is really hard for the proposed method to gain significant improvement.
",96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Weakness,This might be due to embedded annotations' issues that can be simply a result of the domain itself. ,363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Weakness,- The improvement is not a large margin as shown in Table 2. ,195 196 197 198 199 200 201 202 203 204 205 206 207
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Weakness,"-I would have appreciated a discussion of the statistical properties of the results - with the given number of tests, what is the probability that differences are generated by random noise and does a regression on the different design decisions give us a better idea of the importance of the factors?
",228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Weakness,"If the drop in Table 1 is caused by noise, then indeed CS-k-1 can be a much easier and simpler algorithm in terms of implementation.
",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Weakness,Table 2 shows that the learned confidence score can result in better BLEU score. ,133 134 135 136 137 138 139 140 141 142 143 144 145 146
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Weakness,"In a summary, the authors have done a lot of exploration and experimentation, as well as using experiments to prove many of their conjectures, yet many of these conjectures can be directly summarized by previous work. ",451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,"The reproducibility of this work would not be easy, since the code is not open sources and some details of the experimental settings are not very clear:  - line 184-186: the 2 convolutions are said to have stride 4, and that in total they shrink the input by a factor of 4. ",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"-Line 237: How critical was the finetuning process over the SQuad and CommonsenseQA models?
",325 326 327 328 329 330 331 332 333 334 335 336 337 338
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Weakness,"However, the speedup used as the x axis of the graphs is essentially the average percentage of layers the model goes through---that is, for a 50-layer BERT, if examples stop on average at layer 25, this will have a speedup ratio of 0.5. ",611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Weakness,"However, an interesting experiment would be to show the impact that such embeddings can have by comparing with a simple baseline that does not take advantage of those.
",174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Weakness," It is unclear whether the results in Table 5, for example, are statistically significant; if not, it may be good to temper the claims made based on these findings. ",422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Weakness,"
4. ",363
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Weakness,"Please also look at the datasets and baseline methods this paper used for evaluation.
",358 359 360 361 362 363 364 365 366 367 368 369 370 371
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"I think this type of study is valuable, but what could elevate the paper is to propose new methods to mitigate them. ",104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Weakness,- It is unclear why SEC-BERT is better than FIN-BERT. ,130 131 132 133 134 135 136 137 138 139
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Weakness,"For instance, what is the impact of using mergeSGD vs TOD simulation on the overall quality ?
",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,L1 norm between vectors of 2 matrices needs a high memory cost than the matrix multiplication. ,301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Weakness,Is this related to the size of the fine-tuning datasets? ,140 141 142 143 144 145 146 147 148 149
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Weakness,"I particularly focus on the evaluation of the classifier because later sections of the paper (i.e. the RL-based model) use the classifier as a sub-routine, and so demonstrating its efficacy is particularly important. ",404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,"There are two tables, containing around 5 and 9 columns respectively. ",326 327 328 329 330 331 332 333 334 335 336
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"Without an efficient, factored attention for prompting implementation a la [He et al. (2022)](https://arxiv.org/abs/2110.04366) prompt tuning can cause slow downs from the increased sequence length. ",818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842
53d0d9ae0394c4f59496513484fb9e9d625c0064283125135b8f81ec3a08afa63dc10427b9d929924d7cd1d29e9ad560df79372aa72a957bbe91a7acca6ea44c,arr,Weakness,It would be great if the code is indeed released if the paper is accepted. ,199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,the proposed approaches are compared against a baseline based on the “greeting method” by Vilares and Gόmez-Rόdriguez (2018). ,665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Weakness,"As it is, to my understanding, there is no way to be sure that the character embeddings do not lead to detecting a lot of changes independent from phonology, and this is a major issue. ",203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,"In Table 2, the proposed approaches only outperform the baselines in 1 setup (out of 3). ",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,"
 - line 236-251: the same letters (u and v) are used for different things and v is sometimes treated as a variable, sometimes as a function. ",394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Weakness,"Unfortunately, human evaluation is absent (in table 4) to demonstrate its effectiveness.
",166 167 168 169 170 171 172 173 174 175 176 177
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Weakness,"
  - Checklist (Ribeiro et. ",205 206 207 208
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Weakness, ,
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Weakness,"-It’s not clear how h_in(i, j) and h_out(i, j) are computed. ",273 274 275 276 277 278 279 280 281 282 283
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,"This does not actually describe the ""intent"" behind the utterance, which might traditionally be something like ""confirm_arrival"". "" ",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness, The paper should address the merits of BERT that are part of Cont but not of SCR. ,524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
308a3dae511df165c5bafdb5ac87fa3882179218cd92d71a17954ba8f255214d06c106ec2341c49613479511484a01359e8b2cacb280fe807ffa5b2449a80c72,arr,Weakness,The authors have no mention of releasing the code for preprocessing of the datasets and evaluation. ,241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Weakness,"For example, the annotators' agreements in Figure 2 look decent, but they are compared against reviewers' final golden answers. ",148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,What makes it difficult is that they all have different axes and threshold over different values. ,220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Weakness,"
I understand that this task is complicated and believe that adding some examples will help. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Weakness,"Furthermore, I also have some moderate concerns regarding the presentation. ",274 275 276 277 278 279 280 281 282 283
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Weakness,I am concerned about the intuition/motivation of the Similarity evaluator teacher model. ,219 220 221 222 223 224 225 226 227 228 229 230
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Weakness,"That visual information, from captions or images, together with contrastive learning, is slightly beneficial for downstream tasks underlying visual commonsense? ",238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Weakness,"The paper really struggles to find a case where the proposed approach is better than the regular MoS. The improvement on natural language seems to be small, and the paper needs to work on a synthetic language to show the gap between MoS and the proposed approach. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,"In contrast, the base model is trained on the adversarial set only. ",208 209 210 211 212 213 214 215 216 217 218 219
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"[2] Hu et al. (ArXiv 2021). "" ",353 354 355 356 357 358 359
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Weakness,1. ,159
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Weakness,Is it the same system across different methods or not? ,514 515 516 517 518 519 520 521 522 523
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Weakness,1. ,102
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Weakness,"
There are several findings presented on several, almost non-related, tasks and the related work section, while interesting seems like overkill. ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Weakness,"[2] Ao Liu, Shuai Yuan, Chenbin Zhang, Congjian Luo,Yaqing Liao, Kun Bai, and Zenglin Xu. ",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,"As far as I understand, TED intends to measure how close the syntactic trees of both reference and outputs are, which is indicative of how much the model actually followed the syntactic condition. ",488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Weakness,Some of the ablation studies are unclear or problematic. ,186 187 188 189 190 191 192 193 194
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,The proposed approach achieves higher performance than the baseline. ,196 197 198 199 200 201 202 203 204
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,2] systematically compare different span representations in different tasks. ,269 270 271 272 273 274 275 276 277
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Weakness,2.The performance is not convincing. ,184 185 186 187 188
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Weakness,"- While results are competitive on arXiv, some of the baselines are composed of less parameters and obtain better performance.
",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,"-Relatively minor: If there is a much larger number of tasks, the authors’ approach may not be as efficient as shown in table 2 (i.e., two thirds of memory), given that the authors’ approach is still O(k) where k is the number of task. ",362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"These models are much more rarely used than word embeddings, and in much more specialized settings.
",835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Weakness," In Lee et al (2018), their core technique is based on a Mahalanobis distance-based score, which doesn't sound like the brief description of MLE here; neither of their baselines sound like MLE either. ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
0ac9820142b39e37945bfc25038d562d36d08e5407ab516a8f8eb18cc7a696601df7e15caa23159bf9ef420a1e65efadf3778d71d4aa95df26226ff49de26bb3,arr,Weakness,"First, the setting is only on extremely low-resource regime, which is not the only case we want to use data augmentation in real-world applications. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Weakness,"In fact, most of these components depend on each other. ",181 182 183 184 185 186 187 188 189 190
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Weakness,This might be a baseline worth comparing to to show that it improves the Pareto frontier of the speed/accuracy tradeoff. ,246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
30aa157cc690ecbf3ee3034c035b2533e3c1a2e99c7ce2c797371c7c758de51b77204c36880a0163059bed31ff962c7a97d94be7c6d287e09e1c2e2a93ac4e1e,arr,Weakness,"
• There are no comparison and contrast between proposed approaches and baselines. ",149 150 151 152 153 154 155 156 157 158 159 160
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Weakness,"There are quite a few punctuation errors and grammatical errors (l. 41, 137, 457), as well as orthographic inconsistencies (e.g., versions of “full-text” l. 95, 343, Table 3, 459, etc.). ",198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,Why was ReClor and only ReClor chosen? ,171 172 173 174 175 176 177
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Weakness,The authors can just simply use the tasks in Caglayan et al. And also the color-based probing is almost the same as the Color Deprivation in Caglayan et al. ,161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Weakness,-Some annotation protocals and their encessities are not explained. ,235 236 237 238 239 240 241 242 243
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Weakness,"And the strength of CNTF is in the latter 3 knowledge existence, correctness and relevance; above the most competitive baseline. ",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Weakness,Reference:  [1] LiRA: Learning Visual Speech Representations from Audio through Self-supervision https://arxiv.org/abs/2106.09171 [2] LEARNING AUDIO-VISUAL SPEECH REPRESENTATION BY MASKED MULTIMODAL CLUSTER PREDICTION https://openreview.net/pdf?id=Z1Qlm11uOM ,168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness," To make fair comparisons with the baselines, I think baseline methods BERT-CRF in section 3.2 and the BERT-CRF+MLM in 3.4 should also see $e_{i}$ labels. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,"
2. ",160
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Weakness,Their approach should be compared with the baseline setup where N many-to-one models are trained with only their corresponding target languages. ,100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,You use a hard to follow example to illustrate the logic trap you define as  “the change in attribution scores is brought about by the model reasoning process rather than the attribution method unreliability”. ,614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,1. ,329
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"which could have been at least added to the appendix in case there is no space left.
",427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,Zero-shot Event Extraction via Transfer Learning: Challenges and Insights. ,382 383 384 385 386 387 388 389 390
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Weakness,"
2. ",225
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Weakness,"
3. ",149
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,"The “if” clause looks unfinished and I cannot guess what was, probably unintentionally, dropped.
",316 317 318 319 320 321 322 323 324 325 326 327 328 329
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Weakness,I wonder whether some multi-span answer structures are really needed or not? ,77 78 79 80 81 82 83 84 85 86 87 88
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"It seems that the authors are arguing that syntactic factors are more significant in SRL performance, and the experimental results are also consistent with this. ",429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,"GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing, ICLR 2021. ",336 337 338 339 340 341 342 343 344
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Weakness,"For the empirical validation of the method, the evaluation does not reflect a general scenario in machine translation where both perfect and fully erroneous translations exist. ",427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Weakness, ,
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Weakness,"
My opinion is that this short paper could be organized better in a long paper by including the information about annotations and contrast set construction from the appendix, together with more analysis and ablations. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,Using this rank classification approach should be stated plainly as direct prompt reuse is unlikely to work for actual T5 generation. ,1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025
057a3f73710f304801787e253e5ffc7e5d2eb9cf4570a5e3c6dc8edf75ebaadb324aff13a67e27a6057b12080f89cd80cc8d0f000bd23657daf14ff9c30856db,arr,Weakness,-seems to be an extension of earlier published work https://s3.eu-central-1.amazonaws.com/ucu.edu.ua/wp-content/uploads/sites/8/2021/04/Improving-Sequence-Tagging-Approach-for-Grammatical-Error-Correction-Task-.pdf  The authors should properly highlight the contribution made on top of it. ,127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,References: ,467
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,What is the value of k in Table 2? ,556 557 558 559 560 561 562 563 564
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Weakness,"The paper lacks significance tests in their comparisons between models, which may draw some of the conclusions in the paper into question. ",120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,"2) Large scale models are trained using sharding systems of thousands of accelerators, it is a challenging technical question to expand them in a way described in this paper. ( ",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Weakness,"Alternatively, IR metrics such as MAP or Prec@k could be used. ",328 329 330 331 332 333 334 335 336 337 338
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"The main weakness of this paper is that it is not sufficiently grounded in the sociolinguistic side of bias measurement, and therefore makes some significant claims and design decisions that are not entirely appropriate.
",219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Weakness,The LRLMs may have better results when also trained with this task. ,141 142 143 144 145 146 147 148 149 150 151 152
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Weakness, ,
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Weakness,"2.The framework should be tested on more diverse domains.
",194 195 196 197 198 199 200 201 202
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Weakness,-Is the baseline transformer model only trained for 100k steps? ,258 259 260 261 262 263 264 265 266 267
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,I would suggest being more specific and explicit about its contributions and how it relates to previous work. ,360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"In a way, it’s unfair to compare hybrid method to dense/sparse method as shown in table 1, because it’s known that the dense retriever and sparse retriever are complementary. ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Weakness,So whether choosing QA as the pre-training is helping QA task or not is not very clear. ,145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,"I think an ablation study may be needed.
",360 361 362 363 364 365 366 367
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Weakness,"-The introduction of relation embeddings for relation extraction is not new, for example look at all Knowledge graph completion approaches that explicitly model relation embeddings or works on distantly supervised relation extraction. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Weakness,- The type of annotation that labels each sentence into 1 of 9 category is very specific to this task and does not transfer to broader control text generation problem. ,79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Weakness,It's not intuitive that the `importance` and `quality` are mutually exclusive. ,82 83 84 85 86 87 88 89 90 91 92
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Weakness,"
“I just bought this new mascara.”
",207 208 209 210 211 212
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,1. ,167
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Weakness,"In general, the China-India-Africa part of the dataset is not convincing in terms of impact on the obtained results. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Weakness,"Since stereotype detection is quite challenging, it would be important to discuss how to guarantee the annotation quality and whether annotators can reach an agreement on collected corpus.
",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Weakness,"From the first example in Table 1, it can be seen that what affects the model's prediction should be that T2 contains more other semantics (noise) such as ""Canadian"", ""University of Waterloo grads Kaheer Suleman and Sam Pasupalak"", which may lead to semantic representation drifting and then affects the TM models. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Weakness,Table 6 might be more important but it is not in the main body. ,154 155 156 157 158 159 160 161 162 163 164 165 166 167
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,"
Also needs more clarity on how the thresholds/ stats detailed in section 3 on quantifying the attention drifting have been utilized in section 4.1 for attention monitor. ",275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness, ,
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,"Since all SRC and TRG data comes from Cross-Lingual Event Detection datasets, maybe most samples do have an event trigger and thus most $e_{i}$s equal 1. ",339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Weakness,"
However, the baseline MASS model achieves 24.00 BLEU score on Complex whereas SimpDefiner trained only with definition generation achieves 25.02. ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Weakness,"- Relating to the first point, authors should describe more about the traits of the experts and justify why annotation must be carried out by the experts, outside its commercial values. ",160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness,"The paper argues that the SimCSE model also affected by ""syntactic structures"". ",210 211 212 213 214 215 216 217 218 219 220 221
6db5d3547297644e1a01b2dd191f13fced41cc86ff3a74d59ca05167091c7b4bbe9f67ec055106ee390fe9cdb497d99a303a97c2d53e008f5f89e93f722c3fbb,arr,Weakness,"With the abundance of ontologies, knowledge graphs, and automatic reasoning tools, it is odd that none of them is even mentioned, while the task is reduced to a series of machine learning steps, hindering the transparence of the process. ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Weakness,"For the analysis section, extracting a useful QE signal at deeper layers of the pre-trained model is somewhat expected, but is still interesting to find. ",542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Weakness,"Particularly, the paper completely omits lexically constrained decoding methods, both in related work and as baselines for comparison.
",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Weakness,"
2. ",133
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,A few other points that are not fatal: ,238 239 240 241 242 243 244 245
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Weakness,I didn't understand how the figure supported the claim that authors often interpret reviews in a way that supports their argumentative goals. ,238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,  This point is debatable. ,210 211 212 213
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Weakness,"The improvements are marginal, inparticular the ConLL. ",89 90 91 92 93 94 95
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Weakness,1.While the approach proves to be better than entropy or random routing mechanism its not clear how a simple FFN network with a confidence threshold would perform instead. ,212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,"However, it is not very reasonable to assume that the users are knowledgeable enough to provide both positive and negative feedback. ",359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
However, I have some concerns about the experiment.
",284 285 286 287 288 289 290 291
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Weakness,"For example, with the special blank token (the difference between this model and [1]) vs without it. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Weakness, ,
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Weakness,"Given that this work aims to investigate the partial input bias of QE models, more other representative QE models are required to demonstrate that the partial input bias problem is important and the proposed methods are effective. ",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Weakness,"If you can not perform such experiments for some reason, maybe address this in a “future work” section.
",550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Weakness,Table 5 - very few pairs (7 out of 32) show significant gains over the Transformer baseline - it is actually unclear how much language specific model capacity helps on this TED benchmark at all. ,495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness," So it leads to the question, why do we care the proposed label classes in claim detection? ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"- Although author state that components can be replaced by other models for flexibility, authors did not try any change or alternative in the paper to proof the robustness of the proposed framework.
",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Weakness,"The main claim of this work is faster inference compared to the baselines, at a slight cost of accuracy, However, one can achieve the same goal by using the more accurate (but slower) baselines, but initially retrieving a smaller candidate set (e.g., instead of using 1k candidates, use BM25 to retrieve 500). ",194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Weakness,The paper does not consider the application perspective of ESE approaches and the arguments about evaluation metrics is not strong. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Weakness,"The use of the term bimodal suddenly appears in section 5, and the use of the terms hints that it is the multimodality of the distribution that causes the problem. ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,1. ,272
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Weakness,The explanation at line 190 might benefit from a scheme. ,389 390 391 392 393 394 395 396 397 398
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Weakness,"The authors fail to explore reasons for this, neither do they attempt to experiment with other MRC datasets to see if this is ubiquitous. ",355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Weakness,The distillation process of closing the loop in the dual learning setup should be discussed in more detail. ,418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Weakness,"
3- ""Finally, we further fine tune the pre-trained BERT model over unlabeled Reddit posts (i.e., about 40K posts) using masked language modeling (Devlin et al., 2019)."" - ",140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166
6c7386d38647d226e22fb6a21bec815d465a1023fc59c871b959b53ae367be17a28b2839533147dc589795577b8630217bf4ea6311ca501b3d89453b25741324,arr,Weakness,"Instead of comparing an ELECTRA model with the two loss functions with a BERT with one of them, the authors could have compared their model with two ELECTRA models with one of the loss functions only. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Weakness,"1) For the interpolation method, how the \lambda has been set? ",131 132 133 134 135 136 137 138 139 140 141
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Weakness,"In fact, the metric of Xu et al. (namely the entropy of the generation distributions) comes with no or little extra computational costs, while the MC dropout of 10 or 20 introduces considerably large feedforward overheads. ",238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Weakness,"Though the paper talks briefly about the moral value expressions taking different forms in various domains, the BERT model used here doesn’t seem to take into account the domain information. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness, ,
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Weakness,"Though the approach can surpass the sentence-level model baseline, the naive document-to-document translation model and Zheng et al. (2020), these baselines seem weak, for example, Voita et al. (2019) achieve 81.6, 58.1, 72.2 and 80.0 for deixis, lexical cohesion, ellipsis (infl.) ",397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,"
2. ",429
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,"Examples of the generated paraphrases in the training data could have been presented in addition to some intermediate evaluations to confirm the quality of the intermediate stages.
",412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,"Note that, since the proposed method requires each example to pass through a smaller model first and then on the bigger model, the two sequential steps actually _increase_ the processing time for those examples that are passed to the larger model. ",171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Weakness,"It would be more helpful to the readers if the authors show diverse quantitative analyses.
",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Weakness,The seq2seq+CTC joint decoding is also quite standard for ASR. ,158 159 160 161 162 163 164 165 166 167
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Weakness,"As this is a causal problem (estimating the effect of a counterfactual on an observed outcome), such methods examine performance with respect to modifications that we can reason about (i.e. flipping gender/race etc.). ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Weakness,"In Table 6, the improvement of method is marginal and unstable.
",107 108 109 110 111 112 113 114 115 116 117
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,"So I'd be happy if the authors could also provide these figures in the ""time"" dimension. ",232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Weakness,1)	The data labeling methods transform the prediction score in a ranked way. ,91 92 93 94 95 96 97 98 99 100 101 102 103
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,Post-edited content would have been much closer to what your task is and there's plenty of available data out there which is post-edited. ,233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Weakness,"Sentences like ""The performance gap becomes more significant for the extremely low-resource situation."" ",286 287 288 289 290 291 292 293 294 295 296 297 298
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,I believe that the quality of sampling is not necessarily indicative of the ability of MBR to pick a good translation from a pool of samples. ,469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,Regarding table 5: Is not clear how the ASR is calculated. ,421 422 423 424 425 426 427 428 429 430 431
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"
4. ",606
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Weakness,The aforementioned two aspects could make the contribution of the proposed method more obvious and salient. ,214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Weakness,I am not sure there are many weaknesses as such. ,214 215 216 217 218 219 220 221 222 223
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,The comparison with some of the reported works is already not fair due to the different data condition (the usage of external speech data). ,275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Weakness,It appears as if the rivaling models start to converge after a while. ,189 190 191 192 193 194 195 196 197 198 199 200 201
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"-Race and ethnicity are distinct constructs; the evaluation described in Section 4.2 is comparing race senses with colour senses, not ethnicity. ( ",726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,"In addition, the outputs are evaluated only with manual analysis. ",371 372 373 374 375 376 377 378 379 380
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"[1] He et al. (ICLR 2022) ""Towards a Unified View of Parameter-Efficient Transfer Learning."" ",338 339 340 341 342 343 344 345 346 347 348 349 350 351
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Weakness,"Besides, the conclusion “the bigger C is, the slower the original Distinct increases” is also right for NewDistinct. ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Weakness,A key contribution of this work is the teacher-student framework. ,115 116 117 118 119 120 121 122 123 124
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Weakness,"I'd like to see how the accuracy sees significant shifts by just changing one word, some qualitative analysis (or examples to highlight this) would have supported the argument better. ",561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Weakness,"The pinyin-enhanced pre-trained models and processing the abbreviated pinyin have existed in previous works, and this paper only adapted them on a new pre-trained model. ",260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Weakness,How about many other cases? ,108 109 110 111 112
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"-For the CLM experiments, is it widely believed that perplexity is a faithful metric to evaluate ""performance"" of the encoder in question?
",439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Weakness,Were there any inter- or intra-annotator statistics? ,320 321 322 323 324 325 326
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness, ,
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Weakness,"See a similar argument by Kilgarriff, A. (2006). ",158 159 160 161 162 163 164 165
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Weakness,"As they are explicitly modeled, they need supervision from somewhere. ",226 227 228 229 230 231 232 233 234 235
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,I cannot see what kind of new values ICM will have practically for selecting and/or designing multi-label classifiers. ,331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Weakness,The technique contribution is not very sufficient as most components of the system use existing methods or tools. ,52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Weakness,-Authors have not shared any qualitative assessment of the model or error analysis. ,187 188 189 190 191 192 193 194 195 196 197 198 199
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Weakness,"
3. ",163
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Weakness,4- Comparing random and logistic regression based baselines to something that is empowered by BERT is not fair. ,192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Weakness,It is not clear to me the problem of segmentation and it is not clear what are the human annotators doing after the syllable segmentation. ,193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Weakness,"I cannot fully understand the settings for the synthetic data experiments, thus cannot be sure what kind of evidence these experiments provide. ",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness, ,
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Weakness,"From the perspective of research, since the released dataset is automatically generated without further manual revision or annotation, it is hard to say that this work proposes a new research task. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Weakness,"Moreover, the strategy is too simple to combine the one-hot representation and smoothed representation with a weight parameter lambda.
",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Weakness,"-Same words with different senses in different sentences: "" book an Italian trip for me"" vs ""i want an Italian trip book"" ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,How often do they occur? ,325 326 327 328 329
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Weakness,"For instance, for the description of Thai characteristics, and associated challenges. ",182 183 184 185 186 187 188 189 190 191 192
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Weakness,- The use of the appendix is a little more integral than I think would be ideal. ,306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,The innovations in this paper are more like tricks for improving metrics. ,268 269 270 271 272 273 274 275 276 277 278 279
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,-Line 265: How the future utterances are used during evaluation? ,347 348 349 350 351 352 353 354 355 356
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,Thus I am very interested to see which method (masking or noisy) will have better benefits. ,178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"
E.g. based on the criteria for informative extractions described in the paper “Annotating and predicting non-restrictive noun phrase modifications” (Stanovsky et. ",350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,"The metrics in Tables 4 and 5 need explanation, in order to make the paper self-contained. ",520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Weakness,"The paper should be proof-read by a more fluent English speaker.
",247 248 249 250 251 252 253 254 255 256 257
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Weakness,phonological constraints and the distributions in texts. ,305 306 307 308 309 310 311
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Weakness,This is a pretty strong assumption and can be unreliable for many languages. ,110 111 112 113 114 115 116 117 118 119 120 121 122
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Weakness,"
2) Using pre-trained or training from scratch which is better? ",319 320 321 322 323 324 325 326 327 328
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Weakness,### Major weaknesses ,523 524 525
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,I am very sympathetic to the philosophy of this paper and understand its importance. ,541 542 543 544 545 546 547 548 549 550 551 552 553 554
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Weakness, ,
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Weakness,"For example, which notes in the EHR (only the current admission or all previous admissions) do you use as input and how far away are the outcomes from the last note date? ",280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Weakness,"Think about how you would connect the proposed models to real NLG applications, and show the advantage of your model. ",380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Weakness,"I don't find particularly concerns with this paper, though I have questions about several experimental details (see section below for more information). ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,1. ,50
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"Other similar BERT-based models (e.g. BioBERT, SciBERT) has a wider coverage. ",333 334 335 336 337 338 339 340 341 342 343
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Weakness,The TLM-based pre-trained method required translation pairs. ,173 174 175 176 177 178 179
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness, ,
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Weakness,"An analysis section is highly recommended to validate why some set of auxiliary can work better than others.
",95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Weakness,"- Limited to multi-class topical text categorization, which is while important, is ultimately just one task ",120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
4b71ef5ed6c8af64772bcb6d6274a4af5fce058df82ca4593e4825002ce1701218b9be982e81fee4742e9ec63a3dc1da828bf095a8211e0f20b690ab084366fb,arr,Weakness,"Otherwise, thanks for addressing the concerns noted in the previous review. ",145 146 147 148 149 150 151 152 153 154 155
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"LoRA: Low-rank adaptation of large language models."" ",360 361 362 363 364 365 366
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,I wonder how to determine the codebook space? ,170 171 172 173 174 175 176 177
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Weakness,It is well known that ELECTRA-style is efficient and the TLM-based model is helpful to the cross-lingual representation. ,144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Weakness,"-The paper does not include the human evaluation process, which is an integral part of the summarization system setup. ",271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Weakness,-Retrieving (avg # sentences) * 100 sentences (see section 3.3) instead of just 100 sentences seems to be a bit of a cheat. ,260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Weakness,"For instance, the collected ""pristine"" set of tweets may not be pristine enough and might instead contain misinformation as well as out-of-context images. ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Weakness,UpdateROUGE is a newly proposed automatic evaluation metric for the task based on an intuitive heuristic. ,223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Weakness,It has some value as a niche research benchmark but lacks broader impact on research/application ,109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Weakness,"- The evaluation is done on English data only, which leaves some doubts about how this would work with other languages. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Weakness,"
2. ",338
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,"For example, the authors use the development dataset to evaluate the results. ",103 104 105 106 107 108 109 110 111 112 113 114
6db5d3547297644e1a01b2dd191f13fced41cc86ff3a74d59ca05167091c7b4bbe9f67ec055106ee390fe9cdb497d99a303a97c2d53e008f5f89e93f722c3fbb,arr,Weakness,This feels like a step back with respect to the large literature on semantic parsing and logical-based inference. ,226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Weakness,"
  * If there is a non-negligible number of cases where multiple answer spans are distributed across multiple sentences or passages in the datasets, the proposed framework may be important and worth being studied.
",203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Weakness,"Although arguably the presentation is much easier to follow compared with the previous PDF version, there are still some issues in the writing of the proposed method: It remains unclear how constraints (Sec 4) are reflected in losses (Sec 3.2.1 and Sec 3.2.2). ",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Weakness,Analyses of experiments are standard but inadequate. ,68 69 70 71 72 73 74
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Weakness,"The authors also list that the image captioning model does not entirely represent the image most accurately, which could bring concerns upon the “transparency” measurement of this simulation. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,"Because you indicate that deep models are vulnerable to adversarial samples, which indeed is right and therefore you would expect attribution scores to be faithful to the shift caused by the attack.
",648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Weakness,"However, the authors do not explain the reason behind their counter-intuitive change nor provide an ablation study on this modification. ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,It seems the codebook should be large enough to cover all semantic information in the dataset. ,154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Weakness, ,
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,2. ,261
74644b8c9ecdd5fa9ec1f11bf74bb24a859379bf32c3d6cbacd875a97578143afd0288863fc70dd959eddb1a9aabaf66d9ae02d6c1917377dd7d9427c44bde88,arr,Weakness,- Motivation at the beginning is clear but then gets somewhat lost transitioning to presenting SWCC. ,80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Weakness,2. ,311
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Weakness,"2, Oscar (and distilled Bert) are trained on COCO, which part of Visual Genome. ",268 269 270 271 272 273 274 275 276 277 278 279 280 281
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Weakness,"First, there are only two classification baselines and both of them are rule-based, given a fixed set of simple features. ",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Weakness, ,
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Weakness,"Below is a copy from the previous review: > - Need of choice of the two hyperparameters vectors w and v > - This choice, as evident from the authors experiments, is very important > - Process of obtaining v can be quite involved > - The proposed metric works only or gradient-based models > - Although the formulation is intuitive, the metric values themselves can be hard to interpret. ",132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Weakness," Thus, the paper should compare with this line of work. ",114 115 116 117 118 119 120 121 122 123
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Weakness,"The approach in the paper ends up with N models, thus it's unfair to compare against the Many-to-Many baseline (one model) nor the bilingual baseline (one dataset). ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Weakness," Is it a necessary intermediate task for document summarization and text mining (as stated in L261)?
",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Weakness,The paper should include automatic metrics for the generation task. ,263 264 265 266 267 268 269 270 271 272
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,Why is it 1? ,299 300 301 302
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Weakness,"In NCE or InfoNCE, adding the positive term in the denominator is intuitive since it is optimizing the log probability of selecting the positive example. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Weakness,   also Section names - often they are just numbers (see 5.4 or see 4.2 ) - but these should be Section 5.4  and Section 4.2 ,277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
e0111eb824f3bc8901645731c84d882dd0ac2f5052557e28e1b41ef6c2ace7e360932539c4132c61dd5efaaa60eec8d20a141bed6fed819083cfd74de2ebcdc9,arr,Weakness,This is a resubmission and the authors have dealt with the earlier questions effectively. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Weakness,1. ,193
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Weakness,"Even more lower-resource task classifications are missed, such as MRPC in GLUE. ",86 87 88 89 90 91 92 93 94 95 96 97
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Weakness,"-The authors mentioned “2Prompt-based probing approaches such as Auto-Prompt (Shin et al., 2020a), SoftPrompt (Qin and Eisner, 2021), and OptiPrompt (Zhong et al., 2021) need additional labelled data for fine-tuning prompts, but we restrict the scope of our investigation to methods that do not require task data.“ ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"There should have been an exploration (or at least an ablation) to compare different possible techniques to do ""predictive mean"", especially since selecting a summary is far from taking a mean.
",429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Weakness,1. ,218
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,Perhaps the authors would need another whole paper to analyze what “eliminating task-specific nuisances” w.r.t. ,348 349 350 351 352 353 354 355 356 357 358 359 360 361 362
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Weakness,1. ,131
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,Then it would be helpful to show a few examples from each domain to illustrate how they differ structurally. ,454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,"Given that the Hamming distance in the reference is much higher, it may not be necessary to absolutely reduce the number of changes made, if it serves the overall purpose of the text generation to make more changes. ",314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Weakness,"
5) In figure 3(b), why does uniform token sampling is worse than random weights by so much?
",296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Weakness,"This smaller PCFG is over-parameterized though, e.g., its potential $H\in \mathcal{R}^{r \times r}$ is parameterized as $V U^T$ where $U,V\in \mathcal{R}^{r \times m}$ and $r < m$, instead of directly being parameterized as a learned matrix of $\mathcal{R}^{r \times r}$. ",551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Weakness,"The writing itself is far from a solid paper, and I suggest authors go over the writing again.
",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Weakness,Character-level convolutional networks for text classification. ,148 149 150 151 152 153
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,2) The contrast set generation discussed in section 3.3 is not very clear and the readability could be improved. ,169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Weakness,"
4. ",358
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Weakness,What if the forward query and backward query give conflict prediction? ,92 93 94 95 96 97 98 99 100 101 102
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,et. ,284
057a3f73710f304801787e253e5ffc7e5d2eb9cf4570a5e3c6dc8edf75ebaadb324aff13a67e27a6057b12080f89cd80cc8d0f000bd23657daf14ff9c30856db,arr,Weakness,"- Judging the paper for a workshop, I find practically no weaknesses. ",99 100 101 102 103 104 105 106 107 108 109 110
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Weakness,I have two concerns about the experimental results. ,144 145 146 147 148 149 150 151
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Weakness,"The increase in the category of events (such as MAVEN with 100+ types) will exacerbate the problem.
",130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Weakness,"
2. ",272
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,5) Not a weakness of this work as such. ,513 514 515 516 517 518 519 520 521
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,"After obtaining the span representation, it is often to concatenate the boundary token representations to the span representation and feed them to an MLP classifier for labeling. ",341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"While I think the frame-free scheme is justified in this paper, the compatibility with other benchmarks is an important issue that needs to be discussed. ",498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Weakness,-The authors investigate only one prompt per relation which may be suboptimal ,153 154 155 156 157 158 159 160 161 162 163 164
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Weakness,The experimentation done by the authors use both ground truth and provided segmentation which I think is good to show that the technique works even with a segmental model. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Weakness,3. ,439
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Weakness,No major weaknesses ,191 192 193
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Weakness,A fairer comparison would be to run the original text through a pretrained punctuation restoration model. ,155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Weakness, ,
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Weakness,"[1] Aniruddha Kembhavi, Minjoon Seo, Dustin Schwenk, Jonghyun Choi, Ali Farhadi, and Hannaneh Hajishirzi. ",175 176 177 178 179 180 181 182 183 184 185 186 187 188
d420c861389d357cba32905a3ce5bdb49ac1f8cf4307e514dd57f7258c3fb92ed2ba9f8ed6236f98685df72905f399b55c3b1807531a2928752890bf72b2f7e1,arr,Weakness,"- models investigated (ESIM, etc.) ",83 84 85 86 87
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,The clarification of different models being compared is not clear enough. ,437 438 439 440 441 442 443 444 445 446 447
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,I would appreciate a bit more discussion here. ,492 493 494 495 496 497 498 499
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Weakness,No comparison with past works that produce higher quality multilingual models. ,124 125 126 127 128 129 130 131 132 133 134
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,But maybe as a suggestion for future work. ,522 523 524 525 526 527 528 529
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Weakness,"Subtle biases as a result of rejecting samples:     - fetched toxic sentences for rewriting (line 215),     - toxicity classifier (line 218)     - annotator bias ",202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Weakness,"A minor weakness of the paper is a convoluted affine mechanism which may not be easy to interpret.
",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Weakness,"As another example, the figure contains too many colors, and the colors don't particularly mean anything and are a bit distracting. ",407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,"-The used dataset is not been frequently used recently, and recent TOD methods are not also been evaluated. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Weakness,Evaluation metrics: This subsection is difficult to read and not rigorous. ,261 262 263 264 265 266 267 268 269 270 271
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,This is somewhat true for the formality transfer task as well. ,352 353 354 355 356 357 358 359 360 361 362
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,"It is true that the proposed method includes a few simple extensions for relation extraction (e.g., Softmax Layer and Concat Layer), the key idea and most parts of their method are based on existing contrastive learning methods, such as SimCSE proposed by Gao et al. (2021). ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Weakness,For instance on changing NER. ,235 236 237 238 239
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Weakness,"Comparative study of such synthetic datasets, and an analysis of why human-annotated sets might be of more value, if at all, should be performed. ",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"Besides eliminating the frame annotation, what are the major changes to the semantic role labels? ",574 575 576 577 578 579 580 581 582 583 584 585 586 587 588
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,2. ,373
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
However, I believe that the experimental setup should be very carefully designed, as this study could be a baseline for future work in this field. ",555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Weakness,how many sentences per articles? ,137 138 139 140 141
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Weakness,The (minor) weaknesses of the paper are: ,279 280 281 282 283 284 285
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Weakness,   I know what they are but the paper should be self contained and acronyms when introduced first should be elaborated on. ,243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Weakness,Neither do the authors explore the issue of unanswerability in MRC in exhaustive detail. ,249 250 251 252 253 254 255 256 257 258 259 260 261 262
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"If the authors were to share code/data, I would have assigned a higher score). ",542 543 544 545 546 547 548 549 550 551 552 553 554 555
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Weakness,"In general, it seems like one advantage of this method *should* be avoiding the expense of gold standard labels that would be used for another kind of probe, but if instead you need to have a bunch of information about hypernyms and hyponyms, that doesn’t seem like a significant gain. ",304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Weakness,This could be a weak baseline. ,250 251 252 253 254 255
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness, The combination of the individual metrics into one score (AGG; section 5.5) seems to conflate different scales of the different components. ,496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Weakness,"As another example, looking at Figure 4 (a), the original PCFG is equivalent to a smaller PCFG (with fully decomposable potentials) with state size being the rank size. ",523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,5. ,542
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,"what is the ratio of this combination, is it 1:1, if so are you not giving more weight text infilling problem than translation? ",398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Weakness,I'm fine with derivatives if they work. ,232 233 234 235 236 237 238
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"It is essentially a QA task, which isn't really compatible with just caption based training that most of the evaluated most are setup to do (with the exception of 12-1). ",352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Weakness,"- The paper does not appear to have methodological novelty (the paper is somewhat unclear on this score, but does not distinguish what if anything from its approach differs from the original PERIN approach) ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Weakness,"
3. ",246
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Weakness,Figure 1 contains 14 legends but only 13 lines are shown. ,238 239 240 241 242 243 244 245 246 247 248
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Weakness,This method simply encodes additional structure information into the Transformer models in a standard way. ,66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,Other models ,188 189
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Weakness,The approach the authors propose is still useful but not very novel. ,155 156 157 158 159 160 161 162 163 164 165 166
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Weakness,but the authors public their code) 2. ,142 143 144 145 146 147 148
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness, ,
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"2020.
",524
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Weakness,1. ,436
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,It is not intuitive to me that there is a connection between a neuron at a middle layer and the word embeddings (which are used at the input layer). ,295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Weakness, ,
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Weakness,Weaknesses: ,259
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Weakness,Human evaluations were not performed. ,225 226 227 228 229
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,The space can be used to add more clarity and more examples for section 4.1. ,260 261 262 263 264 265 266 267 268 269 270 271 272 273 274
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,__1. ,276
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Weakness,"Could be clarified a bit if there are other clear differences in behavior beyond doing better in the very-aggressive-early-stopping regime.
",450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469
74644b8c9ecdd5fa9ec1f11bf74bb24a859379bf32c3d6cbacd875a97578143afd0288863fc70dd959eddb1a9aabaf66d9ae02d6c1917377dd7d9427c44bde88,arr,Weakness,"Can you elaborate on ""seen as a superset of current defined explicit discourse relations, as most existing automatic methods extract event relations from documents or sentences"" and tie it more closely with what is presented later.
",96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,"The main problem of the paper in my opinion is related to the data Augmentation: I have not been able to understand exactly which are the data augmentation methods used, and their impact on the scores (line 461-470 were quite obscure to me) and how this affects the comparison with other methods. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d,arr,Weakness,"Unfortunately, the above method was not employed as the baseline in this study, in order to validate the effectiveness of using large collocation training corpora to compute the collocation measures for all bigrams. ",358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,-Lines 402-404: How the additional transitions are generated? ,506 507 508 509 510 511 512 513
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,"Also concerning $e_{i}$ in weakness point 1 above, it is not known how $e_{i}$ and $e_{i}$'s distributions look like at all. ",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,"
5. ",267
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Weakness, It would also be useful to check whether the McRae norms agreed with the extracted VG properties. ,396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness, ,
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,It would also be helpful to have a deep dive into the existing datasets to help the reader understand how exactly the Behance dataset differs (summary statistics as well as illustrative qualitative examples). ,158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,  ,
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,The other is combining the embeddings of pinyin with the input embeddings of characters. ,239 240 241 242 243 244 245 246 247 248 249 250 251 252
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"presentation of results] Table 2 should also include the best result from Shen et al. 2021 (one of the baselines), so that we can compare the finegrained results on each language and metric. ",359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Weakness,"I request the authors to try to rectify these in their final submission, especially the second point on the performance metrics for the SGCP baseline. ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Weakness,There isn't one clear aggregation strategy that gives consistent performance gains across all tasks. ,313 314 315 316 317 318 319 320 321 322 323 324 325 326
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"belongs to the ""Feeling"" category). ",228 229 230 231 232
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,"What you are highlighting is the probability distribution between likely candidates for top-K prediction of a softmax, which is not adequately measured by perplexity. ",320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,"However, the practical method introduces the consistency constrain at the token level. ",513 514 515 516 517 518 519 520 521 522 523 524
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Weakness,"This weakness is a little nitpicking esp when I personally execution (replicable) beats idea (novelty); but if there's no code release is produced after the revision process, then this weakness stands given the next.
",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Weakness,-The datasets included in the paper are mainly related to QA. ,232 233 234 235 236 237 238 239 240 241 242
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,3). ,321
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Weakness,"Briefly at the end of the abstract and In 5.1 (Stage-1 Results) in detail, you mention that your dense passage retrieval approach improves over a TF-IDF baseline. ",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Weakness, ,
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Weakness,Experimental part is less convincing. ,109 110 111 112 113
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Weakness,    (a). ,307
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Weakness,I have increased my score to 4. ,383 384 385 386 387 388 389
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,Does using z_obs  / z during training make difference? ( ,328 329 330 331 332 333 334 335 336 337
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"However, it remains unexplored whether this is the same for all tested methods or even just what it would be for the complete CogTaskonomy framework.
",361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,1). ,168
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,3. ,544
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,"Therefore, the improvement of the proposed method over a single T5 model(E2E-T5) may not be a very valuable conclusion. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Weakness,The first and the second point has been properly addressed in the author's reply and the revision. ,564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,"to assess it.
",686 687 688
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,Then the comparison between the setting with and without SR may be unfair. ,261 262 263 264 265 266 267 268 269 270 271 272 273
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Weakness,1. ,148
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,"There should be a discussion on the justification (or maybe limitation).
",330 331 332 333 334 335 336 337 338 339 340
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Weakness,"While the proposed method could make change to the predicted token, whether it make an improvement is questionable. ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Weakness,"For the analysis in Line 469-486, it’s hard to understand the hypothesis without looking at what the instruction looks like for each category. ",191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,"According to my understanding, there is no discrepancy between training and testing w.r.t. ",301 302 303 304 305 306 307 308 309 310 311 312 313
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Weakness,"Structurally, there should be a ""Related Work"" section which would inform the reader that this is where prior research has been done, as well as what differentiates the current work with earlier work. ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"Take ""engineer"" as an instance, in the Merriam-webster dictionary, the first meaning of ""engineer"" as a verb (https://www.merriam-webster.com/dictionary/engineer#:~:text=engineered%3B%20engineering%3B%20engineers,craft%20engineer%20a%20business%20deal) is ""to lay out, construct, or manage as an engineer"". ",451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Weakness,"When conducting the evaluation, do you consider using the F1 score instead of accuracy to have a more comprehensive understanding of model performance? ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Weakness,"In Section 2.1 line 165-170, the paper provides some explanation for the definition of the f function, but it is still not clear why such a setting is well-suited for coreference. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Weakness,"The results presented in the appendix for the sentence level tasks are actually a better proxy for language understanding capacity, but for those, it doesn't seem to matter if we mask characters or words. ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Weakness,I find it difficult connecting section 5 to the issues of hype and overclaiming in general. ,171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,Some claims in the paper lack enough groundings. ,346 347 348 349 350 351 352 353
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Weakness,1. ,97
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,EMNLP 2020. ,422 423
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Weakness,I feel the choice of models used by the authors are different on 1 important aspect. ,250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Weakness,"But this is, to my mind, insufficient as empirical evaluation. ",195 196 197 198 199 200 201 202 203 204
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,What happens when I train e.g. with MLM for the same amount of compute on C4 and then do fine-tuning? ,295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314
97bd72cf67e40492696103ced9dcbd5066d8a3a52f3d2558764aa570e24ae2c7bedddf9ad226e624b1dabcced450f36d6bcd93ece5a871c74fa98b7e2d8145fc,arr,Weakness,"Also, it wasn't clear to me whether the data would can be released, as this is one of the important contributions of the paper. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,	I don’t understand how and why the student model is taught by the teacher model. ,78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Weakness,- The proposed framework is based on the previous template-based information extraction method. ,99 100 101 102 103 104 105 106 107 108 109 110 111
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Weakness,I have not extensively studied the benchmarks in the text-to-SQL task. ,345 346 347 348 349 350 351 352 353 354 355
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,Whether attributions should be purely faithful to model behaviour or   offer human-interpretability is a decision to be made in the definition of an attribution method   or its motivation. ,214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Weakness,"It is important to understand how relative slot accuracy metric differs from the existing AGA metric, and what are the benefit of using this new metric along with (or in place of) the AGA metric. ",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,Experiments include fine-tuning on ALBEF but not fine-tuning on CLIP. ,189 190 191 192 193 194 195 196 197 198
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,"
Regarding Table 6: It is also not clear to what performance the numbers ( acc or auc) refer to? ",500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Weakness,Why not evaluate the proposed method on WMT 2020 QE tasks for REF and SRC+REF scenarios. ,87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Weakness,•	The motivation of applying the attention divergence loss to force attention similarity is still not clear to me. ,165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,However Table 2 suggests that this zero-shot performance isn't well correlated with transfer performance. ,1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Weakness,"As far as I know, IPA-based features may be tailored towards English or other Indo-European languages, which may be a problem for low-resource languages. ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,"How are they ""educated"" and how do the authors ensure the raters provide good-faith annotations? ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Weakness, ,
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Weakness,"Without such analyses, readers will have no idea about how each component contributes to the final performance. ",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,"IIUC, the model still needs cross-modal (x-modal) alignment to train. ",105 106 107 108 109 110 111 112 113 114
b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952,arr,Weakness," Are these computed using the full transformer models (embedding, encoder, decoder, softmax)? ",185 186 187 188 189 190 191 192 193 194 195 196
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Weakness,"The paper ""A howling success or a working sea? ",124 125 126 127 128 129 130 131 132
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Weakness,"For now, it looks like the authors are trying to explore new settings without supporting rationale.
",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,"
  3) The following work is also very relevant and could be added to the related work section: ",214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,The baseline systems such as TRADE are already old. ,499 500 501 502 503 504 505 506 507
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Weakness,"My main complaints are 1) the presentation of this work is a bit misleading to me, 2) I'm not convinced by the main arguments of this work.
",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Weakness,"I want to see a baseline that tests spelling bee on representations specifically optimized for morphology or spelling, so that we can see what the performance of this probe would be on complete information about spelling. ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Weakness,"The authors offer no analysis of their system's actual outputs, of which ""many"" correlate with which ""one"" in the evaluation scheme, and although they use a second metric that contains a component that mitigates this problem, they leave this detail out and send the reader to the appendix to understand what the metric does (this is completely unacceptable. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Weakness,"It seems like the cosine similarity of lower layers in figure 3 are relatively high, while the t-SNE visualizations in Figure 2 are more mixed. ",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,How does the CLEAR approach fare on zero-shot? ,544 545 546 547 548 549 550 551
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness,"-FiD [3], a state-of-the-art reader for open-domain QA (NQ & TriviaQA) is a missing baseline. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,2. ,444
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Weakness,"This work does not report how ""short"" the rationales generated by prior works are. ",241 242 243 244 245 246 247 248 249 250 251 252 253 254
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Weakness,1. ,190
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Weakness,I think many members of our community will find this work rather niche. ,172 173 174 175 176 177 178 179 180 181 182 183 184
99d64669158590f9f3d0b28e3c563bcfac559cd34c4356ddc25b5ea7f25e8701c8824d1c85b3007de9e768e7fbf6bc8067d634e31bd768c285db8576172dac30,arr,Weakness,It would be insightful if the authors could list error patterns at a finer granularity. ,196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Weakness,"In section 6.3, the author(s) mention that Unified VLP underperforms FewVLM on the captioning task. ",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Weakness,"Let’s consider a counter-example: suppose for a low-resource language LR with sentences S1 = {w1, w2, w3, w4}, S2 = {w1, w5, w3, w4} and S3 = {w1, w6, w3, w4}. Where (w2, w5) and (w2, w6) are considered as token pairs by Similarity teachers. ",247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Weakness,2. ,415
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Weakness,2. ,240
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Weakness,"-Approach appears to be very incremental to T5, leading to questions about novelty.
",158 159 160 161 162 163 164 165 166 167 168 169 170
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Weakness,It's also unclear why V&L models are able to store visual commonsense effectively (Is it really from the images or just from the captions?). ,137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Weakness,Attention attribution and entropy terms in section 3.2.1 needs a little more context or definition or example. ,183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"I understand that the authors want to show us that multi-lingual representations improve performance, but understanding the relationship between different languages in this context of VLN is an equally important aspect -- the experimental setting of this paper is perfectly poised to provide this analysis, but the results are tucked away in the Appendix -- this should be moved to the main paper. ",294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"Thus, it is more fair to train those baseline systems (at least one of them) with self-supervised learning. ",633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Weakness,1. ,86
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Weakness,Yet the analysis in table 1 suggest that the new model indeed promises overall improvements that the others cannot achieve (for example 85% accuracy on ASRS). ,202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Weakness,"which seems unlikely to work well, and the Task Tuning approach doesn't seem preferable to just training a prompt on the target model directly. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Weakness,I would expect a more detailed error analysis in the discussion part. ,137 138 139 140 141 142 143 144 145 146 147 148
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"Another weakness I felt, was a lack of description of previous/related work. ",402 403 404 405 406 407 408 409 410 411 412 413
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Weakness,- The biggest concerns/confusions during the reading are the lack of implementation details of the proposed methods. ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
0943e5d2efbf75734b113861f9c2bb8ca031e0740fce519c60b9b17470dea2b0df56aa327e769a0e36e89ac92fa23086cd9ee85094e50a67d721965f0c3509f7,arr,Weakness,- Transfer learning does not look to bring significant improvements. ,42 43 44 45 46 47 48 49 50 51
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,"-Additionally, footnotes are used FAR too extensively in this paper -- it's actually very distracting. ",119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Weakness,"-  In the proposed method, the authors claim that $N$ sparse student modules have probabilities of $p_1, p_2, p_3, ..., p_N$ to substitute the corresponding teacher layers separately. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Weakness,1. ,222
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Weakness,"I wonder about the effectiveness of combining this method with other speedup ways, such as DeeBERT (dynamic early exiting). ",151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,"
    - Have the author(s) run the codes for multiple seeds and reported the mean? ",213 214 215 216 217 218 219 220 221 222 223 224 225 226
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"In practice, we cannot go back in time. ",302 303 304 305 306 307 308 309
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,- The instantiation of the task could not fully justify the benefit of the new task formulation. ,235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"[4] Xiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong Han, Zhiyuan Liu, Juanzi Li, Peng Li, Yankai Lin, Jie Zhou. ",393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,"In fact, if the hash function is instance-level, the sentence-level difficulty of all baselines (including static and dynamic models) can be calculated, which will provide a more comprehensive and fair comparison. ",440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Weakness,"- As correctly mentioned in the paper, the work of Xu et al. is not based on MC dropout. ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,This would be important to confirm that the improvements are actually because architectural improvements of the student were utilized. ,328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Weakness,"	Since an additional confidence network has been involved in producing confidence score, how to ensure the confidence network would not be over-confident or under-confident? ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,"The experiments are limited to one domain (biomedical), one task (text classification) and a single teacher model (BioBERT) and it is not clear what happens if any of these parameters are changed. ",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Weakness,"I understand most of the baseline required translation pairs, too. ",180 181 182 183 184 185 186 187 188 189
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Weakness,It finds a causal role for syntactic representations where previous approaches would have missed it. ,174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"Simple is not bad, but I think there can be smarter ways to ensemble multiple predictions from a summarization system. ",398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Weakness,"
     * It wasn't clear to me if the 671 parallel sentences which were used as a blind test were part of the ParaDetox 12,000 examples or not. ",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Weakness,"Although it presents an in-depth analysis, how to utilize these conclusions is still unclear. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Weakness,"Double edge point] It's an incremental improvement to K-NN based MT approach, little novelty but large engineering and execution effort, backed by good experimental design. ",148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Weakness,"Authors argue that they cannot perform human evaluation, but at least the combination of other metrics would be relevant. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,"The current version generally looks good to me, so I'll mainly put forward some suggestions to further polish it up. ",110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Weakness,"-Human evaluation: The appendix now provides more extensive information, including details on annotator consent.
",196 197 198 199 200 201 202 203 204 205 206 207 208 209
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Weakness,"The experimental details, for the classifier and proposed Bart-model are unspecified. ",294 295 296 297 298 299 300 301 302 303 304
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness," Authors are requested to correctly situate this work within the large history of studies on bias of plug in entropy, which is no more than one kind of work to apply entropy estimate to linguistic data.
",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Weakness,"The refined strategy seems to be a coarse strategy, which is only useful for the relations like “A”, actually I wonder the analysis of the refined strategy on different types of relations of word-pairs, which is benefit for better understanding the influence of refined strategy; ",359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403
6db5d3547297644e1a01b2dd191f13fced41cc86ff3a74d59ca05167091c7b4bbe9f67ec055106ee390fe9cdb497d99a303a97c2d53e008f5f89e93f722c3fbb,arr,Weakness,"The annotation task also seems to be particularly subjective, dealing with individual perception of what is offensive and what is supposedly common ground knowledge. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,"-Because the paper presents so many novelties, it is a bit hard to grasp what led to the improvement on BEIR, i.e. what are the main factors that contribute to the improvement?
",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Weakness,What is the ratio of the posts excluded in respect of this decision? ,127 128 129 130 131 132 133 134 135 136 137 138 139
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,3) Recent works have shown it is possible to continue training language models for either language understanding [1] or additional applications such as code synthesis [2]. ,264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Weakness,"There should be more VLU tasks to prove the argument of the paper, e.g., NLVR. ",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,The Methodology section is very hard to follow. ,249 250 251 252 253 254 255 256
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,"Ironically, the authors claim to get most improvement on prompt 1,2,8 for ASAP dataset (all of which have >510 tokens) ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"we know very well at this point that PTLMs' performances degrade when data distribution shifts; we also know that the magnitude of degradation depends on tasks, domains, or even different models themselves. ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,"So, why is this dataset not used as a potential benchmark for evaluation (for investigating the role of context in detection of hate) as well? ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Weakness,It is not clear how this local self-attention of Eq. (6) is related to “regularity” or “regular types” of entities. ,161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Weakness,But I expect the authors to give a deeper analysis for it. ,155 156 157 158 159 160 161 162 163 164 165 166
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,The authors use another triaffine instead. ,368 369 370 371 372 373
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,"Since they are two core backgrounds of the paper, they should be explained in more detail.
",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Weakness,"- Only English, it is understandable and explained in the paper why that is but still sad ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness, ,
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Weakness,"This is a pernicious problem with template data, but a serious one. ",346 347 348 349 350 351 352 353 354 355 356 357
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Weakness,"However, I find it less motivated by the computational cost of other data augmentation approaches, which are not really that expensive as shown in Table 7. ",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"Mathematically (for someone who is not an expert on linear algebra), why would the dot product between a ""topic vector"" and a ""word vector"" give rise to ""non-trivial cooccurrence""? ",365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,One of the main drawbacks of this approach is that presumably the different component black-box experts of the controlled text generation have to be manually selected and the weighted linear combination has to be fine-tuned for each task. ,201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Weakness,I do not have enough expertise to evaluate the novelty of the actual model presented. ,144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Weakness,-the part that is novel wrt Feng et al 2021 is pretty much just the extension towards ingredient transformation and the transfer learning study (which is however less elaborate as the one in Xia&vanDurme) ,189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Weakness,It lacks case study to show which document-level translation errors are improved by the proposed method. ,204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Weakness,"It would be nice if more analysis could be done about this proposed metric, including how it correlates with human evaluation metrics and how robust it is against multiple alternatives to the correct answer. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Weakness,"Figure 2 does not show the time complexity of SimCSE_{CLS} method.
",184 185 186 187 188 189 190 191 192 193 194
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Weakness,What would be the unit of personal memory in the context of visually grounded dialogues (line 134)? ,247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Weakness,"
2. ",204
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness,[1] Izacard and Grave. ,204 205 206 207
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Weakness,I could not fully understand why people want higher pinyin IME accuracy with full use of V100 GPU. ,280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Weakness,It is not clear how Relative slot accuracy correlates to the precision and recall of the model. ,214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Weakness, I felt that the conclusions drawn from the attempt to train with additional spelling information were not well justified. ,237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"
2. ",496
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness, ,
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Weakness,The pipeline is too complicated and the knowledge distillation may not be easy to control. ,299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Weakness,"However, why is the sub-network on top of the self-attention block important, and what role the authors expect from them are not well-motivated. ",107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,"Intuitively, according to the accuracy of the prediction, there are two main situations for training-inference inconsistency: the inconsistent exit makes the prediction during inference better than that during training, and vice versa. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Weakness,"In other words, use human annotators in the role of the model, and see how well they do compared to neural models as a baseline. ",557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581
2657a42b67131e9d0624d9f7e4de05db53bf2f459a325b9d3bef0cf25d163744e7f0bfbdded5ee0147497f4918b061d944936bd4244f66019d894a3ed76373b4,arr,Weakness, ,
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Weakness,The named entity recognition accuracy metric seems to be weak compared to the proposed scale of the problem. ,449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Weakness,"
[2] Ouyang X, Wang S, Pang C, et al. Ernie-m: Enhanced multilingual representation by aligning cross-lingual semantics with monolingual corpora[J]. ",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Weakness,It seems that MTST in ablation study aims to prove it but the description “multiple-teacher to single-teacher” and “teacher and student have the same neural network structure” is confusing. ,135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,The BERT^2 model is same as model 10. ,214 215 216 217 218 219 220 221
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Weakness,"I imagine this would be easy to achieve by fine-tuning     a model on some splits of the dataset, or training another architecture for     the task, e.g. a BiLSTM. ",287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Weakness,"I would have liked to see this distinction between misinformation and mismatched image captions being clear in the paper.
",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Weakness,Please refer to the question. ,139 140 141 142 143
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,- The technical description of the method (sec 3) was quite difficult to follow. ,522 523 524 525 526 527 528 529 530 531 532 533 534 535
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,There could be other ways of clustering the tasks. ,232 233 234 235 236 237 238 239 240
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Weakness,2. ,195
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Weakness,"Reference: Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei Chang. ",425 426 427 428 429 430 431 432 433 434 435 436 437 438
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,2019. ,381
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Weakness,The authors proposed some values in the reasonable range but without any discussion on how they are decided. ,169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Weakness,"The metrics reported in this paper for SGCP are significantly worse than even the copy baselines which makes me a bit doubtful about validity of the results reproduced by the authors.
",313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Weakness,"Practically, its not feasible to try out all these experimental settings for data annotation for QA datasets for industrial/real-world applications. ",705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Weakness,is not valid. ,186 187 188
34a654d252d0bb72f0bd405e28bc8a2c52097ce0c2fc0293a544b3bd1929cfc5996e389971dc43791136d5d78b742372f89326f61ab0ae0fdb56d762335f5639,arr,Weakness,****The authors have adequately answered most of the weaknesses mentioned in the previous review.***** ,140 141 142 143 144 145 146 147 148 149 150 151 152 153
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Weakness,"Besides, the paper does not show how the cross-entropy loss and query likelihood loss affect the model performance, which requires an ablation study.
",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,"For task weighting, absolute magnitudes don’t matter.) ",419 420 421 422 423 424 425
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Weakness,This paper does not make a significant contribution. ,38 39 40 41 42 43 44 45
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness, ,
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,"Maybe as “noise?”
",444 445 446
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Weakness,"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation. ",381 382 383 384 385 386 387 388
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Weakness,"For the sentiment transfer task, the model with the higher Hamming distance coefficient is considered to be the best model based on the BertScore with respect to the source, which essentially measures how much deviation has been introduced. ",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Weakness,"And the section 5.4 is the description of ablation methods, which would be more clear by listing together with other baseline methods. ",369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Weakness,"That is, we need benchmarks that include counterfactual examples where we know what is the type of manipulation that was done, and compare model predictions between the original examples and the counterfactual examples.
",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,The statement in lines 137-148 also focuses only on LD. ,655 656 657 658 659 660 661 662 663 664
9c42d14ccc84cf2e86bf494b4f4c72974fc1f55456a9cdd542f9d7654aaf3d5779eb6eac51a4cdb96a2edee8473bb8bdb525a43601d147fbac2e8d290269013a,arr,Weakness,"It would be good to discuss that limitation in the conclusion of the paper.
",314 315 316 317 318 319 320 321 322 323 324 325 326 327
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"Hence, the paper would substantially help if the related work sections were expanded to include citations with similar methodologies. ",421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,"
Further, there should be more information on CueNB model as well. ",200 201 202 203 204 205 206 207 208 209 210
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Weakness,"The reviewers, meta-reviewers, action editors, and everybody else involved in the organization of a conference (e.g., NAACL) are being working on this paper for free, but the dataset will be a paid product. ",578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Weakness,The modeling process does not have any specific component to account for such topical variations resulting in different scores. ,298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,-One limitation of this study is that the paper only focuses on single-word cloze queries (as discussed in the paper). ,459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,The paper could benefit from a more substantial discussion of fewer results in the main paper with a more detailed discussion deferred to the Appendix for other experiments. ,267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Weakness,-The applications of this work are described more clearly ,210 211 212 213 214 215 216 217 218
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,did you tried some dialogue embedding from the ODD part and tried to select a TOD dialogue with a similar dialogue embedding? ,425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Weakness,"How does the new dataset and its labels compare to actual cases of out-of-context captions?
",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Weakness,"If you're using a metric, especially if you're arguing that it's better than the other one, at least explain the virtues of it along general lines in the main text).
",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,1. ,350
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Weakness,2- The approach operates on clusters. ,164 165 166 167 168 169
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,Cross-modal code matching: The key of the proposed approach is the x-modal code matching. ,140 141 142 143 144 145 146 147 148 149 150 151 152 153
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,"For example, Section 2.2 introduces $v^p_{t-1}$ in the description which does not appear in the equations. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,"-I also take issue with this sentence: ""Sampling from character-level models leads to very poor translation quality that in turn also influences the MBR decoding that leads to much worse results than beam search."" ",435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Weakness,- The PGD adversarial training baseline might be a weak baseline as the authors restrict the number of gradient steps to 5. ,205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,It is not clear to me how the pseudo sentences are actually generated. ,235 236 237 238 239 240 241 242 243 244 245 246 247
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Weakness,Does this lead to a model which focuses on entity mention detection rather than relation patterns? ,140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Weakness,"
 - Equivalent performance is determined statistically via the failure of a one-sided t-test. ",256 257 258 259 260 261 262 263 264 265 266 267 268
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Weakness,"One could make the argument that this task is inspired pretty directly by NLVR2, and doesn't really add much beyond that beyond just being a harder version of that corpus. ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,I have identified some weaknesses in the paper:  - How general are the obtained results? ,119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Weakness,+ My biggest concern with this paper is that there is a very significant transition gap between Section 3 and 4. ,366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Weakness,"In my opinion, the ""length divergence bias"" should only have a discrepancy in the length of the textual expressions rather than introducing additional semantics. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Weakness,"
3. ",492
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,"-Line 229: What’s t?
",331 332 333 334
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Weakness,"In fairness, Section 5.3 and Table 5 compare VG-trained Oscar with (probably) VG-free CLIP and don't see any large differences between the two, indicating that it's not the VG-in-training that is driving the differences between Bert and the multimodal models (and so more likely to be genre/domain differences, or the actual visual inputs, see point  1).
",313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Weakness,N/A ,208
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,"See ""comments, suggestions and typos."" ",261 262 263 264 265
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Weakness,"minor) It is unclear how the authors arrived at the different components of the ""scoring function,"" nor is it clear how they arrived at the different threshold values/ranges. ",335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Weakness,"While the paper focuses on generalizability and transferability of value classifier, however,  there needs more clarity on domain specificity. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,The paper doesn’t show that whether the token-level method can truely address or mitigate the inconsistency problem at the instance level. ,525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Weakness,2. ,131
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,A potential challenge of applying the proposed model on MAVEN ,322 323 324 325 326 327 328 329 330 331
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Weakness,I would say style transfer could be a good start. ,400 401 402 403 404 405 406 407 408 409
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Weakness,The experiments are held on a private datasets and the exact setup is impossible to reproduce. ,150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,"adequacy?), ",662
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Weakness,1. ,193
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Weakness,- What is the percentage of complex questions in the VQA dataset ? ,83 84 85 86 87 88 89 90 91 92 93 94 95
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Weakness,It could be improved. ,315 316 317 318
9f16d7fbb89be40b6fa6ff149aa34cfcad08f2a811b1bef57d6136992bef789a65da497e685cbeb4e29335b120aaf58d3d7240a775eb25c9fe8bec3fa6bf4ffc,arr,Weakness,2. ,130
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,"
    - Some relatively important description goes to Appendix, which makes reduced readability.
",145 146 147 148 149 150 151 152 153 154 155 156
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Weakness,I did not find many motivating insights from the analysis that could potentially benefit the future work of long-form QA. ,248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,"For this last one, in particular, it is important to know how the annotators were instructed (maybe trained?) ",668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Weakness,"-[minor weakness] Beyond the vocabulary and model performance tables, I want even more out of the comparison between ConfliBERT and BERT because the model is the main contribution (there's no new theoretical contribution, major methodological contribution, or dataset). [ ",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
a08c0e0dafb5d74615009802dfc40b3801cc6a3f779b82e40b03a3f4c3f3bef3a4186e50fbbc8ec1a5364e61382882c08f2d7b7d4689d743a8b74728f99da313,arr,Weakness,"
3. ",132
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"
[2] Li et al., Deep transformers with latent depth, NeurIPS 2020. ",363 364 365 366 367 368 369 370 371 372 373
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Weakness,"
  - To encode whole information for the long and complex dialogue, there is another challenge regarding sequence length.
",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Weakness,How would the proposed method perform under such situations? ,188 189 190 191 192 193 194 195 196
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Weakness,"- Nothing much, a very well-written and thought out papers and experiments; although it's incremental improvements to the LevT, it's an extensive study with solid empirical evidence for the conjectures stated in the paper.
",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Weakness,"A paper like this one, whose  ambition is to make a strong methodological contribution, should have a better coverage of real-world evaluation. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Weakness,"For Eq. (6), the learning of each channel of each element in adjacency matrix A via the biaffine attention module is unclear, especially for non-numeric linguistic features like POS combination or syntactic dependency types. ",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Weakness,"
2) Lacking strong baselines both on entity-level factuality evaluation and summarization. ",165 166 167 168 169 170 171 172 173 174 175
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"Overall, there are three major weaknesses in this paper.
",196 197 198 199 200 201 202 203 204
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,"Though MACE can be used to assess the competent annotators and eliminate redundant annotators, it could be challenging to use when it involves most ambiguous content. ",287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,"For example, what if top 10% (instead of top 50%) dialogue pairs with a high source entropy are selected as the negative training set? ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,"While I do not disagree with the main points regarding   model reasoning process and robustness, I do not think the experiments demonstrate them. ",477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Weakness,"
Why not extract keywords or event tuples? ",83 84 85 86 87 88 89
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Weakness,"Cons: From translation accuracy perspective, the improvement from fixing the conflict is very incremental. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Weakness,"[1] Jungo Kasai, Nikolaos Pappas, Hao Peng, James Cross, and Noah Smith. ",369 370 371 372 373 374 375 376 377 378 379 380
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,I wonder in what downstream tasks the said encoder transferred to? ,547 548 549 550 551 552 553 554 555 556 557
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"This isn't an issue, because its not really the benchmark's problem, but I am not sure the format of the foil is that sensible. ",382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Weakness,I will list the detailed weakness in the next section. ,167 168 169 170 171 172 173 174 175 176
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"Finally, in Section 3.3, the ""predictive mean"", which is to select the summary with the lowest disagreement, seems to be very simple. ",376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"A few weaknesses have been addressed, especially as to the lack of information and to remove misleading information. ",212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Weakness, ,
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Weakness,"
While the statistical rigor is fun to read, I am not sure that the overall findings are novel enough for an ACL paper. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,"
3. ",386
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,Zero-shot Label-Aware Event Trigger and Argument Classification. ,362 363 364 365 366 367 368
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,Details around parameter settings etc. ,152 153 154 155 156
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Weakness,"Regardless, covering more details around training and evaluation would be useful. ",189 190 191 192 193 194 195 196 197 198 199
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Weakness,But little experiments are carried out to prove its effectiveness. ,125 126 127 128 129 130 131 132 133 134
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,How does it change with a skewed label distribution in the sampled dataset? ,500 501 502 503 504 505 506 507 508 509 510 511 512
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Weakness,"
2) For the dropout, thru the reading of the response letter, my understanding is that multiple stochastic masks (w/ 0 and 1) are applied to a document presentation from an encoder. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Weakness,A paywall is also a roadblock for research in the field. ,639 640 641 642 643 644 645 646 647 648 649
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Weakness,"
3) The authors have not motivated their choice of (Bert ) as the sole semantic encoder in their experimental settings. ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,"Although some details are vague and need further investigation, I think the contribution is enough to be accepted as a short paper.
",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"Moreover, this paper addresses the abbreviation pinyin configuration but I doubt this configuration is well justified. ",321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,The authors acknowledge this work and call it simultaneous publication. ,260 261 262 263 264 265 266 267 268 269
3f1a09e155c657a139ccdad41c8d593f45e130a564aa0d3825770e56f02682d43186539fe68060d48acab72dfd294c56a3f6ce65d9331ff71c2c1d4aa73a9500,arr,Weakness,"- The proposed measure of uncertainty (expected entropy) should/could be compared with alternatives in the experiments.
",284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Weakness,"
The tasks require input texts of drastically different lengths, which a single model might not be very good at. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Weakness,"E.g., how the style adapter affects the generated responses, or how it performs if one kind of latent is removed. ",271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"In table 4, the combination of self-supervised tasks ICT and DaPI doesn’t seem to be com- plementary, the effectiveness of DaPI task, which will double the GPU memory usage, is not significant (0.434 -> 0.438) 3. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,And I could imagine a variety of other arguments about the relevance of his work in NLP today. ,324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"
-	Although ConfliBERT is a novel language model, the concept, methodology, implementation follows the BERT model. ",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Weakness,"However, if we go to Table 2, there is no difference between CS-k-1 and CS-opt results on SST-2. ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Weakness,1. ,94
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"The authors write “During training, we 397 create a pseudo sentence {0, 1, 2, ..., 127} for every 398 input and map the original sentence to this pseudo sentence by attention”, but how exactly is a different pseudo embedding is created per sentence? ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,"It’s clear that the MRC model surprisingly maintains prediction accuracy when evaluated on 64% of the test samples, however, what follows in the brackets is unclear i.e. ""68.4% on correctly answered samples and 55.4% on wrongly answered samples"" is an unclear statement. ",491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Weakness,"In the backward query of Fig 4, why the span is ""must visit"" instead of ""a must visit"" given the probability of the word ""a"" is 86%, which is the same as the word ""must""? ",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Weakness,I would suggest putting these parts into related work section. ,164 165 166 167 168 169 170 171 172 173
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Weakness,"In this paper, only one evaluation approaches are used to generate the prediction score. ",112 113 114 115 116 117 118 119 120 121 122 123 124 125
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Weakness,Figure2 provides insightful findings on the residue properties. ,174 175 176 177 178 179 180 181
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Weakness,"
This is clearly difficult to test due to the limited availability of such datasets, but therefore requires a careful discussion. ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Weakness,"
-The proposed tasks lack, in my opinion, a strong motivation. ",208 209 210 211 212 213 214 215 216 217
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"
8. ",605
c476e1916a5e04f95f17a9f2fd62d74fa664c84ea9dcaecf96db78dee71eeb770dff7d76c1e4abe6919622db6936040e8ecc60b449d3472f9457a322c9be0d7e,arr,Weakness,- It is not clear for me about the novelty of the proposed methods. ,92 93 94 95 96 97 98 99 100 101 102 103 104 105
3d1b1462c3af404e05a55b39582f2d5240ce4e0e42e902c4f5d854ee0ae1b8acbf4fcd9c34f67fc7b411b87baa13b45cea716b8b7187ffe563a68072fda21ab0,arr,Weakness,- This paper brings more questions than answers -- many results are counter-intuitive or contradictory without explanation. ,147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,The dataset and problem seems somewhat niche to me. ,55 56 57 58 59 60 61 62 63
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,1. ,77
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,"Therefore, perhaps these simple approaches are sufficient enough for good generalization.
",290 291 292 293 294 295 296 297 298 299 300
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Weakness,"
The findings are not outperforming the current state of the art in several tasks and in those tasks where the CrossAligner does outperform the state of the art, it is not bot much (1 point on F-score more or less). ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Weakness,But isn't the sequence tagging model used is also at the token level? ,168 169 170 171 172 173 174 175 176 177 178 179 180
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Weakness,The link between the ICoL and BM25 weighting is not fully worked out. ,199 200 201 202 203 204 205 206 207 208 209 210 211
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Weakness,"While I don't see any large weaknesses in this work, there are some things that can be updated -  ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Weakness,"For 1), it's not completely clear from early sections that this work focus on the setting where the gold alignments are given. ",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"Related to this concern, I also have a question regarding training the question decomposition component. ",443 444 445 446 447 448 449 450 451 452 453 454 455 456 457
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Weakness,"I'm concerned about is the relevance of the paper to the theme of ACL.
",119 120 121 122 123 124 125 126 127 128 129 130 131 132
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,"Therefore, it's unclear why this method improves over baseline methods, i.e. does it help the model learn from skewed training samples or is it something else? ",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,-**Re. ,273
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Weakness,"More broadly, we can think of model explanation as a causal estimation problem, and evaluate methods as we do in causal inference (sensitivity analysis and the likes). ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Weakness,"In the results in Table 2, there is a large score gap between the newdistinct and original distinct for the system of AdaLab, please give more explanations. ",110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,Is this something that has been adapted? ,646 647 648 649 650 651 652
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Weakness,One point of comparison could be pointing out that overlap of neuron activation works better than Vu et al.'s embedding-based similarity. ,244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Weakness,For example: ,113 114
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,-I'm surprised that in Table 1 CLIP-T performs so badly even when finetuned. ,119 120 121 122 123 124 125 126 127 128 129 130 131
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,What were the chosen parameters? ,282 283 284 285 286
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Weakness,"Without actual examples of the task, it's difficult to follow the text in the paper. ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,"Given the adaptor framework, would the authors’ approaches perform better? ",276 277 278 279 280 281 282 283 284 285
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"[1] Chalkidis, Ilias, et al. ""Large-Scale Multi-Label Text Classification on EU Legislation."" ",468 469 470 471 472 473 474 475 476 477 478 479
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,The use of BERT architecture for this task has already been explored in R^2 BERT [Yang et al. 2020]. ,98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Weakness,Please take a look at some questions on the equations and confusing phonemes below. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Weakness,The annotators would default to it in many cases and as a result the number of annotations for that label become much higher in comparison to the other labels (in your case 15343 for OTHER vs. 21635 for the rest of the labels). ,269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,I have concerns that the overall reduction may not be sufficiently significant. ,288 289 290 291 292 293 294 295 296 297 298 299
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Weakness,Numbers show how often the model is correct but we don't know how far the model deviates from expected dialogue when it generates incorrect conversations. ,218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Weakness,"- The nonlinear transformations in the neural works, such as $exp$ and $tanh$ have not been considered in the theoretical derivations. ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387
71e7b95a72af9ac8519665285f1c20f8f8864dc212f5477ffd96c88ab2a42ae84a3e1a5eb93606189083f3c1271d360fde8eb2d0c0d81ef42c2692f8be1d897c,arr,Weakness,The second concern is that the reason of excluding 25% of the word phrases said in the last paragraph in 4.1 and the reason of using first 50 examples from the OntoNotes test set is not be fully discussed. ,163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Weakness,The explicit: option A system is not a meaningful system in itself. ,319 320 321 322 323 324 325 326 327 328 329 330
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Weakness,It assumes that the resultant GAA model is performant enough to provide meaningful prompts to annotators. ,502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Weakness,"My main concern is that the experiments do nothing to distinguish between the main claim that argument structure constructions (a la construction grammar) are encoded in models, from an alternative explanation that surface features correlated with (but certainly not) argument structure constructions are what these similarity metrics are picking up on. ",295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"This is followed by, “Then, an edge is added between each event node and corresponding cluster node to allow reasoning among cross-document coreferential events.” ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Weakness,"While the authors have explained their reasons for not doing so in the author response along the lines of ""Those systems are not state-of-the-art"", they have compared the results to a number of earlier systems with worse performances (Eg. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,"2020.
",250
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Weakness,    ,
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Weakness,"The authors utilize GPT to estimate the importance of x, which is reasonable. ",148 149 150 151 152 153 154 155 156 157 158 159 160
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,Some points are slightly over-claimed. ,418 419 420 421 422
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Weakness,1. ,108
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Weakness,"
3) The results of the negative penalty scheme show that the proposed uncertainty measure is not that useful in common cases such as 3:1. ",331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Weakness, ,
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Weakness,"Additionally, it seems that GPT is used for utterance and BART for summarization but it will be good to add results for both the models across the tasks to see their impact. ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
dd23042b3a19ead6484687423764d8156f6ea40cec4ccceb6d27ccc6305223ed76957ad46eae750d95766cc378fb0b332d4fcd737dc810c4bee6e8823ca79884,arr,Weakness,"The languages in this paper are some rich-resourced languages indeed, the authors need to test Prix-LM model on some low-resourced languages. ",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Weakness,"With the method described for extracting morally framed argument components on a given topic, it is possible that other differences may also be present. ",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
0805cef3514c6a8a408cb365fd19199aaee44bbc746bb7bc13c51afa2bd0cfdd0e9165c5a40142bf664015f97a59341d81ff0ce405993bbbbaeb8110390c3739,arr,Weakness,The description in the paper use word error rate (WER) all the time. ,120 121 122 123 124 125 126 127 128 129 130 131 132
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Weakness,The authors do not give any explanation or definition of the evaluation metric used. ,147 148 149 150 151 152 153 154 155 156 157 158 159 160
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Weakness,"It would have been nice to see some examples of predictions and explanations of the models in the paper, and in general some insights from qualitative inspections of the data. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,"in [518-521], the authors mention ""We further re-implement BERT^2 proposed by (Yang et al., 2020), and the performance is not so strong as the published state-of-the art like models 9, 10 and 12."". ",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,"Without going to the original paper on CrowS-pairs, the values are barely understandable. ",536 537 538 539 540 541 542 543 544 545 546 547 548
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,"
 - While most of the results are clear, I had difficulties interpreting the figures. ",206 207 208 209 210 211 212 213 214 215 216 217 218 219
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Weakness,Otherwise the algorithm can be run independently of the annotators; one could pre-segment all data automatically and then present it to annotators for correction. ,265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Weakness,"- Based on the empirical analyses (Table 2), it is not clear if pure worst-case-aware sampling ($\phi=0$) is consistently better than pure loss-proportional sampling ($\phi=1$). ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Weakness,"However, some of the topics are not totally covered. ",173 174 175 176 177 178 179 180 181
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Weakness,"The intuition is that given the low pred-wise consistency, the label annotation agreement should be even lower because all labels related to inconsistent predicates are different. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,"Now, the question is what happens if you use predicted cues? ",135 136 137 138 139 140 141 142 143 144 145
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Weakness,"Due to space limitations, parts of the survey tend to very quickly skim over individual papers that does particularly help with understanding their main goals. ",259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Weakness,"By assigning multiple weights, we can still assign higher weightage to minority classes rather than considering the average losses in the group.
",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Weakness,-The motivation of proposing three new probing tasks is not obvious to me. ,148 149 150 151 152 153 154 155 156 157 158 159 160
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,8. ,611
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"They have low performance in unimodal DST, to the best of my knowledge. ",508 509 510 511 512 513 514 515 516 517 518 519 520
9f16d7fbb89be40b6fa6ff149aa34cfcad08f2a811b1bef57d6136992bef789a65da497e685cbeb4e29335b120aaf58d3d7240a775eb25c9fe8bec3fa6bf4ffc,arr,Weakness,"Making a Point: Pointer-Generator Transformers for Disjoint Vocabularies.""
",122 123 124 125 126 127 128 129
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,"However, the deviation is not small according to this figure. ",364 365 366 367 368 369 370 371 372 373
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Weakness, Some examples and statistics would be helpful. ,162 163 164 165 166 167 168
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,Zero-Shot Transfer Learning for Event Extraction. ,346 347 348 349 350 351
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,"On QQP, both full fine-tuning and BitFit suffer very similar drops. ",202 203 204 205 206 207 208 209 210 211 212
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Weakness,"-The human evaluation helps somewhat but is very limited because it lacks comparisons with other methods.
",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,"
1. ",130
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Weakness,"It seems by looking at Figure 4 and 9, that the best performance append before reaching this point. ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Weakness,"If this is different from prior work, that would be unfair and a major flaw. ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"A stereotype is a commonly-held association between one group and some attribute or behavior; although most stereotypes involve negative attributes or disfavored behaviors, a stereotype is not inherently negative. ",590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,"More real estate should be allocated in the main paper to explaining those two, so that the reader is not forced to look at the appendix to understand the main body of the paper.
",460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,Is this conclusion really justified? ,306 307 308 309 310
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Weakness,"This limits the application of the proposed approach if there is no attribute given but the text is implicitly offensive.
",277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"For example, in abstractive summarization tasks, previous studies proposed the method which combines additional information such as length embeddings to embeddings of input tokens [Kikuchi et al., 16, Takase et al., 19].
",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300
bd9e1f80c81f4619d7b93cff38f4ca9e4642566c30cfbbd2b934b29262b4770edd6afc39af1d95c895d124f3b8631b150c371e4af90609ab6780222f71ce8fdd,arr,Weakness,"energy consumption, but does not improve speed as GPUs do not benefit from this change. ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness, ,
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Weakness,1) How was the quality of reviewers' final golden decisions assessed? ,137 138 139 140 141 142 143 144 145 146 147
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Weakness,It would be better if the authors provide some explicit cases or discussions to explain how pre-training on KG link prediction can improve performance on KGQA compared with the previous representative works later. ,112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Weakness,-I don’t understand why generating question-in-context lags behind the question-rewrite method. ,390 391 392 393 394 395 396 397 398 399 400
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Weakness,"Having said that, I am not aware of works applying those approaches to open-domain dialog generation. ",293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,1. ,97
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,[2] Soft Layer Selection with Meta-Learning for Zero-Shot Cross-Lingual Transfer. ,251 252 253 254 255 256 257 258 259 260
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Weakness,"
3. ",221
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,"For example, if the conversation is about a deceased person, past tense is presumably used frequently and only a tense change to present can make the conversation flawed. ",422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"The definition of ""bias"" is debatable. ",537 538 539 540 541 542
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"In only 38% of datasets does the best zero-shot prompt match the best prompt to use for transfer (And of these 5 successes 3 of them are based on using MNLI, a dataset well known for giving strong transfer results [(Phang et al., 2017)](https://arxiv.org/abs/1811.01088)). ",1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Weakness,1. ,277
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Weakness,"While the authors mention leaving this to future work, the study of how many groups to divide each layer into is missing and how sensitive is model performance to the choice of number of groups is missing → how does the proposed group dropout compare to just a regular dropout with group size = 1; I think this is important because the paper proposes “Latent Group Dropout” and whether group dropout is needed or not is a key question that is not experimentally verified. ",345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Weakness,"I'm curious about the strong performance of the RoBERTa model - could it be that this kind of classification task isn't particularly difficult, if we give the model enough training and data? ",398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Weakness,"While debatable, my biggest concern with the paper, or this line of work in general, is if the direction is really worth it.
",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Weakness,- The paper hypothesizes that SimCSE suffers from the cue of sentence length and syntax. ,286 287 288 289 290 291 292 293 294 295 296 297 298 299 300
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,In the prose (and Appendix A.3) it is stated that labels are based on the predictions at `[MASK]` for RoBERTa Models and the T5 Decoder for generation. ,943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"EMNLP 2020.
",480 481
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Weakness,"could produce better embeddings, and that the observations in these works do not necessarily hold in those larger and better models. ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
For example, I think the authors could conduct a quasi-limited experiment using a European language for which a large amount of data is available. ",505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Weakness,are moved to appendix which disrupts the reading flow. ,212 213 214 215 216 217 218 219 220
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,-Difficult to see how this can extend to the structured prediction encoder/decoder setups used quite often across NLP. ,821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"[2] Hongming Zhang, Haoyu Wang, and Dan Roth. ",354 355 356 357 358 359 360 361
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,al. 2019 is not discussed when it is almost the same thing although the use case is different (for Automatic Post Editing). ,285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"Their work however does not really seem to serve well as a baseline since it does not entail a *method*. Rather, they created a corpus to conduct an analysis on the semantics of greetings. ",683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,"Both building blocks of the mix-GLT: GLAT and LT are from previous papers.
",198 199 200 201 202 203 204 205 206 207 208 209 210
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"vs. [text] #1 produces which materials?), ",482 483 484 485 486 487
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Weakness,"A transformation that has different effects based on context is not necessarily a systematicity violation.
",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Weakness,"Although the author mentioned the leverage of tools such as Wikipedia or Google search in l357-l365, it still has strong subjectivity. ",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Weakness,"The authors need to show their task is more useful than vanilla language modeling task on more downstream tasks, such as QA or summarization. ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Weakness,1. ,157
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Weakness,No obvious weaknesses. ,147 148 149
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Weakness,"I would recommend to run PGD with more steps, at least for one of the downstream tasks, to provide a stronger baseline. ",227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Weakness,"As the major contribution of the paper, justifying the design choice matters. ",412 413 414 415 416 417 418 419 420 421 422 423
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Weakness,"For example, what do the labels, “mask-1”, “mask-2” and so on mean? ",161 162 163 164 165 166 167 168 169 170 171 172
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Weakness,"The main weakness of the paper is that some of the proposed approaches lack novelty - ""interleaved learning"", ""labeled learning"", ""multi-task labeled learning"" were studied extensively in the MT community. ",263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Weakness,"How many annotators worked on that, what was their expertise, language fluency. ",308 309 310 311 312 313 314 315 316 317 318 319
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Weakness,"The implications discussed in the paper apply *if* one were to try to project continuous prompts to discrete space using GPT-2's (or any other) embedding matrix, but, as far as I am aware, no one has attempted to interpret continuous prompts in this way. ",349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Weakness,Weaknesses: ,290
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Weakness,-The chosen evaluation metrics are neither appropriate nor insightful for the task. ,99 100 101 102 103 104 105 106 107 108 109 110
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,"In line 84, when you say ""better few-shot accuracy than standard fine-tuning"" did you mean fine-tuning over the entire dataset or fine-tuning in the few shot scenario? ",566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Weakness,"
With this standard cross-modal architecture, it is unclear to me why the proposed approach could resolve the example in Fig. 1, while the other approaches failed to achieve.
",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Weakness,"Generally, I found the evaluations could have been stronger. ",277 278 279 280 281 282 283 284 285
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,There's no significance test mentioned in the paper. ,124 125 126 127 128 129 130 131
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Weakness,The idea of neural pipeline method for data-to-text generation is not entirely new. ,252 253 254 255 256 257 258 259 260 261 262 263 264
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,2. ,198
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Weakness,- More details on how exactly the topic related chit-chat turns would have strengthened the paper. ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"For example, I think it is vague to say that the fantasy novel is more “canonical” (line 355). ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"Secondly although the CogTaskonomy framework is introduced as a combination of two separate methods, there is no analysis how important their combination is. ",250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Weakness,"
3. ",135
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,"It makes for an interesting contrast for the two thinkers, but it also seems to me to be a bit unfair to Harris since it’s hard to counterfactually reason about how Harris would have reacted to the current state of NLP. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Weakness, ,
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Weakness,What specific problem that previous approaches cannot solve but this paper can resolve? ,53 54 55 56 57 58 59 60 61 62 63 64 65
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Weakness, ,
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Weakness,"Similarly, I wonder what's the need for computing the Tucker Depth, and not just using the closest vector in terms of cosine similarity. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Weakness,It would be great if the authors can provide some qualitiative analysis to help readers understanding the quality of result. ,285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,"Specifically, no definition of ""model reasoning process"" is given. ",432 433 434 435 436 437 438 439 440
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Weakness,The evaluation is done on (as far as I can see) no standard splits of the datasets. ,170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Weakness,but the same can be said when comparing to T5-base although at a less impressive speedup. ,385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Weakness,Although I believe this doesn't affect the contribution of this paper. ,194 195 196 197 198 199 200 201 202 203 204
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,"The last question can be important for future research.
",335 336 337 338 339 340 341 342 343
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Weakness,1. ,128
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Weakness,That is treating humans (or a group of annotators) as a black-box (same as neural network model) and checking whether the proposed transformation indeed produces valid comparison. ,90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,Motivation ,361
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"
4. ",429
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"The x-axis of the graph is time, when it would have been more convincing using steps. ",802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Weakness,"How can this be improved?
",250 251 252 253 254
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,"The readers who follow the technical area closely might understand how informative contrasting the proposed method and the baselines are, but for others like me, they look like random choices. ",463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Weakness," I don’t know whether there was just some bad editing around this section, but I really don’t know what the MLE baseline method is supposed to be. ",483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,Does the extent to which the teacher model is negative affect performance of the student model? ,160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Weakness,"Authors claim to be presenting work 'diagnosing the language understanding ability of Chinese BERT models', but the probing tasks introduced can hardly be described as testing understanding. ",113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness, The numbers from Table 1 generally support that this as a good proxy method as 76% of datasets show small improvements when using the best zero-shot performing prompt as initialization when using T5 (although only 54% of datasets show improvement for RoBERTa). ,1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Weakness,"
4. ",561
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Weakness,"While this is done in a scientific way, the authors do not consider other avenues for testing that make more sense such as random experiments based on other work. ",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
c476e1916a5e04f95f17a9f2fd62d74fa664c84ea9dcaecf96db78dee71eeb770dff7d76c1e4abe6919622db6936040e8ecc60b449d3472f9457a322c9be0d7e,arr,Weakness,-The differences in results in Table 2 are very small that make the interpretation of results rather difficult. ,130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Weakness,"Despite the motivation and presented statistics, the paper could transmit a better overview of the proposed challenge. ",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Weakness,c) how many annotators labeled each sample (and how many annotators were there in total)?; ,387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Weakness, ,
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Weakness,"- Overall, I feel that the paper is trying to do a lot of things at one go. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Weakness,were not well motivated and did not add much to the presentation. ,199 200 201 202 203 204 205 206 207 208 209 210
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Weakness,"I think specially when we're talking about an end2end solution, it is very interesting to see undesirable examples. ",200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,There are a lot of problems that I can imagine for real-world large scale models such as GPT3. ,170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,-The first is whether the proposed method generalizes to other contexts. ,176 177 178 179 180 181 182 183 184 185 186
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,"To assess the translations, more information about the language/translation expertise of the authors would be helpful (I don't think this violates anonymity). ",486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,Some intuition/justification could help readers to follow the key idea. ,204 205 206 207 208 209 210 211 212 213
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,The author does not really collect feedback from human users but derives them from labeled data. ,307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,"Although the right to be forgotten supports this approach, these speakers donated their voices to save endangered languages: as such, not exploiting these data seems to go against their own goal when they donated the utterances. ",277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"The extension to the unimodal DST definition is good enough in the CATER dataset, but why the authors pick the CATER dataset as the basis is not obvious and lacks further discussion. ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
bd9e1f80c81f4619d7b93cff38f4ca9e4642566c30cfbbd2b934b29262b4770edd6afc39af1d95c895d124f3b8631b150c371e4af90609ab6780222f71ce8fdd,arr,Weakness,The method helps in (theoretical?) ,30 31 32 33 34
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Weakness,"
(3) It is unrealistic to assume that a defender knows which attack algorithm is used unless the authors show that the adversarial examples generated by different attack algorithms share some common features that can be leveraged to detect them. ",313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,Same question for edit distance cost? ,451 452 453 454 455 456
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Weakness,"It also likely has a considerably larger computation requirement, as the model needs to run twice for each sentence. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Weakness,"Although the average score of LaCon-vanilla is better than others mostly but the difference ranges from -0.6 to 3.6, which is a small number. ",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Weakness,So why don’t we just use the teacher model to conduct zero-shot cross-lingual NER? ,147 148 149 150 151 152 153 154 155 156 157 158 159 160
7e23ee6e56ace10f42339e73b598425e2f2f0f8539fed8f42a514d3a80a537553522ece6eca40ded1d3e587222531371a27d268cbb3ba00f80c3ba8cb0bf286d,arr,Weakness,Nothing particularly wrong here. ,217 218 219 220
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Weakness,"
Some important details of data collection and data generation are omitted. ",64 65 66 67 68 69 70 71 72 73 74
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Weakness,"
2. ",91
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Weakness,The author mention uniformity / alignment which is win in and off itself but they do not present any results based on these metrics (e.g. in https://arxiv.org/pdf/2104.08821.pdf)  ,321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Weakness,-**Missing analysis of empirical running time** ,238 239 240 241 242 243
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,"Table 3) Would there be a better way/metric/visualization to show?
",302 303 304 305 306 307 308 309 310 311
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,All the experiments in the paper are limited to a single-speaker training set. ,230 231 232 233 234 235 236 237 238 239 240 241 242
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Weakness,There needs to be more detail on the implementation of spelling bee. ,369 370 371 372 373 374 375 376 377 378 379 380
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Weakness,"Later on, at line 340: this is condition is written as being bidirectional: Psrc ⇔ Pflw. ",510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Weakness,Figure 2 does not show complete trends w.r.t the training documents. ,129 130 131 132 133 134 135 136 137 138 139
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Weakness,It suggests that only using BitFit is a more wise choice. ,157 158 159 160 161 162 163 164 165 166 167
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,I'd expect a discussion of how this method relates to and differs from existing methods on zero-shot cross-lingua transfer. ,195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Weakness,The technical novelty is rather lacking. ,188 189 190 191 192 193
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Weakness,A main thread of work in this area is how attention correlate with other feature attribution methods. ,312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Weakness,The paper does not compare the results with some of the earlier research work from 2020. ,130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Weakness,I feel the major issue of this paper is the motivation example is not closely connected to the proposed approach. ,197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,No significance test: The paper claims that applying this curriculum learning method improves the zero-shot performance over the baselines by 0.4-1.2 LAS score. ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
If it is inappropriate in those languages, the authors should explain why.
",529 530 531 532 533 534 535 536 537 538 539 540
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Weakness,The paper would benefit from attempting to quantify how useful a model trained on ParaDetox is in a more general setting. ,234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,It can be unclear at times as to what they mean by standard fine-tuning - finetuning all parameters across entire dataset or fine-tuning all parameters for a sampled dataset. ,421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Weakness,"In table 5, why do “other relations” have a very different scale of perplexity compared to “erased relation” before erasing? ",386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Weakness,Additional details regarding the creation of the dataset would be helpful to solve some doubts regarding its robustness. ,193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Weakness,"- The MCTS algorithm itself in the context of text generation is not explained very well, which makes it hard to understand the proposed algorithm ",113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Weakness,"Why mention the data scarcity issue then, rather than going more into detail on the scatteredness aspect? ",241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Weakness,"-Some contributions are not clear, e.g., which datasets were available, which are released (what kind of postprocessing is done)? ",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,"If the style of the paraphrases is similar to or the same as  the original sentences, it will be very difficulty for the model to learn a good style extractor and the whole model will default to a paraphrase model. ",372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,Q3. ,101
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Weakness,"This shows that despite the intuition, the conflict actually does not matter in reality.
",188 189 190 191 192 193 194 195 196 197 198 199 200 201
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,3. ,297
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,How is the edge added? ,354 355 356 357 358
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Weakness,"-the preprocessing of the datasets (many for low-resource languages) needs resources that are themselves scarce, incomplete, or borrowed from other languages (that may use other scripts, and hence there is a transliteration problem on top of others). ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
fd2caf0a98ac82aa472d008400f29ba5bd74e77d5471c83cb7634bca4d59d5c302b38774e1e7775d5f8bf1110a26d537ba5427a759506b0a0807bc3e3590493c,arr,Weakness,"Although the experiments are very comprehensive, this paper lacks technical novelty. ",70 71 72 73 74 75 76 77 78 79 80
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,"It would be interesting to see, whether the reported results pertain across different datasets. ",178 179 180 181 182 183 184 185 186 187 188 189 190 191
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Weakness,"-Additionally, it seems to be an unfair comparison because only the contrastive-probe method was additionally pre-trained for the cloze-style task. ",250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Weakness,"The analysis and discussion    offered by Section 3 is difficult to follow because of this, and it is not    clear how instances ""similar semantics"" are tracked or computed (see, e.g.    Figure 3). ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,"
    - If not run for multiple seeds, is the <1% difference a significant result?
",227 228 229 230 231 232 233 234 235 236 237 238 239 240
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"
1. ",259
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Weakness,it would be much better to explain the problem in words in the introduction. ,393 394 395 396 397 398 399 400 401 402 403 404 405 406
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Weakness,"-Identifying rationales is not a simple problem, specifically for more complicated NLP tasks like machine translation. ",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Weakness,"In the few-shot learning, when the samples are increased from 24 to 1K, the attribute relevance drops by 2 points for positive class as shown in Table 1, and the toxicity metric becomes worse for the detoxification task as shown in Table 2. ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,https://arxiv.org/abs/2106.09685 ,367
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Weakness,"	The improvement compared to other unsupervised methods is not impressive, while there is still a big gap with the strong QE model BERT-BiRNN. ",228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,"-P-value calculation is discussed in Section 3, but no p-values are reported in the experimental results. ",896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Weakness,The paper would also benefit from a greater discussion of these close cases. ,410 411 412 413 414 415 416 417 418 419 420 421 422
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"According to Fig 2, all the pseudo sentences are the same, and I can’t see what is the motivation for that (In Fig 1 we can correctly see different sentences per instance). ",291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,3. ,245
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,-I feel evaluation with self-play is less confident. ,234 235 236 237 238 239 240 241
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Weakness,1. ,161
68c709e853fc85c4a51a2bf31e9323929a8768c91c3f21e30970ee38b5a6ecfa7ccb0abbc60c80205f631bbbaa1a83fdcb50ce32cdd591a45dfbf3dbe31d5180,arr,Weakness,I do not think this is a principled way to ascertain that the intermediate representation actually encodes the property at hand. ,218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Weakness,"However, this end goal is not covered in the paper. ",182 183 184 185 186 187 188 189 190 191
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,Writing can be improved. ,607 608 609 610
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,"Lines 179-182 Surprisingly, the trained MRC model maintained the original prediction on 64.0% of the test set samples (68.4% on correctly answered samples and 55.4% on wrongly answered samples).
",462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation EMNP 2018 3. ,320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness,"Poor efficiency**. The proposed method contains three different modules, each containing an unshared PLM so that the amount of parameters is three times that of the End2End method. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Weakness,I feel they're a strange kind of sentence with a somewhat difficult semantics even for humans. ,329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,-Hidetoshi Shimodaira. ,241 242
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Weakness,The study is not well motivated. ,117 118 119 120 121 122
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"To me, the difference between FairytaleQA and other reading comprehension datasets on stories and narratives is not obvious. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Weakness,"This is most of the way towards being an excellent paper, but it drops the ball in this respect. ",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,"Footnote 6 discusses work on multi-intent identification on ATIS/MultiWOZ/DSTC4 and synthetically generated multi-intent data (MixATIS and MixSNIPS), but this is not discussed in detail in the main text. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Weakness,"Though this paper has conducted comprehensive experiments on knowledge related tasks, it would be even stronger if they demonstrate there also exists improvement on the multilingual knowledge-intensive benchmark, like KILT. ",130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Weakness,The points shared in this section in my review for the previous submission have been clarified in the author responses and/or incorporated in the revised draft. ,459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Weakness,It is not entirely clear what is novel here and what is taken from prior work. ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"For instance, [1] directly combines BiLSTMs with GCNNs and label features in a very similar manner to the method proposed in this paper, albeit with exceptions such as [1] does not use dilated CNNs. ",366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Weakness,"While it is understandable that all these experimental settings require lot of time and human effort to conduct, the fact that this has been tested only on one dataset raises concerns about generalizability of this framework. ",588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,"
2. ",565
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,"-Another simple baseline is to have two separate models: one for tasks that lead to “task interference” like QQP, another for other tasks. ",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,-It is not clear if authors also experimented with the usage of domain ontologies to avoid the generation of placeholders in the evaluated responses  ,265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Weakness,"In this paper, both hierarchical position embedding and section title embedding are borrowed from other papers, so I would say the contribution of this paper is not substantial.
",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,"**What is contributing to the performance improvement?**
",90 91 92 93 94 95 96
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,How was this bin-size hyperparam selected? ,799 800 801 802 803 804
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Weakness,-There is a lack of information about how to give annotations to selected data. ,121 122 123 124 125 126 127 128 129 130 131 132 133 134
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Weakness,"-From row 2-4 in Table 3, the claim “KeyBERT outperforms other two keyword extraction methods.” ",171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,A PCA/TSNE plot of the new embeddings compared to the previous embeddings can be informative to show the changes after post-processing. ,514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,Sampling-based MBR decoding is very new in MT and has a lot of potential to be more optimized in the future. ,379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,This crucially impacts the subsequent steps because the model will greatly rely on the quality of these paraphrases. ,294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Weakness,I think there should be more exploration and analysis in these aspects. ,306 307 308 309 310 311 312 313 314 315 316 317
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Weakness,1. ,215
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Weakness,3.3 puzzled me the most. ,160 161 162 163 164
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Weakness,-The performance improvement from audio-only to audio-visual is very small (WER: 2.7 to 2.6) and there is significance analysis. ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,Will this impact the correctness of the language model scores (log p)? ,374 375 376 377 378 379 380 381 382 383 384 385
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"From your results, I assume the sense embeddings are not normalized. ",658 659 660 661 662 663 664 665 666 667 668
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"Last but not least, the high-quality template and keywords may not always be available in real applications. ( ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Weakness,"From my understanding, replacing entity mentions of the same context should not largely change the relation semantics.
",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,"An example of the way in which ACL is not necessarily set up for this kind of work is that I have to select whether the work is reproducible: I picked ""1 = They would not be able to reproduce the results here no matter how hard they tried."" ",505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553
68c709e853fc85c4a51a2bf31e9323929a8768c91c3f21e30970ee38b5a6ecfa7ccb0abbc60c80205f631bbbaa1a83fdcb50ce32cdd591a45dfbf3dbe31d5180,arr,Weakness,It is computed by subtracting the performance of the probe with re-assigned labels from the reported proxy task performance. ,245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,"Accordingly, I am still a little bit confused about the relation between instance difficulty and training-inference consistency after reading the paper. ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Weakness,- Several important aspects of the approach are underspecified: How are the meaning representations segmented into individual facts (Section 2.1)? ,91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Weakness,- No comparison across languages (only De target language) ,122 123 124 125 126 127 128 129 130
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Weakness,"1) Although the proposed method is indeed interesting, the  authors do not make any attempt to compare it to any other prior methods. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness, ,
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,"To Reviewer2.2**: Good answer.
",274 275 276 277
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,since it's hard to imagine some other set of authors deciding to read Harris and Firth and writing the same paper :-). ,554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness, ,
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Weakness," I think the contribution of the paper lies in more on the engineering side: results on more test-sets to avoid overfitting, speed comparison not only on 1-batch GPU setting but also on x-batch and multi-cpu settings, etc. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Weakness,"Thus, readers cannot judge whether their method can mitigate the “similar relations and similar entities” problem or not. ",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Weakness,"-The development and exact form of the loss function (Eq 1) is unclear.
",141 142 143 144 145 146 147 148 149 150 151 152 153
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Weakness,- The extract-then-generate can be re-phrased as a two-phase summarization system that can be either trained independently or within an end-to-end model. ,189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Weakness,The model architecture description is rather confusing and sometimes uses inconsistent notation. ,257 258 259 260 261 262 263 264 265 266 267 268
f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297,arr,Weakness,I feel the design of NVSB and some experimental results need more explanation (more information in the section below). ,62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,"That would work.
",368 369 370
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Weakness,It would strengthen this paper if authors further explored systematic biases in their datasets and models (e.g. how does accuracy/F1 vary by district?) ,319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Weakness,"As reported at L373, the proposed method rewrites 12% of the questions for all models (\~45 questions per model), which hardly has a significant effect.
",365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Weakness,"
2. ",201
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,"If by humans, what was the agreement? ",316 317 318 319 320 321 322
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Weakness,"I would suggest changing the name to something more precise; perhaps “faithfulness”, since what you’re really testing is the correspondence between the relations the model encodes and the relations that exist in the output? ",434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,"Regarding SE and SS, given that SSL models are trained only on clean read speech it is not properly justified why such tasks are relevant. ",272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Weakness,A brief discussion of the motivation and selection of the auxiliary tasks seem needed in Section 3. ,231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Weakness,"
2. ",273
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,So I highly suggest considering schema generalization where the schemas differ between training and testing and additionally evaluating schema prediction. ,409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,What unchanged samples are you referring to? ,559 560 561 562 563 564 565
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"Also, does the attribution map for the input examples that failed to be classified also work well? ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Weakness,Now we append the same transformation to the text: “It doesn’t run!” ,213 214 215 216 217 218 219 220 221 222 223 224
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Weakness,"Also, it is unclear if techniques that can reduce memory usage (e.g., gradient checkpointing) are used by the authors in this paper to reach longer inputs.
",255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Weakness,"Although they conduct human evaluation, the evaluation metrics are not closely related to the educational purposes. ",342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Weakness,"There are only some minor revisions compared to the last version, where they fix some typos, moving part of human evaluation results into the main part, and change few expressions to make them more clear. ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"However, even after changing those, I ran into a number of other errors. ",319 320 321 322 323 324 325 326 327 328 329 330 331
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"al 2016), extracting “Hercule Poirot” “is” “a Belgian detective” from the sentence  “Hercule Poirot is a Belgian detective, created by Agatha Christie” might not be specific enough (as the modification here seems restrictive). ",371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Weakness,"To me, it seems that ""contextual descriptions"" is a bit too vague and generic as a term for describing the contribution. ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Weakness,And some of these may arise by chance given the relatively small sample size. ,366 367 368 369 370 371 372 373 374 375 376 377 378 379
5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec,arr,Weakness, The authors mostly applied conventional approaches like SVM. ,42 43 44 45 46 47 48 49
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Weakness,"In Equation 4, the test checks whether Psrc => Pflw. ",500 501 502 503 504 505 506 507 508 509
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
For experiments with such a small amount of data, I think a confidence interval should be shown.
",427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Weakness,"Hence, I would argue that the layer conductance analysis is actually not measuring what the authors aim to measure and the conclusions should be revised. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,How many questions are required for each article? ,293 294 295 296 297 298 299 300
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,"energy consumption is only estimated within the attention module, even though the reduction in a Transformer block is added (17%), the reduction of the full model (with the classifier) is not reported. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Weakness,"Based on my understanding, what this paper does simply is to provide an indicator to prevent tedious search on flood level. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Weakness,"- While the language has been improved, there are still some awkward phrases. ",204 205 206 207 208 209 210 211 212 213 214 215 216
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,"For instance, one can know that “Tokyo” is definitely a wrong answer to the question “What is the capital of South Africa?”. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Weakness,Some lines look very similar and not distinct (e.g. MMA and MM[100%]). ,249 250 251 252 253 254 255 256 257 258 259 260
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,their underlying ideas are valuable. ,342 343 344 345 346
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness," In such case, the attention in EQ1 would always output a weight matrix of shape [m, 1], i.e., a vector of all 1s. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness," Although the proposed approach achieves good improvement, it is unclear whether the improvement is significantly better than the baseline systems. ",319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"
-	The paper lacks a sound discussion to explain certain observations. ",426 427 428 429 430 431 432 433 434 435 436
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Weakness,See the prior review. ,140 141 142 143
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Weakness,"Generally speaking, do we have a good reason to believe that these adversarial attacks are realistic? ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Weakness,"Some in our community may find this work, and its domain, rather niche; this paper would be a great fit for the BEA workshop. ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,Why not adding more annotators? ,207 208 209 210 211
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Weakness,Missing explanations about why the models found the automately generated contrast sets more difficult than the human contrast sets. ,199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Weakness,"In the appendix the authors note that the best-first search code could be optimized relatively easily, but one question that doesn’t seem to be answered is: compared to the baseline approaches, how much longer does it take to generate outputs, at least as the method is implemented now?
",292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339
44e7ab41a54cab53f17e79871feb2713cc16df873abd22f680ff5a4c0366953bb1c6c359fd3fd84fa68c262345dae767a3250a4249f7a0583a6569f44fdaa4d1,arr,Weakness,I do not have any concerns about this paper. ,84 85 86 87 88 89 90 91 92
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Weakness,"It took me some time to understand that the schemata introduced in section 2.1 are also considered when designing the new taxonomy (Table 1), making this more explicit (already in section 2.1) would help to make this more clear. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Weakness,"If the point of the early-exiting program is to save computation, then the most straightforward to reduce computation is to try a smaller model (simpler than a large model that does adaptive inference-time things which are not present during learning). ",489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Weakness,"However, what I see is completely different. ",203 204 205 206 207 208 209
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Weakness,Most of the works in literature (and also cited in table 1) use 8k (eg. ,439 440 441 442 443 444 445 446 447 448 449 450 451 452 453
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Weakness,The paper doesn't show how tertiary claim classes and visual claim classes can help in fake news detection. ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Weakness,"It would seem to be a closer comparison and it might prove to be better baseline against NPRM, etc.
",110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Weakness,The paper presentation could benefit from a rewriting that focuses on introducing the problem of personalized KGC and motivating it. ,347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,"However, is the phrase “preventing the model from rote memorizing the entity names or exploiting biased cues via eliminating entity name information” is used, it would help the reader if a connection is made to the actual solution which is mostly referred to as “eliminating task-specific nuisances.”
",380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Weakness,I would have liked to see more analysis around the quality of the collected dataset and the amount of noise it potentially has. ,267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Weakness,"
  - In multi-domain dialogue, the length of dialogue is often long and the information of schema is more complex. ",119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Weakness,It's not bad. ,229 230 231
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness,"There is pretrained language models e.g., based on Longformer where you could encode more passages. ",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Weakness,"But given that it is only a short paper, it is probably not critical (the paper makes enough contributions otherwise) ",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Weakness,"Upon several re-readings, it became apparent that what the authors    actually refer to is lexical overlap (at least as evidenced by Probs C and D    in Figure 1). ",293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,1) I would have liked to have seen a better application domain motivation for why the OOV problem in NER is so important. ,222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Weakness,"While the metrics have their own problems, it would be a good way to compare systems without expensive human evaluation. ",273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Weakness,Comparison (either empirical results or theoretical justifications) to existing load-balancing methods are missing. ,291 292 293 294 295 296 297 298 299 300 301 302 303
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Weakness,"from a distribution on $[-1, 1]$. Is this. ",283 284 285 286 287 288 289 290
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Weakness,"
3. ",368
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Weakness,Smoothed Representation and Mixup Strategy are not proposed by the authors. ,46 47 48 49 50 51 52 53 54 55 56
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Weakness,What is the percetange of male and female singers? ,324 325 326 327 328 329 330 331 332
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,After reading the response: ,176 177 178 179
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Weakness,What is the solution for the same? ,135 136 137 138 139 140 141
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Weakness,-References to the supplementary material/appendix are missing in the main text and should be inserted in the appropriate locations. ,148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,The problem formulation is flawed. ,244 245 246 247 248
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Weakness,It would be interesting to see some comparison between different models. ,239 240 241 242 243 244 245 246 247 248 249
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Weakness,"To me the motivation for the proposed taxonomy is a) that it combines different theories therefore is more complete, missing values have been added and b) that is has different levels of granularity which is useful for both, quantitative analyses and machine learning. ",418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Weakness,The main weakness is that this method can only be applied to the event types and argument roles defined in the ACE dataset (which are not a lot). ,208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Weakness,"There is of course a fair amount of creativity in the pairs, which may yield some strange inferences. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,"Second, they also do no comparison with other domain adaptation methods, such as those work cited in Section 8. ",571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,I don’t think this is fatal though. ,279 280 281 282 283 284 285
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Weakness,1. ,75
262843a4c9c8009e43c652fd03dead78e120f32d62499d0826136d5c4e1204d19e1bcc09ae3b3c7a938f919e9e86262d824cc86c483e18e874e11562461a1524,arr,Weakness,"Reflection on how to mitigate this bias, or discussion of machine learning/other unsupervised approaches to reasonably expanding this list, would be welcomed. ",135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness,Providing more insights how the number of passages influence performance (beyond what is mentioned in paragraph around line 243) would make the paper stronger. ,226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Weakness,It is not clear when deletion operation is used in the refinement period. ,111 112 113 114 115 116 117 118 119 120 121 122 123
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Weakness,"Based on the examples, it seems to be a very ""dumb"" baseline. ",271 272 273 274 275 276 277 278 279 280 281 282
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Weakness,What happens if att^a_u is made equal to att^u_u . ,184 185 186 187 188 189 190 191 192 193
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Weakness,"-while the models are reasonably state of the art (based on ELMo and in line with Lee et al 2018 and Feng et al 2021), newer research such as the Xia&vanDurme paper use more recent language models such as XLM-R as the base model, which may lead to better performance overall ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Weakness,Would be helpful to report variance for finetuning under different random seed settings. ,176 177 178 179 180 181 182 183 184 185 186 187 188
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Weakness,1. ,155
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,My main concern is the limited Effect in real applications. ,64 65 66 67 68 69 70 71 72 73
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Weakness,The post-processing seems complicated. ,130 131 132 133
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,This is not a fatal flaw. ,848 849 850 851 852 853
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Weakness,"So I am left wondering if the conclusions would have been different if the larger-data evaluation included languages with non-concatenative morphologies.
",403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Weakness,"This hybrid approach has been shown effective in several previous works, e.g. https://arxiv.org/abs/2005.00181 or https://arxiv.org/pdf/2004.13969.pdf (and many more) ",151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,-The paper can also benefit from an error analysis. ,344 345 346 347 348 349 350 351 352
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness,Why do you restrict yourself to a maximum sequence length of 512 by using BERT? ,196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,2a) Figure 2 shows how different annotators (for the same language) referred to different time ranges for the same part of the day. ,389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,"
3. ",286
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,I think it is of general interest whether the proposed method actually controlled task weights nicely and/or the other baseline methods assigned task weights poorly and resulted in worse performances and due to that. ,349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Weakness,"The argument feels more like, the change in attribution scores is with respect to the change in samples which eventually will meet a different model reasoning process?
",680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Weakness,"I understand that there should be details about the creation, evaluation and analysis of CORWA. ",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Weakness,"-Dataset details -- I couldn’t find any reference to these datasets, are they new? ",286 287 288 289 290 291 292 293 294 295 296 297 298 299
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"Also, for instance, in 5.1 the analysis is carried out for Italian only, but the choice for such a decision is not given. ",789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Weakness,- Case visualization contains only two examples of each instance and consists of mere conjectures about the reason behind their model’s performance and errors. ,174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Weakness,"
How to train the LOG-CaD and MASS models for complex definitions and the ACCESS and MUSS models for simple definitions? ",132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,"The difference between full fine-tuning validation and test also seems to be within 3% from this table and given that experiments haven't been run over multiple seeds, the conclusion about the lower generalization gap is unformed. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Weakness,"This gets, especially, higher priority as the results of the HiStruct+ model vs. baselines are close to each other. ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07,arr,Weakness,"Also, discussing and revealing the reason why NMT still needs this re-weighting even though the NMT model can in principle implicitly capture them would be really helpful. ",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Weakness,-It is positive that such a range of different visual-linguistic models have been examined. ,312 313 314 315 316 317 318 319 320 321 322 323 324 325
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Weakness,1. ,55
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,It's not surprising that the major performance contribution comes from the pretrained language model (BART). ,430 431 432 433 434 435 436 437 438 439 440 441 442 443 444
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Weakness,Lack of screenshots of the experimental interface ,362 363 364 365 366 367 368
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Weakness,"While it is fair to say that two annotators might have different answers to the same question and both might be correct, it would be better to verify that the answers provided are all valid. ",202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Weakness,"As such, the dataset may have limited usefulness in the further future. ",541 542 543 544 545 546 547 548 549 550 551 552
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Weakness,"I suggest using a typical time-series forecasting set-up, that is, using a sliding window of historical data for training and test on later ones. ",310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Weakness,"In Table 2, I wonder why the authors do not report the results of XLM-R+Concat, which is an important baseline for the proposed method. ",104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Weakness,"-Fair amount of repetition, which is sometimes helpful but can also be a bit distracting (e.g., the difference between inductive learning and transductive learning is explained a couple of times, same with how they used BERT vs. DistilBERT) ",136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
80f0f27bae63d383650b5083d56d54d49670478d69ab16c333d994ebabdcc2558eff25814b0b8333c8a9865b96d20dc0e171383473a1e65de16556abe5eef90c,arr,Weakness,"
(e) Though the paper is focused on syntax guided paraphrase generation, it would be nice if the authors can discuss Si_SCP’s gain in comparison to unsupervised paraphrase generations [Krishna, Kalpesh, John Wieting, and Mohit Iyyer. "" ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Weakness,The proposed framework just concatenate lexical and syntactical conditions as input to achieve the goal of controllable paraphrase generation. ,109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Weakness,"The approach is derivative, meaning it takes two existing approaches and combines them. ",216 217 218 219 220 221 222 223 224 225 226 227 228
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Weakness,The overall writing is poor. ,135 136 137 138 139
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"Compared to cross-task transfer, the gains are minimal and the convergence speed ups are small. ",1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Weakness,I think Appendix B.4 is a good example to empirically show hierarchical structures indeed increases the difficulty of table QA. ,292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Weakness,-The proposed method seems not to improve the training speed of traditional BERT in the pre-training stage. ,122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"More discussion of this criteria and how it relates to compact extractions will be helpful.
",404 405 406 407 408 409 410 411 412 413 414 415 416 417 418
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Weakness,It would be better to add one or two sentences to explain how they are connected to overclaiming. ,215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Weakness,The training cost is much larger than conventional fine-tuning or other parameter-efficient fine-tuning methods. ,122 123 124 125 126 127 128 129 130 131 132 133 134 135
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Weakness,"- The selective attention is rather straightforward.
",141 142 143 144 145 146 147
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Weakness,I am concerned about the novelty of the methods. ,57 58 59 60 61 62 63 64 65
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Weakness,Do feature attribution methods agree or diverge given words in context? ,631 632 633 634 635 636 637 638 639 640 641
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,-Adapter is a widely used framework that performs well for MTL. ,241 242 243 244 245 246 247 248 249 250 251
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,"Moreover, Section 5.1 and Figure 1 do not evaluate the proposed method's effectiveness to measure uncertainty. ",328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Weakness,"While the proposed method extends the existing approach to the entire encoder block, GlobEnc seems to reuse the tactics used in the previous method without any distinctive improvement. ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Weakness,"For a strict comparison to DPR, Top-20 and Top-100 performance should be reported with exactly those numbers of retrieved elements and without post-processing on larger sets of retrieved passages. ",283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Weakness,Can you interpret the results? ,219 220 221 222 223
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Weakness,"In my opinion, this paper is the only integration of these points of view and does not provide deeper insights to inspire audiences in related fields. ",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Weakness,"However, they only show a single sample as an illustration. ",141 142 143 144 145 146 147 148 149 150
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,"-This criticism also applies to this paper under review, since many experiments are conducted using IWSLT data. ",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Weakness,So it is hard for someone to implement this approach in practice. ,327 328 329 330 331 332 333 334 335 336 337 338
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,"Additionally, I have also one minor comment. ",390 391 392 393 394 395 396
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Weakness,1. ,108
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Weakness,It would be great to apply it to more datasets. ,190 191 192 193 194 195 196 197 198 199
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Weakness,Jumping out from the example and we could discuss the issue in a broader sense. ,410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Weakness,The idea of using boundary information is not completely innovative. ,98 99 100 101 102 103 104 105 106 107
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Weakness,"Looking at the comparison results for different evaluations - in terms of table 1, there definitely does not seem to be much difference between the two strategies (auto-rewrite and auto-pred). ",540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Weakness,[1] CTRL: A conditional transformer language model for controllable generation. ,190 191 192 193 194 195 196 197 198 199
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,Coupled with the extra time it takes to train the projector for _Task Tuning_ (which back propagation with the target model) it seems hard to imagine situations where this method is worth doing (that knowledge is useful). ,1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,"The abstract mentions "" two-fold improvements"" in perplexity, whereas the actual improvements are tiny. ",285 286 287 288 289 290 291 292 293 294 295 296 297 298
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Weakness,1. ,93
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,"It may also be good to add in more diverse sources of spontaneous speech to go beyond the design domain, such as YouTube videos or Spotify podcasts.
",191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Weakness,2. ,212
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Weakness,"In other words, is the robustness of your approach dependent on the representational capacity of attacker?
",1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness,Regarding the experiments. ,316 317 318
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,Lack of the analysis of the relation between instance-level consistency and token-level consistency:__ ,472 473 474 475 476 477 478 479 480 481 482 483 484
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Weakness,1. ,213
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Weakness,I am not very familiar with these works so it is hard for me to tell how novel this paper is in context ,198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"-Although BlenderBot is finetuned on the SGD dataset, it is not clear how using more specific TOD chatbots can provide better results ",216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Weakness,-It is hard to understand Figure 3. ,271 272 273 274 275 276 277
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Weakness,"- Experiments are performed only once, with no test of multiple random seeds. ",196 197 198 199 200 201 202 203 204 205 206 207 208
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,I checked the code of  $\alpha$-entmax implemented in https://github.com/deep-spin/entmax and find that the top-k approximation is the default option with K=100 as the default setting. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness, ,
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Weakness,"[1] Ri R, Yamada I, Tsuruoka Y. mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models[J]. ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Weakness,"- The reported improvement is marginal, while achieved with the large overhead of MC sampling. ",392 393 394 395 396 397 398 399 400 401 402 403 404 405 406
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"How to avoid annotation bias?
",306 307 308 309 310
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Weakness,"The previous LRLMs perform poorly on suffix identification compared to the RoBERTa-based model, which is trained with this task. ",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Weakness,"The experimental results on MC are not very significant, Song et al., 2020 achieve better results on agent summary in terms of ROUGE-1 and ROUGE-L. 3. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Weakness,"In this particular example, this may not be much of an issue, but for some cases, this can lead to unintended inconsistency. ",400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,What is the detailed annotation guideline? ,287 288 289 290 291 292
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,"According to Table 3, the performance of BARTword and BARTspan on SST-2 degrades a lot after incorporating text smoothing, why?
",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Weakness,"
4. ",339
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness,"Most ideas presented in the paper have already been considered before (for example, end-to-end training; enhancing retriever with knowledge distillation). ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Weakness,"In addition, some results in table 1 may not be reliable. ",236 237 238 239 240 241 242 243 244 245 246
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Weakness,There are many parts in which I believe the authors should spend some time in providing either more explanations or re-structure a bit the discussion (see the comments section). ,164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"At least, the authors should mention whether these examples occurred during the fine-tuning process. ",369 370 371 372 373 374 375 376 377 378 379 380 381 382
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"For example, as discussed in table 4, using the keywords only can lead to almost the same performance of the model. ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
a08c0e0dafb5d74615009802dfc40b3801cc6a3f779b82e40b03a3f4c3f3bef3a4186e50fbbc8ec1a5364e61382882c08f2d7b7d4689d743a8b74728f99da313,arr,Weakness,"The article is very trivial and didn't write a paragraph to summarize the contribution of the paper, which makes it difficult to focus on the core ideas. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Weakness,The writing still needs improvement. ,149 150 151 152 153
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Weakness,The comparison between ACTUNE and baseline models seems not fair. ,206 207 208 209 210 211 212 213 214 215
a2dbb4d1f528e4c6c48a51354adb882d3af65dffe69005a325d024c09982fd4dc72e38f8af529d3c0d8145db9095fa881f644d51f888c58b24b952fe51374be4,arr,Weakness, ,
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Weakness,"
4. ",303
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Weakness,Were the experts linguistic experts or domain experts? ,191 192 193 194 195 196 197 198
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Weakness,"and ellipsis (VP) respectively with the CADec model, while this work only gets 64.7, 46.3, 65.9 and 53.0. ",438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Weakness,The case study section can be replaced with qualitative and /or error analysis. ,161 162 163 164 165 166 167 168 169 170 171 172 173
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Weakness,1. ,177
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Weakness,"In particular, the authors added experiments on the new Shakespeare dataset, used extra automatic metrics to evaluate their approach and found consistent trends, clarified some questions I had about the modeling, added comparisons to recent few-shot style transfer approaches.
",344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
6695a2d16cadbaadac9a6a13d88ce4c37d0b78386799e141932cd2f36abca22fd324255f8bb1cae45c1f5eb66a945e0fcde3221c9e5cfabbde0339e17e30bebd,arr,Weakness,1. ,76
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Weakness,"The method is defined as ""semanti-driven"", but I think this is very misleading: the approach doesn't directly deal with semantics, but rather with word labels. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"-	While this model is one of its kind in this area, the language model’s scope is too narrow to have a wide range of applications. ",307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Weakness, Why would you want such a one-sided summary? ,365 366 367 368 369 370 371 372
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Weakness,Minor: ,94
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Weakness,"-The array of GLM models evaluated (e.g., GLM_{Doc}, GLM_{Sent}, GLM_{410M}, etc.) ",188 189 190 191 192 193 194 195 196 197 198
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Weakness,-Lack of clarity in the definition of the input/outputs for each subtask ,103 104 105 106 107 108 109 110 111 112 113 114
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,Some examples below -       1. ,341 342 343 344 345
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Weakness,"  I am not surprised since positive example pair in SimCSE is constructed by applying different dropout masks twice to the feedforward layer of the Transformer models, while the input to the Transformer model remains untouched. ",136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"From the results in table 1, it seems like the proposed model is more likely to help when 5%-10% of training data are provided. ( ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Weakness,"In some cases, this paper goes overboard with the analysis in what could seem as an attempt to salvage good results. ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Weakness,"Since the main point of the work is improvement in empirical performance, this needs to be made more clear.
",261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Weakness,"
2. ",175
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,"For the question annotation, how many annotators work for each article? ",276 277 278 279 280 281 282 283 284 285 286
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Weakness,"
4. ",346
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Weakness,-The claim which DPR and BM25 scores aren't comparable is not entirely correct (Line 191). [ ,131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Weakness, The paper is not truly independent given this problem (esp. ,273 274 275 276 277 278 279 280 281 282
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Weakness,M3C has several multi-choice subtasks. ,146 147 148 149 150
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Weakness,I would recommend to use the average across all tokens in a sequence as another pooling strategy to obtain sentence embeddings. ,256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"However, information about its utility and scenarios of applicability is not really elaborated (just a generic sentence at l.60) and are rather left to the reader to imagine. ",290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Weakness,1. ,156
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Weakness,- The authors should more explicitly discuss other work/data that addresses multi-intent sentences. ,78 79 80 81 82 83 84 85 86 87 88 89 90
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,"In section 3.4, the result shows that simple MLM fine-tuning on unlabelled target language data derives considerable gains against BERT-CRF baseline. ",707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Weakness,"4) The formalism you use, a --> b / c, should be introduced more clearly from the beginning. ",349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Weakness,Key concepts should be introduced  ,539 540 541 542 543
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"
8. ",1512
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Weakness,- The paper is not so clear as the introduction part does not show much background about the cognitive models. ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
25ecf77df8e811b8c942cb9933c4bd14112d1de9ed3f8989adcb669076c94472a9497f9ae80d57e03ed8fcb031fa6f84877d8faf869d641e622e8ddebd622cca,arr,Weakness,"vs ""where are they from"" can mean drastically different things, and it's unclear whether a representation that has an identical interpretation of those two phrases is what we really want. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Weakness,It is nicely summarized in related work of this paper. ,180 181 182 183 184 185 186 187 188 189
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,[1] What do you learn from context? ,434 435 436 437 438 439 440
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Weakness,"Maybe the authors should emphasize their way of incorporating alignments (alignments as context, and alignment augmentation), which I think are the main contribution of this work. ",214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,This could be done by providing more informative captions of the figures or linking back to the equations and introduced names (e.g. beta). ,264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Weakness,"Finally, this gap with finetuning is used as a motivating examples but the faster convergence times of things like their initialization strategy is never compared to finetuning. ",908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934
e41e88092bada9f75b4ce8778855411e128fea782712d728ff13b90f98386e6c97f5b383da31df5f5ad9aed07e2e3af42ad0fe8ce53e7dc9d81130c9d24a351e,arr,Weakness,"No weaknesses to me, everything looks good to me! ",62 63 64 65 66 67 68 69 70
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"Therefore, comparisons are required even if the results are not favorable to their method.
",336 337 338 339 340 341 342 343 344 345 346 347 348 349
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,it utilizes quantization technology but does not compare with the other quantization approaches. ,230 231 232 233 234 235 236 237 238 239 240 241 242
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Weakness,"The reason for balancing the test sets regarding the year of publication, not the training, is not clear.
",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,"While the authors compare with this work, they dont talk about it till section 5 (lines 86-88 dont give enough context). ",399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07,arr,Weakness,"After finishing reading, I felt the need to go back go re-examine the hypothesis to understand more and realized that I still don't understand the problem in a machine learning sense. ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Weakness,"
     2. ",420
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Weakness,"Of course, the creation of a dataset has its costs, but so does every other paper, and there are many datasets that are being released for free nowadays. ",611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Weakness, I think the author should investigate and compare more few-shot NLG methods to enhance the persuasiveness of the experimental results. ,234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,"In the paper, the only comparison with top-k approximation is Figure 2 (bottom, center). ",186 187 188 189 190 191 192 193 194 195 196 197 198 199
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Weakness," Or to phrase it differently, no such correlation is observed in the subset of tasks {QQP, MRPC, QNLI, RTE}. ",343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,"So I think there should be some caution in that framing.
",371 372 373 374 375 376 377 378 379 380 381
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Weakness,"For instance, given that the method uses sentence embeddings after a clustering transformation, I wonder what would happen if cluster centroids were directly used instead. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"
2. ",132
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Weakness,"
2. ",71
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"
1. ",350
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Weakness,- A bit unclear if LRA is actually a good evaluation setup for the method (no speed up are shown and the models used are too shallow) ,493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Weakness, ,
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Weakness,"It seems that the proposed re-writing approach makes re-written questions context-independent and self-contained (i.e., easier for the models). ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Weakness,"Besides, I not that the range of $\mathbf{W}$, $(-0.5, 0.5)$ is not equal to that of $\mathbf{w}^*$'s. ",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Weakness,"I'm not convinced that this should be an entire long paper, given that it is largely a replication of existing results. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Weakness,"Regarding the evaluations, an interesting missing evaluation is single-sentence classification tasks, such as sentiment analysis, which was carried out in similar papers (SimCSE). ",444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Weakness,There are no major weaknesses in this version of the paper. ,187 188 189 190 191 192 193 194 195 196 197
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Weakness,1) I miss an analysis for which specific examples encoding multiple passages help. ,108 109 110 111 112 113 114 115 116 117 118 119 120
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,I wasn’t quite convinced on this point. ,276 277 278 279 280 281 282
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Weakness,- the main contribution of fine-tuning a multilingual wav2vec model is not very novel. ,190 191 192 193 194 195 196 197 198 199 200 201 202 203
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Weakness,"
2. ",246
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Weakness,Googleology is bad science. ,166 167 168 169
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Weakness,Then we do not need to manually find a parameter for the schema pruning module. ,275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Weakness,The authors want to use these results to prove that there is little correspondence between continuous prompts and their interpretation. ,286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Weakness,1. ,139
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Weakness,"- The claims in the paper are too strong for cross-lingual transfer, as there are other cross-lingual techniques that are out of the scope of the paper such as annotation projection. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Weakness,Few such works are 1. ,304 305 306 307 308
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Weakness,"The models described in the evaluation rely on a number of strong assumptions, as detailed by the authors in the discussion. ",135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
6de4c24feda039f610f2f5499017edf441c88aa4ccfcd935c5311e14cb3a538507eae0a124803d5f1852a085fc55e85971be82ce03f925c776ba7dcb86604511,arr,Weakness,Most improvements of MT architectures are shown to not hold out when evaluated rigorously on a wide array of datasets and one of the problems is the dataset size: https://arxiv.org/abs/2102.11972 ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"I commend the authors for including the code and data with the submission, but I would have liked to see a script included already (i.e. not just a snippet in the readme) along with a brief description of any dependencies required beyond the requirements.txt and what one might expect when running the script.
",349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Weakness,"Overall, while this paper proposes an interesting empirical result, it makes some unsubstantiated claims and some of the conclusions from the experiments are not adequately justified. ",241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,This task of sequence refinement has been studied well in  1. ,256 257 258 259 260 261 262 263 264 265 266
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Weakness,"On the other hand, the question-replace model is trained to generate contextualized questions and its output is more likely to be grammatically correct. ",430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452
555b9b4626e46bff6dcd1dd669cac930e4e3c587766a39059797b4d5100a130d8c7aa4ee67cb74e7ebc5a9126fed58d4b54ceab34144da5a84f5d402acdf18af,arr,Weakness,How does it affect GPU memory usage? ,148 149 150 151 152 153 154
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,1. ,153
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Weakness,More strong baselines should be included/discussed in the experiments. ,169 170 171 172 173 174 175 176 177
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Weakness,COMET for instance correlates better with human judgements than BLEU [1] and goes further string matching ,176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,"-Relatively minor: Efficient BERT related papers recently often report SQuAD results as well, given that it’s a different format (span selection instead of multiple choice) and the skillset may be different from GLUE. ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,"L246: ""Then we combine the sampled data D and the trivial data D as the augmented data to train the model P in our experiments."" ",373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Weakness,"While I do see the benefits of generating adversarial attacks and the advantages of building tools that guard against them, I find this line of work, and this paper as part of it, problematic. ",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"
This paper should describe whether human can solve this task because the abbreviation pinyin configuration seems too difficult. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"
2. [ ",357 358
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Weakness,"The proposed strategy seems to need gold answers as well, which is incompatible with the real-world use case. ",642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Weakness,"
In my view, the authors’ method helps the QG model focus on the summarized event. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Weakness,This work should be mentioned. ,201 202 203 204 205
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Weakness,It's not clear whether a difference exists between training and testing. ,337 338 339 340 341 342 343 344 345 346 347
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Weakness,In EMNLP ,390 391
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Weakness,"Simple baselines (e.g., document length) that are commonly used for this problem can be used as a comparison point, in a STL setup, where the predicted variable can be different (holistic score, individual trait scores), keeping the text representation constant.
",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Weakness,"The observation regarding the correlation between uncertainty and performance is in fact an expected one, and has already observed in several previous studies (also in the context of language generation), like: ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Weakness,"- **Inefficient design of target segmentation**: If I understand correctly, all input segments are assigned a target segment. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Weakness,   ,
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Weakness,Some minor considerations: ,274 275 276
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Weakness,"
-The evaluation is a bit poor in which there is no error analysis or clear insights (what these results tell us, what is lacking, etc.) ",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Weakness,It is suggested to add the CMU-MOSEI dataset for evaluation. ,282 283 284 285 286 287 288 289 290 291
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,The exposition becomes very dense at times leading to reduced clarity of explanation. ,244 245 246 247 248 249 250 251 252 253 254 255 256
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Weakness,Reading comprehension questions for Kindergarteners are vastly different from 8th grade middle schoolers. ,300 301 302 303 304 305 306 307 308 309 310 311 312
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Weakness,"-Most of the evaluation tasks are already well-known, but had been executed separately. ",176 177 178 179 180 181 182 183 184 185 186 187 188
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Weakness,The novelty of this method seems to be marginal. ,98 99 100 101 102 103 104 105 106
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Weakness,"If we have an oracle selection algorithm, can the performance be fully recovered? ",208 209 210 211 212 213 214 215 216 217 218 219 220
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Weakness,At least they should show some samples and analyze them. ,113 114 115 116 117 118 119 120 121 122
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Weakness,"
4. ",300
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Weakness,[2] Plug and play language models: A simple approach to controlled text generation. ,200 201 202 203 204 205 206 207 208 209 210 211 212
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Weakness,"Secondly, the performance of CNN and linear SVM (e.g., LIBLINEAR) should be compared. ",107 108 109 110 111 112 113 114 115 116 117 118 119
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Weakness,-undertrained models don’t work ,314 315 316 317
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Weakness,"As the domain of data matters in the choice of architecture for generative models, this ambiubality makes it hard to gain methodological insights from this work.
",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Weakness,"In addition, four different query relations is small. ",125 126 127 128 129 130 131 132
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Weakness,"It is encouraged to introduce the motivation by a lightweight experiment, but the Introduction is not the appropriate place for it. ",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Weakness,"
2. ",144
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Weakness,"Although this paper proposes a unified framework, the design of the pre/post-nets for each task is not novel. ",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Weakness,5. ,439
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,"-Line 230: What’s n?
",335 336 337 338
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Weakness,"If the variance is high, it might be better to include an analysis of how to pick training/dev data for few-shot learning / what kind of data will be more helpful for the performance. ",214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,"In such cases it is unclear whether conclusions also apply to current MT systems trained on large datasets.
",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Weakness,"
         - why pre-training on visual-linguistic data is harmful for general NLU instead of just not beneficial. ",296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Weakness,The motivation of this new task is not strong enough to convince the reader. ,119 120 121 122 123 124 125 126 127 128 129 130 131 132
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,"The over-fitting problem is more serious in large models, so the experiment of applying NoisyTune on larger PLMs will be more convincing.
",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Weakness,It only identify negatives that are very close to the original sentence semantically. ,241 242 243 244 245 246 247 248 249 250 251 252 253
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Weakness,"At the very least, I would like to see some experiments using models trained with the Behance dataset on other domains as test sets. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Weakness,[2] Understanding Neural Abstractive Summarization Models via Uncertainty. ,472 473 474 475 476 477 478 479
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,[1] Finetuned Language Models Are Zero-Shot Learners. ,301 302 303 304 305 306 307
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Weakness,"The description in section 3 is not detailed enough.
",220 221 222 223 224 225 226 227 228
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Weakness,"Testing with a clearly non-syntactic proble, destroying syntax but keeping lexical effects by scrambling word order, or probing a model that certainly cannot encode this information. ",338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,Thus I expect that the baseline’s performance is not very much behind the other methods including the proposed method *for the averaged score*. However Figure 2 and 3 shows it performed poorly. ,229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,"But if the video doesn’t contain man, the sentence might become irrelevant)? ",153 154 155 156 157 158 159 160 161 162 163 164
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Weakness,"Furthermore, the attribution values in Fig. 1 are 0 to 1. ",383 384 385 386 387 388 389 390 391 392 393
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Weakness,- Complex attention mechanisms that are hard to interpret ,143 144 145 146 147 148 149 150 151
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Weakness,- [Possibly out of scope] The question still remains why can't a NAT learn the alignment mapping with its cross attention to different token positions? ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,My biggest concern is that the analysis doesn't provide insights on WHICH language benefits WHICH other language in a multilingual setup. ,237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Weakness,1. ,188
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Weakness,"Visually, it is not clear that the red line is “above” the green line any more with dropout than without. ",311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Weakness,"
     __4.2__. What is the value of the hyperparameter lambda of the mixup in the experiments? ",364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Weakness,"- The modeling of the mixture of multiple aspects is not explored deeper enough, and thus the so-called ""first to explore"" (in the Introduction) sounds more like an overclaim to me.
",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"Based on the approach the authors are using, [SimpleTOD](https://arxiv.org/pdf/2005.00796.pdf) (Hosseini-Asl et al. 2020) suits better since it generates dialogue states in an auto-regressive way as well. ",589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Weakness,are all missing. ,186 187 188
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Weakness,"How can we extend the idea to inter-personal knowledge, i.e. common ground?
",264 265 266 267 268 269 270 271 272 273 274 275
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Weakness,- do not provide a new system improving over the RoBERTa baseline system for the edit intention task ,62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Weakness,"Having said that, I lack expertise in ML and may not have a good feel for where this kind of studies belong. ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Weakness,"
2. ",128
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Weakness,"
2. ",181
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Weakness,The interpretation part is a little bit confusing. ,220 221 222 223 224 225 226 227
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,-Such contribution is really useful to assess to which extent models can improve downstream tasks but it does not reveal why they do it. ,377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Weakness,ICLR 2021. ,389 390
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Weakness,"Sec 6.3: The definition of ""transfer"" is unclear. ",494 495 496 497 498 499 500 501
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Weakness,- How the proposed multiple-span answer setting is essential in real-world applications is unclear to me. ,143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Weakness,An explanation of this number is necessary. ,210 211 212 213 214 215 216
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness,"
However, by information theory, any entropy estimator is destined to be no more than an upper bound of the true entropy. ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Weakness,"
2. ",218
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Weakness,The compared methods are not on equal grounds. ,204 205 206 207 208 209 210 211
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Weakness,"It is not self-contained -- the methods are only really explained elsewhere, and I was left with several questions (some listed below) ",120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Weakness,"Although the method performs consistently well with different training languages, there is less discussion on why and how this method helps for the test languages. ",191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Weakness,"In addition, this paper should describe the importance of this configuration such as ""how frequent this configuration occurs"".
",355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Weakness,There is no clear breakdown on how this may work with a variety of architectures such as a swift BART and a Scale T5. ,241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Weakness,-The experiments are limited to only sentiment analysis as a task. ,442 443 444 445 446 447 448 449 450 451 452
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"However, this work design a synthetic dataset, and the agents are separated by the different forms of knowledge (text vs table) and the different proportions of knowledge in the KB. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Weakness,"Only PLMs are considered in this paper and other task-related baselines are missing.
",154 155 156 157 158 159 160 161 162 163 164 165 166
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Weakness,"In fact, those are “hard negatives” which has been shown in many contrastive works as essential in learning a high-quality representation. ",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Weakness,"For instance, it is not clear how to generalize this approach to other sequence-to-sequence tasks like machine translation.
",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Weakness,"My guess is that the improvement is only due to the effect of ensembling, inherent in MC droupout. ",407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"-Lines 159-162: Authors should provide more information about the type/number of personas created, and how the personas are used by the chatbot to generate the given responses. ",238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"The paper covers little qualitative aspects of the domains, so it is hard to understand how they differ in linguistic properties. ",330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Weakness,Are English songs recorded by native speakers? ,333 334 335 336 337 338 339
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Weakness,"So there may be quirks in the dataset that make it tricky to interpret exactly what's going on with model performance.
",377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Weakness,"1) In section 3.1, authors mentioned that they swap gender of a person in MSR-VTT dataset. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Weakness,1. ,97
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Weakness," In fact, no comparison with past work is made. ",135 136 137 138 139 140 141 142 143
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Weakness,1. ,143
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Weakness,A similar but not identical issue: There is no mention of the computational budget\cost in this article. ,435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Weakness,"Right now, it does not pop up clearly to the reader. ",590 591 592 593 594 595 596 597 598 599 600
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,Why only LD benefits from seeing examples containing events? ,665 666 667 668 669 670 671 672 673
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Weakness,"
[2] Program Synthesis with Large Language Models. ",312 313 314 315 316 317 318
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Weakness,"- Unclear what the theorem means in theory and practice (what does the theorem gives us in practical terms, is it still valid in practice given the differences of the actual implementation) ",544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Weakness,"By treating the weights of the last linear layer as the embedding vectors of each class, optimizing the cross-entropy is almost identical to ICL (except that the vectors should be L2 normalized which is basically applying weight normalization to the last linear layer and normalize the features right before the last layer). ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Weakness,"-**Missing analysis of model behavior**: It would be useful and interesting to know what exactly is happening at each stage, e.g. how much text is produced at each stage, and how noisy or detailed intermediate summaries look like.
",200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Weakness,"
3. ",172
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Weakness,"Specifically, the method is not *truly* zero-shot as it can only work in cases where a PLTM for the target languages is available. ",332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Weakness,"As mentioned above, Campos et al. (2020) has already investigated using user feedback to fine-tune deployed QA models. ",467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Weakness,"This seems to be the case, but could be made more explicit. ",439 440 441 442 443 444 445 446 447 448 449 450
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Weakness,"I am not an expert in the field, so I don't know other span-based approaches other than the ones the authors cite, but it seems very expensive in terms of speed classifying all the possible spans in possibly long input sentences. ",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Weakness,"What are the other methods of text infilling, why aren't those compared with your cross-lingual text-infilling approach?
",328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,"[3] Li et al. (ACL 2021). "" ",368 369 370 371 372 373 374
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Weakness,"- the presented dataset is highly unbalanced from the culture point of view, where the western countries are leading (the USA in this case). ",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Weakness,1. ,310
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Weakness,1. [ ,146 147
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Weakness,"Humans still perform well on both cases, but more analysis on why the automatic sets are difficult would be interesting. ",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Weakness,"TD score is defined in Section 2.3, but there is no intuition or justification about why it is defined like this, at least in the same section. ",262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Weakness,"While training with the student model, it is possible that the similarity evaluator teacher may provide incorrect supervision for w2 as the other two tokens have incorrect labels. ",310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,"The experimental results of both GLUE and XTREAMRE show that the improvements are range from 0.2 to 0.8 (Avg score), which seems not significant. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Weakness,The first case is unlikely to occur. ,353 354 355 356 357 358 359
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Weakness," How are the lexicalization, aggregation and post-editing tasks performed (e.g., is this just a T5_small model)?
",125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Weakness,2. ,197
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Weakness,"- The paper would benefit from a more thorough discussion of the data collection / selection process, as well as from an evaluation of the annotation consistency between the four enlisted NLU experts (e.g. how high is the inter-annotator agreement, does having only four annotators introduce unwanted annotation artifacts or biases, were the annotations validated in any way?).
",301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,"Further, the noted choice of faithfulness has implications on some of the ""logic traps""   described subsequently. ",258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Weakness,"Specifically, I find Section 3 difficult to understand as someone who does not directly work on this task. ",324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Weakness,"-It'd be better to compare with published baselines (e.g. [1, 2]). ",285 286 287 288 289 290 291 292 293 294 295
42e1a1ffb6697cfc6e56e3907ec8da5ecbdec3559d597919138cf9de7718f899b458941998c44d697da2e3ed8a114f66da1bc6ced98d98d90b8c92f6a51721b4,arr,Weakness,Is it a random sample or keyword based filtering? ,86 87 88 89 90 91 92 93 94
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"Is there a way to automatically generate those templates with minimum efforts (e.g., event type name)?
",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Weakness,"    b) gets to the fundamental problem with automated evaluation raised in the paper, which is that ""when placed in realistic settings, the models never have access to the ground truth (gold answers) and are only exposed to the conversational history and the passage."" ",599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Weakness, ,
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Weakness,1. ,118
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Weakness,"- My main criticism is that the ""mismatched"" image caption dataset is artificial and may not capture the kind of misinformation that is posted on platforms like Twitter. ",108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Weakness,"Many baseline models are proposed and compared, but for most of them this paper did not explain why they were proposed, what are expected, and further discussions are still missing. ",448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Weakness,- The paper is hard to follow and certain sections (particularly the Experimental Setup) needs to made clearer. ,317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Weakness,"ACL 2018.
",352 353
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Weakness,2) Comparing the rewritten corrections to NLPCC18 and CGED's original error-coded correction would be an interesting analysis to show how much they overlap in reference corrections and whether MuCGEC provides further diversity. ,191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Weakness,"In my opinion, the ""Dynamic Knowledge-enhanced Mask Attention Module"" is one of the most innovative parts of the paper and should be highlighted more in the introduction.
",440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Weakness,"It may be possible to, for example, convert frame-based annotations to frame-free ones. ",523 524 525 526 527 528 529 530 531 532 533 534 535
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Weakness,"This hints at the fact that the methods may be very sensitive to bin size and often provide no actual expected calibration improvement, is that right? ",773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Weakness,1. ,131
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Weakness,"The only thing I would have liked to see was similar few-shot experiments in non-classification tasks too, like some kind of structured prediction, QA, text generation. ",451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Weakness,"The proposed Wide MLP is not novel.
",132 133 134 135 136 137 138
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Weakness,The constant comparison to latent variable models and calling these sentence representations latent codes does not add to the clarity of the paper. ,236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258
0717df21c948fc36edf5f14e8f8c15c7640e5a653f4dcc12c1c89a96aaa861c6aabcd3ec512d9dba6e71a5031f90b6cbf3411e7d555480e0e93fd160fbe0df95,arr,Weakness,"It would help to give a more thorough comparison, particularly to the most similar approaches such as the Bhatia et al. (2020) paper which also addressed meta-reviews. ",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Weakness,"However, in the baseline of vanilla multi-task learning (V-BB), no such kinds of special tokens are used at all, which forms a very unfair baseline to be compared with. ",227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Weakness,"Nevertheless, there might be a hidden factor inside: if a certain language is not included in the pre-training, the vocabulary of the pre-training model might not even have items for the words in this language, which might be split into strange pieces by the subword segmenter. ",247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Weakness,"
(4) The method used to create the dataset seems very simple. ",352 353 354 355 356 357 358 359 360 361 362
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Weakness,"I would like the paper to at least acknowledge this weakness.
",293 294 295 296 297 298 299 300 301 302 303
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,"Assuming that Vrank would be adopted to evaluate VIST models, it is crucial to know its limitations. ",167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Weakness,"As a result, this work will be hard to reproduce. ",381 382 383 384 385 386 387 388 389 390
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"As far as I know, the quality of negatives is more important than the quantity of negatives as shown in TAS-B. 4. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Weakness,-The 5 tasks are indeed an interesting addition to SUPERB but : AST is not new since it has already been used in SSL benchmarks (cf. ,297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Weakness,-The main concern is the technical novelty of this paper. ,88 89 90 91 92 93 94 95 96 97
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Weakness,"What are prompts provided to the blender bot and the impact of different prompts on the quality of generated data?
",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Weakness,"A better introduction would be helpful.
",87 88 89 90 91 92
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Weakness,I wonder if this is an artefact of humans conversing with models or the fact that humans (annotators) did not have access to the full passage. ,225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Weakness,1. ,148
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Weakness,"The authors give no indication of whether the modified datasets, code, system, or the data used in manual evaluation will be made available. ",485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,"
    - It is weird for me that dialogue without success becomes successful dialogue by changing the contents of DB. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Weakness,"The authors use the term “significant” several times in the paper but in fact, did not use any statistical test to check that the results are indeed significantly decreed. ",183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Weakness,"However, I understand that the authors made the best they could to provide some evaluation based on standard and community accepted metrics and that there are no standard metrics for the task. ",111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,"As a consequence, it is hard to situate the proposed methods and insights and how they differ from/ and contribute to the topic. ",337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Weakness,The paper would be much more solid if the authors could verify this hypothesis. ,310 311 312 313 314 315 316 317 318 319 320 321 322 323
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Weakness,"It would also be helpful to include whether this degree of ambiguity is reflected in real-world dialog systems as opposed to benchmark WoZ-collected datasets like MultiWOZ and SGD --- essentially, the problem seems to be intuitive, but the paper lacks some context on how widespread the issue actually is. ",297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Weakness,"- I'm afraid the final number of participants in the user study (3 + 3) makes any drawn conclusions rather unsubstantiated; One would expect some confidence intervals (classical stats approach) or high-density intervals (with Bayesian approach) to see, how much we can trust the study in Table 5 and 6 ",99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Weakness,I know this point is quite subjective and it is definitely not personal against the authors. ,543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Weakness,2b) Section 3.1: the extractive corpus-based approach relies on *English* Wikipedia data. ,493 494 495 496 497 498 499 500 501 502 503 504
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Weakness,"As for the third point, the authors offered the case study and the improvement in robustness as a reply, which does prove part of it, but what I have in mind is something more specific like comparing the human evaluation score (as the translation of $x_{\delta}$) of (1) $y_{\delta}$; (2) $y_{\delta}'$; (3) human translation of $x_\delta$. Ideally, (1) and (3) should be very close while (2) should be much worse. ",581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Weakness,"-Line 211: How many questions were created for this zero-shot intent classifier and what is the accuracy of this system?
",289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Weakness,3. ,160
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Weakness,"- It would be nice in table 5 could present the human results   directly, instead of having the reader need to flip back to compare ",285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Weakness,Weaknesses: I have two major conerns with the work: ,167 168 169 170 171 172 173 174 175
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Weakness, ,
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Weakness,"-In Section 5.2, it's confusing to choose POS tagging as a downstream task, and then neglect it in the analysis because ""PoS tagging seems to require little structural knowledge on language"". ",461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"It sounds unreasonable that increasing the model size can hurt the performance, as recent paper Ni et al. shows that the scaling law is also apply to dense retrieval model, so the preliminary experimental results on Wikipedia about model size should be provided in detail. ",291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Weakness,"In daily conversations, I think it is not widely considered as ""biased"". ",563 564 565 566 567 568 569 570 571 572 573 574
cfd85051633de133ab07f6eb88215422cd4fea1e970f47a60175560c73a5df19e2f26529237ad287500e8a0d96716784d4bd7fbde0962b81ab82806c6ec720b4,arr,Weakness,"Instead, the paper compared to an older baseline proposed by (Garg et al., 2019). ",114 115 116 117 118 119 120 121 122 123 124 125 126 127
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,Perhaps switching evaluation based on that would vastly improve the experimental section of your paper. ,357 358 359 360 361 362 363 364 365 366 367 368 369 370 371
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Weakness,"This seems to be a weakness of the proposed approach since by definition, it is trying to imitate human judgment, but without access to the same information that annotators had to decide. ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Weakness,"From the perspective of models, the proposed method consists of a list of sub-models. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Weakness,"
-It is not clear if the improved results reported in Table 3 are statistically significant. ",369 370 371 372 373 374 375 376 377 378 379 380 381 382 383
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Weakness,"Therefore, the derived objective for token selection (i.e., Equation 3) is not mathematically reasonable. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Weakness,"Thirdly, Yu et al. (2020) conducted the experiments on GENIA, but the paper doesn’t. ",158 159 160 161 162 163 164 165 166 167 168 169 170 171
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Weakness,"Since this paper is proposing a knowledge prompting method, the only real comparison is with self-talk method, however in table 3, only CSQA results are reported (because self-talk templates are only available for CSQA). ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Weakness,-no error analysis of spurious  or missing mentions across all datasets especially - BC5CDR ,302 303 304 305 306 307 308 309 310 311 312 313 314 315
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Weakness,"Further, the CONLL 2003 – OOV data in particular seems quite relevant in this experimental setting. ",475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Weakness,The really exciting part of this work is to use triaffine to fuse information from other related spans. ,374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Weakness,Do authors think that their approach would adapt to SQuAD? ,351 352 353 354 355 356 357 358 359 360
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Weakness,-Section 3 is difficult to follow. ,856 857 858 859 860 861
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Weakness,"The influence of negation expressions on NLP/NLU tasks has been widely proposed in many specialized studies, as well as in the case/error analysis of many NLP/NLU tasks. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Weakness, TF-IDF outperforms KeyBERT in 5 metrics in all 8 metrics. ,189 190 191 192 193 194 195 196 197 198
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Weakness,-The label inference process seems spurious (Section 2.6). ,154 155 156 157 158 159 160 161
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Weakness,I suggest the authors have the paper reviewed by a native English speaker. ,217 218 219 220 221 222 223 224 225 226 227 228 229
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Weakness,"As someone not familiar with this area of research, maybe there is not so much to cite here, but if that is the case, I feel it should be mentioned why there is no related work section. ",469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,"The examples were good overall, but the co-ref part of the benchmark stands out. ",338 339 340 341 342 343 344 345 346 347 348 349 350 351
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Weakness,"Another concern is on the distribution, in Figure 7, authors showed that the sums are still concentrating to a certain value. ",343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Weakness,- The experiments do not seem to consider structured features at all (e.g. 17 clinical features from [1] based on MIMIC-III) which however are critical for patient outcome prediction from both clinical and ML perspectives [2]. ,273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Weakness,"The argument is that, by contrast, Harris misses the boat on this.
",264 265 266 267 268 269 270 271 272 273 274 275
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Weakness,"This is probably not a ""weakness"" per se, just that the paper is not an eye-opener. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
2f057646717645190ed4a85cdff164d798622e9615df6a2ead4abd3705afca31d73b5448c11a794f8ac7f71cebe6c333795e66179f26313f39e3062eb6e25a2b,arr,Weakness,"After the abstract and introduction, I was expecting more about the presence of hate speech in the data, but it does not go further than reporting the % of documents filtered for being tagged as abusive by an existing model. ",194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Weakness,"Presently the paper does not demonstrate that (logic traps) ""in existing   evaluation methods have been ignored for a long time"". ",372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Weakness,Suggesting provide more intuitive examples to demonstrate it. ,136 137 138 139 140 141 142 143
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Weakness,	Missing some details to lend full credibility. ,192 193 194 195 196 197 198
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Weakness,"
    - Though, previous works evaluate their methods by self-play, I feel that human evaluation is required for robust evaluation. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Weakness,"Weijia Xu, Batool Haider, Jason Krone, Saab Mansour. ",261 262 263 264 265 266 267 268
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Weakness,line 249) It's unclear to the reviewer how the scores are combined in the paper. ,116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
b9a61dd81ac6fc9fa0d51b5714499245c8a9e7cb2d12e92562f1a908f16055c9d5c61df7ec947f95ba32f634ded820206edd3f9320780a0b05b0dbf3370384aa,arr,Weakness,"Finally, the taxonomy itself could be an interesting contribution but its exploration remains very limited. ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Weakness,A lack of including this in the simulation may be a cause of concern. ,440 441 442 443 444 445 446 447 448 449 450 451 452 453
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Weakness,What are the sources of stories? ,454 455 456 457 458 459
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Weakness,"The authors claim that ""it is shown that uncertainty outperforms a system explicitly built with an NOA option"". ",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Weakness,1) Improvements are overstated. ,281 282 283 284
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Weakness,"In this new proposed setting, an ideal criterion for designing individual agents is that each has mutually exclusive functionalities, and it is challenging to develop a unified model. ",252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Weakness,"
5. ",336
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Weakness,2. ,243
f8c377dc052065d77805a0b7b2d085a0b319ea5a3e3867e7b1e27b41aa7d6f5f9c91ab6df4758e4f31f7e436bbd62e0d2ced811481318e0557613ae611c1fdf4,arr,Weakness,Is it the case that a few wrong cues can give devastating results on focus detection? ,146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Weakness,How the annotators are paid? ,301 302 303 304 305
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Weakness,Please refer to [1] from the summary above and other references from my prior review. ,278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Weakness,It is hard for me to conclude that the proposed methods is strong enough to compete with others. ,168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Weakness,"The methodology for cross-model transfer (section 5) was less clear, and seemed less well-motivated than the rest of the paper. ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Weakness,"-When not applying active learning, what are different between seed and following rounds? ",152 153 154 155 156 157 158 159 160 161 162 163 164
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Weakness,"It is worth comparing OT with say, Euclidean distance, KL divergence as a side experiment. ",514 515 516 517 518 519 520 521 522 523 524 525 526 527 528
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Weakness,"However, they do not directly state why this is the case. ",157 158 159 160 161 162 163 164 165 166 167
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Weakness,- This paper does not provide a clear and explicit definition of historical-comparative linguistics. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Weakness,"I think the paper shows clear difficulties in the generation and inference aspects, but perhaps classification is getting better. ",430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Weakness, ,
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Weakness,The main body of the paper still lacks examples but I appreciate their inclusion in the appendix. ,271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,1. ,292
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Weakness,-Why did the authors decide to experiment with their model on CNN/DM? ,160 161 162 163 164 165 166 167 168 169 170 171
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Weakness,"
Despite the statistical rigor and attention paid on the details of error especially from Figure 2 where weighted losses are combined, the error analysis makes a lot of generic claims that do not seem to be based on the statistical proof. ",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,The experimental settings may be in favor of the proposed method and the actual performance gap in the averaged loss may not be as significant as presented in the paper. ,175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
0f6a2b765962004b043f0fd2cda78b98188478a2b7f68833886ce981d7037dba27376253b861581a1406ebdcdcf5c6c76153326156a785908d4eb6a6f229e8d4,arr,Weakness,"Even simple, I doubt its effectiveness. ",32 33 34 35 36 37
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Weakness,It would be nice to see some trends and insights into cases when this proposed approach fails to perform well.~ ,365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Weakness,"In section 3.3, the authors claim that the disadvantage of using web search is indirect data leak. ",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Weakness,No statistical analysis of the results is reported although a comparison between models is made. ,271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Weakness,It seemed a little disappointing to me that the 212 new pairs have _not_ been translated to English (if I'm not mistaken). ,390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Weakness,New events may not have clusters. ,170 171 172 173 174 175
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Weakness,"
For example, cross-validation can be considered. ( ",359 360 361 362 363 364 365
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Weakness,"However, I think the paper would benefit from more in-depth analysis of where this improvement comes from. ",351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Weakness,"How it works for ""1-1"" and ""N-N"" situations. ",119 120 121 122 123 124 125 126
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Weakness,"However, further discussion on how this could be addressed (e.g. with better annotation manuals or training) is missing. ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Weakness,Missing in-depth analysis on experimental results. ,168 169 170 171 172 173
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Weakness,"Note: many of these weaknesses can be addressed in a subsequent submission, and I would be happy to reassess them if a resubmission is made. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Weakness,"
2. ",159
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Weakness,"This raises two questions – under what conditions Cont is more likely to perform better and given that Cont is trained on top of BERT, what are the features of BERT that are important in this case. ",487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Weakness,"
2. ",262
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Weakness,"The loss function of the “Uniform” baseline uses a constant weight across tasks, which matches the weights used in the evaluation of average performance. ",205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Weakness,4. ,257
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Weakness,"The multilingual evaluation claims to be of ""the UD data"", a dataset of over 100 languages, yet the authors only select ten without explaining why. ",254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Weakness,More experiments using different architectures are needed to determine if the findings and errors that arise are consistent across different models and different settings. ,333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Weakness,"But in the current experimental setup, authors didn't consider this factor. ",175 176 177 178 179 180 181 182 183 184 185
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Weakness,"	- Section 4.1 describes only the annotation results, without any further discussion of the implications.
",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
ebfe58b10dee02a1cb830e85ec7993f381fa88e9d1e70ec9eba24417b92fdbe8d20ae561d42fbcbdb17d4380fde7845f5850c3fd769aa20c15003fe18fcdfbf0,arr,Recap,This paper proposes a leaderboard to join the progress reporting of the two important factors in automatic text generation: the output of generation models and the metrics used to evaluate the output. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Recap,Based upon the author response I do raise my score slightly from 2.5 to 3.0 to reflect that the definitions referenced in the author response might be sufficient for a target audience that is intimately familiar with WSD. ,7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Recap,"Further, the authors highlight a number of ongoing projects and discuss potential future work. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"In the experiment, they introduced a metric, called OIoU (Opposite Intersection over Union), to evaluate “the diversity degree of reference parsers.” ",241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,Then a model is fine tuned on this dataset to generate questions. ,85 86 87 88 89 90 91 92 93 94 95 96
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Recap,"These experiments use the GPT-2-large model (except when model size is ablated), and projection is defined as follows: continuous prompts are projected to discrete space by finding the token with the nearest-neighbor embedding (where token embeddings are taken to be GPT-2's embedding matrix). ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Recap,"To prepare the benchmark, the authors consider several downstream tasks (and corresponding subtasks) from various existing benchmarks. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Recap,This work has created a benchmark dataset for multi-task learning for biomedical datasets. ,0 1 2 3 4 5 6 7 8 9 10 11 12
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Recap,"The first part is using search-based method to the training data, the second part is training an encoder-only model, the third part includes the training strategy and a length-control algorithm. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Recap,The model is feasible to perform text-to-speech with 30 minutes of training data. ,14 15 16 17 18 19 20 21 22 23 24 25 26
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Recap,"This paper presents a new citation-based related work dataset, CORWA, as well as a baseline model that tags against the CORWA dataset, that is built over the S2ORC dataset, specific to NLP. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,"Notably, the author does not really deploy the model. ",40 41 42 43 44 45 46 47 48
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Recap,"The paper makes the claim that the most obvious way to do knowledge distillation with seq2seq models (just using the generated output from the teacher model as a target output for the student; also called pseudo-labeling), is problematic. ",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Recap,The global tokens can be attended by all input tokens and thus enable long-range interaction. ,55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Recap,"More precisely speaking, the paper defines a phoneme set as a minimum set of speech segment grouping such that a replacement of phonemes results in a change in the distributions of semantic words. ",32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Recap,"The method achieves higher performance with fewer FLOPs compared with strong baselines on classification, regression, and generation tasks, showing its superiority. ",132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Recap,The model is then finetuned by minimising the MSE loss. ,150 151 152 153 154 155 156 157 158 159
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Recap,"The dataset is built using two sources of data, the PG-19 dataset (Rae et al., 2020) and a fanfiction online archive (Archive of Our Own, AO3). ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Recap,"This work presents a study of factual hallucinations, wherein summarization models hallucinate information (i.e. generate information not present in the source document) which is still factually correct. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,Experiments show that training NMT models on such adversarial examples as augmentation data (?) ,167 168 169 170 171 172 173 174 175 176 177 178 179 180
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,"Furthermore, ablation analysis was performed to show the importance of all the components. ",91 92 93 94 95 96 97 98 99 100 101 102 103
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Recap,"The proposed method consistently outperforms the compared baselines on almost all tasks.
",118 119 120 121 122 123 124 125 126 127 128 129
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Recap,This paper proposes a framework for training and extract-the-generate model for the long document summarization task. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,"They quantify this as a delta measure: the difference between accuracy on the standard test set and a ""hard"" test set. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Recap,"Evaluations were performed against prior models, for various numbers of classes. ",34 35 36 37 38 39 40 41 42 43 44
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap," In one variant (""weighted""), the amount of training-time probability assigned to every vocab item except the correct one at each time step in the decoder is varied based on whether the item appears in the source-side vocabulary, target-side vocabulary, or both. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,"First, they introduced in detail about the process of mining geographical location in the paper. ",34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Recap,"The paper studies how factual knowledge is stored inside the pre-trained transformer model, and presents a knowledge attribution method to identify “knowledge neurons” in feed-forward layers. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,It then proposes to frame classification problems as generation problems and claims that a generative model with a uniform prior can overcome this bias. ,66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap,The ablation study further confirms the two-stage training stabilizes the routing and verify the effectiveness of StableMoE. It remains unclear whether the total budget for training (i.e. total compute resources) is smaller compared to exiting MoE methods. ,138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Recap, It then looks to see if you can predict (out of sample) based on a neural embedding model. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"Because of their deceptive nature i.e. easily disregarded or even missed, the paper presents these weaknesses as logic traps. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Recap,They report SOTA performance on this task. ,73 74 75 76 77 78 79
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Recap,This is the second revision of the paper that I have been asked to review. ,88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Recap,"For example, Micro F1 improves over BERTMeSH from 0.685 to 0.745. ",35 36 37 38 39 40 41 42 43 44 45
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"The paper has a theorem that states that the loss is bound by the delta-cover core token selection algorithm in that the loss goes to zero as delta goes to zero.
",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Recap,"This work proposes to frame the task of controlled text generation as sampling from a combination of black-box models that are responsible for various components of interest such as fluency, the controlled attribute, and relevance to the prompt. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Recap,The work's primary contribution is showing this discrepancy by conducting a human evaluation study where CQA systems get to interact with humans - the result human-machine conversational QA dataset is also a contribution. ,128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Recap,"Moreover, even when the word embedding shows low biases, the biases of sense embeddings can be large. ",89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,The author conducts automatic and human evaluations. ,134 135 136 137 138 139 140
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Recap,The authors propose that leveraging the data from similar users extracted from the corpus to enhance the personalized language modeling for a new user. ,22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Recap,"The main claim is that  current contrastive learning-based methods, which are based on either discrete augmentation or continuous augmentation, do not consider the impact of superficial features such as sentence length and syntax. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,The authors tried this approach with several large-scale language models showing substantial performance improvement over the corresponding baselines. ,195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"Ideally, the performance would drop because of the perturbations, but it did not, therefore clearly misleading human decision making. ",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap,"For the XEL task, they evaluated on the UMLS and outperformed baselines  (XLM-R and mBERT, both with contrastive learning) in most languages. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Recap,The paper introduces NATURAL INSTRUCTIONS - a benchmark to measure cross-task generalization of models that learn tasks from natural language instructions. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Recap,The paper described a set of approaches from unsupervised to weakly supervised to segment sentences into words and morphemes under an extremely low-resource setting. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Recap,"As far as I understood, CALM changes (relabels) DB in the failed dialogue to make the dialogue successful (dialog task relabeling).
",7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Recap,"The proposed architecture consists of a normal transformer encoder to encode the source sentence, a tree-based transformer encoder to encode the syntax of the template, and finally a decoder which utilizes both sentence and syntax embeddings to generate the paraphrase. ",24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Recap,"In their experiments, mix-GLT outperforms other strong NAT baselines with higher accuracy, while adding some extra computation. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"Logically, there are still two issues involved in the joint CLIR process (translation + retrieval), but they are now solved at a time after having teached the model how to do it. ",322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Recap,They show that complex hierarchical structures increase the difficulty of both table QA and text generation. ,70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Recap,An interesting and thorough paper combining clinical text with relevant-to-patient medical literature to improve patient outcome predictions. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Recap,They observe that it doesn't really help in case of more common/usual negative penalty schemes such as 3:1. ,108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Recap,The authors evaluate all of their contributions and prove that each of them brings improvements over the previous state of the art. ,235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Recap,"Here, the values of the energies come from blackbox models that correspond to attributes of generation (fluency, faithfulness to conditioning, etc.). ",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Recap,The paper shows that pre-training on the target language and the LDND distance between the source and target languages have the biggest impact on the cross-lingual performance. ,87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Recap,"But most of the improvements can be captured by a heuristic multi-task group dropout baseline, and there is a small improvement (0.5 bleu) over this baseline with the variational approach proposed. ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Recap,"The authors entertain the hypothesis that syntactic information is redundantly encoded in neural language models, which has two important implications for probing and causal analysis: 1. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,"The existing evaluation procedure ignores the impact of the model’s output on upcoming exchanges, thereby detracting from real-world scenarios. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Recap,The datasets span text classification (6 datasets) and legal question answering (1 dataset) tasks. ,35 36 37 38 39 40 41 42 43 44 45 46 47 48
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Recap,"In other words, the cross lingual summarization is the combination of machine translation and summarization.
",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Recap,"This paper analyzes roles of image and text in the problem of claim detection, which is often the first stage of fake news detection. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Recap,"In this work, the summarization is performed in N coarse-grained stages and one fine-grained final stage. ",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Recap,"Dual learning is employed to better learn the unconstrained relation between personal memory $Z^m$ and knowledge $Z^k$ , and variational method is proposed to approximately marginalize out $Z^m$ and $Z^k$ during inference. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Recap,"This paper provides a general framework for cross lingual UMLS entity linking which can be adapted to other source languages with some prerequisites specifically four steps - unsupervised learning of a language specific UMLS dictionary, generation of candidate mentions, high level recall matching of candidate mentions to UMLs concepts  and leveraging pre trained neural (Transformer) language models for contextual relevance to determine which candidates are correct. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Recap,"The results after applying the method shows less over-confidence, better model calibration, flatter neural minima and more smoothed loss landscapes which plausibly explain performance improvement rather than directly/only addressing the inconsistent boundary span labeling problem in NER. ",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Recap,The method of THE-X converts a fine-tuned model into a cloud service and processes users' data without peaking the data itself. ,37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Recap,It proposes learning how to mix the outcomes of three experts. ,9 10 11 12 13 14 15 16 17 18 19
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Recap,"As this results in many candidate outputs, this work also utilizes path recombination to combine similar hypotheses. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Recap,"The authors outline a general metamorphic testing framework (with a useful graphical model formalism to describe different variants of it), and show how most past work falls narrowly into the category of robustness tests. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Recap,This paper borrows a idea from the optimal transport problem to propose a framework for evaluating and interpreting semantic textual similarity (STS). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"There is also a sentence that was a bit unclear to me:  L555: “Thus, we only reduce sequence length in the input layer, which is before the first encoder”. ",398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,"	There exist more complex question types, e.g., compare, count. ",230 231 232 233 234 235 236 237 238
db14eda600a57c45529a8ae7db67ef709b17efd9bc501459d16886267bb64db205b07db81311c17bd4e2bec40a9d83d6cff10898a7f5016d5b2799e8ccb4c73b,arr,Recap,The benchmark will be released. ,67 68 69 70 71
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Recap,"This approach is clearly explained and produces good results, with the proposed model outperforming both a lexicon-based baseline and existing work for four of the five moral foundations (for 'care' the lexicon-based approach performed better than the other two).
",98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
4a1c1a54db4c8630e04e4e5f045f69749e7bf8d6b6bf7fe1b5abc8f64b63aac51dbe6e0e4f0a4a667815ef7b8e80d00ca2eac00026243514c420f95834081e42,arr,Recap,"In addition, the paper used only a very small set of parameters in CLIP models during fine-tuning, including bias and normalization terms. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Recap,"The authors evaluated the proposed models on multiple controllable text generation tasks, such as controlling sentiment and topics. ",63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Recap,This paper conducts experiments on two benchmark datasets with the proposed SR module. ,58 59 60 61 62 63 64 65 66 67 68 69 70
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Recap,The paper focuses on exploring the role of context in determining the humans’ (annotators) perception of hate or counter-hate in social media comments. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"Some solutions for improving handling negation were presented before, here the authors looked also into another semantics related task – synonyms and antonyms detection. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Recap,"Thus the authors propose a method, where they incorporate pseudo embedding and momentum updating to further help the contrastive learning.
",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap, ,
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Recap,Extensive experiments show that the proposed method shows significant improvement over existing subgraph-oriented KBQA models. ,82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Recap,"However, I am also curious about the performance of using other pre-trained LM for Chinese, like *T5-PEGASUS-Chinese*. The experiments are extensive, both automatic and human evaluations are conducted. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,The paper is clear about how this methodological contribution builds on and differs from other recent efforts to improve the prosody of TTS. ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Recap,"The authors thus propose an approach that saves memory and at the same time achieves good results on GLUE.
",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,"The predicted quality values are added with different offset values, which can then be used to generate multiple paraphrases, and a method to obtain optimum offset values for a dataset using the dev-set is also proposed. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Recap,"The proposed approach is compared against other modeling paradigms used in the ARA literature, namely classification and regression across 3 languages (English, French and Spanish). ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,"At inference the paper uses a tweak from GECToR, adjusting the keep probability by a tuned amount. ",200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,This fine-tuning/training process is done in two phases. ,137 138 139 140 141 142 143 144
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Recap,"
Due to the non-distinction of MWP patterns, current methods, which are based on neural networks, perform poorly. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,	Encoding of cross-document knowledge graphs via graph neural networks and use of event and document level events to detect misinformation at both levels. ,129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,In the second method (_Task Tuning_) they learn the `projector` via backpropagation. ,192 193 194 195 196 197 198 199 200 201 202 203
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Recap,While adding adapters to their decoders they can adjust the style (sentiment) of their responses while maintaining decent performance in automatic evaluation. ,111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap, ,
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Recap,The goal is to continuously learn new pretraining data domains for a language model such that we do not need to retrain a new one from scratch. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Recap,"On the one hand, conversational question answering (CQA) has been a challenging problem in language understanding and of many applications. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Recap,"Through the experiments, the authors provide some insights that will benefit future research. ",86 87 88 89 90 91 92 93 94 95 96 97 98
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Recap,"
The authors also propose a model that is retrained from pre-trained models in multiple languages, and hypothesize that this will be effective for speech recognition with small amounts of data, such as for endangered languages. ",68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Recap,"
They propose a sequence-aware pre-training method for improving current models' ability of reasoning over multimodal information to solve the task (MLM, (patch-based) ""image-swapping"" prediction ((P)ISP), sequential MRM). ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,The questions are going to be close to the passage in representation space and by transitivity they are going to be close among themselves even though they are semantically different (Transitivity Conflict). ,27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Recap,"One of them handles the entity recognition task, the other is responsible for entity similarity. ",30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Recap,"The experimental results show that comparing to baselines like PPLM and GeDi, the proposed model can achieve a good balance between fluency and controllability.
",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Recap,The reranker also enables enables retrieved documents from different retrievers (e.g. DPR & BM25) to be combined seamlessly. ,36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Recap,This paper proposed a Waywardness Hypothesis for the connection between continuous prompt and discrete prompt and use experiments to justify this connection. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap,The proposed DST definition comprises of dialogue states from the traditional DST setting and dialogue states that represent the states of visible objects. ,67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Recap,"Specifi- cally, this paper proposes a novel iterative contrastive learning to pretrain dual-tower dense retriever, then use lexical matching method to further enhance the pretrained dense retrieval model. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Recap,The paper targets low-resource text-to-speech by using the articulation features instead of phoneme identity. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Recap,The authors formulate the metric and establish its properties in relationship with group fairness and individual fairness. ,21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Recap,"Empirically, this results in improvements in WSD performance on several English datasets. ",54 55 56 57 58 59 60 61 62 63 64 65
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Recap,Their approach outperforms the baselines. ,59 60 61 62 63
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Recap,"After reading through the authors' response and the new draft, I've updated my review. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Recap,"In this new formulation, there are multiple agents, each of which is capable of solving some specific types of tasks. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Recap,"The work is comprised of three main parts: development of a technique for mining argumentative statements which correspond to a given moral position from text; integration with IBM Project Debater’s narrative generation API to generate arguments pro/con a given topic which match a given moral position; and, a detailed user-study assessing the impact of morally-framed arguments on audiences of different political ideologies.
",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"This invites a conversation about increasingly capable attackers.
",808 809 810 811 812 813 814 815
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Recap,"The persona inference attack is viewed as a supervised classification task, and the defense learning strategies to prevent it include loss functions such as Kullback-Leibler divergence and mutual information. ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Recap,"The authors also proposed DDNET approach which is a unification of knowledge distillation and dual attention techniques, and showed the efficacy of DDNET empirically by applying DDNET to various spoken QA models. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Recap,The paper proposes a method to incorporate hierarchical structure information into text summarization tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,References: ,232
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Recap,"The paper describes a new approach towards MeSH label prediction, utilizing the title abstract journal relative information. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Recap,The authors also present the human evaluation that demonstrates the successful performance of the pipeline. ,59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,"
2. ",136
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Recap,Overall the conflict is interesting but the result is very mixed. ,75 76 77 78 79 80 81 82 83 84 85
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Recap,"
The proposed method replaces sentence embeddings from the private document for embeddings obtained from a set of public documents. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
25ecf77df8e811b8c942cb9933c4bd14112d1de9ed3f8989adcb669076c94472a9497f9ae80d57e03ed8fcb031fa6f84877d8faf869d641e622e8ddebd622cca,arr,Recap,The authors draw several key conclusions about BERT via this paraphrase-based analysis. ,27 28 29 30 31 32 33 34 35 36 37 38
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Recap,The paper is a standard ACL-level paper and I tend to recommend to accept it. ,77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
63e6907546809c29c6678e0b7768044386cffcd2d9d29d2cd0a6402acf7cf545807ce23f46172008b74dd4293dd59263459da0d53716a3518eddfccb173e0844,arr,Recap, The bias terms constitute very few parameters of a pre-trained LM and so BitFit is more efficient than DiffPrune and Adapters in terms of the number of parameters fine-tuned. ,40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Recap,This paper studies efficiently processes long input sequences for conditional language generation with Transformer. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Recap,"Finally, a zero-shot experiment is conducted to demonstrate the effectiveness of the models on information extraction from unseen data. ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Recap,An elaborate expression is an expression ABAC (A B1 A B2 in the paper but i prefer ABAC to indicate the identity of the words so swill use that) like “people pile people lump” fo ra throng of people. ,13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Recap,"To train the entire network, there have been three losses defined (generator, oracle, and consistency), of which generator is the decoder loss, oracle is used to optimize the extractor with oracle labels, consistency is used to marginalize dynamic attention with extractor distribution. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Recap,Experimental results on XTREME and GLEU benchmark datasets suggest that NoisyTune gives small improvement consistently on various settings. ,61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,They propose a new solution – intermediate training on tasks related to meaning matching. ,63 64 65 66 67 68 69 70 71 72 73 74 75 76
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Recap,"The authors present a rigorous, well thought-out algorithm. ",14 15 16 17 18 19 20 21
0943e5d2efbf75734b113861f9c2bb8ca031e0740fce519c60b9b17470dea2b0df56aa327e769a0e36e89ac92fa23086cd9ee85094e50a67d721965f0c3509f7,arr,Recap,The utility of the corpus is demonstrated by training a ML classifier. ,15 16 17 18 19 20 21 22 23 24 25 26
6de4c24feda039f610f2f5499017edf441c88aa4ccfcd935c5311e14cb3a538507eae0a124803d5f1852a085fc55e85971be82ce03f925c776ba7dcb86604511,arr,Recap,The claims are that this method while adding a (reasonably small) computational cost overhead. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Recap,"As a researcher in SRL, I am usually very excited to see new resources for the task but, in this case, it seems like MuPAD will not be released openly to the research community. ",231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,The proposed approach is shown to be significantly better than the baselines. ,183 184 185 186 187 188 189 190 191 192 193 194
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Recap,"The authors built an annotated corpus based on Europarl to control for variables such as original or translationese, content in terms of topics, and sentence length, and extracted comparable sub-corpora of aligned and unaligned directions to empirically show the following: aligned training and test directions perform best, alignment direction is also relevant when producing synthetic data with supervised training and back-translation, but the impact of data and model alignment varies among language pairs and translations when considering other factors. ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,"For between task transfer, they either directly re-use a prompt from a source task on the target task or they use the prompt learned from the source task as the initialization point for the target task.
",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Recap,"84-91).
",113
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Recap,Mitigation Strategies on how to make attention more faithful ,107 108 109 110 111 112 113 114 115
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,It is composed of a set of 19 handpicked relations with 1k instances per relation. ,34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
3a14a02b9c496d9bcd7b06aedeaa8d9c48fa003e7be1b23f9cb631571dd75d894c70b500313f5f1e5ca1c867cfb04c23cad117d1072ae2d0ebbb7964c16ccdf3,arr,Recap,"Instead of using future information from language modeling directly in the output layer of the attention model, they transform the monotonic attention mechanism to explicitly use the future information. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Recap,This paper tackles the problem of measuring social biases in sense embeddings. ,0 1 2 3 4 5 6 7 8 9 10 11
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Recap,"Generally, the performance gains are not unambiguous and the settings in which this method is strongly preferred to other comparable systems could be clarified. ",206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Recap,"The effectiveness of DEAM rests on determining ways to manipulate AMRs—i.e., step (b). ",111 112 113 114 115 116 117 118 119 120 121 122 123
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Recap,This paper explores whether intermediate pre-training on visual knowledge can improve performance on commonsense reasoning tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Recap,"I am increasing my score due to improved clarity to 3, but underscore that a more in-depth comparison on other datasets and with other parameter-efficient approaches is still missing.** ",128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Recap,This paper focuses on revising errors made by a generation model while it generates additional tokens continuously. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,The experiments are conducted on three datasets and six low-resource languages. ,119 120 121 122 123 124 125 126 127 128 129
3398ca971c1ee00e7f56db6a5d9069a561805ba4bd33e4cc84ef6a4c1acf331a4d8c1a7e53ebf415d32cbefe4396b1808e031ddcef812a37768f40bde058252f,arr,Recap,"The framework has 5 translation directions (English to: Chinese, German, Italian, Russian and Spanish), and also provides statistical and linguistic analysis for 7 (non-)commerical neural MT systems. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Recap,"In this paper, the authors propose a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Recap,"This paper presents DiBiMT, a new test suite for semantic biases in machine translation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13
fb8abed24b895c60af95d65f500024e37b39c870800b09362cb415350eecdb493573e965cb693012ce459c254f4446514a17effdbceccb50b7ce870bb3bc6119,arr,Recap,This paper presents a link prediction method where knowledge from a commonsense KG is used to guide negative sampling and inference. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,"Some of the challenges include the presence of more speakers, less formal and more spontaneous speech, and presence of frequent emotional sentences that need to be marked by exclamation marks. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Recap,This paper augments the standard cross-modal retrieval framework with an additional codebook. ,0 1 2 3 4 5 6 7 8 9 10 11
3f1a09e155c657a139ccdad41c8d593f45e130a564aa0d3825770e56f02682d43186539fe68060d48acab72dfd294c56a3f6ce65d9331ff71c2c1d4aa73a9500,arr,Recap,"
If the evaluation is conducted under a negative marking scheme, it is sensible to choose an answer or abstain from giving an answer if the system is not very confident with any of the answer options. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"
To address these issues, adaptive inference has been suggested. ",34 35 36 37 38 39 40 41 42
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Recap,"LexGLUE is based on seven English publicly available legal NLP datasets, selected using criteria largely from SuperGLUE. ",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,"In the original task 16 sentences are created by combining four verbs with four constructions, after which a participant is asked to sort them based on sentence meaning. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"For GLUE, the author shows that their method out-performs various baselines at the same speed-up factor and stays behind 1.5 points in accuracy of an unpruned Bert-base model.
",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,"The paper then proposes to use multiple hidden vectors to compute mixture of softmax, and term the approach multi-facet softmax due to the use of multiple projections. ",119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
b1fb88206c3832e9f87e6f8115045f3478d45617776f8397f37664d4de722806db84bff9744f31328a47ad99443cf3b52355d950d9e6fa09b9747dbb3b9f4f21,arr,Recap,Ablation studies and empirical analysis reveal the performance gain may come from the diverse cross-attention distribution of the teacher model and concise and abstractive summaries generated from the teacher model. ,30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,The authors have evaluated the state-of-the-art punctuation restoration models (neural based BiLSTM and graphical based CRF) and found that the performance of the PR models on their data set is far below compared to existing datasets revealing its challenging nature. ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"Note, the defense is across the utterance embeddings which are inherently richer than output token sequences. ",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Recap,"Moreover, the authors also collect annotations of possible orders alternative to the originally authored ones to create multiple references. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,"Based on the resulting insights, they propose a new 4-way classification setup that is more suitable for the task and that guarantees a more systematic analysis of language phenomena in real-world data. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Recap,An exemplar is a natural sentence with a desired surface form for the output paraphrase. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
4825eb030d8afb393c246a33e9d8a1f793b90ea88cb57ce09e675891f7d509d82c4b6cc50d7f8dc386a279b6854b3692285cbe651def3090bb02344787ef1b3f,arr,Recap,The proposed attack method can generate natural-looking attacks. ,27 28 29 30 31 32 33 34
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Recap,"By sampling multiple summaries from the models, the authors also propose the use of a ""predictive mean"" which is basically selecting the summary with the lowest disagreement, as the output summary. ",29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Recap,"
They propose a novel variation of knowledge distillation to train the initial retrieval, reranker and generation using only ground truth on the target sequence output.
",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Recap,"Considering the instability of PLMs, my concern is that the findings of this paper might not be supported when we use different hyper-parameters (e.g., using different random seeds, learning rates, batch sizes). ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Recap,The authors show that that this domain adapatation scheme transfers the benefits of the general-domain student models: fewer parameters with same performance for ALBERT and improved performance over BERT for RoBERTa. ,59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Recap,"They introduced a curation method by creating a template, create the ontology, translate using machine translation, and then ask annotators to edit the translations. ",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,"
2. ",219
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Recap,"This paper argues that existing benchmarks for the text-to-SQL task have failed to capture the out-of-domain problem on column operations, matching domain-specific phrases to composite operation over columns. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,"The authors demonstrate  by finetuning the generative model as a classifier, however this reintroduces bias according to their delta metric. ",104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Recap,This paper presents several logic failures in the way that attribution methods are evaluated. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Recap,"Changing a representation based on a probe may therefore only partially change whether the property is encoded in the model, and might not influence the model decision, even if the model is relying on syntax.
",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Recap,the    multilingual non-contrastive case. ,104 105 106 107
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Recap, ,
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Recap,"Despite the simple technical design, the experiments show that PTG achieves superior performance than the baseline methods on several NLG tasks. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,"For datasets, they use the common benchmark PD dataset for training and evaluation. ",136 137 138 139 140 141 142 143 144 145 146 147 148
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,"Ensembling is performed over RoBERTa, DeBERTa and XLNet with different model sizes and edit vocabulary sizes. ",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Recap,"The paper provides a corpus of editorial edits for Wikipedia articles, scientific articles and news. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,This paper focuses on quality estimation of machine translation systems. ,0 1 2 3 4 5 6 7 8 9
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Recap,It processed linguistic feature and multi-layers of visual embeddings through the cross-modal transformer to obtain the multi-layer visual-linguistic embeddding. ,20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Recap,Models optimised in this way reach the performance of models finetuned on the whole training set and the approach is argued to generalise to some other tasks. ,51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Recap,The paper proposes an efficient and flexible BERT-based multi-task framework. ,0 1 2 3 4 5 6 7 8 9
7e23ee6e56ace10f42339e73b598425e2f2f0f8539fed8f42a514d3a80a537553522ece6eca40ded1d3e587222531371a27d268cbb3ba00f80c3ba8cb0bf286d,arr,Recap,They find that the best results are achieved with several teacher models and back-translated documents help just as much as genuine documents. ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Recap,They propose a weighting strategy to take consideration of the reliability of the teachers. ,30 31 32 33 34 35 36 37 38 39 40 41 42 43
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Recap,The approach makes use of a teacher model based on query translation and monolingual IR in English. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Recap,"To clarify the last part above, the issue may be that “minor” is underspecified. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93
dd23042b3a19ead6484687423764d8156f6ea40cec4ccceb6d27ccc6305223ed76957ad46eae750d95766cc378fb0b332d4fcd737dc810c4bee6e8823ca79884,arr,Recap,Comprehensive experiments demonstrate the effectiveness and robustness of Prix-LM for automatic KB construction in multilingual setups. ,57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Recap,It constructs a lattice graph along with the hypothesis recombination method to shrink the size of the graph. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Recap,This paper proposed a hierarchical recurrent aggregation framework to reduce the few-shot NLG task. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Recap,They observe all models perform poorly compared to a segment-based RoBERT model trained on the suffix identification task. ,49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"The main difference of the proposed method compared to traditional methods, each module is trained using neural networks by leveraging recent pre-trained generation models like BART. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap, ,
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,I like that the authors include discussion of varying m and different scoring functions in the paper to make it more complete. ,83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Recap,It then describes how underclaiming can affect making progress. ,31 32 33 34 35 36 37 38 39
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Recap,"Another important contribution is the proposed adaptation of the model-agnostic meta-learning (MAML) to TTS, resulting in a novel procedure that the authors call LAML (language-agnostic meta-learning). ",32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Recap,"All the questions are multiple-choice, composed by professional writers and validated by MTurk annotators to be answerable and unambiguous. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,This paper investigates the ability of the raw sequence-to-sequence model in document-level translation. ,0 1 2 3 4 5 6 7 8 9 10 11 12
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"Are they significant?**
",262 263 264
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Recap, ,
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Recap,"Overall, this leaves me unsure whether the added complexity of this approach is worth it over the simpler baselines (vanilla Transformer or heuristic multi-task group dropout). ",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Recap,"Besides, the authors also had detailed analysis of the benefits of proposed methods. ",35 36 37 38 39 40 41 42 43 44 45 46 47
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Recap,The underlying model is ColBERT with XLM-R as the pretained language model. ,11 12 13 14 15 16 17 18 19 20 21 22
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Recap,"A little more formally, the hypothesis is that for any downstream task and arbitrary text $p_d$ of length L, there exists some continuous prompt $\tilde{p}_c$ of length L such that $\tilde{p}_c$ results in a test loss close to that of the best continuous prompt $p^*_c$ of length L, and yet $\tilde{p}_c$ projects to $p_d$ (when projected into discrete space).
",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
ce67bb03e40a4cb585035890d55be2d05240f7adac74d42a128163bf2da6fb5aaa06f54690655904e48dfa3e8e8d52de6d2b888a1a626b9b87ecb5f9584ab004,arr,Recap,The authors propose a new learned metric for ranking the quality of generated visual stories. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
4825eb030d8afb393c246a33e9d8a1f793b90ea88cb57ce09e675891f7d509d82c4b6cc50d7f8dc386a279b6854b3692285cbe651def3090bb02344787ef1b3f,arr,Recap,"Furthermore, the authors propose a defense model, which can improve the robustness of conversational models. ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Recap,"This is important for triggering business opportunities.
",10 11 12 13 14 15 16
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Recap,"Throughout training, this labeled set is updated with the models own predictions. ",26 27 28 29 30 31 32 33 34 35 36 37
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Recap,The paper proposes an extension to the ARAE architecture. ,17 18 19 20 21 22 23 24 25
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Recap,The key novelties are (1) an internal graph representation of the operators and (2) a novel pretraining setting. ,25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Recap,"On the other hand, it remains open as to what the impact of the proposed approach would be on any of the noted downstream applications, or beyond English. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Recap,"It introduces two effective distillation techniques, calibrated teacher training and activation boundary distillation, both proven beneficial for the results. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Recap,This paper studies the research problem of Adversarial Attack on text data. ,0 1 2 3 4 5 6 7 8 9 10 11
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Recap,"On the XOR-TyDi leaderboard, one of this paper's models is the current best. ",127 128 129 130 131 132 133 134 135 136 137 138 139
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Recap,"For details, please see my previous review comments.
",18 19 20 21 22 23 24 25
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Recap,"While the model components are all previously explored, it is interesting to see their application in a clinical outcome prediction setting with notes.
",107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Recap,"To this end, the proposed method (a) converts an utterance to an AMR graph, a semantic representation that abstracts away from syntax, (b) injects inconsistency to AMR, (c) translates the manipulated AMR back to text. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"The following baselines, in increasing performance order, are used: (1) [bottom] ColBERT IR model + XML-RoBERTa multilingual masked language model, fine-tuned with English data       (2) ColBERT IR model + XML-RoBERTa multilingual masked language model, fine-tuned with both English and cross-language data  (3) [top] classical approach: MT + ColBERT IR model, fine-tuned with English data  ",395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Recap,They show how their benchmark datasets capture these properties. ,46 47 48 49 50 51 52 53 54
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Recap,The problem is important and interesting. ,18 19 20 21 22 23
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Recap,This paper presents two approaches for reducing the storage costs in late interaction ranking models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Recap,No annotations are performed. ,15 16 17 18
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,This paper describes a contrastive learning approach to automatically solving math word problems (MWP) and investigates multilingual approaches to the problem. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Recap,"Models: The authors experimentally compare text-only BERT-base and a range of existing cross-modal models, pretrained with the different objectives, as far as applicable. ",72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Recap,Each of these experts focuses on a different kind of information (table reasoning). ,20 21 22 23 24 25 26 27 28 29 30 31 32
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,"Since the most frequent issue was related to coreference, the paper proposes a question-rewrite method to amend references by replacing them with the original entities, mentioned in the history. ",169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Recap,This work proposes to improve lexically constrained non-autoregressive translation by incorporating constraints during training and utilizing the source-side alignment during training and inference. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Recap,The authors introduced several simplifications to the datasets to make the benchmark more standardized and easily accessible. ,49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Recap,"The motivation for this last method is to inform the model as to what source word(s) correspond to the constraint, so that the context can be better generated. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Recap,"As shown in Figure 1, the audio branch is initialized from a pre-trained wav2vec 2.0, the visual branch is initialized from a pre-trained MoCo v2, and the two branches are fused before seq2seq+CTC decoding. ",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Recap,They compare their novel model on the KILT leaderboard and demonstrate effectiveness gains compared to relevant related work. ,63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Recap,Additional experiment on the impact of training on data is also analyzed in the paper. ,160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,The paper proposes a multi-task knowledge distillation framework for unsupervised cross-lingual NER applications. ,0 1 2 3 4 5 6 7 8 9 10 11 12
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Recap,The authors also discussed several social and research implications of waywardness. ,77 78 79 80 81 82 83 84 85 86 87
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Recap,In experiments the authors test the methods' viability on many language pairs and show competitive performance across the board. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"
5. ",125
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,If the method is trained in 4. ,103 104 105 106 107 108 109
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,"
3) the multi-resolutional data processing approach may somehow increase the instance weight of the document-level data, and how this affects the performance is not studied. ",228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap,"The proposed balanced loss is not distinct from the one in Switch Transformer.
",103 104 105 106 107 108 109 110 111 112 113 114 115
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Recap,"To overcome the challenges of homogenous word representations with quantized model which can impact conditional models such as GPT, authors present two modifications 1./ Word level contrastive distillation loss. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Recap,"They evaluate this model in 18 tasks and show that ConfliBERT performs better than BERT overall, particularly in settings with less annotated data. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Recap,"This paper introduces a new multimodal dialogue state tracking dataset, with simulated dialogues of moving objects that have varying shapes, colors, and sizes. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Recap,The authors transform the relations in the UMLS knowledge graph to form triples for probing PLMs’ biomedical knowledge. ,11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Recap,The method is based on integrated gradients and several refining steps. ,26 27 28 29 30 31 32 33 34 35 36
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,"The proposed core-set selection algorithm works right before the FF layer, which reduces the number of vectors in the input set according to a pre-defined length configuration. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap, ,
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Recap,The authors proposed a Locally Aggregated Feature Attribution method and claimed that this is a novel gradient-based feature attribution method for NLP models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"To solve this challenge, they propose a conditional variational autoencoder with adversarial training to perform singing beautifying. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Recap,This paper discusses how to transfer text from one domain to another by preserving some attributes (constraints). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Recap,The proposed method seems reasonable and in general using the cooperative losses seem nice. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Recap,They then run a sentiment classifier and see whether that classifier maintains are ranking between the pair of sequences after their transformation. ,80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Recap,"The paper addresses a sub-topic in the realm of mis/disinformation, namely images posted on social media with a misleading caption. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,"These heuristics help in identifying answers of a specific type appropriate for narratives (identifying characters, setting, plot etc). ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Recap,"The full dataset contains over 30k claims.
",63 64 65 66 67 68 69
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Recap,"In this paper, the authors propose to tackle the task of text style transfer where several constraints (topics, pronus, proper nouns, sentence length) are expected. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,This is a contribution to the field of modeling singing. ,104 105 106 107 108 109 110 111 112 113
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Recap, ,
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Recap,"Entity alignments map entities mentioned in text to corresponding row/column headers/subheaders and quantities are mapped to with single-cell quantities or to multiple cell via an operator that should be applied to the multiple cell values (e.g., average, difference, etc.). ",70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Recap,"The paper proposed a promising indicator, gradient accordance, to alleviate Flooding method from hyper-parameter search. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Recap,"The authors also demonstrate that the method is applicable to a ResNet trained on CIFAR to do vision classification.
",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
0e30497ecba61ed356a72b0213bc87e06347be6b0164284ff6f25182bf1e310ac082f086cd5e0d6455085d4bf4025289c6f66bb8555e953606e080663f2aa9c1,arr,Recap,"The authors improve the previous Universal Rewriter model with some techniques, including style-controlled back-translation, paraphrase vectors for style extractor, multi-task learning. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap, ,
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Recap,Experiments show that the framework can reduce up to 2/3 of the model parameters while hardly hurting the model performance. ,63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Recap,"They then conduct experiments on HUE corpora with the LM model, taking BERT as the baseline. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Recap,"It explores a number of possible hash strategies, and compares with previous work. ",14 15 16 17 18 19 20 21 22 23 24 25 26
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Recap,They add a time estimation module to the temporal KGQA. ,15 16 17 18 19 20 21 22 23 24
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Recap,"The authors present a method to identify tokens indicative of spurious correlations by: (i) identifying tokens that significantly affect model predictions (e.g. by looking at assigned attention, aggregated over a corpus); (ii) filter these tokens through cross-dataset analysis: removing tokens which are significant across multiple dataset (and thus unlikely to represent spurious correlations); and (iii) further filter the tokens through perturbation analysis: remove tokens which if replaced by their synonyms cause the classifier to change the predicted score significantly.
",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,"By NLP technology, the author studied the papers published at the conference included in ACL anthology to quantitatively explore the relationship between the location of conferences in a research field and diversity of participation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Recap,"
Generally, this paper introduces an important but not well-studied research question (i.e. to what extent are sense embeddings biased?), ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,I assume it stands for information extraction)  ,91 92 93 94 95 96 97
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"
They experiment with the MTQE-PE data set that has both Direct Assessment (DA) with a scale of 0-100 of MT sentences by humans and Post Editing of these sentences. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Recap,"Further analysis shows how automated evaluation differs from human evaluation, and what human evaluation tells about current CQA modeling strategies including insights for future work. ",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Recap,The method can increase the number of test cases by a polynomial factor. ,30 31 32 33 34 35 36 37 38 39 40 41 42
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Recap,"Then, they annotated the collected sentences with semantic role labels using a frame-free methodology (which eliminates the need to instruct the annotators about an ontology, e.g., PropBank or FrameNet), trained a system on the source domain and evaluated the resulting system on the out-of-domain test sets.
",113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Recap,"Although limited, the paper additionally presents some descriptive analyses of the collected annotations. ",98 99 100 101 102 103 104 105 106 107 108 109 110
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Recap,"The authors also release the FRUIT-WIKI dataset, a collection of over 170K distantly supervised data produced from pairs of Wikipedia snapshots, along with our data generation pipeline and a gold evaluation set of 914 instances whose edits are guaranteed to be supported by the evidence. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,"One potential solution is to use a mixture of softmax (MoS), but the paper further argues that MoS is still not expressive enough, and attribute the limitation to the reuse of a single hidden vector. ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap,"The backbone is Transformer block, and Mask Vision Modeling (similar to Mask Language Modeling) is used to self-supervise the learning of visual representations.
",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Recap," Furthermore, a biaffine transformation is learnt to help compare synonym representations to the representation of the input text for a given code. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Recap,"This paper propose a two-stage training for the complete many-to-many Multilingual NMT, where the model is first pretrained on the complete multilingual dataset, then finetuned only with the same target language data. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Recap,Extensive experiments are conducted on two KBQA datasets: WebQSP and CWQ. ,46 47 48 49 50 51 52 53 54 55 56
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Recap,A method to train dense retrieval without the need of any supervised data using a combination of ICT and SimCSE. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Recap,This paper tackles the problem of retrieval-augmented generation. ,0 1 2 3 4 5 6 7
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Recap,"Moreover, char-based evaluation metrics are suggested, and ablation experiments are implemented on the number of references, error types, text sources, etc. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Recap,"In this paper, authors propose a new variation of slot accuracy metric, called as relative slot accuracy (RSA), for dialog state tracking (DST) evaluation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,The dataset is annotated by experienced annotators. ,89 90 91 92 93 94 95
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Recap,The proposed method is novel and the experiments are comprehensive. ,48 49 50 51 52 53 54 55 56 57
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Recap,"This paper formulates implicit offensive text detection (OTD) as a multi-hop reasoning problem that includes the chain of reasoning, generating a dataset that consists of explicit and implicit offensive texts, to demonstrate how the detection is difficult and should be handled. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,The model performance is compared with several existing baselines. ,130 131 132 133 134 135 136 137 138
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,Their results outperform HDSF and GROVER at the document level and random guessing and logistic regression heuristics at the event level. ,152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Recap,They provide results that show that their method outperforms prior work. ,36 37 38 39 40 41 42 43 44 45 46
03cb8483ba66064a3c9b4a132af185e861b3dd292bf0b90105956dfbf7cc7e88e5bff423e0904e34b16baa401f61c0938331c4795c5fcfa86fdf99d4eb48c7af,arr,Recap,"Then they further analyze the cause for this poor performance and propose ways to mitigate it and partially close the gap with the performance of the discriminative model by discriminative fine-tuning.
",72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Recap,"
The proposed model shows the state of the art results on T-REx SPO and T-REx DS ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Recap,This paper reviews recent state of NLP in South Asia with special focus on historical comparative linguistics. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Recap,The paper also propose a weakly supervised pre-training for SR and a unsupervised pre-training method for the retriever. ,28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Recap,"With comparable performance with the full-precision models, paper present 14.4× and 13.4× compression rates on GPT-2 and BART, respectively. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Recap,"Specifically, they designed templates for each task they consider and prompted GPT3 to produce relevant knowledge for each question. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Recap,"
The experimental results show that these entity-based approaches consistently outperform word-based baselines, and entity representations provide more language-agnostic features to solve the downstream tasks. ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Recap,"The main takeaway is that, indeed, even though the system achieves very good results on the test set of the source domain, there is a significant drop in performance on the target domains. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Recap,Two encoders are used for extracting related syntactic information to direct the generation process. ,69 70 71 72 73 74 75 76 77 78 79 80 81 82
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,Extensive comparative experiments were performed to show that the proposed method outperforms existing methods. ,77 78 79 80 81 82 83 84 85 86 87 88 89 90
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,"On a sub-family of factor graph grammars which subsume most commonly-used structured prediction models such as HMMs, HSMMs, and PCFGs, this work proposes to marginalize the state nodes first and only perform inference in the induced rank nodes, which reduces the complexity by replacing a factor of the state size by a factor of the rank size which is usually smaller. ",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
a0821b6cbd2b3bfbddc644f83e27e1bac50ac0153c23386ca20f5725418f812cc73f2220474452bd2b77d97410b6c4814451212581aec2b8fd71c84521db7a70,arr,Recap,"From the experimental results, the pre-training strategy proved useful to improve the performance on the benchmark MultiWOZ. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Recap,"To this end, this paper proposes a three-stage framework: 1) learn to predict the question type distribution, 2) extract salient question-worthy events from the text, and 3) generate educational questions based on the outputs from steps 1) and 2). ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Recap,The idea of incorporating patient-specific medical literature is novel. ,24 25 26 27 28 29 30 31 32
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Recap,And a decoder self-attention-based interaction mechanism to share other role’s summary information. ,61 62 63 64 65 66 67 68 69 70 71 72
30c560d953cfea79231c569c75aac1ddba56028f9cab0b15bd35b305d101a59a9b3b75c0394aedbe0e76635db490468e6549fb78b4a28744db731dedf1b5ad0b,arr,Recap,The key idea is to control the sampling to sample more from languages with higher losses. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"In general, the results of all the models measured by the hit rate metrics were not good. ",238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,The paper presents a dedicated annotated corpus for the punctuation restoration task. ,0 1 2 3 4 5 6 7 8 9 10 11
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,They explore using already trained prompts to transfer knowledge between tasks (using the same frozen model) and also the transfer of prompt between _different_ frozen models. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Recap,"This paper presents two extensions for improving non-autoregressive machine translation (NAT) with lexical constraints, with a focus on low frequency words. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"Using a sentence level QE system, they use feature attribution in a sentence level QE system to determine the errorfull  spans of words in a target translation that most contribute to the QE model score. ",10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Recap,The paper also releases a new parallel bilingual ARA dataset for future research. ,63 64 65 66 67 68 69 70 71 72 73 74 75
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,"
Opposing values or different ways of prioritizing these values lead to conflicts and disagreements. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"Various downstream applications of the defensed embeddings with compatible performance to traditional LM embeddings would concretely prove that there is little utility degradation, thus expanding on the evaluated metrics; this is largely out of the scope of the paper but would solidify its results. ",925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Recap,"
The problem originates from using a single hidden state vector and global word vectors for dot product and softmax calculations. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
0805cef3514c6a8a408cb365fd19199aaee44bbc746bb7bc13c51afa2bd0cfdd0e9165c5a40142bf664015f97a59341d81ff0ce405993bbbbaeb8110390c3739,arr,Recap,The experimental results showed that all these approaches lead to better performance in both pipeline and E2E-based spoken NER systems. ,37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Recap,This paper proposes an unsupervised pre-training method for dense retriever. ,0 1 2 3 4 5 6 7 8 9
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Recap,"Experiments show that the proposed approaches outperform the state of the art on an English and a Chinese dataset.
",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,"First, one encoder computes contextualized vector representation of tokens in the given passage. ",42 43 44 45 46 47 48 49 50 51 52 53 54
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Recap,"To expand a bit, the authors start by revisiting the SPP, which sometimes goes by the name of softmax bottleneck in literature. ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Recap,improve SOTA performance when generalizing to unseen environments (Room-across-room dataset) 2. ,59 60 61 62 63 64 65 66 67 68 69
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"In its analysis, the paper shows factual information of how attribution methods can be misleading when they approve of a model’s prediction countering the actual norm or expectation. ",118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap,The paper proposes a pre-training strategy that leverages on the multilingual knowledge base to learn representations for entities and relations among them. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Recap,"They considered the following 3 use cases: (1) a foreign language speaker uses ToD in the foreign-language country (F&F), or (2) an English country (F&E), (3) an English speaker uses ToD in a foreign-language country (E&F), which are different from the traditional E&E use case where an English speaker uses ToD in an English-speaking country. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Recap,"This paper deals with the temporal misalignment problem, which occurs when an NLP model is trained on a dataset created from data of a certain time period and tested/used for data of another time period. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Recap,"Since one cannot have parallel corpora with originals in the 2 languages simultaneously, the authors analyse which is the best configuration in data and model alignments for maximising machine translation quality. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Recap,Experiments are performed on distilling BERT and evaluated on a number of tasks/datasets in the GLUE benchmark. ,101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"Thus this paper addresses limitations of the adversarial data collection process, which is the large amount of time needed to collect the dataset. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Recap,This paper discusses an important task for endangered language documentation -- i.e. phoneme transcription. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Recap,"This paper describes modifications made to the ReClor data set and ELECTRA, a system built to perform machine reading comprehension (MRC) on that data set, so that both the data and the system handle uncertainty in the selection of multiple-choice answers and abstain from providing an answer when the question posed is unanswerable. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Recap,The paper reports an extensive study of explanations in out-of-domain settings. ,0 1 2 3 4 5 6 7 8 9 10
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Recap,"Their analyses reveal that zero-shot performance can vary significantly with different prompts, but the performance stabilizes with the availability of a few examples. ",62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
be568f104f0e1b637d4b120996bb430002bf55f8aa8f7bfcccdfef78019a1d7ca572c1a9c80d282ad99b174db590ca56de7e2b169b6378daa39bc1201d886fa5,arr,Recap,"
The task of simple definition generation proposed in this paper is challenging due to the lack of training data unlike ordinary definition generation. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Recap,"The key feature of this model is that it computes representations at multiple scales (token, segment and document level). ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,Nearly all of the concerns I and other reviewers raised were addressed. ,119 120 121 122 123 124 125 126 127 128 129 130
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,The authors present a variational inference based method to learn these mappings without access to explicit supervision. ,97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Recap,The background section provides all the necessary material to understand and contextualize the task. ,79 80 81 82 83 84 85 86 87 88 89 90 91 92
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Recap,And it is also more memory efficient than many other BERTs as tested on GLUE devset. ,52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Recap,They propose monotonic regional attention and unified pretraining to better adapt multi-task training. ,14 15 16 17 18 19 20 21 22 23 24 25 26
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Recap,This method is claimed to be cost-effective. ,67 68 69 70 71 72 73
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Recap,The authors experiment with neural and other baseline models. ,18 19 20 21 22 23 24 25 26
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap," The dialogues mainly focus on visually-grounded object reasoning, where a question is raised to query the states of objects in the given video clip.
",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Recap,"To this end, the authors propose a new biomedical probing suite derived from UMLS and evaluate different PLMs with multiple probing techniques on it. ",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Recap,"These instructions are mapped to a unified schema which include definition, prompt, positive/negative examples etc. ( ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Recap,This work compares whole-word-masking and character-level masking for Chinese masked language modelling. ,0 1 2 3 4 5 6 7 8 9 10 11
057a3f73710f304801787e253e5ffc7e5d2eb9cf4570a5e3c6dc8edf75ebaadb324aff13a67e27a6057b12080f89cd80cc8d0f000bd23657daf14ff9c30856db,arr,Recap,It allows to achieve new SOTA on BEA2019 test. ,21 22 23 24 25 26 27 28 29
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Recap,There is also evidence that abstractness of argument structure in representations increases as a function of the amount of pretraining: LMs with more pretraining data show a stronger tendency to group sentences by argument structure than by verb identity. ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Recap,The paper presents a new task called: Spoken Conversational Question Answering (SCQA). ,0 1 2 3 4 5 6 7 8 9 10 11
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,And more analysis and insights to the optimal number of iterations would be helpful. ,202 203 204 205 206 207 208 209 210 211 212 213 214 215
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Recap,"In other words, this task does not require identifying entities.
",23 24 25 26 27 28 29 30 31 32
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Recap,"This paper proposes VHED, 1) a dataset comprising human judgments over story pairs from the VIST dataset, and 2) Vrank, a reference-free metric for VIST. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,"To motivate the use of contrastive learning, the paper opens with an analysis of the effect of training epoch and encoder layer on the clustering of MWPs by prototype equation. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Recap,"The setting of this work is limited labeled data and much more unlabelled data.
",23 24 25 26 27 28 29 30 31 32 33 34 35 36
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Recap,"The first is how to protect users’ plain text data from access by third-party service providers, and the second one is the performance issue. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,"If the underlying values can be made explicit, valuable insights can be gained in the analysis of different discourses. ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Recap, The paper compares a pairwise neural ranking model with existing non-ranking ARA methods and explores the monolingual and cross-lingual transferability of their ARA ranking model. ,29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"This helps significantly reduce training time cost, and allows deployment of a single shared premise encoder for input sentences across various different tasks (saving memory costs).
",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Recap,This paper introduces a method to improve both interpretations and inference by training an end-to-end model to simultaneously generate explanations and labels for the NLI and CQA tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Recap,"Additionally, the source prompts will be released as an open-source library to enable future experimentation on prompt-based transfer learning in other tasks/domains. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Recap,"They investigate two ways of using the entity representations in cross-lingual transfer tasks: (1) perform entity linking for the input text, and append the detected entity tokens to the input sequence;  (2) use the entity [MASK] token from the MEP task as a language-independent feature extractor. ",32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Recap,"The main novelty is that the paper proposed an energy-based interpretation of the swift model predictions, and results in estimating the density function of the examples suitable for the swift model. ",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Recap,"The discrete augmentation approaches (Wu et al., 2020; Meng et al., 2021) sometimes distorts semantic meaning of sentences, creating positive pairs that do not indeed have the same meaning. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Recap,"Although it heavily relies on IBM API, it poses its own research question (moral arguments for audiences), builds a distantly-supervised classifier for moral arguments, and conducts a nicely designed user study. ",29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Recap,"This paper presentes a multi task learning approach for automatic grading of English essays, by considering a holistic score as well as scores on individual essay traits. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Recap,"Experimental results show that both methods for knowledge incorporation improve the system's performance.
",42 43 44 45 46 47 48 49 50 51 52 53 54
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,"The paper also presents a new method for probing PLMs, called Contrastive-Probe. ",58 59 60 61 62 63 64 65 66 67 68 69
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Recap,The hypothesis is that for any arbitrary text there exists a continuous prompt whose discrete projection is said arbitrary text *and* whose resulting performance is almost as good as the best possible continuous prompt. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,"Therefore, this work adopts the NMN and proposes VGNMN which decomposes the task into a pipeline. ",29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Recap,"The auxiliary tasks include: (1) autocompletion, MLM objective based on hand-crafted rules, (2) pre-action (what is needed) and goal generation (pseudo intent) and (3) action arguments prediction, using labels from FrameNet. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Recap,"At the same time, formula mask language model is also employed to get better representation of the spreadsheet formula. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Recap,"The main contributions are two complementary/auxiliary objective functions:   * Numerical Reference Prediction,   * Numerical Calculation Prediction. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Recap,"The authors propose mix-GLT, a technique for training non-autoregressive transformer (NAT). ",0 1 2 3 4 5 6 7 8 9 10
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Recap,"As a result, the authors are calling the community to build models that can improve the performance. ",72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,A serious issue! ,141 142 143
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Recap,The proposed model is evaluated on two benchmark datasets - MedMentions (a dataset for biomedical entity linking ) and ZeShEL (a dataset for zero-shot entity linking). ,49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Recap,The contrast sets are created by swiping the gender of a person or using pre-trained LMs to replace verb phrases with top K most probable phrases. ,50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Recap,"They run their model on three datasets, namely CNN/DM, arXiv, and Pubmed, showing their system staying competitive (in some cases outperforms model-wise baselines). ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,Similarity evaluator teacher model is based on siamese neural network. ,44 45 46 47 48 49 50 51 52 53
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Recap,This dataset contains complex types of chapter transitions that require long-range context understanding. ,19 20 21 22 23 24 25 26 27 28 29 30 31
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Recap,The paper is now more solid and worthy of publication. ,154 155 156 157 158 159 160 161 162 163
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Recap,The authors worked with two languages that are still being documented Mboshi and Japhug. ,27 28 29 30 31 32 33 34 35 36 37 38 39 40
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Recap,"The method uses a combination of a SciBERT encoder, contrastive learning, multi-instance learning, and optimal transport. ",60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Recap,Most state of the art models are trained or fine-tuned on datasets developed specifically for this task. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Recap,"The authors empirically find that providing instructions about a task in natural language (in a structured format specifying role of each section in an instruction, such as definition, prompt, etc.) ",62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,This paper proposes an LM pre-training method for bi-encoder models. ,0 1 2 3 4 5 6 7 8 9
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"While most neural singing models focus on automatic pitch correction, the authors also extend their model to modify vocal tone and achieves good performance. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Recap,The proposed approach uses two-step training (with labeled parallel and task-specific datasets) and six linguistically inspired training losses in two combinations (models). ,61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,"It proposes a multi-resolutional data processing step which iteratively split document corpus into k (1, 2, 4, 8,...) parts and feeds them to the sentence-to-sentence translation model. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Recap,The authors experiment on NLI and conversational QA tasks. ,95 96 97 98 99 100 101 102 103
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"The proposed model will perform an early exit based on layer K’s prediction if layer K is confident, and the patient counter is above a predetermined limit. ",299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,"Due to the particular parameterization, there is a problem termed softmax bottleneck, where the degree of freedom for the output word distribution is limited by the dimension of the hidden vector. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Recap,"The proposed framework consists of three modules, lexicalization, aggregation, and post-editing, which are composed of PLMs and do not share parameters. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"Personally, I am not aware of any other work that probes contextualized word representations for argument constructions, and I appreciate that the authors take their inspiration directly from the psycholinguistic literature on the psychological reality of argument constructions. ",262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"Label tuning is not as effective, but a lot of performance can be recovered using knowledge distillation. ",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Recap,"The improvements are noteworthy, albeit on a narrow task. ",33 34 35 36 37 38 39 40 41
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Recap,"This paper developed a new dataset, GlobalWOZ, a multilingual extension of the English MultiWOZ to about 20 languages through machine translation (to save cost) and replacing entities occurring in the English dataset with local entities that are most likely to be used in a foreign language (in the country where the language is spoken). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,"To do this, they created their own fake data, apply cross-document coreference, group data into three sets based on event “clusters” (topically related events), and report event detection results. ",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Recap,"As dialog task relabeling is not enough to make successful performance, three additional auxiliary tricks are suggested: task-specific auxiliary loss, task pretraining, and model-based dialogue rollouts. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Recap,Although this is the paper summary section and criticism should not appear here - I feel obligated to mention here that the authors did not report any statistical analysis of their result! ,97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,"Heuristic rules are applied to the design of the model for answer extraction (e.g., extracting named entities and noun chunks as potential answers and semantic roles of verbs as annotated in Propbank). ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Recap,The authors further add a contrastive loss to enhance the models' controllability. ,35 36 37 38 39 40 41 42 43 44 45 46
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Recap,The authors aim to improve interpretability for structure and style control in knowledge-grounded conversational models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Recap,"First, they show that under a harsh negative-penalty (3:5) for wrong answers, abstaining from answering a certain amount of questions improves the overall performance. ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,the model architecture is the bi-encoder architecture. ,35 36 37 38 39 40 41
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Recap,The main contribution of this paper is an extensive survey of works since 2019 that study the questions around the explanatory power of attention mechanisms. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,Empirically this work scales HMMs and PCFGs to very large state spaces and achieves strong performance. ,199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"**What is the task?**
",0 1 2 3
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Recap,"2- They also propose to improve the inference lattency of the systems by using an ""unbalanced"" Transformer architecture with 9 encoding layers but only 2 decoding layers. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Recap,"Nearly all tables in the dataset are hierarchical, with fine-grained annotations of quantity and entity alignment. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,The paper proposed a unified framework to exert both syntactic and keyword control for paraphrase generation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Recap,"This paper targets a source of ambiguity in user interactions with task-oriented dialog systems: when a user asks for an action (e.g. booking) to be taken with regards to, or asks a question about an ambiguous/underspecified entity. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Recap,"For contributions, the authors show first that syntactic information is redundantly encoded in language models, based on estimates of mutual information between different parts of the embeddings. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Recap,The authors explain in detail UE methods and conduct extensive experiments comparing the different methods for a Transformer model trained for the selected tasks. ,46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,The KL loss seems to flatten the over-learning problem in CE fine-tuning and the MI loss makes the network private by leveraging a MLP to remove statistical co-occurences in the embeddings related to personas. ,322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Recap,"Results show the proposed method can outperform state-of-the-art detection approaches, such as FGWS, on most datasets. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Recap,"However, I have some concerns about the performance. ",82 83 84 85 86 87 88 89
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Recap,The paper compares the pipeline approach and end-2-end approach to analyze how they benefit from external data. ,35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Recap,This paper proposes three new tasks based on a corpus of historical texts. ,0 1 2 3 4 5 6 7 8 9 10 11 12
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Recap,"The proposed mix-GLT combines the 1) latent transformer (LT) that uses discrete latent variables to reduce multi-modality problems with 2) glancing transformer (GLAT), a fast and strong NAT baseline. ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Recap,"The proposed framework makes use of self-chatting approaches using a SotA system, as well as fine-tuned versions of the chatbot to play the role of a salesman and a user. ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
6695a2d16cadbaadac9a6a13d88ce4c37d0b78386799e141932cd2f36abca22fd324255f8bb1cae45c1f5eb66a945e0fcde3221c9e5cfabbde0339e17e30bebd,arr,Recap,"The model outperforms existing methods on two tasks - cross-corpus ranking and zero shot, cross-lingual ranking - based on ranking metrics. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Recap,The authors present a neural OpenIE system which produces “compact” extractions. ,26 27 28 29 30 31 32 33 34 35 36
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,"Since this definition does not enforce source-side semantic agreement, the authors choose to build bilingual adversarial pairs (such that the target-side sentence will still have the same semantic as the perturbed source). ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Recap,A total of five datasets are involved in the experiments. ,119 120 121 122 123 124 125 126 127 128
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,The goal of the presented research was to improve results for NLP tasks requiring semantic understanding. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,"The paper finds that using predicted answers while retaining existing questions suffers from 3 drawbacks: unresolved coreference, incoherence, and change in the correct answer. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Recap,"However, the proposed method seems too trivial and underperforms the state-of-the-art parser on the English datasets by a large margin. ",120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,	The experiment for inference time comparison should be added. ,210 211 212 213 214 215 216 217 218
0f595b4bd968ef5daacc88c4edb581bf7f683af30b6874ba157c6d2282aabead577041409b949924e4bc5ef54c543d85a10e962be8e70304dea65e1b18441bdb,arr,Recap,"Their results are highly suggestive that ""although language users may use phonological hierarchies like those proposed in Mortensen (2006) to select appropriate orders for EEs and CCs, it is clearly not the case that they must (though they will perform a bit better if they do)"". ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Recap,"This paper proposes a bidimensional leaderboard, or Billboard, that measures progress both on generation tasks and automatic evaluation of NLG simultaneously. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Recap,This paper investigates the aspect sentiment triplet extraction task and optimized bidirectional machine reading comprehension method with 4 improvements. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,The author has discussed related work on using interactive feedback for other NLP tasks. ,174 175 176 177 178 179 180 181 182 183 184 185 186 187
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Recap,This paper also proposes their own models on this task SEC-BERT-SHAPE. ,43 44 45 46 47 48 49 50 51 52 53
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Recap,"To reduce the computational cost and potential risk of ""over-refinement"", the authors design a local constraint that narrow the refinement span to the N nearest tokens. ",96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Recap,A selective attention mechanism is proposed for Vision Transformer to correlate words with image patches. ,27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Recap,This paper compiles and annotates a multi-reference Chinese Grammatical Error Correction (MuCGEC) evaluation dataset from three different Chinese Second Language sources. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Recap,"The paper investigates methods to automatically generate morally framed arguments (relying on a specific stance, on the given topic focusing on the given morals), and analyses the effect of these arguments on different audiences (namely, as liberals and conservatives). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Recap,"To motivate the new metric contribution, this work provides rich insights regarding the evaluation protocols being used in VIST. ",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Recap, ,
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Recap,"The authors attribute the cause of this bias to both the model and the human annotators as they tend of provide a high score to fluent but inadequate translations.
",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Recap,"To develop a benchmark, the authors collected a new KGC dataset based on Reddit containing personalized information (e.g. user profile and dialogue history). ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Recap,"The remaining concern I have is the instability of major PLMs (e.g., https://openreview.net/forum?id=nzpLWnVAyah), where PLMs are very sensitive to hyper-parameters both in pre-training and fine-tuning. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Recap,"This paper introduced Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Recap,"The authors train several SOTA systems on their parallel dataset and show significant improvements over unsupervised systems, emphasizing the benefits of focusing efforts on creating parallel data, as opposed utilizing non-parallel data. ",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Recap,This paper proposes a method based on Optimal Transport (OT) to simultaneously incorporate the interaction between syntax and semantics as part of the content preservation objective for Text Style Transfer (TST) training. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,This work attempts to demonstrate that privacy concerns exist by a simple attacker network that identifies persona attributes and proposes defense objectives that reduce the exploitation of the model's hidden state. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,Then the 10 closest entity representations are selected with a Nearest Neighbor Search. ,124 125 126 127 128 129 130 131 132 133 134 135 136
d0adbc683b1920556f2f658448daf2792434b209a9960622144d3cf741857c04c0854fce75bf2591fe5e861afaa3a58b2593abb0ea1927e3b4e1168cb2175c86,arr,Recap,The paper advances research in Temporal KGQA through a unified time-sensitive question answering framework (TSQA). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,"The results show the effectiveness of the proposed method, although there are still some limitations (e.g., tending to shift to movie reviews regardless of prompts). ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Recap,"On the GLUE benchmark, the proposed method outperfroms other smaller BERT variants with a better accuracy-model_size trade-off. ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,"The performance of structured prediction models can be greatly improved by scaling to larger state spaces, yet the inference complexity of these models scales poorly w.r.t. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,This work shows that those works are essentially performing message passing on a factor graph with two types of nodes: the original state nodes and auxiliary rank nodes induced by the low-rank tensor decomposition. ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Recap,"The authors also performed layer conductance analysis to validate the hypothesis about vanishing gradients, showing that MSLR leads to models with larger layer conductance values. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Recap,"This differs from previous work which mostly focused on the alignment direction between the translation model and the test set.
",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Recap,"This paper presents a new dataset - DISAPERE, which includes discourse related annotations over scientific peer reviews and rebuttals. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
3398ca971c1ee00e7f56db6a5d9069a561805ba4bd33e4cc84ef6a4c1acf331a4d8c1a7e53ebf415d32cbefe4396b1808e031ddcef812a37768f40bde058252f,arr,Recap,"This well-written paper presents ""DIBIMT"", a manually annotated and curated benchmark to measure semantic biases in word sense disambiguation in machine translation via 4 newly defined metrics. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Recap,"Preliminary results show that pre-trained transformer models achieve moderate performance, therefore leaving room for future work. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Recap,"
Experimental results on a diverse set of tasks with multiple languages under limited annotation budgets show that the proposed method outperforms the models that are trained on one language and employed with zero-shot transer for inference and the models that are trained on target datasets where the annotation budget are equally divided across languages. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Recap,"They conduct experiments on four tasks including Link Prediction (LP), Knowledge probing from LMs (LM-KP), Cross-lingual entity linking (XEL), and Bilingual lexicon induction (BLI). ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Recap,This paper introduces a new method called CrossAligner which is used to transfer knowledge from English (or a high-resource language) to some other language without the presence of data using a zero-shot approach. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,This motivates the authors to tackle the task and initially address the following problems: they systematically evaluate existing taxonomies from social and psychological science. ,93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Recap,"The key insight of the method is to use language-agnostic special tokens (e.g., <Victim>) for the template. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Recap,"The authors categorize text classification literature into BOW-based models, Graph-based Models and Sequence models. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28
19f388a29acd478e296a556b93da193a08c35983f08334eb804d61a3b42f687cf8b7a8ad0984b98d01112105066170a4441bd5a07e61e8179253006a3cd6aeff,arr,Recap,This paper proposes to learn discriminative representations for open relation extraction. ,0 1 2 3 4 5 6 7 8 9 10
cae04ea5a5edc93df8355c570815cbecec45d18562b5e323e53d02cb9a95394dff757192c80981f891adf14462e54a81f0786e4017a672b721801666e52f162e,arr,Recap,"Based on PERIN, the weighted bipartite graph between all queries and nodes is applied to indicate the prior ordering of the graph. ",34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Recap,Reported results outperform SOTA on AirDialogue dataset. ,65 66 67 68 69 70 71
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Recap,This paper is about character-level machine translation. ,0 1 2 3 4 5 6
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Recap,They propose a simple BERT based architecture that processes several passages simultaneously and thus allows for inter-sentence information flow during encoding. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Recap,"The next experiment also involves transformations in NLI inputs, which lead to specific changes in inference labels. ",114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Recap,a post-processing method involving grap's repetition and PoS information. ,60 61 62 63 64 65 66 67 68
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Recap,"This approach was found to outperform the baseline model, and several insights were offered by inspecting the influence of text clustering and image OCR'ing. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,This paper proposes a method for Paraphrase Generation with an explicit control for the desired quality of the generated text. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Recap,"First, the authors constructed MedLAMA, a biomedical knowledge probing benchmark dataset based on the UMLS knowledge graph. ",7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Recap,"I found much of the response (and changes) to be reasonable, with many of my complaints (especially regarding lack of information on the human evaluation) addressed in this version of the paper. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Recap,"This paper presents COMUS, a method to fuse the representations of the text and the graphical mathematical syntax for math understanding tasks. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Recap,They propose to use a very simple approach (Masked label smoothing) that addresses the conflict. ,42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Recap, Experiments on classification as well as translation tasks show that the proposed approach achieves substantial speedup while retain the accuracy of the super model. ,43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"-Experiments that validate the defense and shows no informativity loss i.e downstream capabilities.
",204 205 206 207 208 209 210 211 212 213 214 215 216
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Recap,"However, I think the system description is still very involved and make it hard to judge the technical contributions of their system. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Recap,They show the effectiveness of their approach through various experiments and improve performance. ,57 58 59 60 61 62 63 64 65 66 67 68 69
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"Each method has its advantages and drawbacks: Exiting based on a confidence threshold is dependent on a single layer’s output, making it prone to noisy decisions. ",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Recap,The authors propose a multiple choice task posed over 10 images. ,0 1 2 3 4 5 6 7 8 9 10
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Recap,"Experiments are conducted on several tasks such as controllable debiasing, sentiment and formality transfer and prompted generation, and results show that this method outperforms task-specific baselines. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"That is, in contrast with classical MT-based CLIR systems, where we can clearly distinguish two phases/stages/subprocesses involved (translation + monolingual retrieval), this is now solved altogether. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Recap,without extensive finetuing. ,38 39 40
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,The subset of personas that are unseen are still significantly below the original language model. ,775 776 777 778 779 780 781 782 783 784 785 786 787 788 789
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Recap,"
The authors report results of 11 different PLMs and compare them to human performance. ",24 25 26 27 28 29 30 31 32 33 34 35 36 37
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Recap,"
It presents a simple but efficient approach ""split-then-summarize"" using a greedy algorithm for choosing the good partition.
",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Recap,The authors demonstrated that their proposed model improves over single-span models (generalized for multi-span QA) and over vanilla sequence tagging models. ,149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Recap,The authors conduct experiments on standard benchmark NLP tasks showing that their approach produces better/competitive results to baselines. ,97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
80f0f27bae63d383650b5083d56d54d49670478d69ab16c333d994ebabdcc2558eff25814b0b8333c8a9865b96d20dc0e171383473a1e65de16556abe5eef90c,arr,Recap,They tackled two problems of such generation (a) encoding the structural information -- by using a tree transformer to capture parent-child and sibling relationships and (b) retrieving syntactic structure to guide the generation - by introducing a synthetic template retriever. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Recap,The paper introduces a token attribution analysis method for transformer based models building upon previous norm-based and rollout aggregation methods. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap, ,
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Recap,"Technically, DiffCSE combines the standard contrastive objective from SimCSE with a difference-prediction objective conditioned on the sentence embedding. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,The PPL increase was explained by the authors as possibly stemming from the noisy nature of the KL loss with respect to the persona predictors task; the attacker model does not want a uniform model. ,657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Recap,"Their methods outperformance baselines including: random selection, Exercise Maker ( a rule based method) and BERT. ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Recap,"They do so by applying the Integrated Gradients method to the hidden layers of the FFNs in BERT-base, specifically when the model receives inputs about relational knowledge. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Recap,The proposed method is shown to have improved recall@k for candidate retrieval. ,90 91 92 93 94 95 96 97 98 99 100 101
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Recap,Paper hypothesize that problem of column operations is challenging for SOTA Text-to-SQL parsers. ,24 25 26 27 28 29 30 31 32 33 34 35 36
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,Authors have also presented ablation studies that prove the value of each component. ,220 221 222 223 224 225 226 227 228 229 230 231 232
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Recap,"In experiments, the authors compare with several baselines, showing the advantage of the proposed method. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Recap,Authors conduct an extensive analysis based on the annotation by humans as wells as the automatic system's decision. ,36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,"energy consumption is only estimated within the attention module, even though the reduction in a Transformer block is added (17%), the reduction of the full model (with the classifier) is not reported. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Recap,"The representation they aim to build relies on entity linking, so the authors explore this problem on several multilingual datasets, and draw conclusions regarding the cross-lingual consistency of NER and EL systems. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Recap,"While I do like the distinction between different types (levels) of extreme speech, I would expect to see more clarifications with examples among the 3 types extreme speech and if there are culture differences in the annotations across countries. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,"I really appreciate the authors' willingness to do so and look forward to the valuable resource being available for the research community.
",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Recap,"The authors observe that while much progress has been made on automatic evaluation metrics, NLG modeling papers often still report very old metrics like BLEU and ROUGE. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Recap,This method improves the performance of both BART and PEGASUS models. ,60 61 62 63 64 65 66 67 68 69 70
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Recap,Figure 1 gives a good summary. ,57 58 59 60 61 62
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Recap,"The paper introduces GlobalWoZ, a  mutllingual task-oriented dataset built from translating MultiWoZ dataset to 20 other languages. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Recap,"To tackle this problem, they propose DCLR framework to alleviate the influence sampling bias. ",32 33 34 35 36 37 38 39 40 41 42 43 44 45
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Recap,The embeddings of clinical notes and top relevant literature are then combined to predict the patient outcomes on MIMIC-III datasets. ,46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Recap,"
The problem basically states that the model can not output arbitrary distribution over the vocabulary.
",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Recap,"The authors evaluate the effect of several factors such as the LDND distance between the source and target languages, matching language families, matching writing systems and the pre-training of the source and target languages. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Recap,"After reading the authors' response, most questions and concerns are addressed. ",4 5 6 7 8 9 10 11 12 13 14
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Recap,This paper highlights a limitation of conventional softmax classifiers that use a single low rank fixed weight matrix in the softmax layer to compute logits via dot products from a single contextual embedding. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Recap, ,
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Recap,The model has the largest vocabulary  trained on the largest Hebrew corpus to date. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Recap,"In order to improve generation diversification, a template retriever is designed in practice. ",56 57 58 59 60 61 62 63 64 65 66 67 68
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,The change introduced by the authors are as follows as far as I can tell: ,206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,"
2. ",33
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Recap,The experiments show the proposed approach can improve the performance of Yu et al (2020). ,51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Recap,"Besides the promising experimental results, one strength of presented method is its scalable inference that could easily enable future applications based on the method. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Recap,They propose MAE. ,78 79 80
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Recap,"In experiment 2, inspired by jabbewocky priming studies, they find that representations of verbs placed into a novel (and usually ungrammatical or incoherent) syntactic frame have representations that more closely resemble verbs that canonically appear in that frame. ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Recap,"The paper assumes the teacher network is trainable and proposes a simple technique that, in the MAML framework, applies ""pilot updates"" in the inner loop to make the teacher and student networks more compatible. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
7f996fb9f31b45dea2339c0d4716c6c109c47c5b38feee689425e631026e454379762bebbea912d49f29530016a12a703c629819acd26de68018289115cb6bdd,arr,Recap,"However, using a probe trained on the full vocabulary as a way to initialize a LM does not seem to be useful, as the LM reaches the same training loss as a control one rather quickly. ",218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"1) Template verbalization with  2) ordering module, then the 3) aggregation and 4) sentence compression. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Recap,Their experimental results show that the proposed method improved some tasks compared with a standard distillation method. ,36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Recap,"To this end, the paper constructs adversarial test sets to verify this conclusion. ",25 26 27 28 29 30 31 32 33 34 35 36 37
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Recap,"That being said, some details needed for reproducibility are needed, and claims about the initial set being a “minor” source of supervision are contradicted throughout the text.
",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Recap,A subset of especially challenging questions is also selected in a task where annotators answer the question under strict time constraints. ,32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Recap,"This method goes beyond penalizing high-frequency words, but instead learn multi-level features of generic responses. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap, ,
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Recap,"Furthermore, they demonstrate that employing    contrastive learning a multilingual scenario improves performance w.r.t. ",91 92 93 94 95 96 97 98 99 100 101 102 103
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,- An instance weighting method to reduce the bias caused by false negatives - similarity between original sentence and each negative ,236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Recap,"Then, the method conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Recap,"Unlike previous works using descriptions of given schema, The SDT uses an example dialogue that consists of context and prompt based on the schema. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Recap,It achieves the debiased sampling by 1) adding per-example noise-based negatives and iteratively improving them by maximizing the non-uniform objective; 2) adding a similarity based filtering (based on a separate model) to remove false negatives. ,29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,The generated QA pairs are ranked via a classification task that decides if a QA pair is more similar to a ground truth pair or not. ,107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Recap,"And finally, to promote better uniformity across learned embeddings - label embeddings are also regularized. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"
Despite the exhaustive experimentation, all the experimental settings are done using one model-in-the-loop, one question prompt generator and 2 datasets of similar domains. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Recap,The new model outperforms those baselines when little data is available. ,35 36 37 38 39 40 41 42 43 44 45
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Recap,"Utilising a prompt-based approach, rather than optimising models to predict the expected label (i.e. whether two word senses are different), this paper proposes to predict (embeddings of) words synonymous to those in question and compare the distances of these embeddings. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Recap,"The main point of the paper is a corpus of baking recipes annotated for coreference and bridging relations (both 1-to-1 and many-to-1 transformations of ingredients) and experiments to learn coreference resolution on this genre by transfer from either just unsupervised pretraining (GloVe, ELMo) or including supervised training on an existing larger chemical corpus and subsequent transfer using a state-of-the-art model for span linking coreference. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"The paper highlights the potential damage of neglecting these traps such as inaccurate evaluation, unfair comparison, unmerited pressure to re-use unreliable evaluation techniques etc. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"The LM+MI variants are likely sufficiently private from my understanding, but reveals attributes/personas that are not relevant; this is of concern in smaller persona datasets. ",534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,1. ,209
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Recap,"To improve ranking performance, this work follows Nogueira et al 2020 and generates a special boolean token after generating the query, while training is a combination of classification loss and language modeling loss. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,"The expansion ends when the number of core-set reaching a certain number.
",85 86 87 88 89 90 91 92 93 94 95 96
5f9df67495c17db90e7bfcce611efe8b65edcb225b9fb603e5b7e3d30b198f39a36e0c38f66bc04a063129ecdaf2e387b1cb42291be7cf83de659b9fb091736c,arr,Recap,b) the authors proposed two methods for incorporating knowledge: a retrieval setup based on embedding similarity; a generation setup that completes knowledge triplets with COMET. ,37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Recap,The proposed approach proves effective by achieving new state-of-the-art on several STS benchmarks. ,153 154 155 156 157 158 159 160 161 162 163 164 165
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,"The number and the pronunciation of output characters should be consistent with the input pinyin, and the meaning of output should fit the input context.
",48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Recap,"Their goal is that in releasing this benchmark, it will be easier to measure progress on legal language understanding, which currently has relatively fragmented resources and evaluations. ",10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Recap,"The paper also studied large-scale training with in-house settings, including En-centric vs. multilingual-centric pretraining, and light-weight decoder architecture. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Recap,"This paper presents a method for identifying event types and their arguments in a low-resource scenario, i.e., with a limited amount of training examples. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Recap,"In addition to wide MLP, sequential BERT and DistilBERT models are fine-tuned, which overall yield state-of-the-art results on 5 well-known text categorization datasets. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Recap,"The authors also discuss a human in the loop (HITL) environment for accomplishing such work, based on their incremental, correction-based annotation of a trained transformer model in their annotation loop.
",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"From my intuition, this means that the defense objective robustly defends against the attacker model regardless of persona. ",790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Recap,This paper presents the idea of creating domain confused examples paired with contrastive learning for unsupervised domain adaptation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Recap,Experimental results show that the proposed method achieved better performance than previous methods in automatic and human evaluation. ,127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Recap,"Below is a copy from the previous review: >In this paper the authors proposed a new fairness metric, accumulated prediction sensitivity. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,This paper explores the effects of using a generative model that provides question prompts to human annotators in either the standard or adversarial data collection for training a QA model. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Recap,The authors utilize normalizing flows to model the sentence representations in a flexible space as transformed from a (shared between languages) simple base distribution. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Recap,"Moreover, the authors also attempted to use focal loss to further reduce the partial input bias in the QE model. ",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Recap,"The authors take as base model an approach very similar to that of Xu & Carpuat 2021 and expand it with a) ""constrained training"", where the system already sees lexicon constraints at training time and b) ""alignment prompting"", where alignment information is included into the model. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Recap,"Additionally, they use FairytaleQA for training question generation models and show that it can be used to ask high-quality reading comprehension questions. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Recap,Propose a schema expansion method using heuristics to expand columns into sets of derived columns. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Recap,"The paper finds that having certain characteristics is correlated with perceptions towards racism, for example, believing in freedom of speech, predisposes one to be more lax in annotating anti-Black toxicity. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Recap,The general motivation of this paper is to provide tools that analyze pairs of review and rebuttal in the peer-review process of scientific work and assess Area Chairs in making sense of this discussion to reach better-informed decisions of acceptance or rejection. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Recap, ,
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Recap,"The authors run experiments that evaluate the different approaches using 4 dialog datasets (PersonaChat, OpenSubtitles, Ubuntu and Twitter) where they show the effect of each approach on the resulting model as measured using BLEU, perplexity and F1. ",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
8a618d10cbf3a6fdb1c30d9e784a394d2d3e8b68cf89fd358b594d32344a4135636f7101c4b16ef3f3dc6a4a088e76a45ecc437ea2c733070c1b8098834e40ba,arr,Recap,This paper describes an advancement in counterfactual probes that test whether neural nets make use syntactic information. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Recap,"This paper use methods relying on spelling, using character embeddings, to detect sound change across time. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Recap,This paper introduces a domain-specific model for analyzing political conflict and violence. ,0 1 2 3 4 5 6 7 8 9 10 11
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,"Though the approach can surpass the sentence-level model baseline, the naive document-to-document translation model and Zheng et al. (2020), these baselines seem weak, for example, Voita et al. (2019) achieve 81.6, 58.1, 72.2 and 80.0 for deixis, lexical cohesion, ellipsis (infl.) ",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Recap,"Empirically, the set of potential pronunciations are not prohibitively large, and is feasible to enumerate. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Recap," The authors compared the quality of estimators on unigram distribution, information study on the association between gendered inanimate nouns and their modifying adjectives, and finally with similarity between grammatical gender partitions between languages. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
80f0f27bae63d383650b5083d56d54d49670478d69ab16c333d994ebabdcc2558eff25814b0b8333c8a9865b96d20dc0e171383473a1e65de16556abe5eef90c,arr,Recap,"In this paper, the authors proposed Structural Information-augmented Syntax Controlled Paraphrasing (Si_SCP) which is a syntax-controlled paraphrase generation technique. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Recap,A dynamic table of content-based navigator called DYNAMICTOC has been proposed for persona-based document consumption that highlights sections of interest. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Recap,"The tasks addressed are tagging, NER, and dependency parsing. ",34 35 36 37 38 39 40 41 42
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Recap,"
3) LEDR (Lexicon-ENhanced Dense Retrieval) that combine BM25 with a dense retriever to consider both lexical and semantic matching. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,The paper addresses a fundamental shortcoming in evaluating conversational question answering (CQA) models based on the gold-annotated question-answer pairs. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Recap,"Results show some improvements over simple baseline models that use only clinical text.
",61 62 63 64 65 66 67 68 69 70 71 72 73
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,Maybe a driving example describing step by step the example in Figures 2 and 3 could help to clarify the methodology. ,126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,Their approach is as follows:  ,72 73 74 75 76
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Recap,"Half of the data is then articifially made out-of-context, by both randomly connecting captions to images, and doing so in a more informed way by selecting on semantic similarity. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Recap, ,
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Recap,"1- Observing that many-to-many multilingual systems have issues with target language generation, they propose to fine-tune a N-to-N multilingual MT system into N   N-to-1 many-to-one MT system. ",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Recap,"While WSD can be considered part of the traditional NLP preprocessing pipeline, it's impact on modern end-to-end solution is likely small. ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Recap,This paper also analyzes the effect of using different hand-craft prompts/noisy prompts for zero-shot/few-shot performance and the effect of two pre-training objectives on different tasks. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,Figure 1 shows that the learned representations of utterance can manifest sensitive information about the persona. ,91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Recap,"A few related techniques are also applied to further boost performance, e.g. function recovering finetuning, domain specific tokens. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,Enhancing the target model as well as Excluding predictions with lower confidence. ,368 369 370 371 372 373 374 375 376 377 378 379
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Recap,"The proposed model combines BiLSTMs, Dilated CNNs and GCNNs to extract features from abstracts, titles and the mesh term hierarchy respectively. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap, ,
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"The proposed approach combines the benefits of dynamic adversarial data collection, i.e. human annotators generating data points for the model and generative models that are traditionally used to augment datasets with adversarial data points. ",30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"
3. ",75
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Recap,"For syntactic constraints, in particular, the authors also propose a new method for extracting exemplars based on syntax similarity, called SSE. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Recap,"Compared with previous work on prompt transfer learning, PTG further demonstrates that (1) combining information from multiple source tasks and (2) introducing task-level and instance-level attention mechanisms are helpful. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"This paper collects data points from several experimental settings to compare the effects of sampling strategies, using model-in-the-loop (standard vs adversarial data collection), datasets used to train the GAAs, and whether answer prompts are provided or not. ",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Recap,"Besides, the authors also explore which knowledge transfer methods are beneficial for the downstream tasks. ",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,"For between model transfer, they uses these same methods but include a learnable `projector` (a small, 2 layer neural-network) that maps the prompts from one frozen model to another be using the projected prompt in one of the methods mentioned above. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
6bd292c3f083f1a278739bedb1db76eb53014bcfa286c850680811f20b8fe3f79ba1881809e4fd3532754f4e6344d24365f551e1c879292061577d5b3b70f0e6,arr,Recap,  ,
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,This optimum offset value is then used to specify quality constraints for the test set examples and  accordingly the paraphrases are generated. ,157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Recap,"X-GEAR takes as input i) a passage, ii) a trigger word (a predicate, e.g., ""killed""), and iii) a template indicating the desired roles (e.g., <Victim>NONE</Victim>). ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Recap,"This is a relation between inputs, follow up inputs based on the internal structure of those inputs, and outputs. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Recap,"However, unlike previous PLM based methods, S-OSC pays specific attention to two things: (1) order of triples in the linearized sequence should match the ordering in GT sentence (2) part-of-speech tags can help the model know when to copy and when to generate new words. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Recap,The paper deals with the problem of audio-visual speech recognition (AVSR). ,0 1 2 3 4 5 6 7 8 9 10
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Recap,There are no changes in the updated version that warrant a change in my score or the review. ,10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Recap,"The authors collect a large multimodal data of 884k tweets on the topics of Climate Change, COVID-19, and Military Vehicles. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Recap,The explanation is scored against the gold-standard human-provided evaluation results in e-SNLI and CoS-E datasets. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Recap,"Evaluation of several video-text models on the proposed contrast sets demonstrate that the existing models show a drop in model performance (on verb antonym swaps, etc). ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Recap,"This paper introduces a new method for MeSH indexing, combining multiple methods including, but not limited to, dilated CNNs, masked attention, and graph CNNs. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Recap,improves model performance on cross-task generalization. ,92 93 94 95 96 97
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Recap,Their method learns a fixed number of source prompts (represented as vectors) based on source generation tasks and then derives a target prompt for the target generation task. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Recap,"For this goal, the main contribution of this paper is a dataset of peer-reviews annotated with discourse labels and relations between the rebuttal and review pairs. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Recap,"The recombination methods generalize previous work to account for merge a hypothesis with candidates from earlier timesteps, and then propagates any merges back through the original lattice; these changes allow for significantly more merges to occur. ",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,The authors further use BitFit to reduce the per task parameters for efficient deployment. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"Recent work has seen that entailment models are effective at zero/few-shot classification, where the input sentence is used as the premise and label strings are used as hypothesis. ",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Recap,Both regularity-aware and -agnostic models are trained such their backbone hidden representations are orthogonal. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Recap,VDTN: which is a multimodal transformer-based model that combines video and dialog features to answer the user's questions. ,56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Recap,It uses dialogue context as well as commonsense and domain knowledge for generating responses in counseling conversations. ,11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Recap,"This paper introduces coherence boosting, in which a weight is used at inference time to mix the log-probabilities generated by a language model on long- and short-term contexts. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,"To adapt the Chinese GPT for pinyin input, they propose two methods. ",73 74 75 76 77 78 79 80 81 82 83 84
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"During inference, they also propose shape-aware dynamitc time warping to better align parallel pitch contours. ",48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,The iterative consistency filtering might propagate errors in the synthetic data especially with high number of iterations. ,175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
3f1a09e155c657a139ccdad41c8d593f45e130a564aa0d3825770e56f02682d43186539fe68060d48acab72dfd294c56a3f6ce65d9331ff71c2c1d4aa73a9500,arr,Recap,"
This paper presents empirical results from the extensive experiments using this dataset and concludes that the uncertainty measure could be used to detect questions that the system is not confident about. ",140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Recap,https://arxiv.org/pdf/2110.04366.pdf ,200
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Recap,"
That combination of using multiple synonyms in the attention mechanism and a biaffine transformation in the architecture is novel to the best of my knowledge. ",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap,"It introduces a two-stage training routing strategy called StableMoE to stabilize the routing: first learns a lightweight and more balanced router via a balanced loss and the router distillation, then freezes the router for stable token-to-expert assignment for second-stage training that only has the task loss. ",40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,"This method is empirically shown to be most aligned with human evaluation when compared to other evaluation methods.
",198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Recap,This paper proposes the regularity-aware and regularity-agnostic models for Chinese NER and present the combined loss to train them. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Recap,"In the experiment results, the regularity-aware models lead to improvements over the previous models on three Chinese NER datasets. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
bb5a8e3b3e4a450f10be587fad043a653ab3922dc3798914e2badaa74796866bbdd71f6a889a588c0f2535002bda3505dba5aa44a81fb7963f440559db74e96e,arr,Recap,This is a revision of a previously submitted article. ,0 1 2 3 4 5 6 7 8
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Recap,The authors propose a general controllable paraphrase generation framework (GCPG) to achieve lexical and syntactical aware CPG. ,28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,"Hence, I will be focusing more on the changes from the last submitted version.
",10 11 12 13 14 15 16 17 18 19 20 21 22 23
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Recap,Here all layers are taken into the training without any additional parameters. ,36 37 38 39 40 41 42 43 44 45 46 47
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Recap,This paper describes a framework to inculcate temporal order into question answering over knowledge bases. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Recap,"Punctuation restoration is the process of restoring text structures such as sentences, phrases etc by inserting four types of punctuation marks (period, comma, question mark and exclamation mark) into non-punctuated text. ",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,The authors conduct some classification experiments with transformer-based models and discuss the results in an analysis. ,167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Recap,This paper propose to use an additional loss to automatically learn model confidence for NMT models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,The latter is composed of all the wrongly predicted examples by a biased model. ,52 53 54 55 56 57 58 59 60 61 62 63 64 65
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Recap,"They show that they can successfully detect the selected sound changes in the datasets, and identify precisely the context of the change. ",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap,"Given the importance of proper calibration to so many applications of NLP, I suspect these methods would be of interest to practitioners in the field even if they do not provide an across-the-board calibration improvement, but it is not clear from the writeup when they work and when they do not. ",244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Recap,"The authors empirically confirm this hypothesis by showing that for five downstream classification tasks they are able to find continuous prompts which project to certain arbitrary sentences (at least very closely, as evaluated by F1) but whose resulting accuracy is almost as good as that of the optimal prompt (as evaluated by the difference in test accuracy). ",140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"Using several theoretical and experimental analysis, it specifically reveals the weaknesses of existing attribution methods designed to qualify and support research propositions by assessing model predictions. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Recap,The study shows that the proposed methods achieve good TTS results (in terms of both intelligibiligy and naturalness) with little training data. ,58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Recap,The authors report that the majority of classification errors are not severe as at least one annotator agreed with the model prediction in all evaluation settings. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Recap,and proposes a framework for testing this (extends existing datasets and creates a new one). ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Recap,"The authors employ these tasks to investigate     models trained via different masking strategies: character-based masking,     word-based masking or both. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Recap,The main contribution of this work is three-fold: 1. ,0 1 2 3 4 5 6 7 8
fb8abed24b895c60af95d65f500024e37b39c870800b09362cb415350eecdb493573e965cb693012ce459c254f4446514a17effdbceccb50b7ce870bb3bc6119,arr,Recap,The general idea is that existing commonsense knowledge is applied to delimit the range of meaningful negative samples. ,21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"1,2]. ",144
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Recap,This paper first stipulates desirable properties for metrics measuring the performance of multi-label classification systems where the label set has a hierarchical structure. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
d5a6f95cdf5edc2a3be93d808261420466d28656c9e7ac77a480e0616ed4c562b296c16dbd8f44483aa034f3e84ed9255ed648bedb91345cdb6e7b9a447d3acb,arr,Recap,The authors experiment with various baselines models for solving this task in a two-step approach. ,70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Recap,"2) Superfluous information minimization, which entails minimizing task-non-specific information. ",36 37 38 39 40 41 42 43 44
d85a9e84b9e1945cd30dddaef9d362226c99792cf6d3a74ed2d091b71ae6791f31caba3356b4c23a6403a3554b8f5cfe1b995c6c1d7a9842be286ff114911e11,arr,Recap,The authors also establish baseline results on each dataset using various models. ,40 41 42 43 44 45 46 47 48 49 50 51
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"The authors validate their approach on several classification datasets in English, German and Spanish. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Recap,This sub-task of dialogue summarization is important for dialogues in specific domains. ,10 11 12 13 14 15 16 17 18 19 20 21
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Recap,"On the other hand, speech modality in a natural form for conversation and contains additional information in audio signals. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap," This work applies this technique to dense  text retrieval, and augments the original contrastive loss with soft binary cross-entropy losses. ",40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
9718a739d8caa017664be63a426c74dc7d8daff635c7dfdb44370137bf06fe6e6e1668afefb0860bc026efb02485979591635a255987a98fd6dfde30e4ab8f8c,arr,Recap,"However, it is known that the estimation of entropy from raw data can be quite challenging knowing that the MLE estimator in expectation underestimates entropy and the power-law governing linguistic data cannot be effectively captured by such estimates. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,"Performance improvements are obtained by: (1) upgrading model size to Large (GECToR used Base), (2) changing tokenizer (GECToR changed tokenizer from the one used during pretraining), (3) filtering of edit free sentences, (4) increasing vocabulary size (the vocabulary of possible edits), (5) ensembling by majority vote on edit spans instead of ensembling on average output tag probabilities, (6) distillation. ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Recap,It can be trained in a weakly supervised way or in an unsupervised way and be fine-tuned in an end-to-end manner. ,37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Recap,The authors compare the performance of encoding models across a wide range of NLP tasks and discuss the differences between encoding fMRI stimuli from reading vs. from listening to stories. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Recap,The idea enables human interaction in the form of lexical constraints while asking the NMT model to fill the remaining parts of the translation. ,10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Recap,This work focuses on the multi-modal sequence ordering task. ,0 1 2 3 4 5 6 7 8
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"In other words, we are teaching the system how to solve the translation part of the process. ",297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Recap,"Using the language of factor graph grammars, this work unifies previous low-rank tensor decomposition works such as Yang et al 2021b  and Chiu et al 2021. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Recap,"Specifically, they leverage monolingual triples and cross-lingual links from existing multilingual KBs DBpedia, and formulate them as the autoregressive language modeling training objective via starting from XLM-R’s pretrained model. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,Few-shot classification is a challenging setting where very little training data is available (5-100 examples per label). ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Recap," It is argued ICM satisfies more of the desirable properties than others.
",48 49 50 51 52 53 54 55 56 57 58 59
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,"Their task settings are that the input of the model includes a sequence of Chinese characters as the context and a sequence of pinyin (perfect pinyin or abbreviated pinyin), and the output is a sequence of Chinese characters. ",10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Recap,It shows that initializing with prompts from different tasks is helpful in terms of both quality and convergence speed. ,12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"The authors contribute a derivative dataset from PersonaChat that aligns private attributes to the respective personas.
",171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Recap,"The paper is well-written and thorough, for example conducting a meta-analysis of which human annotations to use when learning the global ensemble metric. ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Recap,"Given a text, the model is required to produce the corresponding tables, including both schema and cell values. ",10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Recap,The paper proposes an encoder-decoder-based framework for document re-ranking. ,0 1 2 3 4 5 6 7 8
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Recap," This test suite differs from previous work by balancing question generation to create pairs of instances to test models and focusing on six capabilities, rephrasing, ontological, order, visual obfuscation, attribute antonym, and negation.
",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,"They find that this method can give consistent gains in terms of task performance as well as speed of convergence.
",381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,"Because different questions have answers in different sentences the contrastive conflict is generally resolved.
",130 131 132 133 134 135 136 137 138 139 140 141 142 143
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"
The framework follows traditional data-to-text diagram. ",9 10 11 12 13 14
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Recap,The authors examine the faithfulness of post-hoc explanations (feature attribution approaches) and the out-of-domain performances of inherently faithful models (select-then-predict). ,11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Recap,This is the second time for this paper to be submitted. ,0 1 2 3 4 5 6 7 8 9 10
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Recap,The authors experiment with the recent ViT models trained on image classification as well as DETR trained on object detection and CATR trained on image captioning. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Recap,At translation time the invertibility of normalizing flows can be used to map between sentence representations in different languages. ,43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Recap,"This paper proposes a domain knowledge transfer framework, that distills an existing domain-specific model into another general domain student PLM, which significantly improves the students' performance in domain tasks, and in some cases even outperforms the teacher model.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"SL proves to be more challenging, with the evaluated models obtaining F1 scores of up to 72 points. ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Recap,The curated benchmark consists of 19 relations with 1000 examples each. ,29 30 31 32 33 34 35 36 37 38 39
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Recap,The authors evaluate the proposed method on three benchmark datasets using supervised and unsupervised settings and claim to achieve new SoTA results. ,91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Recap,"Using spelling as a necessary proxy to phonetics, the authors model phonological change through the use of diachronic character embeddings. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Recap,"The resulting model, LongT5, outperforms existing models designed for long sequences on long document summarization with arXiv, PubMed, BigPatent, and MediaSum. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Recap,"After the three tasks are introduced, the paper investigates the performance of baselines systems, mainly based on language models. ",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
6c7386d38647d226e22fb6a21bec815d465a1023fc59c871b959b53ae367be17a28b2839533147dc589795577b8630217bf4ea6311ca501b3d89453b25741324,arr,Recap,This paper presents a transformer-based model to generate open close tests for language learning and assessment. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"**What are the key techniques used to tackle this task?**
",176 177 178 179 180 181 182 183 184 185
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Recap,The authors can also do a better job at explaining why optimizing equation (3) and (4) can lead the noise-based negatives into more non-uniform semantic space. ,108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Recap,"For evaluation, each verb occurrence garners a prediction of which referential noun phrase is selected by it, and the resulting accuracy is reported. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Recap,"This paper explores the topic of automatic readability assessment, specifically reframing the task as one of pairwise ranking. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Recap,Then they pre-train the language model based on phonetic data and then fine-tune it in the Swahili NER task. ,10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,"However, empirical results show that this is achieved at the expense of classification accuracy. ",90 91 92 93 94 95 96 97 98 99 100 101 102 103
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Recap,"The experiments are conducted on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document specific metrics. ",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Recap,"To do so, an agent is trained to learn shared and visually-aligned cross lingual representations (English, Hindi, Telugu), and an environment agnostic visual representation. ",30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Recap,[1] Prefix-tuning: Optimizing continuous prompts for generation. ,105 106 107 108 109 110 111
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Recap, ,
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,"This paper presents 2 approaches to removing multiplication computation in the popular Transformer attention: 1) binary quantization of attention inputs, and 2) the use of L1 norm to compare between queries and keys. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,The authors borrow several experiments from this body of (psycho)linguistic research to assess to what extent current language models comply with construction grammar theory. ,89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Recap,"
They show the viability of the proposed approach on synthetic datasets and  on real sound changes in Danish geographical names (in particular, the authors focus on lenition). ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Recap,Event argument extraction is then reduced to a slot filling task where the difference between languages lies in the different arguments. ,40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Recap,The architecture of the STL stack is based on the work by Dong et al. (2017). ,53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
fcc2d390db2717ce8d77836ca10248ee73a8d94600bd9528cef5d26d16f18393f230b60463fae854e5f652936577b5b37ccc698e95ca831fa89d8e7a12079552,arr,Recap,"The confidence network will produce a loss by adding up the gating values, which is combined with cross-entropy loss in training with a hyperparameter lambda. ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"The authors show that the best model is one that achieves low accuracy on the person prediction task and achieves, secondly, the lowest max-ratio score.
",589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Recap,The paper studies the benefits of introducing a Bayesian perspective to abstractive summarization. ,0 1 2 3 4 5 6 7 8 9 10 11 12
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Recap,"The paper introduces SkillSpan, the first open-source, expert-annotated dataset for skill extraction, which is essentially sequential labeling of skill and knowledge in job postings. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,They find that direct reuse of a prompt projected by a `projector` learned with their _Task Tuning_ method does better especially when the tasks are within the same cluster. ,436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Recap,In experiments with four datasets all baselines are outperformed. ,76 77 78 79 80 81 82 83 84
af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07,arr,Recap,The definition is simplified to the quotient of NMT probability and the LM probability. ,28 29 30 31 32 33 34 35 36 37 38 39 40 41
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Recap,"Specifically, SWRM consists of a sentiment word position detection module based on BERT, a multimodal feature extraction module based on LSTM and BERT, an aggregation network and a multimodal gating network for fusing different features. ",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Recap,"The paper shows the importance of code-switching use-cases (i.e., E&F and F&E) and further provides interesting discussion on overestimation of translate-train baseline which is commonly used in building a practical setting of a multilingual ToD system especially on local entities. ",120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
0f595b4bd968ef5daacc88c4edb581bf7f683af30b6874ba157c6d2282aabead577041409b949924e4bc5ef54c543d85a10e962be8e70304dea65e1b18441bdb,arr,Recap,The authors use a variety of NLP methods to answer a number of linguistic questions regarding the phonology-syntax interface. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,"
---- ",28
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"
To enable training the pipeline model, the paper contributes a large dataset named Wikifluent corpus. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"The authors additionally use BERTScore to evaluate the similarity in embedding space, BLEU to check similarity of unigram and bigrams, and Dist to check the distinct unigram and bigrams. ",692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Recap,"Specifically, the authors propose to utilize hierarchical position (HP) and Section title (ST) of sentences to refine the output embeddings based on the inter sentential and sectional information. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Recap,It revises the potential errors by considering the representation of  the target future context and generates the next target token synchronously. ,10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,Wouldn't the system just learn to reproduce the underlying rules of the automatic benchmark creation? ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Recap,"The main strengths of the paper are in 1) the novelty of the dataset and the fine-grained taxonomy it adopts, 2) the interdisciplinary nature of the adopted taxonomy, and 3) the size and coverage (for the U.S. part). ",107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,It is found that all models that were considered (both mono- and multilingual) yield clusters that are closer to construction sorting than verb sorting. ,223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Recap,Backtranslations and pivot translation are also explored. ,46 47 48 49 50 51 52
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,"The authors have committed to releasing the dataset, pending approvals from the concerned organizations. ",68 69 70 71 72 73 74 75 76 77 78 79 80 81
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Recap,"Compared to previous work which either produces explanations that are used to infer the label or vice-versa, this work introduces a framework that trains both tasks jointly. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Recap,"As I am a returning reviewer for the paper I will keep any of my previous points that still hold for this version of the paper and add new ones where appropriate.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Recap,"Specifically, the authors multiply the output of a pre-trained BERT with the word embedding matrix to get the smoothed representation of an input token. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Recap,"The authors take the now-common, end-to-end neural network perspective in training a model to tag references but specifically contributing a model for citation-driven citation fragments. ",32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,"
Human values can provide the underlying motives behind arguments and can explain why someone takes a position or what goals the person sees as worth striving for. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Recap,"
They also construct a dataset called WD Dataset for evaluating their input methods.
",100 101 102 103 104 105 106 107 108 109 110 111 112
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Recap,"After    demonstrating this phenomenon via several angles, the authors train a seq2seq    MWP model (BERT encoder + tree decoder) supplemented with a contrastive loss    --- mono- and multilingually. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Recap,The present paper investigates the Word-in-Context task in a few-shot setting. ,0 1 2 3 4 5 6 7 8 9 10
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Recap,"-The problematic issue this paper focuses on is the difficulty of distinguishing similar but different-class relations, called “similar relations” and “similar entities” (see the details in line 71-84 and Table 1 shows some examples).
",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"This makes one wonder if LRA is indeed a good evaluation setup for their method.
",383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,"The paper proposes to convert both syntactic controlled generation (target syntax can be represented by either masked sequence, linearized constituency tree, masked template, or exemplar sentences) and keyword control to a sequence-to-sequence task formulation. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Recap,"For mining of morally framed statements, a BERT classifier based on data collected automatically using distant supervision was used. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Recap,This semantic dissociation from syntax is learned in representation obtained from the pre-trained models (mBERT and XLM-100). ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Recap,The intuition is based upon the hypothesis that semantically related words in both sentences should have the same syntactic importance too. ,32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Recap,"Meanwhile, they propose two heuristic methods: 1. ",44 45 46 47 48 49 50
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Recap,"The authors propose and evaluate an approach for automatic question generation in an educational context, specifically looking at the role of summarization (whether it be human or automatic) in the process. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,"The pipeline contains three components, including a heuristic-based answer generation model, a BART-based question generation model, and a BERT-based QA-pairs ranking model. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Recap,The authors shows that combining all three losses improves the fine-tuning results of BERT. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Recap,"This suggests the new challenge provided by this dataset, but seems to be influential as a future direction of OTD. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Recap,"With the tools ready, the authors then examine various LMs and MT models for the SPP. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"
2. ",58
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap,They evaluated the proposed approach on the aforementioned downstream tasks. ,94 95 96 97 98 99 100 101 102 103
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,The experimental results show promising improvement over previous work. ,74 75 76 77 78 79 80 81 82
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Recap,This method requires no internal classifiers and can perform token-level early exiting without supervision. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Recap,"However, there is limited novelty as utilizing self-supervised representations for AVSR has been done before. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Recap,"
3. ",93
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Recap,Three contributions are (1) articulatory features for TTS; (2) LAML which is a modified version of MAML; (3) Interesting analysis over the framework could be very helpful for practical usage. ,27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Recap,The model is pre-trained with a combined objective of masked language modeling and prefix language modeling. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
4b71ef5ed6c8af64772bcb6d6274a4af5fce058df82ca4593e4825002ce1701218b9be982e81fee4742e9ec63a3dc1da828bf095a8211e0f20b690ab084366fb,arr,Recap,NOTE: This is my re-review of this submission. ,0 1 2 3 4 5 6 7
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Recap,"This paper presents and empirically confirms the ""prompt waywardness hypothesis"" in the context of continuous prompt tuning. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Recap,This paper proposes a conversation-based VQA (Co-VQA) framework to decompose a complex question into a sequence of sub-questions and get the final result by answering the sub-questions. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Recap,"This paper proposed the use of a set of auxiliary tasks to capture some form of interdependency between arcs in semantic dependency parsing in order to provide a simpler implementation that can obtain robust performance, which achieved near-SOTA and systematic performance on one English SemEval-2015 dataset and one French deep syntactic cyclic graphs. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,I think the material presented is well-suited for a short paper. ,128 129 130 131 132 133 134 135 136 137 138
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Recap,They conclude larger dataset than 99 mins could yield PER below 10% and be useful for language documentation. ,109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"
This allows for robustness while still providing an easy real time control of the speed-accuracy tradeoff, and achieves SOTA results on most of the GLUE benchmark tasks. ",326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Recap, ,
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,The first experiment is based on the sentence sorting task of Bencini and Goldberg (2020). ,126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Recap,"Specifically, it focused on fooling stock prediction models over the Tweet data. ",12 13 14 15 16 17 18 19 20 21 22 23
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Recap, Experimental results show that this work achieves substantial improvements over previous baselines. ,83 84 85 86 87 88 89 90 91 92 93 94
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Recap,"This dataset is composed via crowdsourcing, with extensive expert validation. ",39 40 41 42 43 44 45 46 47 48
555b9b4626e46bff6dcd1dd669cac930e4e3c587766a39059797b4d5100a130d8c7aa4ee67cb74e7ebc5a9126fed58d4b54ceab34144da5a84f5d402acdf18af,arr,Recap,"Their token-level contrastive distillation approach is elegant, simple, and easy to comprehend. ",35 36 37 38 39 40 41 42 43 44 45 46
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Recap,"Instead of using a dual-encoder framework, the paper regards documents and the input and queries as output, and uses the generative likelihood of queries to retrieve documents. ",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,"In their evaluation, they use 6 offensive language datasets in a multi-task learning regime. ",137 138 139 140 141 142 143 144 145 146 147 148 149 150
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Recap, ,
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,PromDA uses T5-Large for data augmentation and BERT-base for NLU model. ,90 91 92 93 94 95 96 97 98 99 100
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Recap,This paper proposes a novel refinement method to synchronously refine the previously generated words and generate the next word for language generation models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Recap,The paper introduces an approach for easily incorporating both lexical and syntactic constraints to a model for sentence paraphrasing. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Recap,This paper investigates an interesting problem of automatically generating high-cognitive-demand educational questions for children’s storybooks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,This paper proposes to use the synonyms of the ICD codes to enrich the code representations. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Recap,Paper design two modules: schema expansion and schema pruning which can be added to these SOTA parsers to handle the problem of column operations. ,81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"The core idea is to improve the random negative sampling strategy for alleviating the sampling bias problem.
",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,The dataset is based on the UMLS metathesaurus. ,26 27 28 29 30 31 32 33
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Recap,An extensive annotation and data cleaning process is followed to ensure that the quality of the data is maintained while collecting a sufficient number of samples. ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Recap,They show their competitive performance (as measured by automatic and human eval metrics) on Wizard of Wikipedia and CMU DoG datasets. ,18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Recap,"Differently from existing approaches, the proposed approach doesn't rely on manually designed dialogue states and realization schemas. ",24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,[1] Neural data-to-text generation: A comparison between pipeline and end-to-end architectures. ,200 201 202 203 204 205 206 207 208 209 210
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,"The generated question-answer pairs are then used for the pre-training.
",102 103 104 105 106 107 108 109 110 111
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Recap,"Such attacks are modified examples that differ by individual words compared to the original examples, yet receive a substantially different prediction when used as input to a trained predictor.
",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,This problem emphasizes why KL loss is particularly useful. ,580 581 582 583 584 585 586 587 588
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Recap,"This paper introduces two grammatical error correction probing tasks for     Chinese masked language models: one for replacing erroneous characters or     words, and another for inserting the correct character or word in order to     make a sentence grammatical. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Recap,The proposed method uses clustering to reduce the features that has to be retrieved through NCE. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
f4d5395d46a0f2f0866fa4410edd21d000d1791f07ef488bea12fe58ae905b9bb44fd8d0b92f1da10bb6456a4dca4cf8ca35d0350654cb42b3a947b8edb49b7f,arr,Recap,The authors conduct experiments on text summarization and machine translation tasks. ,33 34 35 36 37 38 39 40 41 42 43
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Recap, ,
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Recap,Another main contribution is a baseline model which could tag the CORWA labels from unlabeled texts. ,30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
3440a8cac0acda8d2760dbc4b435400589f1a5f3b2d4bfc9728c8e5f990e7a0ad599d0d2c16f0bdbce56541e6064c9e0138cd6d2691c84a52e25d82c5da47894,arr,Recap,The experimental results show that the proposed method is slightly better than the baseline under low-resource settings. ,35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"In this work, the authors suggest a new way of deciding whether to perform early exit. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Recap,"The datasets are adapted from four existing table-to-text datasets, i.e., Rotowire, E2E, WikiTableText and WikiBio. ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Recap,This method is based on the core-set based token selection method which is justified by theoretical results. ,30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"The results obtained are clearly positive, notably outperforming the lower baselines and approaching the top monolingual state-of-the-art approach. ",449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Recap,"Empirical results on the two datasets show that the proposed method can significantly outperform two strong baseline parsers, seq2seq of Shi et al. (2020) and SmBop of Rubin and Berant (2021). ",99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Recap,The experimental results show the superiority of incorporating pre-trained multilingual entity representations. ,23 24 25 26 27 28 29 30 31 32 33 34
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,"First of all, I would like to thank the reviewers for their detailed responses to my, and other reviewers', concerns.
",24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Recap,More detailed feedback is nevertheless provided below. ,130 131 132 133 134 135 136
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Recap,"The paper investigates the transferability of ""soft prompts"" across tasks and models. ",0 1 2 3 4 5 6 7 8 9 10 11
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Recap,"Its aim is to overcome the problem of training data imbalance (not all words have the same number of senses, and this is related to their frequencies). ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"For the Jabberwocky experiment, as a difference from the Johnson and Goldberg (2013) setting, sentences for each construction are generated by randomly filling real words in the templates. ",165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Recap,CTC loss is used during the training. ,27 28 29 30 31 32 33
5385e108c4289cb35d6f7b461c2bcaeebbee34cca1d25e188f47b58f7879ab8a08786fd6c10f4d8ff2bf799a34aa55688a1d2e6b2dc16ea4f97e52d290ac21bb,arr,Recap,The authors conduct rigorous experiment analysis to show the advantage of the method ,16 17 18 19 20 21 22 23 24 25 26 27 28
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Recap,"Since the proposed metric requires a choice of the way of computing two hyperparameter vectors, the authors experiment with different choices and show that this choice matters quite a lot. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Recap,"For compressing pre-computed document embeddings, the paper proposes to Funnel Transformer. ",36 37 38 39 40 41 42 43 44 45 46
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Recap,"E.g. a token like “Spielberg” may correlate with a “positive” label in a specific movie reviews dataset, but in itself the token is not a “genuine” indication of a positive review and relying on it may hurt a model's ability to generalize to new datasets or domains.
",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Recap,This balance encourages generation to meet certain constraints while maintaining quality. ,52 53 54 55 56 57 58 59 60 61 62
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Recap,"The paper proposes a new approach named BEEP to combine information from clinical notes and relevant medical literature to enhance the prediction of patient outcomes (prolonged mechanical ventilation, in-hospital mortality and length of stay). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,Table 4 shows that the performance across unseen persona labels. ,721 722 723 724 725 726 727 728 729 730
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,"Since, for a given sentence, generating a paraphrase of an arbitrary quality might not be possible, the authors also propose a Quality Predictor model to estimate the typical paraphrase quality of a given sentence by training a regression model on the paraphrase dataset. ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
f8dd2bb2c1fb28d2ae5168d42381a9bc9131a91981c1b52e65852e6c94852c00bdff0da9749b2af7111f889c30c8262f14473fd17e5fbbfbdb790cc4cb3f645f,arr,Recap,The misinformation is detected based on the difference of the event information graph created using a cluster of documents based on the inconsistency of the event information provided in a document. ,8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Recap,*(minor edits from previous review XYZ)* ,0 1 2 3 4 5
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,In this paper this setup is adapted by comparing the contextualised representation of a semantically implausible verb in a certain ASC with the averaged representation of a prototypical verb. ,348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Recap,"Finally, they perform an examination by an expert on the predicted answers and find that the automatic evaluation might underestimate the performance of the models. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Recap,"The paper presents and extensive literature survey and an empirical evaluation of three character-level architectures, two of which have not been used in MT before. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Recap,"
Overall, this work has conducted a series of solid experiments to demonstrate the effectiveness of entity representations in multilingual tasks and provided in-depth analysis on entity representations. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Recap,"The authors introduce LexGLUE, a benchmark dataset to evaluate the performance of NLP models in legal NLU tasks. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Recap,"The method leverages a linear classifier operating on the residue of sentence embedding to detect the adversary.
",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,They have also evaluated the performance of existing NLP toolkits for the task sentence splitting on this dataset and found that they perform very poorly suggesting the importance of this kind of training data. ,174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Recap,"
Abbreviated pinyin input is user-friendly since the number of typing characters is fewer. ",36 37 38 39 40 41 42 43 44 45 46 47 48
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Recap,"navigating through unseen environments.
",26 27 28 29
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Recap,"To analyze the attribution from a token to another token in transformer networks more accurately than previous studies, the authors proposed a new method named GlobEnc. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,"In construction grammar theory it is argued that the argument structure of a verb is not governed by the lexical entry of the verb itself, but by more abstract argument structure constructions that are independent of the verb. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
21f74d3b60a2101f1630894856ba99180af6242a02b80070fe7274f02c867becdb7ff3d683a90f84d0f414d7b873d0fa2c18407c4bedd4e1bebb8dbcedc40de6,arr,Recap,"Instead of limiting the word alignment model training to parallel text (bitext), the authors follow the line of work which exploits multi-parallel corpora, which enables recovering missing alignments between a source and a target language. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Recap,"The model takes a sequence of graphemes and a sequence of phones, and produces a score. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap,"The authors present a method of calibrating learned multiclass classification models during training, that is, improving model calibration (in other words, pushing accuracy-versus-model-confidence graphs towards the identity line---well-calibrated models have confidence perfectly reflecting prediction accuracy).
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Recap,The paper's contributions are 3 folds:  1. ,7 8 9 10 11 12 13
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Recap,The paper claims that their intuition is using unlabelled data in training (line 097-101). ,29 30 31 32 33 34 35 36 37 38 39 40 41 42
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Recap,The paper reports many interesting findings. ,106 107 108 109 110 111
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Recap,The paper is a resubmission of previous work that looked at neutralising framing bias in news stories. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Recap,"First, they create a data variation that replaces one of the choices with 'None of the Above' to create a dataset with 25% unanswerable questions. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Recap,The experimental results on four datasets show the effectiveness of the proposed method. ,56 57 58 59 60 61 62 63 64 65 66 67 68
42ae5ac0b6ebf8dbeb0aacafa17347e79484894bf3755dc74179c72dc37a6c50f1ec70fcebe4c3d99626a87a96b3c794fad2694e04ff203897c71a6b4e97a96e,arr,Recap,Experiments are presented involving 5  document classification datasets that show the extent to which the method being proposed is effective. ,66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,**What are the main results? ,257 258 259 260 261
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Recap,"
These event-specific templates describe the event types in a natural language way. ",14 15 16 17 18 19 20 21 22 23 24 25
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Recap,As cited in the current paper both FastSpeech-2 and conditional VAE are already proposed in the literature. ,42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Recap," In the present work, multiple synonyms are used in the attention mechanism in order to attend to all descriptions of a code. ",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Recap,"It then follows a few suggestions on how to mitigate such issue, including making clear reports, and adopting better evaluation practices, analysis and forecasting. ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Recap,"This paper presents a method for inducing unsupervised tags for word sequences, later to be compared against POS tags. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"[1] Matching the Blanks: Distributional Similarity for Relation Learning, Soares et. ",176 177 178 179 180 181 182 183 184 185 186
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Recap,"The paper’s authors create a dataset to imitate the two types of disparity, including “vocabulary limitation” and “visual access”. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,They also conducted a series of additional experiments to understand the importance of pinyin context and pinyin constrained training. ,175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Recap,This paper discusses hype and overclaiming phenomena in NLP research. ,0 1 2 3 4 5 6 7 8 9
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Recap,"Then different ""base"" machine translations are trained and finetuned on the LIV->EN data. ",33 34 35 36 37 38 39 40 41 42 43 44 45
d513753e38dcfe4c58a23e10ba65e409f7fda38a35816f269ff978bd1aa5e54e7256c0a2aaedddd9746f25768309b3ed75c2bfe6295055e519d9133bcea7bb7d,arr,Recap,The motivation is that prior datasets for punctuation restoration are on scripted or non spontaneous speech like TED talks and meetings. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Recap,This paper proposed to extend the monolingual entity representation model (LUKE) to the multilingual version and further conduct experiments on several cross-lingual tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
4a1c1a54db4c8630e04e4e5f045f69749e7bf8d6b6bf7fe1b5abc8f64b63aac51dbe6e0e4f0a4a667815ef7b8e80d00ca2eac00026243514c420f95834081e42,arr,Recap,"In the VQA task, the paper proposed a two-step method to mitigate the gap between natural language description and question answering. ",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"However, the questions raised in the 1st sound still have not been well answered. ",262 263 264 265 266 267 268 269 270 271 272 273 274 275
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"The authors perform a series of intent detection (ID) and slot labeling (SL) experiments based on this new resource, with a particular focus on low-resource settings. ",89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Recap,Experiments show that the resultant operator is faster than 1.5-entmax on WMT14 En-De and WMT13 En-Ru translation tasks. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap," The score differences are not large -- I think never more than 0.5 BLEU) -- but the authors report that using masked label smoothing statistically outperforms regular label smoothing when vocab selection is also turned on.
",167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,"Then it proposes a span-based method with a novel triaffine attention and scoring mechanism to fuse the identified heterogeneous factors for span representation and classification.
",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Recap,They demonstrated the effectiveness of their method on 7 semantic textual similarity tasks. ,68 69 70 71 72 73 74 75 76 77 78 79 80
dda72a5f50547fe97924633fcb28632d0b317269b369e94de3151b704b5528cc41bf8c852516c55fb127076131d32da6a29acb5526dea98dcefdbd0f847d74f3,arr,Recap,"This paper attempts to address potential catastrophic forgetting, data imbalance and rare word issues, for intent detection in the medical domain. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Recap,This paper proposes a latent-variable model based on a variational probabilistic modeling framework for conditional compute in multi-domain and multilingual machine translation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap,"To demonstrate this new schema of DST, the authors generated dialogues based on an extended CATER video split, with additional ground-truth labeling for bounding boxes and visual objects across frames. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
fd35e7df6ba77a0794a94b00ec6cfb948a3ee80b9591adacc34966a10018c2a1af14748f9d8f4a54eb5db32f8acbd46ffd0035b600b6aa71551cbe78e7238a79,arr,Recap,This paper presents a method to improve text generation by refining the target output while decoding. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,"Although the author claims that their work is the first for QA, there is significant overlap between this work and Campos et al. (2020), which also uses binary user feedback to improve a Conversational QA model. ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Recap,"To address it, the paper conducts the same method to construct adversarial training sets and retrain TM models on them. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Recap,"
     - CLIP sentence embeddings outperform GPT-2 sentence embeddings on the STS-benchmark. ",102 103 104 105 106 107 108 109 110 111 112
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Recap,They design a model that is able to decompose a multi-hop question to simple questions that could be answered by one agent. ,151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Recap,"The main motivation of using NoisyTune is in line with other work (e.g., by Chen et al. 2020 and Lee et al. 2020) on avoiding large deviation of parameters from the pretrained model to avoid overfitting during finetuning. ",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Recap,The authors also make some points with regard to some views of what attributions should or should not be and argues otherwise. ,77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap, ,
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Recap,The experimental results seems to confirm the utility of such dataset when testing against a Challenge Set and a Out Of Domain dataset. ,55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Recap,"In experiments,  the analysis and results based on the information axis demonstrate the embedding of deep models learned is far apart from the extant character sequences. ",47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Recap,"For learning cross-modal alignment, a vector quantization method is proposed. ",56 57 58 59 60 61 62 63 64 65
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Recap,This paper proposes a Meta-Review Dataset of annotated ICLR reviews and a new task of controlled generation with passage macro structures. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Recap,"This paper digs into the evaluation of Non-AutoRegressive machine translation model and reveals several flaws in standard evaluation methodology, to provide a better understanding of the merits and weakness of NAR model.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"
Long inference times - due to high rate of queries and amount of computation needed. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Recap,Overall the work is solid with simple ideas and good results. ,48 49 50 51 52 53 54 55 56 57 58
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Recap,The experimental results show its effectiveness on BEIR benchmark including 18 datasets. ,25 26 27 28 29 30 31 32 33 34 35 36
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Recap,This paper proposed a method to elicit knowledge from language models and used the generated knowledge to enhance commonsense reasoning tasks’ performance. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Recap,"The proposed methods are designed by keeping in mind that they should aid in reducing the bias, be comparable or superior to the original performance and not lead to extensive computational overhead. ",98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap,"I believe the decisions pivot around an increased sample-efficiency claim (line 316), but this claim was not stated precisely (the free variable $\epsilon$ bounds ""calibration error,"" which I do not believe is defined), and the claim does not have a proof, so the relationship between the system setup decisions and sample efficiency claims is not at all clear.
",132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
cff563c41391b46a21cff06dbd6d523743628330e339eaf8cfe600f0d9c05fed00df32de7000a49a87627121ef98e12e57219ddd0df9ee55489a6deb8b9ce88b,arr,Recap,The system outperforms previous approaches to this problem on both the PTB dataset and a small subset of UD treebanks. ,68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Recap,"Additionally, the most successful extractive corpus-based method is tested on other  (although unlabeled) 24 languages. ",114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Recap,"This leads to the suggestions,that these models generalize better than other models. ",35 36 37 38 39 40 41 42 43 44 45 46
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,and topics (sports/world). ,98 99 100
f2b2affe077eb681cf80d31c0928c3fd120cbb3e4d7089b6d9ae44197032113b76920cf2938e7c2321aca5782db4fcfe1116f3bedd4f1803df19f50fd34fa94e,arr,Recap,"Empirically, the proposed parser achieves the new state-of-the-art performance on the SQUALL dataset. ",17 18 19 20 21 22 23 24 25 26 27 28 29
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Recap,"This paper applies conditional variational auto encoder to treat these latent variables.
",115 116 117 118 119 120 121 122 123 124 125 126
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Recap,"
The paper also demonstates that active learning provides additional benefits. ",69 70 71 72 73 74 75 76 77 78
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Recap,The subgraph retriever constructs the subgraph by expanding paths from topic entities and merging the trees. ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Recap,"The author concluded that a soft prompt could complete a desired task while projecting to any given task-related/unrelated target text, at a small cost of accuracy. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Recap,Results are promising on two long summarization datasets (GovReport and QMSum) and competitive on arXiv. ,79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Recap,The reasoning process is accomplished via attentive memories with novel differentiable logic operators. ,39 40 41 42 43 44 45 46 47 48 49 50 51
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Recap,"To change the verb (or the action) in the text, a masked language model is used to find good replacements for verb phrases. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Recap,The authors explore weak supervision and distant supervision for training the subgraph retriever and also propose an end-to-end training method to jointly learn the retriever and reasoner. ,55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Recap,The context and questions of MultiSpanQA are extracted from Natural Questions and the answer sets are re-annotated by three trained annotators. ,40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Recap,"The results show that there can be various factors that influence the effectiveness of cross-lingual transfer, like pre-training inclusion, language families, etc. ",50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Recap,The user study described was carefully planned and executed. ,137 138 139 140 141 142 143 144 145
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Recap,"
Authors conclude that other estimators are more reliable than the plugin estimator. ",55 56 57 58 59 60 61 62 63 64 65 66
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Recap,Experimental results on two benchmarks are used to validate the effectiveness of the method. ,73 74 75 76 77 78 79 80 81 82 83 84 85 86
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Recap,"Further, the authors also investigate if the context helps improve the models that detect hate speech or counter hate. ",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Recap,"Based on this they develop a framework that integrates the values from the various theories and that provides different levels of granularity, thus making an automatic classification of these values more feasible. ",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Recap,This work improves the span-based methods of nested NER. ,0 1 2 3 4 5 6 7 8
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Recap,"The authors find that having separate networks to learn separate tasks would lead to good performance, but requires a large memory. ",6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"
This paper shows that the use of GAA without adversarial model in the loop is can achieve near-adversarial accuracy but at much higher speed of generating the adversarial dataset. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
64d426bdd2237b1a76367942d93054e27cbba57122d341c186e2724c64f32ea70276be64edd40415fcfa2a55ffb540f5d6e8d89acd4ac1bf95878ac359286fa7,arr,Recap,The authors show that this form of augmentation helps on its own as well as when combined with other standard data augmentation techniques. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,"Although, the same results question the utility of dual learning and it should be discussed in more detail. ",253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Recap,"Some of the key findings include: (i) the ability of a value classifier to generalize to novel domains when trained on multiple domains combined with a small amount of data from the novel domain, (ii) fine-tuning on a novel domain causes catastrophic forgetting of the pre-trained domains. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Recap,"
Second, the authors demonstrate how the identified neurons can be numerically modified to update and delete relational information, showcasing notable changes in model behavior for each modification.
",201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227
24c4ce1de0320c577f507e388cc171c9f56cdcf29d39ddfe80193ba47b9c6711f9b9bd48b1e113be98448e7e58c7d8b32a71629363759dd41736354ce7eb15ba,arr,Recap,"This paper presents NLU++, a new dataset for NLU tasks including intent detection and slot labeling across two domains, banking and hotels. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,***This is from Reviewer XYZ of the previous version.*** ,0 1 2 3 4 5 6 7 8
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap,"MixUp (Zhang+ 2018) was initially proposed for image models, which creates augmented examples by linearly interpolating both the representations and labels between positive-negative sample pairs. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap, ,
0a403ec48d3198d320628d852e9d215734dd5b90e7550c2f7e94480e4f3838c337bd750b3183e4dfde5d7ab98546c927689c027e6fcab5451486c3938a682b7b,arr,Recap,Experiments show the usefulness of these two tasks. ,19 20 21 22 23 24 25 26
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,This reaffirms the authors motivations. ,427 428 429 430 431
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap, There's also a small software package with a README as part of the uploaded submission -- but it's not mentioned in the text and so I almost missed it. ,217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Recap,"Through the statistics of ACL conference papers in recent years, the authors find that the current researchers are encouraged to go beyond the prototype experiment (optimizing accuracy/F1 on an English dataset) in only a single dimension. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Recap,The paper presents a novel dataset for the task of stereotype detection. ,0 1 2 3 4 5 6 7 8 9 10 11
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Recap,The paper goes on to show that this can help to identify and abstain from (falsely) predicting hard examples and to identify unanswerable questions on a constructed dataset. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,This is mostly because offensive language phrases are typically relying on specific stereotypes. ,124 125 126 127 128 129 130 131 132 133 134 135 136
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Recap,"They use BLEUVarN as a metric of uncertainty for a possible summarization, showing the variations across the summary samples. ",34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
d72c02867ce702f7e553875ad03451e0860fa305526db7863c13003278aa32c8bbf41bec04ce9c895dd7fca3fa468cee271e5dc2413cf2eb8ad02ea322eb5f63,arr,Recap,This paper compares three entropy estimators with the simplest plug in entropy estimator on linguistic data of CELEX corpora and synthetic data. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Recap,"They observe that although multimodal models are better storing visual commonsense, they are still subject to reporting bias. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
7f996fb9f31b45dea2339c0d4716c6c109c47c5b38feee689425e631026e454379762bebbea912d49f29530016a12a703c629819acd26de68018289115cb6bdd,arr,Recap,"It is trained on part of the model's vocabulary, and tested on the other: if it manages to succesfully generalize, the embedding must contain orthographic information. ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Recap,"This paper proposes to extract word-level quality information for machine translated text from a state-of-the-art sentence-level quality estimation (QE) model, based on pre-trained contextual embeddings, fine-tuned in a semi-supervised way, i.e. using only sentence-level scores for fine-tuning. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,Contrastive-Probe do not rely on the MLM head of the PLM being probed. ,97 98 99 100 101 102 103 104 105 106 107 108 109
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"Additionally, expanding the attacker model to more complex neural networks is a worthwhile practical application for the proposed loss functions. ",969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988
9c42d14ccc84cf2e86bf494b4f4c72974fc1f55456a9cdd542f9d7654aaf3d5779eb6eac51a4cdb96a2edee8473bb8bdb525a43601d147fbac2e8d290269013a,arr,Recap,"They also obtain SOTA results for Hebrew morpheme segmentation, POS tagging, and dependency parsing. ",130 131 132 133 134 135 136 137 138 139 140 141 142 143
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Recap,This paper presents a data augmentation with ranking-based learning for open relation extraction. ,0 1 2 3 4 5 6 7 8 9 10 11 12
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Recap,Extensive experiments and an ablation study are conducted to support the paper's claim. ,100 101 102 103 104 105 106 107 108 109 110 111 112
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,The QG model takes as input the concatenation of QA-pairs. ,116 117 118 119 120 121 122 123 124 125
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Recap,"
2) ICoL (Iterative Contrastive Learning) that iteratively trains the query and document encoders with a cache mechanism to mitigate the insufficient memory on a single GPU and allow more negative instances for better performance. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,"Based on the newly collected dataset, the author proposes a pipeline-based system of question-answer pair generation (QAG) conditioned on given stories. ",48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap," Several models trained on different amounts of data have been tested, with the goal of simulating different levels of proficiency in human speakers.
",40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Recap,"When the input is below a predefined number of tokens, the final summary is generated. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Recap,This paper describes a methodology for collecting parallel data for the task of detoxification. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Recap,They found several conclusions about the relation between human and machine attentions. ,20 21 22 23 24 25 26 27 28 29 30 31
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Recap,"By comparing to a baseline (which takes activation values as the attribution score), the authors show their identified neurons are specific to the input fact and not shared with other facts, indicating the neurons are more likely to express the specific factual knowledge. ",48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Recap,"This paper presents an English Reddit corpus which consists of Parent/Target comments to explore whether the conversational context is important to identify a message as Hate, Counter, or Neutral considering both human judgments and system predictions. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Recap,They further introduce a reinforcement learning agent that can identify the most informative examples in multi-task learning setup. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Recap,"
The main question is shaped around the issue of reporting bias: do vision & language models (trained on visually grounded text & images) suffer less from reporting bias than text-only models (trained on wikipedia etc)? ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"On the downside, the methodology lacks some details which are difficult to understand in the current version: ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,"This paper proposes a prompt-based data augmentation pipeline, PromDA, targeting to improve model performance for low-resource NLU with high quality synthetic data. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Recap,The proposed dataset consists of multi-turn conversations and passages in both text and speech form. ,12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"It includes two domains (""Hotel"" and ""Bank""), with 1k and 2k samples, respectively.
",76 77 78 79 80 81 82 83 84 85 86 87 88
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Recap,The results show that the suggested approach is promising but a lot of challenges remain. ,94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"The authors use a pre-trained version of GPT-2, DialogGPT, as the initial set of model weights and fine-tune DialogGPT with the PersonaChat dataset. ",252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Recap,The test sets of the remaining 17 languages are machine translated. ,192 193 194 195 196 197 198 199 200 201 202
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Recap,Authors first study which types of knowledge can benefit which tasks. ,32 33 34 35 36 37 38 39 40 41 42
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Recap,"
The authors evaluate these contributions on the recently proposed BEIR benchmark and show the effectiveness of their system. ",99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
089fa4b7f0e4265532d65b1eea05ac48c8b82e01358b15feea59cf8855580971154b1b47fe6ad58eed10e64e8b2d89d6aa582d55e183b9fe28b3b25ec81b4fa8,arr,Recap,"As per the experimental results, we cannot identify a single algorithm that performs better across datasets. ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Recap,If the output of the encoder is far out of the distribution then the large model takes over to ensure there is quality. ,68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Recap,  ,
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,"Moreover, human evaluators verify that the QA pairs from the proposed system have higher readability and relevance with respect to the stories. ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07,arr,Recap,"Experiments shows that the training strategy improves the translation quality, over two training datasets, outperforming previous works. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Recap,The output of individual essay traits (scores) are concatenated with the essay representation for the primary task and passed through a dense layer to predict the overall score for the essay. ,69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,"
However, there are some issues with the paper: 1) it uses different experiment settings (e.g., a 32k batch size, a beam size of 5) and does not mention some details (e.g., the number of training steps), these different settings may contribute the performance and the comparisons in Table 2 may not be sufficiently reliable. ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
97bd72cf67e40492696103ced9dcbd5066d8a3a52f3d2558764aa570e24ae2c7bedddf9ad226e624b1dabcced450f36d6bcd93ece5a871c74fa98b7e2d8145fc,arr,Recap,"Finally, the study presents a set of experiments, in which various models trained to perform the specified task on that data set. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Recap,"
Unsurprisingly, most of the models do not suffer from the problems and those who do, only fail to argmax some ""corner case"" subwords. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,This is a combination of 2 previous approaches which exploit the classifier’s output (as a confidence measure) and the agreement between previous classifiers. ,162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
fd2caf0a98ac82aa472d008400f29ba5bd74e77d5471c83cb7634bca4d59d5c302b38774e1e7775d5f8bf1110a26d537ba5427a759506b0a0807bc3e3590493c,arr,Recap,This paper aims to find the best strategy to select training examples for few-shot transfer. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Recap,"To realize this goal,  the author formalizes this task as a seq2seq problem via equipping BART with two extensions: table constraint and table relation embeddings. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Recap,A baseline for detecting adversarial examples also has been proposed in which the authors assume that the distributions of the clean example’s features follow a multivariate Gaussian distribution and apply kPCA to reduce the feature dimensionality and MCD to remove the outliers in the training set. ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"
All the metrics they define cannot handle MT target sentences that are all correct or all wrong as the authors acknowledge. ",112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Recap,Results on BEIR benchmark show that the proposed method achieves SOTA performance compared with supervised dense retrieval model. ,42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Recap,The paper also presents positive results on GLUE and Long-Range-Arena benchmark. ,68 69 70 71 72 73 74 75 76 77 78
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Recap,"This paper proposes a novel supervised contrastive learning method, LaCon, which makes sufficient use of label information by three defined contrastive loss: instance-centered contrastive loss, label-centered contrastive loss, and label embedding regularizer loss. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Recap,-Authors also investigate the performance of using different sizes of the training sets: they show that dropping training set under 99 mins degrade performance significantly. ,84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Recap,"Furthermore, the authors demonstrated the effectiveness of their created parallel data by training various detoxification seq2seq BART-based models and showing that the trained models outperform current STOA methods. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Recap,"The work involves training models for Pubmed abstract retrieval based on the patient's admission note (the query); combining the text of the clinical note and the retrieved and re-ranked abstracts for patient outcome predictions, namely predicting prolonged mechanical ventilation, mortality, and length of stay. ",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Recap,"The authors find that benchmarks contain more than 60% hallucinated responses, and that models can amplify the amount of hallucinated responses.
",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Recap,Pinyin represents a pronunciation of a corresponding Chinese character. ,8 9 10 11 12 13 14 15 16
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Recap,"By generating rationales at different length levels, the authors study how much rationale would be sufficient for humans to confidently make predictions. ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Recap,They also release several baselines on the benchmark they release. ,37 38 39 40 41 42 43 44 45 46
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Recap,"Both these objectives are modeled after the information bottleneck principle in information theory science.
",45 46 47 48 49 50 51 52 53 54 55 56 57 58
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Recap,"This approach is presented as more linguistically sound, it outperforms previous models in applications and leads to better explainability. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Recap,Two major claims are: 1. ,54 55 56 57 58
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Recap,"
The experimental part and the analysis of the result are satisfactory.
",110 111 112 113 114 115 116 117 118 119 120
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,"Due to the limits of previously defined datasets, they propose a data collection to derive a crowd-sourced dataset based on Reddit content. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
77d66f94629e1c83b3c1a782416ae04a1c794ecef8ebc7d7aaa74007bbc4de32ffb3812d67ab562a0a01f1631722fe14330dacea6b1d6b3f7bdb19d4c92ba83e,arr,Recap,The paper also proposes to use a graphical notation to summarize the inner structure of metamorphic relations. ,43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"The number of wrong predictions, i.e. words which are in a different relation to a  given word at the top of the list of the most probable predictions were counted. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Recap,This paper proposes a simple but powerful approach that uses a single Transformer architecture to tackle KG link prediction and question answering treated as sequence-to-sequence tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,"Overall, this paper is well-written and contains comprehensive experiment results and analysis. ",68 69 70 71 72 73 74 75 76 77 78 79
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Recap,"Using such a dataset, they develop VRank as a reference-free model for story generation evaluation. ",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"
 The authors also checked if the additional training step can negatively influence the results obtained on the other tasks. ",352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Recap,This paper advocates the importance of cultural awareness when designing an NLP solution. ,0 1 2 3 4 5 6 7 8 9 10 11 12
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Recap,The paper introduces the Pragmatic Rational Speaker framework that allows a speaker to take the listener’s disparities into account when communicating. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
6e33f0781de36470afb2ea4cdbe34390839f5f6e8b8f5bdf32522fec53a81fecac498484449053b6784972f2da0ec6a0d66b80a16d83e257d00e881ac15bf207,arr,Recap,This task is generating a summary in a target language from a source document in a source language. ,7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Recap, ,
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap,"The model outperformed these baselines, and analyses on model components were provided. ",179 180 181 182 183 184 185 186 187 188 189 190
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Recap,"In this paper, the author(s) propose a new method, FewVLM, for learning vision-language tasks using a few examples. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,On the other hand slot accuracy is a function of total number of predefined slots of all domains and by definition it is prone to overestimating the model performance. ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Recap,"However, there is a sizable body of work that aims solely on producing a single model for various languages, seeking to reduce the number of parameters while retaining performance. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,Is the statement only true for the baselines or also for the core set selection algorithm? ,427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,Their third set results examine transfer across models. ,401 402 403 404 405 406 407 408
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Recap,Experiments on STS datasets and transfer tasks show the effectiveness of DiffCSE. ,45 46 47 48 49 50 51 52 53 54 55 56
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Recap, ,
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Recap,The experiments in the second part of the paper show a real improvement using this generic algorithm (agnostic to the used model)  over the naive baseline. ,26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
089fa4b7f0e4265532d65b1eea05ac48c8b82e01358b15feea59cf8855580971154b1b47fe6ad58eed10e64e8b2d89d6aa582d55e183b9fe28b3b25ec81b4fa8,arr,Recap,"They have dealt with four datasets covering four jurisdictions, five languages, and various sensitive attributes. ",24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Recap,"To tackle this issue, the authors present a new meta-learning approach (DAML) which trains a style transfer system that can quickly adapt to unseen domains during inference (with a few unpaired examples). ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Recap,"On the methodology, prior domain knowledge is injected via column expansion templates, which requires a small amount of manual effort. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,"The quality of a paraphrase is defined as a 3 dimensional vector consisting of its semantic similarity with the source sentence, and lexical and syntactic diversity. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Recap,They present strong baseline models based on the recent CLIP model and extend it further to adapt it to the present task. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Recap,"The results on En-De in-domain and out-of-domain data, as well as a comparison with other constrained models show that the proposed model a) improves the quality b) does not increase latency ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
e5cf4b80a9f86f6084a8fb5583388adc52ba45dcdcaa635b2e6eef1cf2689f386bbd7968793f75921c05bf88c6bfd8e8134141ca43e69df1b72b046a6e2309fc,arr,Recap,They report improved scores for all cases. ,87 88 89 90 91 92 93
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Recap,This relies on a cross lingual token alignment based on greedily aligning tokens with the highest cosine similarity. ,84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,"One of the advantage of this approach is the possibility to easily include answers with multiple tokens.
",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"In addition, they propose to use the word-level QE task as a new benchmark for evaluating explainability methods.
",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"An ablation study is also performed, proving that both KD processes actually contribute to the results. ",467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Recap,"This seems to be a primarily theoretical ML paper that describes the _softmax bottleneck_ problem in neural LMs, which results from the fact that a single hidden state embedding cannot be close to the embeddings of all possible candidate next words under certain conditions. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
c476e1916a5e04f95f17a9f2fd62d74fa664c84ea9dcaecf96db78dee71eeb770dff7d76c1e4abe6919622db6936040e8ecc60b449d3472f9457a322c9be0d7e,arr,Recap,This paper proposes a framework for zero shot cross-lingual natural language understanding that makes use of translation systems and bases on learning the alignment from unlabeled parallel data. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Recap,A highlight of such a neural-symbolic method is that the final loss can smoothly be back-propagated to the trainable modules. ,145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Recap,"Since only minor revisions have been made to the paper, my views of the paper have not changed. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Recap,"The key idea is to update loss weights so that the weighted sum of task-specific gradients moves model parameters to the direction which reduces all task-specific losses computed on held-out data.
",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
4f07dd880235b4dade9d1edea523d9d689b9c28b10a5a91db77bc98a5960270516696c225c92bf8d553c45f810de2bb75ad74ab717ea7a8450c4ac83a8ecade1,arr,Recap,They use ELECTRA's RTE head to do the gap/non gap (gap means the token should be masked in open cloze tests) token-level classification and use ELECTRA's MLM head to do the MLM auxiliary task. ,10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
a09847ed94d9d36c62841908a6163e9cbb9e341099ac05ab01ec5a9c9de0e32dd33a5f044591d548fb961736b3ef91c5043ff5a59632d5bfa86eaf5303e5f438,arr,Recap,I believe this work would be valuable to the community of people working on text-to-SQL parsing. ,87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,"Through their experiments, the authors show that the quality of the generated paraphrases monotonically increases with the offset specified in the input until a certain point, after which the responsiveness to the input might decrease as it becomes increasingly difficult to generate high quality paraphrases when the requested control values deviates significantly from the typical value. ",179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Recap,"The authors first identify two limitations that exists with prior works: (i) adversarial perturbations for text often require a large number of search steps; and (ii) while expanding the search space for adversarial perturbations to augment the training set may improve robustness of the trained model to such perturbations, it could also hurt model performance on the clean data. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Recap,"This is then used in experimentation which initially follows the Rational Speech Act (which this paper also extends), and the models are evaluated along the performance (measures the accuracy of the collaborative game), efficiency (measures time used for model training), and transparency (shift in vocabulary that is used in accordance with different speakers). ",95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Recap,"But as its contribution is incremental, it is unlikely to be improved through minor modifications. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Recap,Then the task-specific layers in each single-task model are compressed using knowledge distillation. ,31 32 33 34 35 36 37 38 39 40 41 42 43
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Recap,I really like the paper and I think should be accepted. ,119 120 121 122 123 124 125 126 127 128 129
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Recap,Training a reranker to better approximate the contribution of each retrieved document to the generation process. ,20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Recap,The paper presents a novel way of using annotator rationales. ,0 1 2 3 4 5 6 7 8 9
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Recap,"Then, the authors measure the ability of state-of-the-art AI techniques to sequence instruction steps. ",50 51 52 53 54 55 56 57 58 59 60 61 62 63
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Recap,The paper presents a novel dataset of arguments annotated with human values from a taxonomy of 54 values. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Recap,"Experimental results on the two new datasets show that (i) multimodality is beneficial, where humans seem to more effectively benefit from the visual information than the models, that (ii) models fall short against human performance irrespective of the modality, that (iii) the sequence-aware pre-training method the authors propose slightly improves effectiveness. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Recap,Evaluation issues with respect to methodology used by J&W and W&P and evaluation using humans 5. ,91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,The second KD process is focused on teaching the CLIR system to encode (internally) a source-language text (e.g. the input query to the CLIR system) in the same way as the target-language monolingual system. ,223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Recap,"Specifically, they employ 1) weighting method to punish false negatives 2) generate noise-based negatives to guarantee the uniformity of the representation space. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,"Recognizing the need for automatic detection of real versus fake news, they train a system for event detection at two levels – document level and event level. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,Then a Teacher Student Distillation model is simultaneously trained with both teachers’ soft labels to improve the representation for the target language. ,81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Recap,"Additionally, in the standard data collection setting, GAA provides a measurable speedup in collecting the dataset in general, but also the effective examples that fool the model by a significant margin. ",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Recap,The authors introduce a dynamic inference approach that combines large and small models to provide the quality of the large model with the inference speed of the small model. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,The method uses a conditional variational autoencoder to generate prosodic attributes for input text. ,25 26 27 28 29 30 31 32 33 34 35 36 37 38
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Recap,"DEAM is compared against other seemingly trivial baselines that shuffle utterances, shuffle one speaker’s utterances, or insert random utterances. ",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,"The contrastive learning approach proposed here involves finding difficult negative examples, which is done by choosing structurally similar equation trees with different operations in the intermediate nodes. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,This paper applies this setup to LMs by clustering the 4x4 sentences based on their (averaged) sentence representations. ,205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Recap,The paper aims to find the minimum spanning arborescences in an entity-mention graph to get better mention and entity representations by modeling the coreference relationships. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"The authors acknowledge that speed ups in these cases are insignificant because of the shallow nature of the networks used.
",363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Recap,"Finally, the paper shows cross-domain transfer learning experiment results. ",99 100 101 102 103 104 105 106 107
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Recap,"
The resources are to be publicly released (already done anonymously on OPUS, will be further shared once able to be deanonymized). ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Recap,"Actually, the medical dataset is not very suitable for this task, the authors also mention this consideration. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,Some ensemble statistics (interquartile range or std deviation) would have been good in the tables to give the reader some idea of what the meaningful differences are in the experiments. ,288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,"This means, for example, that the phrase 'Mary asked the time' is given different prosody in the contexts 'Who asked the time? ------.' ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Recap," ReClor is augmented to contain four variations of the same content/question/answer-choice triplets but with three versions of the same triplet containing a ""None of the above"" answer choice. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Recap,This paper addresses some key issues of the Entity Set Expansion (ESE) problem; from the evaluation metrics and dataset perspective. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Recap,"Finally, a new model is proposed that uses titles in addition to article summaries as a way of focusing on the framing used by each side. ",68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,"
3. ",117
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Recap,"It presents supervised, unsupervised and semi-supervised frameworks for training, and provides a unified perspective for both single-aspect control and multi-aspect control. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Recap,"Finally, human evaluations show the feasibility of the proposed approach. ",86 87 88 89 90 91 92 93 94 95
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Recap,"First, train task-specific models (but for each model, only finetune the top n layers). ",63 64 65 66 67 68 69 70 71 72 73 74 75 76
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Recap,This paper presented a fine-grained stereotype detection set and proposed a reinforcement-learning based multi-task framework for stereotype detection. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Recap,"The authors mentioned that existing datasets do not consider entities that belong to multiple concepts, are non-named and vaguely attached to the concepts they belong to. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Recap,"This paper is similar to ""Learning Music Helps You Read"", that is, it tests the transferability of structure from synthetic pretraining data. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Recap,"
The contribution of this paper: 1. ",13 14 15 16 17 18
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,It’s interesting to see that modeling knowledge selection as a dependent process on memory selection results in significantly improved results. ,233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Recap,Ablation study provides the importance of each of the component / architectural choices. ,130 131 132 133 134 135 136 137 138 139 140 141 142
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Recap,"This paper proposes a “plug and play” method for controlled text generation using language models, i.e., it does not require finetuning of the language model used for generation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"They explore 4 models for feature attribution for sentence level QE method: LIME, Information Bottleneck, Integrated Gradients, and Attention. ",77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Recap,This paper discusses methods to improve MT for Interactive machine translation but not in a standard sense. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Recap,"In addition to automatic evaluations, human evaluation is also conducted to demonstrate the effectiveness of DYNAMICTOC. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"Such a finding is certainly interesting as a construction-oriented preference in the original task was observed only in more proficient speakers.
",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Recap,"First, more useful error-related word-level information is encoded at deeper layers of the model, second, both source and target sentences appear to have an impact on feature attribution, third, frequency of words in the machine translation training corpus and sentence-level QE seem to be in a relation of some sort. ",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Recap,"On the other hand, I feel that is often difficult to disentangle between linguistic and cultural dimension, and in many cases  the problems/solutions are overlapping with the typical low-resource language scenarios (e.g. where a particular language/dialect/sociolect can be associated with a specific cultural group), and in such cases the general heuristic could be described as ""the more cultural-specific data we can acquire, the better""; while in other cases it is difficult to propose any conclusive solution (e.g. see the case for model training in Section 6.2, where methods balancing for bias would require access to demographic attributes, but the problem would persist because one cannot really be sure that such attributes adequately reflect culture). ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Recap,"What they do is fine-tuning BERT on financial documents, and replace the fragment of numbers into a special token. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Recap,This paper consists of two main parts. ,0 1 2 3 4 5 6
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Recap,"When combined with existing reasoning modules such as GraftNet and NSM, the approach achieves SOTA performance. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Recap,"But I found already the previous version of the paper to be very good.*
",67 68 69 70 71 72 73 74 75 76 77 78 79 80
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,This paper shows that the complexity around prompt choices can be easily managed by finetuning on Null prompt ,70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,This paper presents new methods for zero/few-shot classification focusing on improving inference and training time costs. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Recap,This paper is about determining the syntactic ability of two Dutch variants of transformer based language model BERT: BERTje and RobBERT. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,Dialogue state trackers (DST) extract important information from multi-turn dialogue situations and structures the belief state that appears during the conversation in the form of domain-slot-value. ,3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Recap,"The work argues that input attribution method evaluation criteria (the means in which one attribution method is compared against another) posses several ignored flaws and have ""negatively affected the research field"". ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Recap,"
The Co-VQA contains three components: Questioner, Oracle, and Answerer, to decompose the question, provide oracle answers in the training procedure and perform reasoning model on the sequence of sub-questions seperately. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Recap,"Authors followed standard TTS evaluation protocols to evaluate their proposed architecture, and evaluation results are in favor of the proposed architecture. ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Recap,"I enjoyed reading it, especially for the attempt of brining awareness on cultural issues, which are often neglected in current NLP practices. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Recap,"Also, the authors introduce a gated relative position bias which the author claim is helpful to the pretrained model. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Recap,"To alleviate the problem of error propagation due to Automatic Speech Recognition (ASR) system for multi-modal sentiment analysis task the paper provides a refinement approach by detecting the positions of the sentiment words in the text and dynamically refine the word embeddings in the detected positions by incorporating multimodal clues such as low voice, sad face and textual context. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Recap, ,
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Recap,This paper proposes a smoothing regularization technique for NER. ,0 1 2 3 4 5 6 7 8
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Recap,defines the task which pertains to state tracking over a multi-turn conversation between the system and the user wherein the user asks questions and the system provides answers from a video scene. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Recap,The authors' analysis reveals that entity representations provide more language-agnostic features to solve the downstream tasks. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Recap,"I think this paper offers valuable contributions, both methodical as well as in the insights that are shared alongside quantitative results. ",136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Recap,"The paper presents a detailed analysis of the dataset and a thorough evaluation of long-context and extractive QA models on the presented data, demonstrating that all the models are far behind human performance. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Recap,"This paper focuses on an important task incomplete utterance rewriting, the goal of which is to rewrite a semantically incomplete sentence into a semantically self-contained utterance. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Recap,"This paper compares two figures, Firth and Harris, who are often cited as foundational in modern computational linguistics but who are rarely actually read, perhaps even not by the people who cite them. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
a09847ed94d9d36c62841908a6163e9cbb9e341099ac05ab01ec5a9c9de0e32dd33a5f044591d548fb961736b3ef91c5043ff5a59632d5bfa86eaf5303e5f438,arr,Recap,"This paper identifies an important and challenging problem for out-of-domain generalization of text-to-SQL parsers, which is the alignment between composite column operations and their corresponding domain-specific mentions in natural language. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,"They find that this can produce strong performance (measured in relative performance, the direct source to target prompt transfer performance divided by the performance researched from directly training on the target task) within clusters of similar tasks.
",315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Recap,"In experiments, the authors presented several baseline models to evaluate different aspects of the proposed DVD-DST dataset. ",162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,They posit that knowledge selection is dependent on memory selection and memory is selected based on the context. ,56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Recap,"
The authors cast this problem as a sequence tagging problem and show its efficacy by comparison with a simple baseline. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Recap,This paper propose a novel encoder-decoder model for language generation. ,0 1 2 3 4 5 6 7 8 9
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,It is trained as a similarity prediction task with two uniformly sampled tokens from two input sentences. ,54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Recap,Experiments on several quality estimation tasks demonstrate the effectiveness of the proposed method in improving model performance and detecting noisy samples and out-of-domain data. ,101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Recap,A limited set of potential pronunciations are generated based on orthographic rules. ,16 17 18 19 20 21 22 23 24 25 26 27
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,The paper apply MedLAMA using Contrastive-Prove and other approaches on different PLMs (general and biomedical domain) and show that their approach allow to better measure the biomedical knowledge included in the models. ,154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Recap,"The paper ""Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation"" proposes to transfer the benefits of advances in general domain LMs, such as fewer parameters or more accurate predictions, to domain-specific LMs via knowledge distillation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,It was shown that the response time for words that are considered prototypical for a certain construction type (e.g. _give_ for ditransitives) was significantly lower for congruent construction-word pairs. ,319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Recap,The paper surveys existing metrics very thoroughly and then proceeds to define the formal desiderata for metrics designed for the targeted problem and evaluates existing metrics with respect to these properties. ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Recap,"The paper describes a novel prompt-based transfer learning approach for text generation i.e., PTG. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,"Improvements are reported on NQ, TriviaQA and SQuAD, especially on SQuAD where conflicts are reported to be severe (i.e. often multiple different questions are extracted from the same passage). ",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"Puduppully, et al., 2019. ",223 224 225 226
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Recap,"This work focuses on spoken NER task and explores the use of external data in various form which is not annotated for the task such as plain speech audio, plain text, and speech with transcripts. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"Inference from these types of approaches typically need a number of forward passes (equal to the number of labels) through a large pretrained model, which involves an expensive cross-attention step between the input sentence and hypothesis.
",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Recap,"The only part which is more research-heavy is handling the rich morphology of Hebrew, where the authors experiment with introducing a morphological segmentation component into the neural setup (a task which is highly non-trivial for Hebrew).
",199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
de3c8e7b1b41f35cbd5e964397fef97e665ad35d2f3b989493cecb77ee77776a9e0a300d36f7c3c2c4cbc561b69cec073be42cf033541305b52d94cc9c126e40,arr,Recap,This paper mainly investigates prompt-based finetuning in few-shot learning. ,0 1 2 3 4 5 6 7 8
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Recap,"In addition, the paper also carefully constructs the probing position of the softmax layer, in order to enable the whole method applicable to seq2seq models that have a decoder. ",62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap," For the MWR task, queries, like “happy is the synonym of [MASK]”, were used. ",124 125 126 127 128 129 130 131 132 133 134 135 136 137
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"From the perspective of social chatbots, no existing chatbot dataset for private persona information exists. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Recap,"Such implicit assumptions, labelled as “human values” in the paper and in the social sciences, are shared beliefs regarding the positive assessment of some dimension, e.g., “having a comfortable life is good”, “being polite is good”, etc. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Recap,"It also evaluates strong unimodal and multimodal baselines, and analyzes the potential and drawbacks of current models. ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"To encode the needed information in language models, the authors proposed the approach with the intermediate model training on the newly defined meaning matching task. ",286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,For simplicity they have used English as the target language for their experiments. ,42 43 44 45 46 47 48 49 50 51 52 53 54
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Recap,These latent variables decide which sub-network of the model is selected for each task / language pair. ,32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Recap,"The methodology is introduced by example, and by doing so creates two parallel-data datasets for detoxification. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,This paper looks at ensembles of Large Transformers tagger models for Grammatical Error Correction. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Recap,"The dataset released with the paper contains 5270 English arguments annotated with a 54-level taxonomy of human values, which is  organized hierarchically and covers four geographical cultures (USA, China, India, Africa). ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,Joint goal accuracy verifies if the predicted belief states perfectly matches the gold labels. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Recap,"This paper concerns compounds and elaborate expressions (EEs) in Hmong, Lahu, and Chinese. ",0 1 2 3 4 5 6 7 8 9 10 11 12
4b5cc87c513b6a19e50ca5e5ff28894bf79724155d775685d718d58e8e5fb3ed3bbbb70d292693e2126f19cc4245e097cd9dad40520ee999c416e74222813451,arr,Recap,"They find that a significant amount of information about spelling is retained by the embedding, and that explicitly providing information about spelling during training by using spelling bee does not provide additional advantage to the model. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Recap,"The proposed algorithm is expected to (a) avoid undesirable task performance trade-offs (i.e, sacrificing performance on one task to improve on another task) and (b) facilitate better generalization.
",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Recap,"In this paper, the authors propose an unsupervised multiple-task and multiple-teacher model for cross-lingual NER. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Recap,This paper applies a method known as *flooding* [1] when fine-tuning BERT-base on various downstream tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Recap,"The dataset created consists of high-quality test sets in 3 languages (Chinese, Spanish, and Indonesia) that have been post-edited by professional translators after machine translation. ",167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,They also find that the correlation decreases as the size of the frozen model grows. ,575 576 577 578 579 580 581 582 583 584 585 586 587 588 589
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Recap,"On the other hand, morpheme-based segmentation benefits more from underserviced training. ",114 115 116 117 118 119 120 121 122 123 124
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Recap,An example of this would be background knowledge about the summarization topic. ,27 28 29 30 31 32 33 34 35 36 37 38
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,The formal definition of their pre-training task includes: ,10 11 12 13 14 15 16 17
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Recap, ,
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,"The same three tasks were then solved using the resulting models and generally, there was a significant increase in the results for the large models. ",318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Recap,"
In particular, an energy based router is adopted to determine whether the swift model or the super model should be used to run inference on the given input example. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Recap,"And the improvement is also demonstrated in other three language generation task, including summarization, storytelling and simultaneous machine translation. ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Recap,The authors also introduce two new modifications to the existing approaches and show that they are able to improve the existing approaches. ,70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Recap,Further pruning on the reduced dimension of the datastore before the KNN retrieval. ,57 58 59 60 61 62 63 64 65 66 67 68 69
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Recap,Then they proposed a knowledge distillation method to resolve such problems for PLM-pruning. ,53 54 55 56 57 58 59 60 61 62 63 64 65
4825eb030d8afb393c246a33e9d8a1f793b90ea88cb57ce09e675891f7d509d82c4b6cc50d7f8dc386a279b6854b3692285cbe651def3090bb02344787ef1b3f,arr,Recap,The authors first present a method that generates universal adversarial triggers with language model loss or selection criteria. ,9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Recap,"Finally, the embeddings are spread apart by passing them through a network trained with an unsupervised clustering signal, and, if understand correctly, averaged together. ",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,1. ,89
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Recap,The paper suggests a dual attention technique to tackle the underperformance and shows that indeed the performance increases. ,53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Recap,The authors insisted that the proposed contrastive-probe method achieved significant improvement on probing with MedLAMA data. ,68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,This work focuses on span-based Nested NER task. ,0 1 2 3 4 5 6 7
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Recap, ,
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Recap,The paper leverages self-supervised audio and visual representations for audio-visual speech recognition (AVSR) on the LRS2 and LRW. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,This review is for a resubmission that I reviewed earlier. ,0 1 2 3 4 5 6 7 8 9
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,"The authors additionally report model distillation results on synthetic data, where a single model achieves near SOTA with 73.21 on the BEA-2019 test. ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,"The specific innovation of this paper is the cross-utterance conditioning, so that in order to synthesise prosodic speech for an utterance, the VAE is conditioned on text of several preceding and following utterances as well as the current one. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
ebfe58b10dee02a1cb830e85ec7993f381fa88e9d1e70ec9eba24417b92fdbe8d20ae561d42fbcbdb17d4380fde7845f5850c3fd769aa20c15003fe18fcdfbf0,arr,Recap,"The current version of the leaderboard includes three downstream tasks, including machine translation, summarization and image captioning. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Recap,"Finally, they test if transitive relations of hypernymy and synonymity, when applied to pairs (x1,x2) and (x2,x3), also apply to (x1,x3). ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,The result shows that a QA model initialized with a small number of labeled training data can be improved by a large margin of accuracy after being fine-tuned with derived feedback data. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,"The paper further proposes ""label tuning"", where the premise encoder is kept fixed, and only the label embeddings are tuned. ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Recap,"Second, the label centered contrastive loss which uses labels to mine positive and negative labels from a batch. ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Recap,Experiments show that the learned confidence can better reflect the quality the model output and using the learned confidence can result in better BLEU score. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"They did not compare their search strategy to others, such as genetic algorithm (Alzantot et al., 2018) both in the performance and computational cost.
",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Recap,"This paper expands on previous work, that has found that MT QE is considerably biased towards the fluency of the translation, often disregarding the source sentence (adequacy). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Recap,Authors demonstrate that by modifying a recent dense passage retrieval method proposed by Karpukhin et. ,42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Recap,The paper discusses the introduction into direct speech translation models of contrastive learning methods that aim at reducing the difference between the encoded representations of speech and text with the same content. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Recap,Experiment on four popular table-to-text dataset reveals the effectiveness of proposed methods (a little marginal). ,52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
c00ac5b1456ef83c612b05b56da585d3f7c84d7985e7a58de417b8e342288e7c1727d92be22f51facf611a8de175a001ef3fa182015848728b5ded175b853667,arr,Recap,The proposed improvements through alignment constraints during training and or inference ,13 14 15 16 17 18 19 20 21 22 23
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,"For simplicity, English is always used as the target language. ",385 386 387 388 389 390 391 392 393 394
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Recap,"This paper focus on mitigating the partial input bias of neural QE models, which means that some strong QE models tend to over-rely on the translation while ignoring the source sentence to some extent. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Recap,The paper presents two experiments using synthetic and real-world text classification datasets. ,60 61 62 63 64 65 66 67 68 69 70 71
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Recap,Additional analysis on the change in values of layer wise bias terms reveals that finetuning a specific subset of bias terms can also lead to marginally lower performance as compared to finetuning all bias terms. ,60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
b576530cde6bfac341d89934c90e7ba2ec6698e2521662f9ea3f800d72fc1e77747d48178bd77e4fbb6ad11866097c3154c99b9f3d2b9e07aa08b5e1e68bee72,arr,Recap,"Relying on a taxonomy of values based on literature and consistent with those used in social sciences, and collecting data across 4 cultural domain, the paper presents a robust study on the automatic detection of values with very encouraging results. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,The call this method _ON_. ,287 288 289 290 291
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Recap,"
(3) The authors show empirical success of their approach. ",144 145 146 147 148 149 150 151 152
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"A defense on sequence embeddings, i.e contextual embeddings in GPT, should constitute effective defense at the token sequence level.
",233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
c1af730b370c44b11d64851ee9d2f5ea9eb336b8c04301c2681c8d1bfdf213c74db334a970ae2b248018ee30be7a033c695c8c021292d26e3f53ccac0f23ec28,arr,Recap,Cluster-assisted contrastive learning is proposed to reduce noisy in-batch negatives by selecting negatives from clusters. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
6c7386d38647d226e22fb6a21bec815d465a1023fc59c871b959b53ae367be17a28b2839533147dc589795577b8630217bf4ea6311ca501b3d89453b25741324,arr,Recap,"It is based on ELECTRA and makes use of two loss functions, one of which is standard token classification loss and the other is a language-based loss function that makes sure that a potential gap is not too open-ended. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Recap,The authors propose a weakly supervised approach based on multi-task learning to pre-train better vector representations for the former task. ,11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Recap, ,
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Recap,"The evaluation is based on two schema-guided datasets: SGD and MultiWOZ-leave-one-out, and two SOTA models for schema-guide dialog: T5-ind and T5-seq. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Recap,Siamese Networks perform similar to their cross-attention counter-parts. ,210 211 212 213 214 215 216 217
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Recap,"
The paper finally explores the space of synonym representations. ",145 146 147 148 149 150 151 152 153
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Recap,"
They show that there are slot filling templates where two proposed alternatives are clearly expressed in the text. ",70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Recap,"In addition, they confirmed that the vector norm-based method (Kobayashi et al. 2020) and the consideration of residual connection (Kobayashi et al., 2021), which were proposed as local analysis methods, contribute to global faithfulness. ",95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Recap,"Besides, the confidence is also utilized to smooth labels for preventing miscalibration. ",89 90 91 92 93 94 95 96 97 98 99 100
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,"Moreover, the authors conduct a comprehensive experiment. ",178 179 180 181 182 183 184
d1921e5f5febc1efa6ccd005802a9c3efc66b8840ed104fdcade7b07f9f498a3eee437ee46bfdde58663ee7bf9cdaab4873670ba950b1a71a31bdc9388fbba99,arr,Recap,"Experiments are conducted using five standard question answering datasets under zero-shot, few-shot, multi-hop, and out-of-domain scenarios, and report enhanced empirical performance. ",86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
bb5a8e3b3e4a450f10be587fad043a653ab3922dc3798914e2badaa74796866bbdd71f6a889a588c0f2535002bda3505dba5aa44a81fb7963f440559db74e96e,arr,Recap,"
The article clearly contains revisions, based on my suggestions and I can also see some of the revisions, requested by the other reviewers. ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Recap,"Specifically, the authors (1) propose to use a distilled version of a PLM during data collection and then leverage a larger model to annotate unlabeled examples for training on the (presumably more complex) successor model. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
534dd4d039e9277fd00d16e3f1cdf7b7ce3d9bf240f6b3db32d966ede32db1ff6121fa15bfe1ba49c20bf8fe510e0805c0d4cc63da74ec69523a1bab60678fa0,arr,Recap,"Later, the authors also investigate the impact of time and historical events using the best performant model (finetuned AnchiBERT). ",140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Recap,They then compare and contrast the recent ASR architectures towards this scenario and try to understand them in the single speaker scenario. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Recap,I.e. it introduces a method to combine a faster but less accurate and a slower but more accurate model so that the final product is about two times faster than Super model but is as efficient. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Recap,This paper provides evidence for the hypothesis that learned representations in BERT and RoBERTa encode abstract information about argument structure. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Recap,"The author's analysis shows that developing models that can update articles faithfully requires new capabilities for neural generation models, and opens doors to many new applications. ",101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Recap,"This paper proposed a unified framework to handle reference-only, source-only and source-reference-combined evaluation tasks. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"It finally reduces the sampling bias and improves the model performance.
",98 99 100 101 102 103 104 105 106 107 108
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Recap,This work deals with a purported flaw of modern neural OpenIE systems: their tendency to extract overly specific arguments which are not useful for upstream tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,"So, in this sense this metric this metric underestimates the model performance. ",84 85 86 87 88 89 90 91 92 93 94 95
31bf3ddda37804ff4f8b1bd9bb4c2398575c52476674569b8bdefcb418e77c6c01f7d5e3c90579ccacaf1683ddbff5e262778d373db27eff7a62abd33a72bbc0,arr,Recap,The training set consisted of word-sentence pairs. ,311 312 313 314 315 316 317
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Recap,"The authors note that although the effectiveness of self-supervised learning has been shown in both modalities separately, they largely remain under explored for AVSR. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Recap,"The dataset contains roughly 86 000 tweets, out of which 3400 are labeled manually by multiple annotators for the training and evaluation of multimodal models. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Recap,The experiments demonstrate how this method can be useful for low-resource settings in a meta-learning scenario. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Recap," The empirical results on the GLUE benchmark also show the effectiveness of the proposed method and achieve the best results compared with a range of baselines.
",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap, ,
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"For instance, how do the symmetry loss looks like? ",66 67 68 69 70 71 72 73 74
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Recap,Experimental results on WMT21 demonstrated that the proposed approach outperformed direct bi-lingual systems and pivot translation systems. ,72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Recap,This work deals with “mutual promotion” where they “promote” in both directions. ,16 17 18 19 20 21 22 23 24 25 26 27
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap, ,
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Recap,"Specifically, the proposed approach contains two mutual information based training objectives: i) Information maximization between context and entity surface forms. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
534dd4d039e9277fd00d16e3f1cdf7b7ce3d9bf240f6b3db32d966ede32db1ff6121fa15bfe1ba49c20bf8fe510e0805c0d4cc63da74ec69523a1bab60678fa0,arr,Recap,The authors investigate the performance of two pretrained language models (PLMs) based on BERT on this data by first continuing the pretraining of the PLMs and later finetuning them to perform a series of supervised tasks. ,36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
6d9d8c0ef5b9d5797bdc062da19e902c7f0b13aef06794efbdac8f5a17cc33bc5ab6421aeda2e0c9ca8d023a9247ea9d6277f035413039804facf3f75ae26db3,arr,Recap,"The data collection and preparation are described in the paper, as well as the data used for the proposed challenges/tasks. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,The prefixes can be learned either without attribute labels (via label variables; similar to the VQ-VAE method) or with attribute labels (via a margin loss). ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
c1af730b370c44b11d64851ee9d2f5ea9eb336b8c04301c2681c8d1bfdf213c74db334a970ae2b248018ee30be7a033c695c8c021292d26e3f53ccac0f23ec28,arr,Recap,This paper proposes a contrastive learning framework to learn phrase representations in an unsupervised way. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
0e30497ecba61ed356a72b0213bc87e06347be6b0164284ff6f25182bf1e310ac082f086cd5e0d6455085d4bf4025289c6f66bb8555e953606e080663f2aa9c1,arr,Recap,The automatic and human evaluations on Indic languages show that the proposed method achieves better performance than previous baselines. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
026afc14b184ea209f525ff954622af51d20da3b5c48638ee94702a3fd3fa0e8ff2dd803da166faf69d21801e8fbb848241fab10fae9027e4565aea564242499,arr,Recap,"The paper deals with misinformation detection in Twitter, using multimodal data (images and text). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Recap,2) it uses the generated sequences to train a discriminator that learns to detect whether a sequence compiles or not. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Recap,"Finally, the authors demonstrate that performance on downstream tasks improves with better punctuation annotations. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Recap,"An intuitive solution is using predicated history, however, this invalidates some questions. ",68 69 70 71 72 73 74 75 76 77 78 79
cabc87768a08817dcb0751a10628db60f2c17acee3397a0e469bddfcd8fecf0a4603079fd884a00b6ef1536b76e7d156b850e59dec8639ef98e4d0e6941bb570,arr,Recap,The paper releases a new dataset for Chinese Grammatical Error Correction which differs from the previous ones by its multi-source and multi-reference nature. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Recap,"Their algorithm uses MCTS, where the policy balances sequence likelihood with the score from a discriminator that determines the presence of certain textual attributes. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Recap,"When generating the i-th token, the proposed approach will predict the token at position i-1 again for a potential revising. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Recap,This paper investigates the effectiveness of entity representations in multilingual language models. ,0 1 2 3 4 5 6 7 8 9 10 11
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Recap,"It is shown that pre-training in a more resourced language gives a slight improvement compared to the model without pre-training in simple NER tasks, where you just need to determine whether or not there are named entities in the text, or to determine the presence and number of named entities in the text. ",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Recap,"
In particular, it targets endangered languages with only one speaker data, and the goal is to reduce the cost of transcription such languages. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Recap, ,
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Recap,The paper is essentially an exploration of the design space for seq2seq architectures that produce code from natural language. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Recap,One key feature of this dataset is that each question is annotated with the specific reading comprehension skill required to answer it. ,18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"The authors also show that they can achieve the same average performance as the unpruned baseline at a 1.5X speed up.
",267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Recap,"Experimental results shows the superiority of the proposed approach on in-distribution and out-of-distribution settings, especially for few-shot learning scenarios. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Recap,They show empirical gains relative to some other baseline methods. ,46 47 48 49 50 51 52 53 54 55
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Recap,"It is modelled on previous test suites such as ContraWSD and MuCoW, but combines manually annotated and curated data with decent multilingual coverage. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap,"Generally, the calibrated systems' plots do not seem obviously notably superior to the baseline calibrations (Fig 2, Fig 1(top)), though the methods do indeed achieve superior ECE (expected calibration error) performance across some of the tasks (xSLUE, a suite of multiclass classification NLP tasks, Table 1) and, somewhat surprisingly, superior top-level accuracy/F1 (table 1).
",190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Recap,Distilling the knowledge from the reranker to the retriever ,55 56 57 58 59 60 61 62 63
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Recap,"The proposed mLUKE model exhibits strong empirical results with the word inputs (mLUKE-W), it also also shows even better performance with the entity representations (mLUKE-E) in cross-lingual transfer tasks. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e,arr,Recap,"This paper proposes “Show, Don’t Tell” (SDT), which frames an example dialogue as a prompt for describing schema to the DST model. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Recap,"Overall, I believe the data and experiments introduced by this work would be interesting to many, and I recommend it's acceptance. ",135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Recap,Experiments demonstrate the effectiveness of the model. ,45 46 47 48 49 50 51
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Recap,The authors start by encoding the prompt and the available entities (extracted from UMLS). ,110 111 112 113 114 115 116 117 118 119 120 121 122 123
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Recap,"Evidence comes from two experimental methods loosely inspired by psycholinguistics: In experiment 1, inspired by the sentence sorting task, they find that similarity scores are higher for representations of sentences (i.e. an average of token embeddings) with the same argument structure (but different verbs) than for sentences with the same verb (but different argument structures). ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,I would like to keep my original score. ,20 21 22 23 24 25 26 27
3f1a09e155c657a139ccdad41c8d593f45e130a564aa0d3825770e56f02682d43186539fe68060d48acab72dfd294c56a3f6ce65d9331ff71c2c1d4aa73a9500,arr,Recap,"
In addition, the authors devised a dedicated benchmark dataset by modifying the ReClor corpus while removing the correct answer from a subset of possible answers. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Recap,"
The approaches are evaluated on two high resource language pairs i.e. En-De and En-Zh. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Recap,The dataset is extremely challenging for the present state of the art models to solve with an extremely wide gap between human and mode performance. ,49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Recap,The proposed methods are able to achieve low latency and keep the BLEU scores of translation accuracies. ,20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Recap,"It then fits SVMs/decision trees/etc to see if you can predict the ordering based on phonology, which is successful as a classifier. ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Recap,The paper describes an early exiting strategy based on hashing tokens to particular layers. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Recap,It would be interesting to include the comparison of using different pretrained langauge model for data augmentation to understand the benefits of model size in this pipeline. ,101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,	Creation of a within-document knowledge graph based on IE (“IE” is never defined. ,78 79 80 81 82 83 84 85 86 87 88 89 90
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,In summary it appears that the defense strategies work with little affect to the evaluated metrics. ,909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Recap,"The authors proposed Context-Aware Language Models (CALM).
",0 1 2 3 4 5 6
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Recap,"The paper investigates the problem of detecting implicit offensive comments in dialogue, where multiple interpretative steps may be needed to uncover the offensive nature of the comment. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Recap,"The experiment includes two intrinsic evaluations, based on event embedding similarity and one extrinsic evaluation, MCNC. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
6d82987300bc04250812d8c1a91a38c01eccbea86f56e48232e221e92d9edae62b335eaba1c5c9cd55b27185ce0fb92fb0eb914835cd3c85658ecec9411b3e3e,arr,Recap,"Compared with the previous version, it has a significant improvement in organization and experiments. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,moved around the notation explanation closer to where they are used so it's easier for the readers to follow. ,222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Recap,This paper studies how the vision model impacts the performance of multimodal translation through multiple probing experiments. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Recap,"Along with describing the task and arguing for its importance, the paper presents a new dataset of implicit offensive comments (annotated with the ""reasoning steps"" required to go from the original implicit comment to its explicit equivalent). ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Recap,"The method relies on recent advances in large, multilingual pre-trained language models (PTLM) such as MT5, which have been shown to perform robust cross-lingual reasoning. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Recap,"The authors catalog numerous aspects of the process of doing so, including identifying some issues with the original dataset which they work to remedy. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Recap,Experimental results show that the proposed framework significantly improves the base model on different datasets. ,37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,The authors have presented results on the next-job prediction task. ,145 146 147 148 149 150 151 152 153 154
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Recap,A cross-encoder is used for re-ranking the retrieved candidates and it yields comparable or better results to the baseline ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
34a654d252d0bb72f0bd405e28bc8a2c52097ce0c2fc0293a544b3bd1929cfc5996e389971dc43791136d5d78b742372f89326f61ab0ae0fdb56d762335f5639,arr,Recap,The paper analyzes the importance of negation in some natural language understanding tasks. ,0 1 2 3 4 5 6 7 8 9 10 11 12
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap, ,
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Recap,This paper proposes a unified representation model Prix-LM for multilingual knowledge base (KB) construction and completion. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Recap,"The performance of the algorithm is tested on five datasets, i.e., IMDB, AG News, SST-2, QNLI and MRPC, and achieved state-of-the-art robust accuracy. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Recap,"-Authors demonstrate that fine-tuning the pretrained wav2vec model gives significantly better performance except for 1 language.
",68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Recap,3- They also make some experiments to establish the usefulness of mult-centric pretraining over english-centric pretraining. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Recap,The real-world data experiment shows ICM ranked tested classifiers similar to the existing metrics but penalizes them differently. ,92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
747249d6df576d913b4dd001992510d9682657fee6f4ea775a23731979bf7af0362f975f45b8c27ae3b04e093fa81069cf32428adf42b4026a447055a6907e27,arr,Recap,They also release a benchmark for adversarial example detection on 4  attack methods across 4 models and 3 datasets. ,45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Recap,Both languages have data available but at different levels of granularity. ,41 42 43 44 45 46 47 48 49 50 51
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Recap,This paper proposed auxiliary tasks that introduce some form of interdependence of arc decisions. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,"Specifically, this paper tries to resolve two specific aspects of prompt engineering - 1. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,Their second results look at the performance of using a prompt learned on a source task to initialize the prompt for a target task and then doing Prompt Tuning. ,352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"For example, if input features responsible for certain predictions are perturbed, scores provided by attribution methods should reflect the significant change or difference in the model’s predictions given the perturbations. ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"Besides, the novelty of this study is limited. ",104 105 106 107 108 109 110 111
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Recap,The dataset is composed of a subset of sentences from three different sources which were corrected by humans. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Recap,"With the proposed training schedule, author reports a significant improvement over both bilingual and pivot-based baselines. ",32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,Results show that multi-facet softmax can improve over the regular mixture of softmax. ,146 147 148 149 150 151 152 153 154 155 156 157 158
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Recap,"The method is based on the introduction of two complementary losses, a self-supervised contrastive loss that controls the distance between samples and a classification loss that aims to satisfy the constraints. ",19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Recap,"I guess this is a general problematic when one has to deal with something like culture, which is notoriously difficult to define. ",240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Recap,"To improve the correlation between the inferred label and the generated interpretation, an additional adversarial regularization is used. ",118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Recap,Here are some examples: ,105 106 107 108
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Recap,My other concern was that the job representations learned by the proposed approach were not used in downstream tasks that could illustrate the utility of the representations and how the representations fare with respect to other off-the-shelf representations (say using BERT). ,104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Recap,"The authors survey the attribution evaluation literature, and argue that such logic failures hinder the advancements of better, more reliable attribution methods. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Recap,The enhanced model shows improvement compared to the original T5 model. ,23 24 25 26 27 28 29 30 31 32 33
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap,"Based on the experimental results, they conclude that the proposed approach can leverage pre-training on multilingual knowledge bases to learn better representations for downstream knowledge base construction tasks.
",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Recap,It is based on a new training and evaluation dataset. ,83 84 85 86 87 88 89 90 91 92
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Recap,This paper introduces a suffix identification dataset ChapterBreak to evaluate the long-range understanding ability of long-range Transformer language models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
42ae5ac0b6ebf8dbeb0aacafa17347e79484894bf3755dc74179c72dc37a6c50f1ec70fcebe4c3d99626a87a96b3c794fad2694e04ff203897c71a6b4e97a96e,arr,Recap,"The early stopping method being presented is based on two considerations: the probabilities of the predicted class label, and the similarity of the output class distribution to the true class distribution.
",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Recap, (2) propose UPS to reduce candidates for labeling. ,54 55 56 57 58 59 60 61
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Recap,The mapping from speech segments to word distributions is realized by a neural network and quantization. ,65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,"
3. ",258
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Recap, ,
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Recap,"Afterwards, a reasoning chain that explains the flow from implicit to an explicitly offensive statement, is augmented. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,Their new seq-2se1 formulation allows use of pre-trained language models for controlled paraphrase generation. ,58 59 60 61 62 63 64 65 66 67 68 69 70 71
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Recap,"The two datasets are about cooking recipes and “How-To"" instructions (WikiHow) respectively. ",19 20 21 22 23 24 25 26 27 28 29 30
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,"Per sentence representations are computed by using per sentence special indicator tokens, then a similar approach to DPR is used to finetune sentence representations. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Recap,"They have conducted automatic and human evals and compared the proposed approach to existing baselines in both tasks (i.e., personalized dialogue response generation and knowledge grounded response generation). ",155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
dd056f7a2dceb082794add58f5c9ac90bf0c4b548fd748bf04ae661653318b8f6a71581632bf40b980fd52fec28ca3e3bfc5ebf480c021391a689bcce40c5f53,arr,Recap,They justify their work by performing experiments on inferring instance difficulty. ,27 28 29 30 31 32 33 34 35 36 37
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Recap, They evaluate their approach on GLUE and SuperGLUE finding a 3.3x and 2.9 speedup with almost no variation inaccuracy. ,120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Recap,"I do appreciate that these changes improve the clarity of the paper, however, the present version still lacks an in-depth comparison to other related work on parameter efficient models as criticized in my previous review. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Recap,This paper aims to train a fully unsupervised pretrained retriever for zero-shot text retrieval. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Recap,"This paper focuses on an approach of Non-Autoregressive Generation (NAR) for summarization tasks, it includes three parts. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Recap,"The problems with pseudo-labeling relate to known but important to restate problems with current abstractive summarization models in general: they generally copy from the target document, and they generally only copy the leading line of the target document. ",47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Recap,The paper also explores the speedup in overall training time and the associated cost in terms of loss in scoring the essay traits. ,169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Recap,"This make it possible to draw helpful comparative conclusions: for example, model size does not predict performance, and all models fail on some zero-shot tasks, including the ones included in oLMpics which to this human seem quite simple. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Recap,"The paper proposes a new benchmark for the task of analogical reasoning, framing it as two tasks over a new corpus. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
2fb33bc9fdbcd79cacf981e5d8f5870b249322065a211b6c886864d9ffcba2d9dff02d00c95d18272fb974869f2836bd84eebb25117b7bd525525b27049465db,arr,Recap,The authors argue that the most fundamental problem of South Asian NLP is data scatteredness instead of data scarcity. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Recap,This paper discusses methods for improving multi-domain training for dialog response generation. ,31 32 33 34 35 36 37 38 39 40 41 42
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Recap,This framework can improve the label efficiency (requires less data annotation to achieve a similar performance) by sampling samples on both uncertainty and diversity. ,57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d,arr,Recap,"It proposes a statistical definition of phonemes (through their conditional distributions over word labels) and introduces a novel neural network, information quantizer, which makes use of this statistics to create a phoneme inventory from a set of words. ",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,"Then, they analyzed the results from the following four aspects: Where is NLP research done? ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,"They find that direct re-use of a prompt projected by the `projector` learned via the _Distance Minimization_ method results in poor performance, especially within the Sentiment tasks. ",409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Recap,So it could avoid skip and search problem and reduce the computational cost of intermediate layer distillation. ,48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
dfd2ab193176f5966f14f5955687cf4e9b38cfdf5757e0cad23cca2bad60275ec30dfe3c06f55b0bf02741baed5b541ed734f52904675c5eaf7214f95f7a1ae3,arr,Recap,This work provides a broad and thorough analysis of how 8 different model families and varying model sizes for a total of 28 models perform on the oLMpics benchmark and the psycholinguistic probing datasets from Ettinger (2020). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484,arr,Recap,"
The paper proposes a strategy based on some transition rules to create the expert-guided dataset. ",40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,Efficient deployment? ,88 89
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Recap,"Particularly, they explore the training of two common operations in TE (attach and merge) together. ",9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Recap,The effectiveness of the proposed method is evaluated on a diverse set of source-target tasks under different experimental conditions that test how the approach performs under various data-scarce settings (defined w/ respect to the target task). ,58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Recap,"Specifically, the “mutual promotion” is done using stepwise integration mechanism (SIM; Section 2.2). ",28 29 30 31 32 33 34 35 36 37 38 39 40
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Recap,"If it maintains a ranking, this indicates that the model is systematic. ",102 103 104 105 106 107 108 109 110 111 112 113
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Recap,"To reduce the computational cost, this work adapts an encoder-decoder model to this task, such that the encoder only needs to be run once per document and the computational cost decreases from `num_documents * num_queries * (encoder_cost + decoder_cost)` to `num_documents * encoder_cost + num_documents * num_queries * decoder_cost`. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Recap,"The main contribution of the paper is in the Label Tuning technique, which allows to 1) re-use the architecture for multiple tasks and ii) to save computational cost at inference time. ",54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Recap,Different types of sentence classification tasks are improved by using such text smoothing method. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Recap,"Compared to the first prediction for position i-1, the second prediction adds the predicted i-1 token as extra context in the self-attention module. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Recap,"This paper presents a new dataset called FairytaleQA, which consists of 10,580 expert-annotated questions from 278 children-friendly stories. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Recap,"Specifically, the authors reuses the context vectors at previous decoding steps (i.e., c_1, c_2, ..., c_{i-2}) to calculate the refined probabilities in a similar way to the standard generation probabilities (the only difference is that using c_{0<n<i-1} instead of c_{i-1}). ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Recap,Within the context of adversarial attacks this is an interesting paper that clearly demonstrates a method for generating such attacks. ,97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Recap,"This paper proposed a new PLM-pruning method based on knowledge distillation, aiming to resolve the overfitting problem under the pretrain-and-finetune paradigm. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Recap,They also design a novel Video Dialogue Transformer Network as a strong baseline for the task. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Recap,"
The authors claim it is important to have a benchmark for this, as NLU is more and more used for applications in legal domains, but it is not so clear what works and what not. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Recap,This paper proposes a new pre-trained variational encoder-decoder dialog model which has continuous latent variables to deal with the one-to-many mapping problem in dialogue response generation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Recap,The main idea proposed in this paper is to devise event-argument templates which are language agnostic and act as a bridge across across languages. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42,arr,Recap,"This paper proposes BiTIIMT which is the Bilingual Text-infilling (BiTI) task, extending text-infilling from monolingual setting to bilingual setting and aiming to fill in missing segments in a revised translation for a given source sentence. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Recap,"Experimental results showed that the proposed method is a faithful index that correlates well with the gradient x input method (Kindermans et al., 2016). ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
fd2caf0a98ac82aa472d008400f29ba5bd74e77d5471c83cb7634bca4d59d5c302b38774e1e7775d5f8bf1110a26d537ba5427a759506b0a0807bc3e3590493c,arr,Recap,"They evaluated 5 data selection methods (data cross-entropy, predictive entropy, gradient embedding, loss embedding) on 3 tasks (POS tagging, NER, NLI) from 20 languages (categorized into 3 groups) . ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Recap,"To measure the bias of the generated summaries, the authors use lexical estimates of polarity which is shown to correlate with relative framing bias. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Recap,"Overall, I find the general framework and specific results to be valuable contributions. ",199 200 201 202 203 204 205 206 207 208 209 210 211
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Recap,"In this resubmitted paper, the authors propose a framework that generates tables of contents for long documents based on different personas. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Recap,The paper presents a novel approach to understanding math problems from their textual formulations. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
221ad7f949cb1f5c5f3bcab5e88ee960b3385360885b8ecf2525af406fd16c04dfeaf00faedde7e6343158a5115bde930a341861b9e71fd38fef836626ba122e,arr,Recap,The author proposed a novel detection approach that separates factual from non-factual hallucinations of entities. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Recap,"
The task itself is very interesting, well-motivated, and offers a new difficult challenge to the NLP community. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Recap,"
These representations are further refined via attention mechanisms over the entity-context interactions. ",26 27 28 29 30 31 32 33 34 35 36 37
33c5ba3000f2702fa82968f6a7b8aecef894796f1350dc3d2402074feef723c609ac2ce48cb38b38ce43259507c584aca21106d5e3154bd7cf4e6d91595faa46,arr,Recap,"In this paper the authors propose a pre-trained retriever that does not require any supervised date for training, called LaPraDoR. Specifically, they present 3 contributions in their paper :  1) LaPraDoR : an all-around unsupervised pretrained dense retriever, that achieves state-of-the-art performance on the BEIR benchmark. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Recap,This paper considers structural bias to be cases where the label can be predicted based on a specific feature (the authors motivate this with the example of hypothesis-only bias in NLI). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Recap,The experiments are conducted over multiple datasets for both single and multiple aspect control for text generation. ,142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,They claim that their attack method does not need to know the training dataset used by the victim models. ,124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Recap,"
They provide empirical evidence that their approach can provide improvements in perplexity in Language Models and top-k accuracy for Question Answering. ",189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,For the exemplar-based syntax control: the paper proposes a new method of creating training exemplars. ,88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Recap,The experiments show that the approach works competitively in monolingual settings and gets strong results in cross-corpus and zero shot cross-lingual settings. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Recap,This paper explores the knowledge-grounded conversation generation task. ,0 1 2 3 4 5 6 7
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Recap,"When compared to the baseline, their method outperforms on the three defined quality metrics (semantic similarity, lexical and syntactic diversity), i-BLEU score as well as the human judgements for semantic similarity. ",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
a649a9267d49174512ea282c0f21d08b743bf94b491455b77c1a5879cd1b3eb72a1afeac7861274998aafc5eb824313246019b9f6658cf01e02f377b944c7e33,arr,Recap,"Modeling a dialogue as POMDP, this paper reports an approach and a training recipe for end to end solution to generate task oriented dialogue. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Recap,"In summary, I think it is a borderline paper of ACL, or as a Findings paper. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,"To overcome this problem, special output layers or parameterization needs to be designed. ",71 72 73 74 75 76 77 78 79 80 81 82 83
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Recap,"Also, models can be further improved with the help of knowledge distillation and contrastive learning methods. ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Recap,The newly introduced model is empirically compared with several others from prior work. ,22 23 24 25 26 27 28 29 30 31 32 33 34
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Recap,The policy is trained via an actor-critic reinforcement learning algorithm to optimise the F1 measure of the classification task. ,176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Recap,The proposed methods outperform  two baselines in both monolingual and multilingual settings. ,45 46 47 48 49 50 51 52 53 54 55 56
53d0d9ae0394c4f59496513484fb9e9d625c0064283125135b8f81ec3a08afa63dc10427b9d929924d7cd1d29e9ad560df79372aa72a957bbe91a7acca6ea44c,arr,Recap,Overall the paper shows that explanations extracted from sentence-level QE models can be used to detect translation errors. ,69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Recap,"Experimental results show that visual knowledge helps tasks related to physical commonsense, especially in few-shot settings. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Recap,Overall the idea is clear and simple with strong motivations. ,39 40 41 42 43 44 45 46 47 48
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Recap,This work is a well-done paper. ,60 61 62 63 64 65
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Recap,The paper surveys the state of NLP for South Asian languages with a focus on historical linguistics. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Recap,"On two role-based dialogue summarization datasets, the authors perform automatic and human evaluation to show improvements over base architectures. ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,"This is intriguing because it shows that the attacking model has focused on some features that lead to an (sub)-optimal result, namely, ""my favorite color is blue"" persona/attribute. ",850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Recap,"The main contribution of the paper is to propose a practical core-set selection algorithm which effectively find a $\delta$-cover of the token embeddings, and thus reduces redundant tokens. ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,The data-text pairs are collected from Wikipedia dump. ,51 52 53 54 55 56 57 58
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Recap,An error analysis of the collected dataset is performed which sheds some light on the properties of the stories. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Recap,"The final model shows good performance compared to related approaches, one of which uses the full article. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,"This paper proposes a solution for ""Contrastive Conflicts"". ",0 1 2 3 4 5 6 7
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Recap,The paper argues that jointly adopting both label smoothing and vocabulary sharing techniques can be conflicting. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Recap,"Although the paper is complete and well written, the proposed method is not that exciting. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,The objective function used is similar to that of many previous studies. ,112 113 114 115 116 117 118 119 120 121 122 123
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,"
The factors are tokens, boundaries, labels and related spans. ",28 29 30 31 32 33 34 35 36
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Recap,The method aims to use curriculum learning to optimize the worst-case-aware loss rather than averaged loss in common multi-task learning settings. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"
Using this approach helps deal with both issues at once. ",102 103 104 105 106 107 108 109 110 111
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Recap,"Overall, the proposed approach makes substantial improvements over prior state-of-the-art methods. ",24 25 26 27 28 29 30 31 32 33 34
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Recap,"This paper study the learned embeddings' distribution from the CharacterBERT model using a new analysis tool (i.e., information axis). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Recap,The paper then proposes a remedy to said issue by mapping the representations of both positive and negative examples to a pseudo sentence with the same length and structure. ,124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,"can improve the model's robustness on both artificially and naturally noisy test sets compared to several other existing adversarial example generation methods.
",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Recap,"Comprehensive error analysis is performed, with a particular eye for where model performance and human performance differ, offering some interesting insights into the difficulty of processing metaphoric language. ",114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"In the introduction, the authors claimed that structured prediction models are more vulnerable to adversarial examples than text classifiers. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,The second experiment is based on that of Johnson and Goldberg (2013). ,262 263 264 265 266 267 268 269 270 271 272 273
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"In my opinion, this is a solid work.
",133 134 135 136 137 138 139 140
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Recap,"The paper shows two SOTA parsers SEQ2SEQ (Shi et al. 2020) and SMBOP (Rubin and Berant2021), struggle on the proposed benchmarks. ",60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Recap,"These images are quite similar (either frames from the same video, or static images selected to be similar). ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap," Evaluation is mainly by BLEU score on a variety of data sets (IWSLT, WMT, CASIA) and language pairs. ",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Recap,The perspective is interesting. ,13 14 15 16
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Recap,2. ,116
ca04bf1a0e948cf1faf52156c5feb14c0357c5fe6aec36b0e063b7c89dfd398d9f8b839b5c4db8129f8a31606587c4d4ec8988a1ac835c46a99e80c43e992443,arr,Recap,"When the authors applied several conventional proving methods with existing pre-trained language models (PLMs) to MedLAMA, other methods showed poor performances, because they have weaknesses in handling multi-token answers. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Recap,"After discovering that these probing techniques lead to very low accuracy values, the authors design a novel 'rewiring' pretraining objective that boosts accuracy scores for retrieval-based probing. ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Recap,"This paper introduces LexGLUE, a new benchmark for language understanding for English legal texts. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13
9be4cd67158be4faa4c59473d6690b7fe2fb8afd8f5050ce37657133f74993022dfa997fe2b2d4767e4578282b15b8e691051cd0e661c7e13103474137eef1ef,arr,Recap,They also show that English is not necessarily the optimal source language as usually perceived by the community. ,114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap,"This framework consists of two teacher training models as two tasks, i.e., Entity recognizer teacher and similarity evaluator teacher for entity recognition and token type identification, respectively in the source language. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,They advocate preserving the meaning and fluency of the original text when generating adversarial examples. ,50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,Human evaluation metrics are reported on three evaluation questions for 70QA pairs. ,141 142 143 144 145 146 147 148 149 150 151 152
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap,"Furthermore, this paper also explores perturbing the representations with 0.1 dropout rate, and this technique can be combined with the MixUp strategy.
",60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,"The dataset annotated 4 types of punctuations, i.e. comma, period, question, and exclamation for live streaming video transcripts. ",12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Recap,This paper focus on table pretraining via spreadsheet formula to realize numerical reasoning. ,0 1 2 3 4 5 6 7 8 9 10 11 12
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Recap,"The analysis of these results is rather succinct, but proposes nonetheless a few interesting observation nuggets. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Recap,"Two latent variables are employed for the controlling of types and boundaries for segments during generation, after an auxiliary task to classify segments into knowledge-relevant or knowledge-irrelevant. ",8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,What are the diversity benefits? ,74 75 76 77 78
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"Additionally, they define a patience counter which counts how many consecutive classification layers have been confident in their prediction (based on the previous definition). ",275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Recap,"The findings demonstrate that sense embeddings do not conform to the behavior of word embeddings with respect to social biases, and that sense embeddings often show higher degrees of bias under the presented evaluations. ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Recap,This paper studies the discourse structure of long-form answers by analyzing two datasets: ELI5 and Natural Questions (NQ). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Recap,"Authors present  a novel finetuning method, BitFit, where instead of finetuning the entire model the authors finetune only the `bias’ terms and the final task-specific classification layer. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Recap,"The authors examine the task of predicting the verdict of bail applications (a binary task, which is to predict whether or not the application was denied or granted). ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Recap,The core design decisions of the method were difficult to find the motivation of. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Recap,"In particular, the authors introduce cooperative losses to better model the constraints. ",26 27 28 29 30 31 32 33 34 35 36 37
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,"A lot of detailed model descriptions are described in experiments, which is quite confusing. ",186 187 188 189 190 191 192 193 194 195 196 197 198 199
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Recap,"Different from previous datasets that focus more on the explicit stereotype, the constructed dataset considers explicit, implicit and non-stereotypes. ",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Recap,This paper introduces an approach to produce privacy-preserving document embeddings with the property that every single sentence of the document could be replaced by some other random one while obtaining a similar embedding for the document. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Recap,The paper proposes a minor improvement to the existing word sense disambiguation approaches. ,0 1 2 3 4 5 6 7 8 9 10 11 12
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Recap,This paper conducts an extensive empirical study to assess the faithfulness of post-hoc explanations and the performance of select-then-predict models in out-of-domain settings. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
dd23042b3a19ead6484687423764d8156f6ea40cec4ccceb6d27ccc6305223ed76957ad46eae750d95766cc378fb0b332d4fcd737dc810c4bee6e8823ca79884,arr,Recap,"The authors propose Prix-LM, a unified multilingual representation model that can capture, propagate and enrich knowledge in and from multilingual KBs. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,They find that all methods are able to distinguish between multiple prompts (created by training with different random seeds) trained for the same task from prompts trained for other tasks. ,522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Recap,This paper proposes to incorporate the hierarchical structure of source sentences into the extractive summarization system models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Recap,The paper works on creating sentence embeddings targeting the semantic similarity (STS) task. ,0 1 2 3 4 5 6 7 8 9 10 11 12
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Recap,This paper is well organized and well written. ,58 59 60 61 62 63 64 65
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Recap,"This paper takes advantage of data (utterances, annotations) that is produced as part of language documentation to use for automatic linguistic segmentation, mainly at the word level. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Recap, ,
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Recap,"This paper tackles question answering under a new setting, where models should extract multiple spans from textual context as an answer set. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Recap,The effectiveness of this approach is demonstrated on (a) a simulated dataset mismatched image captions and (b) real-world data of misinformation. ,47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Recap,"The idea is interesting, especially the *Attention Divergence Loss*, which guides the inter-attention by means of intra-attention. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Recap,One receives all pinyin representations (perfect pinyin) and the other receives the initial characters of pinyin (abbreviated pinyin). ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Recap,"The authors experiment with different methods for constraint generation, following previous work. ",90 91 92 93 94 95 96 97 98 99 100 101
74619dd7e1e302942143426ecf3f670db7807713703baf890d1222b3f73ade64d6afbad41f6020c16c572ff97aacdb5818af1b38af645648830b40b3fbab9b8d,arr,Recap,"However, it seems that they train the reference models on the same dataset used by the victim model (at least for the dependency parsing task). ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,They also propose a new WD dataset that contains 15 domains. ,149 150 151 152 153 154 155 156 157 158 159
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Recap,"First, the term representations are auto-encoded using ""side information"" (representing the static embedding for the term). ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Recap,CONTRIBUTIONS: (1) The authors propose a pipeline that collects domain knowledge (medical) through web mining and apply it to build up a counseling knowledge base. ,55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Recap,This paper alleviates the generic response issue in generative dialogue models by proposing a novel negative training paradigm called negative distillation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Recap,This is the task of taking an offensive sentence and paraphrasing it into a so-called “neutral sentence”. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Recap,An additional attention regularization term is added to the cross entropy loss to explicitly align the decoder-syntax encoder cross-attention map to the paraphrase-template alignment known at training time. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Recap,"Explore the SSAL approaches for NLP, which have not been well-studied. ",82 83 84 85 86 87 88 89 90 91 92
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Recap,The paper conducts many experiments in some state-of-the-art VQA systems in the proposed dataset to reveal existing major issues. ,49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e,arr,Recap, ,
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Recap,"Experiments over multiple downstream tasks, mostly over semantic similarity benchmarks, demonstrate the effectiveness of the method, mostly compared to the recent SimCSE method. ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Recap,"The authors perform some analyses of their dataset and ablations, including the distribution of types of chapter transitions and other types of discourse boundaries. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Recap,"Overall, I liked reading the paper because everything was stitched and motivated well throughout the paper. ",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Recap,The paper aims to investigate the robustness of pre-trained language models from a geometry-aware perspective. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Recap,Design a framework that: (1) explore the high-certainty samples for data annotation; (2) generate pseudo-labels for certain samples. ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,"If the sorting is done based on the construction type, and not on verb form, this is taken as evidence as abstract argument structure playing a more central role for sentence meaning than verb lexicality does. ",169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Recap,The paper also conducts multiple probing experiments to explore the effectiveness of stronger visual features and different learning objectives. ,42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,"- A noise-based negatives generation strategy to reduce the bias caused by the anisotropy PLM-derived representations - initialize new negatives based on a Gaussian distribution and iteratively update these negatives by non-uniformity maximization.
",203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Recap,"Most behavioral LM analysis work focuses on introducing a particular challenge dataset, and only evaluates a handful of LMs on that dataset. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Recap,"Along with the description of the methodology is a breakdown of the monetary costs of conducting such a resource project, which sums to a cost of 811.55$ for ~20.000 toxic → neural paraphrase samples - of these, 12.000 are unique toxic sentences. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,=== UPDATE === ,203 204 205
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Recap,"This paper proposes NoisyTune, which is a method to add noise using the standard deviation of matrix-wise parameters during fine-tuning pretrained language models. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,"The experiment results show that by fixing the speedup ratio at 3x, the proposed core-set selection algorithm shows advantage over other competitors.
",112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
6c26dceacb73b871ce03b6529120a74be5f83263bb5f69e1e3c8dfe655d56fc9d9e11dfaf7fecaeb8befdd8cae54cf7a940ca1a2241cc6f2570d7cadc0986bcb,arr,Recap,"
This work ensembles SOTA Seq2Edit and Seq2Seq models with Structured BERT and beats previous SOTAs on an earlier benchmark dataset NLPCC18. ",40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Recap,The models utilized in this paper are based on the well known GECToR system. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Recap,"Besides, authors attempt to evaluate the correlation between the commonsense in language models and pre-training data such as Wikipedia and VG. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
0909e18d6543fb938fbbc76b929ee91db3362584afe0043413fa43730372504bb836138dc424c5a3f4b33b5ffd8bd9a0131df90ee7c7041ad242384ddcce3441,arr,Recap,"Then, three kinds of statements, namely implicitly offensive, explicitly offensive, and non-offensive ones are created concerning the attribute. ",62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Recap," The paper describes the construction of the data set, including agreement and encountered challenges, as well as experimental results that can serve as a baseline for future work. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
4aecdba508d4b3430d7e9fb9b1991de8e04e8fcff4fb43ad45484536a4f0a586e7a1e58298ed4357571dc05915e0825af63939334a5d7c1ce0cbf71c9b72c962,arr,Recap, ,
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,"
2. ",87
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Recap,The dataset was evaluated using SOTA models. ,59 60 61 62 63 64 65
0717df21c948fc36edf5f14e8f8c15c7640e5a653f4dcc12c1c89a96aaa861c6aabcd3ec512d9dba6e71a5031f90b6cbf3411e7d555480e0e93fd160fbe0df95,arr,Recap,"The data is thoroughly described and analysed, and a series of experiments are carried out comparing a range of baselines to a system based on Transformers. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Recap,"This issue is also known as ""the softmax bottleneck"" The limitation is that not all rankings of vocabulary items by probability can be represented and the authors highlight a consequence of this limitation with the following example. ",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Recap, ,
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,To solve these problems the authors propose a new metric called Relative Slot Accuracy that does not depend on the predefined number of unique slots and also scores the models in a way that matches human intuition. ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Recap,"The authors proposed an LSTM based model and compared single task and multi task settings to show that Multi-task learning based system gives better performance, and is also much faster than the single task setup. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
0805cef3514c6a8a408cb365fd19199aaee44bbc746bb7bc13c51afa2bd0cfdd0e9165c5a40142bf664015f97a59341d81ff0ce405993bbbbaeb8110390c3739,arr,Recap,The paper explored the approaches to use external data to improve the spoken NER performance of both pipeline and E2E-based systems. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Recap,This paper introduces a new corpus of error-annotated sentences for grammatical error correction for Chinese. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Recap,"The authors collect the meta reviews of ICLR and label the sentences with 9 categories of sentence types: abstract, strength, weakness, rating summary, AC disagreement, rebuttal process, suggestion, decision, and misc.. With these sentence labels, the authors introduce a task of controlled generation focused on the macro structure of the review. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,Experiments The authors gather a persona aligned utterance dataset from Dialogue NLI and PersonaChat. ,365 366 367 368 369 370 371 372 373 374 375 376 377 378
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Recap, Experiments and ablation studies confirm the effectiveness. ,35 36 37 38 39 40 41
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Recap,Then it introduces the Information Contrast Model (ICM) and compares it with other metrics which are commonly used in the literature to evaluate multi-label classification. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
0c2af0134351deb5469149f07a357dea647d9a30080556b9e68e7ba35723f4e87d93b02fa5dc5a84319df47c26a135e7986fe0613416bbea0b49a34a6b5d68f2,arr,Recap,"The effectiveness of the proposed approach is validated in different data conditions, comparing it with several previous works and with a thorough analysis targeted to validate the claim that similarity of the representations of the same sentences with different modalities is actually increased. ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Recap,"In the experimental part, the benchmark is used to test a set of neural language models, whose performances are not satisfactory and highlight the difficulty of this benchmark.
",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Recap,"However, existing works only focus on lexically or syntactically CPG, lacking a unified control framework. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Recap,This paper describes the development of a data set that can be used to develop a system that can generate automated feedback to learners' responses to short-answer questions. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Recap,Preliminary results show that neural networks present various performances towards different properties. ,53 54 55 56 57 58 59 60 61 62 63 64
03cb8483ba66064a3c9b4a132af185e861b3dd292bf0b90105956dfbf7cc7e88e5bff423e0904e34b16baa401f61c0938331c4795c5fcfa86fdf99d4eb48c7af,arr,Recap,"
The problem is addressed by reformulating the NLI task as a generative task where a model is conditioned on the biased subset of the input and the label and generates the remaining subset of the input.
",18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Recap,The authors start with dataset introduction. ,21 22 23 24 25 26
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Recap,"
  To answer this question, an empirical work is conducted by comparing several interpretability related approaches, so-called feature attribution methods, as well as a supervised and an unsupervised approach, along with a random classification baseline. ",77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Recap,The premise is that the extractor should pass on important information from the source to the generator for producing abstractive summaries. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Recap,"They rely on three datasets to test the effectiveness of their methods: a synthetic one in a language having a simplified phonotactic system, one in Danish with synthetically generated sound change, and a real one in Danish, with known sound change. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,The idea of using synonyms of the ICD codes is simple and effective. ,55 56 57 58 59 60 61 62 63 64 65 66 67
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Recap,They have two methods for learning this `projector`. ,144 145 146 147 148 149 150 151
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Recap,"The authors also tested two machine learning tasks: (1) sentence classification for the proposed schema, and (2) sentence ranking to determine the context mapping from rebuttal to review. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Recap,"They propose to render the RDF triples into natural language, aka facts, using domain-specific templates, and then develop general modules which perform the text rewriting operations (ordering, aggregation) required to render the clunky fact-based sentences into fluent text. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Recap,"
At the end of my reading, I still feel that I did not get what are, specifically, the directions indicated by the authors (this might well be a limitation of mine) ... ",262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293
2e201a8e027839a0a11cf2338bcd103dba544ad4421e97e62a9580843bb66aa6270b7c940568df3085e283317f5255589a7e1c410a5e1aad3a2205f640730cef,arr,Recap, ,
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Recap,"
The methods differ in  (i) the domain of the data for pre-training (e.g., pre-training LMs on text of the visual domain (MSCOCO captions), and training visual-linguistic models using MSCOCO's images-caption pairs), as well as in  (ii) the pre-training objectives (voken classification, MLM, cross-modal contrastive learning (CMCL), cross-modal knowledge distillation). ",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,"The subjective evaluations include human perceptions of naturalness, and AB testing for preference of systems with/out the cross-utterance context. ",151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Recap,"The paper explores three unexplored usecases on multilingual task-oriented dialogue (ToD) systems where the speaker where a foreign language speaker uses ToD in the foreign-language country (F&F) or an English country (F&E), and an English speaker uses ToD in a foreign-language country (E&F). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
d0adbc683b1920556f2f658448daf2792434b209a9960622144d3cf741857c04c0854fce75bf2591fe5e861afaa3a58b2593abb0ea1927e3b4e1168cb2175c86,arr,Recap,"The framework involves a time-sensitive approach to learn temporal KG embeddings, and contrastive losses to improve answer retrieval, and enhance the model's ability in capturing temporal signals. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Recap,"The authors use a multi-task learning (MLT) approach, adding an auxiliary task of parsing a previous dataset with a different scheme but sharing the embeddings and some model parameters. ",108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
6b2ca8bb05bc0d53aec7d4cf25940f4cd603d3cd4189c894565711b7a703237bff6efeb3c26e742a3f16ab5e9080a7ae8c948f3c5565c55e74d1c0145696f35b,arr,Recap,"Finally, the paper shows how how entailment models can be exploited to determine which reasoning step is most likely at each stage. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Recap, ,
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Recap,"In this way, column operations can be reduced to regular column matching. ",87 88 89 90 91 92 93 94 95 96 97 98
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Recap,"The method encodes hierarchical structure information, such as section titles, sentence positions, and section positions. ",14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Recap,"This paper proposes HASHEE, a very simple Hash-based Early Exiting approach. ",0 1 2 3 4 5 6 7 8 9 10
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Recap,The experimental results show its superiority over traditional classification models. ,29 30 31 32 33 34 35 36 37 38
0a002bffe97e066700662691d4501cc2891b11564c66fd6ad3579891499dd7f10958eabf422336201db439e4d9f952535019dbeba172ed0258ec1cb3eed73f25,arr,Recap,	More detailed analysis of the cascading errors is necessary. ,220 221 222 223 224 225 226 227 228
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap,This short paper presents an alternative to label smoothing for neural MT. ,0 1 2 3 4 5 6 7 8 9 10 11
840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0,arr,Recap,The results show that the performance of TM models on such test sets is worse. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Recap,This paper offers an argument generation system designed to highlight the particular moral status of considerations adduced in favor or against controversial proposals in summarizing query searches. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Recap,"(This is a v2 submission and since the paper hasn't substantially changed, I've left the summary the same as in v1) ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"This paper proposes a novel task called singing voice beautifying, the task of improving of quality of amuteur singing performance. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Recap,This paper investigates the causes of an Event Detection model’s skewed performance and presents trigger saliency attribution to explicitly assess the underlying pattern of events. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,"Campos, Jon Ander, et al. ""Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning."" ",233 234 235 236 237 238 239 240 241 242 243 244 245 246 247
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap, ,
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Recap,"A novel OpenIE algorithm is employed: it is based on a slot filling architecture recently suggested for relation extraction, but in this work it’s employed as part of a pipeline system which the authors show further increases performance. ",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Recap,The authors then analyze their method is both efficient and interpretable for STS. ,62 63 64 65 66 67 68 69 70 71 72 73 74
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Recap,This paper introduces a novel model based on pre-trained Los (BERT family) for the task of Automated Essay Scoring (AES). ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Recap,2.) ,98
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Recap,"Overall, I think this paper is not ready for ACL* venue yet and might still be a good pick for workshops. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Recap,"FORTAP, a FORmula-driven TAble pre-training model, is proposed in this paper, which incorporates numerical reasoning capabilities based on large-scale spreadsheet formulas.
",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Recap,Two methods for knowledge integration are proposed: a retrieval-based method and a generative method. ,28 29 30 31 32 33 34 35 36 37 38 39 40 41
1f3ed846cf117ae2eecd5e3d9d19a85c37510c11c3463afa9ded734ea9f7dc0569a0ad64808fed511202bc3a62103801e85b7e7d14a8617220cf2ec989190cb1,arr,Recap,The paper is overall a solid contribution for combining active learning and self-training in NLP and I recommend acceptance. ,80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Recap,"
They use a SVM baseline and different pretrained transformers on this task to get an initial performance picture ",100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
f4d5395d46a0f2f0866fa4410edd21d000d1791f07ef488bea12fe58ae905b9bb44fd8d0b92f1da10bb6456a4dca4cf8ca35d0350654cb42b3a947b8edb49b7f,arr,Recap,The proposed method includes two key components of a modified best-first search and a path recombination mechanism. ,16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Recap,"In this work, the authors design a self-explaining model, LIMITEDINK, that can take controls on rationale length by incorporating contextual information and supporting flexibly extracting rationales at any target length. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
c9e07574b08c7c4d0effb33c800855f358653db7167f6d3547696c380a8353c7f13d8253927da31d2f985df3709a41e9973e5e76c92a4f5f16752f40f1ceaecc,arr,Recap,"See my previous summary.
",0 1 2 3
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Recap,The authors of this paper propose a new method that assesses dialogue models through the live evaluation process and overcomes the drawback of requiring pre-created reference dialogues. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
ebfe58b10dee02a1cb830e85ec7993f381fa88e9d1e70ec9eba24417b92fdbe8d20ae561d42fbcbdb17d4380fde7845f5850c3fd769aa20c15003fe18fcdfbf0,arr,Recap,The strength of submitted metrics is analyzed by their complementarity to human-based metrics. ,46 47 48 49 50 51 52 53 54 55 56 57 58
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Recap,This paper studies whether and how contextual modeling in DocNMT is transferable via multilingual modeling. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Recap,An entity similarity evaluator is proposed to help NER as an auxiliary task. ,18 19 20 21 22 23 24 25 26 27 28 29 30
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Recap,"The proposed approach consists of two stages: 1) Pretrain an NMT model on all available parallel data between any languages; 2) Finetune the model on ""many-to-one"" data for all target languages (multilingual many-to-one finetuning). ",20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Recap,"Under CGPG, constraints are represented as text sequences that are concatenated to the source sentence. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,Analysis shows that the contrastive learning objective results in well defined clusters. ,255 256 257 258 259 260 261 262 263 264 265 266
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Recap,"The representations of the label and the explanation tokens are combined through gating mechanisms and used as input for the next timestep, enabling the model to use the explanation generated thus far to predict the label and the predicted label to guide the generation of the next explanation token. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Recap,The main contribution of this paper is to analyze the partial input bias problem and explore different approaches using auxiliary tasks for mitigating this bias. ,73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
25d81c5100d51b1e76e62a58136ddf202f0cd593dce3022314fa2faf872ce35425d15424a77e74592c2b856df0c9814c93b25c8d33ed6e03a9808afb71c740b5,arr,Recap,"Since the authors did not update their paper, my comments and scores for this paper stay unchanged. ",6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Recap,"CrowS-pairs consists of about ~1500 English sentence pairs, where one sentence of each pair shows a certain type of social bias, and the other is an unbiased version of it. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Recap,The paper tackles a fundamental problem of linear layer followed by a softmax. ,0 1 2 3 4 5 6 7 8 9 10 11 12
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Recap,They test multiple BERT variants on the new corpora and show that multilingual BERT exhibits the lowest bias. ,69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Recap,"First, the author introduces the current practical homomorphic encryptions and transformer-based model. ",18 19 20 21 22 23 24 25 26 27 28 29
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"The method is evaluated using the GLUE and LRA benchmarks.
",229 230 231 232 233 234 235 236 237 238
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Recap,The paper is easy to read. ,97 98 99 100 101 102
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,"In experiments, the authors compare with the attention based method and first K selection method. ",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap,"While some sections are technical and dense, they are accessible to researchers in speech processing in general. ",148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Recap,"Authors find the classifier is effective and correlates well with humans, and the RL summarizer achieves better faithfulness/factuality than baselines while not significantly sacrificing ROUGE. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Recap,"The second is dependency structure, for which a head-to-tail token grouping method is used. ",76 77 78 79 80 81 82 83 84 85 86 87 88 89
5055d6e9bee3c38f171f9a51c2cc9db4023bba622f8b471a60e20864e21b6e012403a4b741ecaf347e239448fde93bfbf299ec9f5ee6bf0091d4c33ee9b19ba0,arr,Recap,"The paper presents the first results on time expression grounding, which aims at define a specific period of the day for each time expression like ""morning"", ""night"" etc. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Recap,"In light of these findings, the authors of this paper isolate and attribute the knowledge-recalling tendencies of such models to a few neurons in the feed-forward networks (FFN) of the BERT architecture. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,The results show that using cross-utterance context leads to greater expression of appropriate prosodic variation. ,196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Recap,The authors present a strong method for unsupervised constituency parsing that relies on RoBERTa and constituent classification based on an initial set of constituents / distuents. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
68c709e853fc85c4a51a2bf31e9323929a8768c91c3f21e30970ee38b5a6ecfa7ccb0abbc60c80205f631bbbaa1a83fdcb50ce32cdd591a45dfbf3dbe31d5180,arr,Recap,They employ probes (linear and non-linear classifiers) to quantify the strength of the learned representation with respect to a linguistic property. ,31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Recap,"The authors argue that, over the recent years, research in SRL has predominantly focused on in-domain settings where a model is trained and evaluated on data coming from the same distribution/domain (CoNLL-2005 and CoNLL-2009 are two exceptions as they provide an out-of-domain test set, but it is extremely small only 400 sentences).
",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,"The intuition of of the algorithm is similar to DBSCAN with iterations, it starts with a core set containing only CLS embedding. ",48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,When these models were tested for domain adaptation i.e. training on existing datasets and testing on proposed dataset it was found that performance of all the models degrade significantly. ,145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Recap,"Masked label smoothing (with vocab sharing) is tested against Transformer-base, vocab sharing alone, label smoothing alone, and vocab sharing + label smoothing together. ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Recap,"This paper is about the task of vision-and-language navigation (VLN), with the aim of solving two challenges: 1. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Recap,"-To mitigate this issue, the authors propose a new relation contrastive learning framework (RCL). ",67 68 69 70 71 72 73 74 75 76 77 78 79 80
e0111eb824f3bc8901645731c84d882dd0ac2f5052557e28e1b41ef6c2ace7e360932539c4132c61dd5efaaa60eec8d20a141bed6fed819083cfd74de2ebcdc9,arr,Recap,They also provide baselines for the dataset. ,18 19 20 21 22 23 24
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Recap, ,
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Recap,The idea is to take the text input and replace words which is connected to person entities and verbs and make changes so the text doesn't describe the video anymore. ,23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,The original experiment utilized a priming-based task to probe for the reality of ASCs. ,274 275 276 277 278 279 280 281 282 283 284 285 286 287
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Recap,"The author(s) thus provide a  dataset comprising three corpora of records written in Hanja during the Joseon dynasty; four models for four tasks (King prediction, topic classification, named entity recognition, summary retrieval); as well as a language model pretrained on the Hanja documents.
",50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"In the first sentence sorting experment, inspired by the experiment by Bencini and Goldberg (2000), the authors generate sentences by using verbs that are compatible with 4 different constructions and create sentence embeddings by averaging the token vectors. ",63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Recap,The first one is concatenating pinyin input to the context of  Chinese characters. ,85 86 87 88 89 90 91 92 93 94 95 96 97
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Recap,"The authors aggregate a corpus of 6,846 text pairs containing — (a) the context referred as “parent” and the comment to be classified referred to as “target”, and (b) annotations indicating whether each target is hate/counter-hate/neutral. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Recap,The paper presents a transformer based model for generating paraphrases for an input sentence with an added constraint of following a specific syntactic template. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Recap,Automated evaluation metrics include calculating a ROUGE-L score. ,133 134 135 136 137 138 139 140
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Recap," The key technical ingredient is a moral-argument filter, learned in a creative way from remote supervision and fine-tuning of a transformer language model, that can assist in content selection in IBM's Project Debater API. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"In general, I find the theorem hard to follow for an average reader of an ACL-like conference. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
73837843c65a425ff419296a34871a445f1e2fee4cb8940431054c5ec0c1beb405f43cdd40fd27e52cf27aab7574eb4f160655995346c0889edc41328e588bdb,arr,Recap,The authors study human performance and the performances of several CLIP-based models and show that there is a large gap between machine performance and human performance. ,54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Recap,"This architecture can reduce decoding lattency by 50% over a ""balanced"" architecture.
",106 107 108 109 110 111 112 113 114 115 116 117
395f3cafa74691254b06a12d8efd53c79d240eea7e7aa486f8121a919a2552b8e5021b038ab05ca134f071fbbea89874ff0e84c846ea62952509fd12a704c6a2,arr,Recap,Results show that the method gains very incremental improvement in translation accuracy and some improvement in model calibration. ,57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
cf042f2488f47016af123f2a468a503b92a3114fade995fd8d6fa7eaed3e87d5d765d404aabc84169ca045b9cd294a29f97a75bf77527356b42170694f5ceaf7,arr,Recap,"Interestingly, the authors measure the correlation of the proposed metric with a human judgment of fairness. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap," Oblation study shows that perturbation is only marginally helpful by itself, but a lot more helpful when combined with MuxUp. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Recap,The authors of this paper propose an empirical study for the zero-shot capabilities of CLIP models and demonstrate that CLIP models have strong few-shot capabilities. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Recap,"The main takeaway is that LMs benefit the most from a nested structure from the synthesized language, with an especially strong downstream performance. ",150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Recap,"They report good BLEU improvement on the WMT21 multilingual translation task.
",68 69 70 71 72 73 74 75 76 77 78
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Recap,"The paper proposes a novel model called R^2G which combines neural initial retrieval and reranking into a BART-based sequence- to-sequence generation model.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
3157d8a8980d26bab69c208803b2e28cfb897da55fe2f26c7bc2b13323adf33ac953adff54c60aa83ba1dc97c6fb586ddc58637cbcaedbd7899bfdc4c3c35021,arr,Recap,"In this paper, the authors challenge the basis of the seq2seq-based ABSA framework and propose the simple yet effective Seq2Path framework. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Recap,Then it expands the core set by selecting m closest vectors to the core set. ,70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Recap,"
This is a second revised version. ",124 125 126 127 128 129
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Recap,"In experiment GPT2-based DialoGPT pretrained upon Reddit comment chains, PersonaChat is used in fine-tuning, about 10K dialogs and 98K personas. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,Masked language models suffer from 2 big problems:  Overthinking - too much processing may hinder results for some instances. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Recap,The experimental results demonstrate that the approach can improve the performance of entity liking and the learned representations can be used for better entity coreference discovery. ,25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Recap,The key idea of the proposed method is to combine neural token representations and inductive logic programming (ILP) so that the reasoning chains are more interpretable to humans. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Recap,This paper tries to answer the question: `what kinds of synthetic data contributes to BT performance? ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Recap,"
Their method tries to output Chinese characters given perfect pinyin, which consists of both initials and finals, or abbreviated pinyin, which only uses characters' initials. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Recap,This submission proposed a model for offensive span detection (OSD). ,0 1 2 3 4 5 6 7 8 9
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Recap,"Moreover, the authors also show that their pipeline could be used to retrieve toxic and non-toxic sentence pairs from existing paraphrasing parallel datasets (e.g., ParaNMT). ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,This paper treats MWP solving as a text-to-equation-tree translation problem using an encoder-decoder architecture. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54
94148813f03ca637725d569e550ee1ff920852551bc2ea49a0d585745454f65089350482ba0bd13d36a4aee4c0353195b83aa6612cd02b7e43cdda03e0717cae,arr,Recap,The paper presents experiments where mBERT models along with appropriate task-specific layers on top are fine-tuned on multiple languages simultaneously. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
db14eda600a57c45529a8ae7db67ef709b17efd9bc501459d16886267bb64db205b07db81311c17bd4e2bec40a9d83d6cff10898a7f5016d5b2799e8ccb4c73b,arr,Recap,The paper also presents 4 novel metrics for the task. ,39 40 41 42 43 44 45 46 47 48
a29a1dc746271e6018ad4ecf7a57733b728a0d9eb96d7e2774901756bc16e064b02755cc9b84a287975faea3603a14669d67a6cb6492d6ab13b584229d419504,arr,Recap,"Understanding the problem from a geometrically motivated perspective, the authors propose ""multi-facet softmax (MFS)"". ",47 48 49 50 51 52 53 54 55 56 57 58 59 60
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Recap,The proposed framework can alleviate the sampling bias in the random negative example sampling in contrastive learning. ,12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Recap, ,
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Recap,"The problems resulting from the Square One Bias, the recommendations to overcome this, the examples   (one-dimensional research) and counter-examples (multi-dimensional research) are also discussed in the paper. ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap, ,
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Recap,The authors propose to use static semi-factual generation + dynamic human-intervened correction to get better performance on OOD and few-shot performance. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Recap,The coarse stage performs multiple times to gradually reduce the input length specific to the input length limitation of the backbone model. ,56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
44e7ab41a54cab53f17e79871feb2713cc16df873abd22f680ff5a4c0366953bb1c6c359fd3fd84fa68c262345dae767a3250a4249f7a0583a6569f44fdaa4d1,arr,Recap,"This paper presents an interesting finding, i.e., fine-tuning only the bias terms of pre-trained language models is competitive with fine-tuning the entire model. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Recap,"They first introduce three methods to calculate the similarity between a target user and the selected anchor users, and then either leverage the data of similar anchor users to fine-tune the language model or interpolate the anchor user models based on the similarity. ",46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Recap,"The proposed method is evaluated on four nested NER datasets: ACE2004, ACE2005, GENIA, and KBP2017. ",62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Recap,"The authors run the MC dropout method on two pre-trained summarization models, sampling different summarization texts according to specific dropout filters. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap,It also misses the inference speedup results. ,175 176 177 178 179 180 181
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Recap,"
4. ",102
0a077695fd70410b318e1d7ed88a4865517d24a132f37ee5b037d792bc0ebcb6e94154eeb46a0f5a7fef898511f2447105d6d2228cf51d037bb1f25829eb3f19,arr,Recap,The result shows that the proposed method outperforms baselines on all the evaluations. ,55 56 57 58 59 60 61 62 63 64 65 66 67
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Recap,The authors propose a simple yet effective method to generate synthetic data for better translation performance. ,29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,Choosing the right prompt? ,43 44 45 46
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Recap,"A thoughtful ablation study follows to analyze the impact of some related factors (e.g., search steps, step size, training epochs). ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Recap,## Paper Summary ,0 1 2
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Recap,"Given the specificity of the moral values  This involves experiments that evaluate a multi-label moral value classifier conducted under different cross-domain training settings that analyze the following scenarios — (a) ideal all-data training scenario, (b) generalizability, (c) transferability, and (d) catastrophic forgetting. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
c6c39076e1b552f939302745dd1ace9caa51cacb6976befea16f746f11b816dd40444402cb05c9ceb4f42386f7928d59262274c3fd8a0d5d9f3b539809d1171c,arr,Recap,The paper applies the worst-case aware curriculum learning algorithm to zero-shot cross-lingual transfer for dependency parsing. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Recap,The human evaluation shows that the automatically generated dialogues have a reasonable quality with natural conversation ﬂows from a business point of view. ,40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"The results of vector clustering show that in all the tested languages sentences that share the same constructions are more similar than sentences sharing the same main verb, with the only exception of the LM model trained with the  smallest amount of data. ",101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,"
4. ",127
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Recap,"
2. ",241
d2f89b026470a56fb3b20d882764ded6aaae66e094719dabee68a6f04faf7c111ff5c0f79d1bf1eb93be90b82a8c144f862783328987628be410f73426803ccc,arr,Recap,This article reports on a much more extensive experiment: the authors evalute a relatively large number of models (all transformer-based). ,22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Recap,Empirical evaluations show the the proposed method outperforms competitive baselines on 7 semantic textual similarity tasks. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Recap,"Motivated by the assumption that all the components in the encoder block, in general, are meaningful for token attribution analysis, this work proposes a GlobEnc, which incorporates all the components in the encoder block in the model. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Recap,The extension is a phoneme level conditional VAE. ,34 35 36 37 38 39 40 41
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Recap,This paper proposes a dynamic inference approach to speedup inference with large language models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,L1 norm between vectors of 2 matrices needs a high memory cost than the matrix multiplication. ,128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Recap,"In addition to annotation procedure and quality control, the paper provides analysis on the annotations, including consistency on predicates/arguments, accuracy of annotators, and distribution of labels. ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Recap,The student model is trained with two objectives. ,40 41 42 43 44 45 46 47
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Recap,  ,
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Recap,"
2) It evaluates contextualized word and sentence embeddings obtained from the CLIP language encoder to those obtained from GPT-2 and finds:      - CLIP contextualized word embeddings (CWEs) outperform GPT-2 CEWs on 6 world-level evaluation tasks. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Recap,"For each competency, examples are generated semi-automatically from existing language + vision tasks, such QA in V7W, and are created in a FOIL style, where one example correctly describes the image, while another example makes a minimal change to caption and does not describe the image. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Recap,This paper introduces an auto-regressive blank infilling model based upon an encoder-decoder architecture. ,0 1 2 3 4 5 6 7 8 9 10 11 12
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Recap,Adding data augmentation brought slight changes in the performance. ,136 137 138 139 140 141 142 143 144
747249d6df576d913b4dd001992510d9682657fee6f4ea775a23731979bf7af0362f975f45b8c27ae3b04e093fa81069cf32428adf42b4026a447055a6907e27,arr,Recap,My concern is mainly on the model and task scales and the  comparison of the baseline model. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
a4d17e177b9cc956a54af949fd992ed3c10d2f2528d56b84cbe0218f2e86b733e5c33c59a5e6fc7ffac540576c6935b808cb5e46d91f3b0666b3f5363e0ccb1b,arr,Recap,"The approach, a variational method that models interdependencies between persona and knowledge using latent variables and employs dual learning to jointly optimize the relationship between dialogue context, personal memory, and knowledge, achieves strong performance on the new dataset relative to competitive baselines under both automated and human evaluation paradigms. ",90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Recap,"But the human-machine conversations, which would result when the models are deployed or used, represent a fundamentally different distribution from human-human conversations. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Recap,"This paper poses a problem setting named text-to-table, as a new way of information extraction. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Recap,"Flooding is a regularizer that prevents the model from converging to zero training loss by choosing an appropriate *flooding level*. Moreover, according to the authors, flooding encourages the model to converge to a flat region of the loss landscape. ",16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Recap,"For LMs with masked language modeling objective, downstream tasks such as POS tagging and dependency parsing are also considered. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"For intent detection, MLP classifiers are compared with models based on the question answering (QA) paradigm. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Recap,"The dataset is formed of about 5K documents collected from two domains, news articles and restaurant reviews. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Recap,The work focuses on the quality of speech synthesis models when less than 5 hours or speech are available to train the model. ,15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Recap,1. ,57
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Recap,The regularity-agnostic model is based on the biaffine attention decoder to mainly focus on detecting the boundary of an entity mention. ,41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,"Overall, I think this paper introduces a simple but effective method to improve automatic ICD coding and conducts experiments to verify its effectiveness. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap,This work collects a large-scale RC dataset for educational purposes. ,0 1 2 3 4 5 6 7 8 9
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Recap,"Also, using dropout for augmentation is more effective than other augmentation techniques (Table 3), which is consistent with the result of Guo et al. (2021). ",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Recap,All the triples must be verbalized although their order must be determined and which ones should be grouped (aggregated together) to give rise to a single sentence. ,47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
8c890587897b7eb6684e2468cb6435d2844312c17e8335f883170fc270c6d418f05d5f6051cb0b4172aa8b08bf4bb0d92c6057d18108313a830726aa593c9bb2,arr,Recap,"The paper focuses on the topic of *argument structure constructions* (ASCs), an important topic in the framework of construction grammars. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Recap,This paper proposes a strategy of joint learning across multiple languages using a single model. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
5b5ef3b14ef11f5de9552db4739690bedddabc06110d0c367e05618ce1e565d812bd0f032409a83c7247c8872318ac8fedce38dcd970f0931c721838464b177a,arr,Recap,"The authors show results that demonstrate drastically worse performance as recursive depth and number of noun phrases increase, and conclude that the models have not properly learned the underlying syntax of the linguistic phenomena they describe; ie discontinuous constituents/cross-serial dependencies. ",92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Recap,The authors also demonstrate the experiments on different subtasks in the framework. ,47 48 49 50 51 52 53 54 55 56 57 58
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Recap,"The first 3 are trained from scratch and the last one is fine-tuned.
",28 29 30 31 32 33 34 35 36 37 38 39 40
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Recap,"The work provides a detailed quantitative analysis of each component's role, layer-wise evaluation and achieves better results than previous methods on three classification datasets. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Recap,Paper proposes quantization of generative PLMs coming from GPT and BART family. ,0 1 2 3 4 5 6 7 8 9 10 11
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Recap,"For example, a ""time_span"" column can be expanded as ""start_time"" and ""end_time"" columns. ",65 66 67 68 69 70 71 72 73 74 75 76 77
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Recap,"Specifically, a biaffine function with constraints is used to embed different relations of word pairs for multi-channel graph construction and then aggregate information over such graph, meanwhile a refined strategy is proposed for measuring the match degree of word pairs. ",47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
3e521497d8a22e01c7c3dc64dfca54bcf11a65c980f2592aa438e68185654a9c4a837d594dbb5470bc911d85823ec282d62821090e63c5313442a329883f7fe5,arr,Recap,The method inlcudes 2 major steps: 1) use a rationale extraction model trained on small amount of annotated rationales to highlight rationales and replace non-rationales with synonyms (semi-factual generation) and 2) ask human annotators to identify false rationales (use synonym replacement for the false span) and missing rationales (extract a subsequence) to generate as the new examples. ,21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Recap,This paper focuses on transitioning from chit to task-oriented dialogues. ,0 1 2 3 4 5 6 7 8 9
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Recap,"They show that their method outperforms text-based and graph-based methods, both with and without pre-training, as well as competitive methods designed for math problems (i.e. MathBert) across four tasks in the math domain. ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Recap,"On NaturalQuestion and TriviaQA, their largest model also outperforms existing models. ",115 116 117 118 119 120 121 122 123 124 125
e720868dc986e40c40c00c14a79ca6e977bc7e1c7db9423bbcd27f2331be3b2283e9c420beabf11b1bfc7f1a46b9b5503698216903c307f81e40a9b579b728a4,arr,Recap,"Experimental results show that the proposed method improves the performance over the baseline methods, especially when evaluated using AUC. ",36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap, ,
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"The presented findings demonstrate that QA models generally outperform MLP models on the ID task, achieving F1 scores of up to 93 points. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Recap,Results show that the method achieves the best performance on topic mining and phrase representations. ,13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Recap,Summary:     This paper aims to explore unanswerability in multiple-choice MRC. ,0 1 2 3 4 5 6 7 8 9
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Recap,"For this, a general-domain student model is trained to mimic the neuron activation patterns of a calibrated domain-specific teacher model. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Recap,"Moreover, an error analysis of the best systems is presented. ",54 55 56 57 58 59 60 61 62 63
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Recap,2) low-quality prompt also learn fast when increasing data size 3) the masked language modeling objective helps vqa more while the prefix language modeling objective boosts captioning performance. ,95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Recap,"The paper list several limitations, however, of the study that need future work, including how the generated captions do not entirely and accurately represent the image at hand due to various interactions within the image itself. ",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Recap,"The authors of this paper identify four dimensions of culture associated with the NLP systems, i.e., linguistic form, common ground, aboutness, and values. ",13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Recap,"Besides, a set of experiments are conducted to investigate the difference between online learning and offline learning, and the importance of model initialisation in the proposed bandit learning approach. ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Recap,"Such methods are evaluated against newly created gold standard temporal annotations for 4 languages (Italian, Hindi, English and Portuguese). ",95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Recap,The authors define six sentence-level discourse roles for long-form answers and ask human annotators to label a total of 1.3K examples. ,18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Recap,"Although I gave him 3.5 points, if I could, I would give him a score between 3-3.5. ( ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Recap,"Clearly their supervision is relatively easy to acquire, although it appears their approach is sensitive to choice of initial labeled set. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Recap,"The model is, like the baselines compared to, adaptive, in the sense of allowing different test examples to use more or less computation as needed. ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Recap,The boundary smoothing can mitigate the over-confidence issue by reassigning the entity probabilities from annotated spans to the surrounding ones. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Recap,How to chose the right prompt? ,27 28 29 30 31 32
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Recap,"The two models are trained jointly, where NMT learns the task and the confidence network learns to produce the correct confidence. ",68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
fa94bed3bbc96280dc3b98466265c78b317b246d3e86a68e0e4e342ae683a71685264427a80693ea4c82caae2deb33bbc15e71930c843ffac162fb15a7d09086,arr,Recap,"They evaluate the best configurations of multi-task learning (combinations of auxiliary tasks and final prediction flows) on one French and three English datasets and find that their methods outperform the vanilla biaffine parser.
",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Recap,"This paper studies the text-to-SQL generalization problem, focusing on the Column Operations problem. ",0 1 2 3 4 5 6 7 8 9 10 11 12
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Recap,"The main novelty of this work is the dataset itself, which includes punctuation on spontaneous speech because models trained on prepared speech do not perform as well. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Recap,"Once a sufficient number of layers yield sufficiently low-entropy predictions, computation can be terminated (with both of these ""sufficiencies"" in the previous sentence corresponding to a different inference-time hyperparameter).
",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Recap,The main novelty of this paper is representation of surrounding utterances using a pre-trained  BERT model and generation of prosodically varied samples with the help of learned contextual information. ,59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Recap,"It proposes a syntax-aware memory network to capture the interactions between the text and formula representations, and it explores the use of pre-training tasks to 1) improve the language representation, 2) improve the graphical representation, and 3) combine them. ",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Recap,They show the effectiveness of their approach on multiple-choice structured queries (Wikihop and Medhop dataset). ,18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Recap,"The authors also conducted a fine-grained analysis understanding the effect of different prompts, data sizes, and pre-training objectives. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Recap,This paper investigates the effects of moral framing on the persuasiveness of arguments relating to controversial topics. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Recap,Experiments include three translation directions towards English and are performed on a publicly available dataset. ,111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Recap,"For example, there can be a QA agent that answers natural language (NL) questions and an instruction following agent that could execute actions to accomplish an NL intent. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Recap,This paper proposes an interaction-based model for role-oriented dialogue summarization. ,0 1 2 3 4 5 6 7 8 9
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Recap,"
What guarantees does this give us in theory? ",116 117 118 119 120 121 122 123
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Recap, The SR approach uses a dual-encoder to expand paths to induce the subgraph and stop the expansion automatically. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Recap,"Strengths, weaknesses, and scores are based on the author responses and current revised draft. ",319 320 321 322 323 324 325 326 327 328 329 330 331 332
debf5134addd4de011069d05d32a522fece6c708c3e570db0932d7105f7ca093e86d49954d943c97bc4e7c07d49b1ded4588f15d9b58aa4f18deba615b73e631,arr,Recap,The Chinese pinyin input method converts an input pinyin sequence into a corresponding Chinese characters. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Recap,"Modern style transfer research operates in an ""unsupervised"" setting, where no parallel training data (pairs of sentences differing in style) is available, but assume access to a large unpaired corpus in each style.
",25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Recap,Their proposal takes as basis a ColBERT IR architecture (with proved state-of-the-art performance) and a pre-trained multilingual masked language model (XML-RoBERTa in their experiments). ,65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Recap,This paper studies translationese effects (differences between original and translations in the same language) in machine translation. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
fb4a2b7c398bae50dfab314db4211f66db60cc40866617c48e02e1bec342456adc0f2832a39cd6e7b8a9a494d9414ef2150459f23195e539b540a290d5dc5418,arr,Recap,"The authors found that for congruent prototype-Jabberwocky pairings distance are significantly lower, even in the scenario where construction prototypes are built by using relatively low frequency verbs. ",223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,2) A second example of a logic trap is using arribution methods as ground truth to evaluate target attribution method. ,231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250
19f388a29acd478e296a556b93da193a08c35983f08334eb804d61a3b42f687cf8b7a8ad0984b98d01112105066170a4441bd5a07e61e8179253006a3cd6aeff,arr,Recap,"So, I recommend accepting the paper as a short paper. ",63 64 65 66 67 68 69 70 71 72
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Recap, ,
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Recap,The multi-layer visual-linguistic embedding is further aggregated through the proposed hierarchical cross-modal aggregation. ,39 40 41 42 43 44 45 46 47 48 49 50 51
1bfcb4def70d12c57ccdb42cca9d080fa5b2a22145f457c877091f8505973ebbba7e8a21d9e666421f4d700c07f226e76f3f8c4788a8a9d72632048b2ade2491,arr,Recap,"As a great amount of the ancient Korean documents were written in Hanja, that is hard to understand now. ",31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Recap,The pre-training dataset is generated jointly using question generation and a student-teacher framework. ,89 90 91 92 93 94 95 96 97 98 99 100 101
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Recap,Visualization of label and instance representation also shows the reason for different performances. ,62 63 64 65 66 67 68 69 70 71 72 73 74
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Recap,"Objective evaluations include word error rate (corresponding to intelligibility), reconstruction error, and expressive diversity (energy and pitch variability). ",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Recap,"This work can be a good example of the application of MTL in settings, where the primary task is intuitively influenced by the auxiliary tasks, but the weightage of the individual tasks in this aggregation is not definitive or well-established.
",264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303
bebacb425efb7bf0d90d2245050d9417e1417ee8710380b04cbb1c44f987aa468873f689de669b8b8f90f7e2dd4d9c4bb86835e3454935d2bb6d501aeee63980,arr,Recap,This paper centers on commonsense knowledge probing and the issue of reporting bias. ,0 1 2 3 4 5 6 7 8 9 10 11 12
883cec982be6ead1ee077df92d0d08618b52f2c4d4c39b923d78fb412dcf88496ff4894080de73f3c786310afcab26fa9e04cafe7020c5561b3835c375a0fd0c,arr,Recap,The paper addresses the problem of privacy for document embeddings. ,0 1 2 3 4 5 6 7 8 9
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Recap,"The paper proposes a new dataset for reading comprehension with multi-span answers, MultiSpanQA. ",0 1 2 3 4 5 6 7 8 9 10 11 12
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Recap,"And in inference, the text is anonymous and the results are computed in the ciphertext. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Recap, The intent is to enable large pre-trained models to better leverage transfer learning. ,20 21 22 23 24 25 26 27 28 29 30 31 32
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Recap,The paper presents a method for representing the relevance of a linguistic dataset to the corresponding language and its speakers. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Recap,"To investigate the domain adaptation performance, the paper conducts a biaffine baseline and a multi-task learning model on top of the baseline model, which are the first scores on this new benchmark. ",77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Recap,"Furthermore, a comprehensive ablation study was performed, showing that the label feature model has the largest impact on model performance, yet, other parts of the method still impact performance substantially. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Recap,The paper proposes a novel and automatic way of transitioning from chit-chat to task-oriented (TOD) mode. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Recap,"Beyond the experimental contribution, the authors also propose an efficient way to find the *flooding level*, a crucial hyperparameter of the flooding method, based on *gradient accordance*. Moreover, they convincingly analyse and discuss their contributions.
",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Recap,"They construct this dataset by collecting a wealth of statistical reports and Wikipedia pages, and then asking human annotators to convert sentence descriptions into question-answer pairs. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Recap,The authors here propose a new task called neutral summary generation where the aim is to create an unbiased summary of potentially biased stories covering one event. ,17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Recap,The paper is clear in terms of the problem motivation and goals. ,130 131 132 133 134 135 136 137 138 139 140 141
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Recap,"This paper addresses the problem of how to weight task-specific losses in multi-task learning and presents an algorithm to adapt weights of loss functions, each of which corresponds to a task, during training.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Recap,"Instead of learning extra no. of parameters to fine-tune / adapt a model, KNN-based MT learns a smaller meta network without unfreezing the pre-trained base model. ",15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Recap,This paper addresses and focuses on disambiguation resolution on task-oriented dialog systems. ,0 1 2 3 4 5 6 7 8 9 10 11
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Recap,I have reflected changes to my last review by striking the weaknesses that have been addressed satisfactorily. ,229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
4f10ec5193a009e80509f8af752083af20c189deead2c88813e4fa7441489f0e92bee6da70a91f5524c0a3142d1b8f68242a9157a11e8589f1aa9d62a2597afe,arr,Recap,This paper presents a semi-supervised method for word-level quality estimation by using sentence level QE models which are mapped to word-level QE using feature attribution (rationale extraction) methods. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,What are the environmental costs? ,69 70 71 72 73
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Recap,"The paper presents an ablation study to test the impact of each of the components of the proposed method, as well as experiments that show that the improvement is stable in the low supervision case. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Recap,They then go over results after pretraining on masked language model objectives and then fine tuning on dependency parsing. ,95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Recap,Two probing tasks (insertion & replacement) adapted from grammatical error correction datasets are used to test models trained with the two masking schemes. ,12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Recap,They evaluate two tasks on this dataset: table QA and natural language generation. ,57 58 59 60 61 62 63 64 65 66 67 68 69
03ec0e75773d76912986c4d1f756e56aa55e3d5c563a696175ded04ee84f8a7ae514f30744a0cf853ec1ca9d0fd8a45276f892b8e1dcf5d905677300ba3f05a2,arr,Recap,"It compares different architectures on two endangered languages (for one of them, the training set is built by the authors), showing that FastSpeech is less data-hungry than Tacotron, hence supporting its adoption in these cases. ",38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Recap,"This work approaches the task of long text summarization with a multi-stage framework, dealing with the input length limitation of modern Transformer-based models. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Recap,"for example over 56% of Ro-En sentences are discarded.
",144 145 146 147 148 149 150 151 152
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Recap,The authors propose identifying these puzzles in the representation space by utilizing adversarial examples---the method searches for an extreme direction that would shift a data point to the direction of the other domain. ,18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,2020. ,257
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Recap,The paper provides a benchmark dataset that can be used for training & evaluation of automated fact checking systems. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Recap,This paper proposes using metamorphic testing to verify the behavior of NLP models. ,0 1 2 3 4 5 6 7 8 9 10 11 12
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Recap,as it discusses the limitations of current SRL systems on out-of-domain instances. ,275 276 277 278 279 280 281 282 283 284 285 286
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Recap,This paper proposes a new template-based generation model for the event extraction task. ,0 1 2 3 4 5 6 7 8 9 10 11 12
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Recap,Experimental results show the proposed methodology outperforms baseline models in most cases. ,129 130 131 132 133 134 135 136 137 138 139 140
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Recap,"====== 	 This paper proposes a novel approach to the task of knowledge-grounded dialogue generation, that additionally exploits commonsense external knowledge augmented with named-entity triples extracted from co-reference chains detected in the dialogues themselves. ",92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Recap,The paper is about an unsupervised approach to sentence simplification that integrates paraphrasing into an iterative text simplification system. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,This is an important evaluation because the training defense mechanism is significantly more useful if it does not require all personas present for training. ,731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Recap,The authors used their proposed pipeline to collect the first parallel English detoxification dataset (ParaDetox). ,28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Recap,"In IMT, usually MT predicts the next set of tokens given the prefix that has been post-edited by translators. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Recap,"The paper first highlights this problem by using human annotators to converse with 4 CQA models, trained on QuAC. ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Recap,The dataset 16k images from the NYT articles and an additional 61k weakly supervised samples from the wikipedia dataset. ,30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Recap,"  Second, this paper proposes a new dataset for testing sense embedding biases (SSSB), by creating templates and filling them with target/attribute words. ",33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54
8cdbb2b513520303dc39890672a3088db78f2234c8bb6d933c898b0961a7497b997110acfcc767fa821dc2ae5ca2b15c3e743768e9b1caa9688c9924900d078a,arr,Recap,"
Essentially, the authors assign different weights to words during training, depending on their frequencies. ",40 41 42 43 44 45 46 47 48 49 50 51 52 53
043aba43da4da9c0ab308268b8ace3bbc8c1ac766b70111814b13fb419cb7b1fdfe563dfa98d1263c3c060b2463526f656e0bddd2544c15ee19026645c76bcce,arr,Recap,"The solution proposed by the paper is to use smaller granularity units, i.e. contextualized sentences. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Recap,"The paper first provides deep analysis on 3 use cases for ToD (E&F, F&E, F&F) aside of English-speaker in English-speaking country. ",17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Recap,"
The input sentences are first passed through the frozen LM, then mapped to a prompt shape which is then appended to the input of the same LM. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Recap,Fig. 4). ,44 45
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Recap,"In the experiments, they show their method achieves better results on most cross-lingual transferability tasks and show XLM-E requires less computation resource than previous methods. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
a6f83f54bd43db725bd0f67fc819f1c0b0bf631d8badf27f63f1eaca61865c0f943ea31260da63ebb8157c4b7131d3f08990bba93564e11293c433f2a1cd5109,arr,Recap,This paper studies and analyses a novel document-level NMT framework using multilingual transfer learning to improve the document-level translation quality for some student languages without parallel document corpus by applying the teacher models trained on parallel document corpus. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Recap,The paper proposes an approach with an information-theoretic solution for the out-of-vocabulary (OOV) entity recognition problem. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"Moreover, the paper empirically proves this error by showing a drop in the model's confidence in its prediction on unchanged samples. ( ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Recap,"The evaluation is reported in terms of F1 on three different segmentation levels (morphological boundary level, token level, and type-level). ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
c06c5336dbaf412ee7395c25aa3061dc3921e0460085fe6f98819b94402e329f794cb5c03978342933205cebef78da100b857aeb422856c92f9402cb501a0dc4,arr,Recap,They use a variational framework for training using an evidence lower bound of the likelihood. ,53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Recap,"A segment-level model trained directly for this task substantially outperforms existing models including Local Transformer, Routing Transformer, Big Bird, GPT-2 and GPT-3. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Recap,**Note**: *This is only a slight revision of my previous review for a previous version of this paper. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381,arr,Recap, The methods come from previous work but this paper adapts them to the sentiment task and shows that they perform quite well across several data sets. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Recap,So the much higher additional effort to obtain evidence instead of relying on other structured data in a patient's EHR is not justified. ,210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Recap,"The authors use token-wise similarity from pre-trained language models, which differs their method from the previous sentence-wise comparisons between representations, like SimCSE. ",22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
db8aa6185bc491825bf2992a2710571f719ac68eb37b18c177945628dc57d9f9e7385a81f423fab54ef5a1e10c2a7c49686661def2ad1831924f07ffa0cc9c2e,arr,Recap,They then compare these models on five benchmark datasets and find that an efficient wide MLP can achieve competitive results and should be considered as a strong baseline for text classification tasks. ,29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
2d2c451d0cf3d6c8e07fac9a9aa93e82a6f015082c3bede9c4759e317fe831e30797058a2181bdb6a7a5087b92a1c2468840dee2c64c320045187388802a886d,arr,Recap, ,
b9dd642435d7c4f925a0e47c19372f1a754fb7bff99c879ff12ccfed4a733f7cccf063ab77f07f18f7b54bed25a40d36231d16976912f4d22a1a4b8d75f4a70e,arr,Recap, ,
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Recap,"They propose a method called ELLE, which aims to expand the current model's width and depth upon a new data source is available. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
0c8881f95c9a0f6e4195aefded8d28262cf507daba02d911311a5428388cb0a65528ba766d3c878c0ded60814a02fe0e1e9ed516e32a02b82cc7fcc586d01e20,arr,Recap,"On sentence-level tasks, there is little difference between the two. ",73 74 75 76 77 78 79 80 81 82
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Recap,The whole idea is interesting and straightforward. ,65 66 67 68 69 70 71
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Recap,This allows modeling the notion of focus. ,24 25 26 27 28 29 30
82d6c7a265215702f4ee28c34e120f0b7068a8a16cfc3d11e386e60c4faca1475ae6f565b6bf5ff3eb954b2eb4298534e19f534faeb5394a976a7957866e6e1a,arr,Recap,"Once encoded, the cosine similarity of the two encodings is computed and it's used in a Textual Entailment like task to decide the label of the input. ",27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Recap,"This paper pursues a line of research about 'prompting', a method that leverages the prediction capability of pre-trained language models to help perform few-shot classification. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Recap,This paper focused on the task of multi-span question answering. ,0 1 2 3 4 5 6 7 8 9
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,it utilizes quantization technology but does not compare with the other quantization approaches. ,57 58 59 60 61 62 63 64 65 66 67 68 69
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Recap,"Experiment on the DPR framework shows that DAR significantly outperforms vanilla DPR and its combinations with different data augmentation strategies (QA,DA,AR). ",82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Recap,"The paper explores the task of detecting of adversarial examples in the space of NLP problems, as opposed to the more common types of defence against them (e.g. adversarial training). ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Recap,"This paper studies style transfer for languages where no style-labelled corpora are available and furthers related prior work that either assumes access to large style-labelled corpora and the more recent few-shot transfer using only 3-10 sentences at inference for extracting the target style.
",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Recap,Experimental results show that the proposed model yields significant improvements on six target language datasets and outperforms the existing state-of-the-art approaches. ,44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Recap,"In addition, the authors also collect human generated contrast sets to compare with the automatic ones. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Recap,"Moreover, QA pairs are created from these source declarative sentences and are included in the dataset. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Recap,The framework proposed in this paper is similar to rule-based data-to-text generation. ,70 71 72 73 74 75 76 77 78 79 80 81
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Recap,The main contribution of the paper is a human-annotated dataset (BehancePR) for punctuation restoration in livestreaming video transcripts. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Recap,"The results showed that although the example-based prompt will take more annotation time, using example-based prompt, the fine-tuned seq2seq model will lead to better generalization to new APIs, more data-efficient, and robust to schema variations. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
262843a4c9c8009e43c652fd03dead78e120f32d62499d0826136d5c4e1204d19e1bcc09ae3b3c7a938f919e9e86262d824cc86c483e18e874e11562461a1524,arr,Recap,"In addition to describing the corpus creation, the authors conduct preliminary experiments which show that taking into consideration the Parent comment improves the model's performance, highlighting the importance of considering the conversational context. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Recap,"This work presents a novel NER learning framework to address the poor performances issue on out of vocabulary (OOV) entity recognition; and, more in general, to help NER systems to generalize better and avoid ""mention"" memorization. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Recap,"As far as the traditional generation pipeline is concerned, it does not include any content selection or document planning. ",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
7a37c234f802105737b8ef07f91799a41ae3c4a9419fed87a7039887ab871146b2e4f16a9c9e85e04bb8947847d04bda1c4d675bc1149a1bf212ece34c59726d,arr,Recap,The authors argue that it makes more sense to formulate automatic fact-checking as an entailment problem in which the veracity of the claim is evaluated against existing evidence. ,14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41
0ac9820142b39e37945bfc25038d562d36d08e5407ab516a8f8eb18cc7a696601df7e15caa23159bf9ef420a1e65efadf3778d71d4aa95df26226ff49de26bb3,arr,Recap,"The paper proposes a data augmentation method using a controllable smoothed representation, which is obtained by combining the one-hot representation and the smooth representation through masked language modeling. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Recap,"The authors also demonstrate that generic intents transfer across domains, with ID models trained on the one of the two domains being able to detect generic intents in the other domain with substantial accuracy. ",184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Recap,"The authors further compare this method against other data generation schemes, such as back translation, finding that learning with domain confused examples provides far greater benefit. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Recap,This paper addresses a text classification task: assigning ICD-9-CM codes to a clinical text. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Recap,"Finally, the authors then give a discussion and conclusion for follow-up researchers. ",37 38 39 40 41 42 43 44 45 46 47 48
76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404,arr,Recap,"
6. ",172
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Recap,They argue that information for other role’s utterances and summaries can improve the informativeness and quality of dialogue summaries. ,7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Recap,The authors analyze a known dataset for the existence of this particular bias for 7 language directions and show that there is bias for two of them (en-de and en-zh). ,27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Recap,"When trained with full training sets in source domains, the QA model can also be adapted to target domains, where only user feedback is available.
",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Recap,This fluctuation hurts sample efficiency and leads to slower convergence. ,30 31 32 33 34 35 36 37 38 39
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Recap,"In the beginning, the authors present a hypothesis that model pruning increases the risk of overfitting at the fine-tuning phase as well as some empirical results that demonstrate this hypothesis (Fig. 2). ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Recap,"While the experiments show that there is no single best approach on all metrics, the proposed approaches improve the results over simple corpora concatenation or single-corpora training. ",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Recap,"Following the same line, this paper proposes to leverage a picker and a generator to jointly predict the final utterance. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
c84a94af6f02cdbccfaf147ae5e059ab15fdf2a2f986a62d424b0264a96ce3f409dbdabd63f069cfe698d8cd4d1da5aaf51a6f1af64e49ef4b15a67004eba4fb,arr,Recap, ,
2ea8df75b5e58259ce59dbb4f6447ae8fbd49951f49a57418898bfefae29cacb63dcace110f3bbddeb7e7bb9f0ebe02628a9872cbfdd100a96ab205c18a15532,arr,Recap,"Finally, they discussed about the carbon cost and diversity gain associated with conferences in the ACL Anthology. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Recap,**What are the main contributions of the paper? ,109 110 111 112 113 114 115 116
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Recap,"For the BIL task, they evaluated on the VecMap and outperformed baselines (XLM-R + Mirror). ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Recap,"The annotation is done by attributing each sentence to one of the 9 categories (abstract, strength, weakness, ... ). ",21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Recap,The authors take advantage of the existing datasets and annotate the data with six phonological properties. ,13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Recap,"
  They define some threshold which determines whether a classifier is confident of it’s prediction. ",261 262 263 264 265 266 267 268 269 270 271 272 273 274
534dd4d039e9277fd00d16e3f1cdf7b7ce3d9bf240f6b3db32d966ede32db1ff6121fa15bfe1ba49c20bf8fe510e0805c0d4cc63da74ec69523a1bab60678fa0,arr,Recap,"This dataset comprises three datasets: AJD, DRS, DRRI (DRRI was proposed in this work). ",22 23 24 25 26 27 28 29 30 31 32 33 34 35
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,Problem Large language models are ubiquitous in application and particularly useful when constructing chatbots. ,77 78 79 80 81 82 83 84 85 86 87 88 89 90
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Recap,"Two helpful examples of logic traps include, (1) the assumption that a humans' decision making process is equivalent to that of a neural network. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
eb76be8eb039c9d2bbeb057ddca56f1f32be077147400cc9c2223a0fa77476cb4006397c698b6ea9752209576eeadbd204f0d5094ebfe920643cd380bd53a80a,arr,Recap,The results demonstrate the effectiveness of the proposed approach. ,69 70 71 72 73 74 75 76 77
44e7ab41a54cab53f17e79871feb2713cc16df873abd22f680ff5a4c0366953bb1c6c359fd3fd84fa68c262345dae767a3250a4249f7a0583a6569f44fdaa4d1,arr,Recap,"The authors compared the proposed method Bias-terms Fine-tuning (BitFit) with other parameter-efficient fine-tuning methods (e.g., Adapters, Diff-Pruning). ",23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
7b615d609f85242d0bfcc1c31465512c1392c92758410e60ee31f24a7a307e552ad59858bc5a10774f88d28e1ea4bfd7eafb244a25cd8dc62ee7058ebd7aa9c1,arr,Recap,The method achieves SOTA Rouge performance for three public popular summarization datasets. ,29 30 31 32 33 34 35 36 37 38 39 40
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Recap, ,
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Recap,"This means the current evaluation paradigm does not accurately capture the use-case and therefore, tracking modeling improvement with that evaluation paradigm will not be meaningful. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Recap,The authors start with an iterative framework in which an input sentence is revised using two edit operations: delete and paraphrase. ,19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Recap,The extensive experimental evaluation seems to confirm the validity of the model. ,52 53 54 55 56 57 58 59 60 61 62 63
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Recap,The paper mainly proposes an approximation approach for transformer model inference so that it can apply homomorphic encryption. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Recap,This paper focuses generally on the task of diverse decoding from conditional language generation models. ,0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
67aa42fd3fff5135563c8c2e90cf2b290f60d94fce5866d856c25a47b88f1796bd7f427af889a9325a91b7fe8b6e13f74e423aff7aa71fd04f1abef48c3ace5d,arr,Recap,-Analyzing persona identification and understanding as a privacy risk ,192 193 194 195 196 197 198 199 200
19bfba0c6a677941f5cbc4abb300a092e2dd6b520a5e920d590329c5670d94b8e0829ff2d771f312f449d1c2fff15cb6611890583e047e3f2e9d16025af1ef0b,arr,Recap,"The authors proposed an improved version of the $\alpha$-entmax which does not require sorting during computation, which aims to reduce the latency of the operation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
3c5f1606df31ea38d2c235d4bab7fc8fca35beb21054360eae4e1ff7255482add111c6640a53a0a71d0537cc44a8303324cb2cbd6890f974d12ceff469936c39,arr,Recap,at gold-k as an alternative. ,81 82 83 84 85
c29f875efad0be673bd7a12f43f37625d8bdbff8992cc8be203f512f659310b5e5169cdf0336a51cdbc949b35de3b69b1f8eb5fdb69493bd13e8ea7373d3c30c,arr,Recap,"Experiments are conducted on three datasets, one for document-level relation extraction (DocRED) and two for joint entity and relation extraction (NYT, WebNLG). ",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Recap,They also show that model performance is strongly correlated with semantic proximity and stronger retrieval performance does not guarantee robustness to word-level manipulation. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Recap,The work also puts forth a new automated evaluation paradigm that mirrors human evaluation results more closely than the existing evaluation strategy of using the gold answers. ,186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Recap,It starts with the prior observation that there is a phonological hierarchy that dictates the ordering of the B and C words (or for compounds the A and B words). ,52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Recap,"This dataset could help better characterize the intentions and interactions between reviewers and authors, which in turn can assist decision making for area chair.
",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
ac111729bd87f7f328f3b1424cee51b2f2c3155d5fe61d34fe4c5df11ead409b069a3d0d90d15ee9380fd9d122976d953e64ee7041789513ea0e1b99d30e4098,arr,Recap,Results show that the contrastive learning method improves MWP solving in both the monolingual and multilingual settings compared to recent baselines. ,221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Recap,Traditional early exiting methods focus on predicting instance difficulty by heuristic metrics or learnable modules so that easier instances can be assigned to lower layers to exit while more difficult instances can go through more layers. ,11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Recap,"As a baseline attribution score, the authors choose regular, unmodified activation scores of the neurons.
",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Recap,"The paper creates a corpus of verbal negations and adapts QA-SRL to collect questions and answers regarding the arguments of the affirmative counterpart of a negated predicate, and manipulate them to generate the affirmative interpretation. ",0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Recap,"
The authors designed a unified experimental setup, the STP test bed, and used it to compare 4 different models under 11 different languages. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Recap,"The authors first collect a parallel corpus on LIV, LV, ET and EN, by assembling available digital resources and via manual translations. ",11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Recap,"Locally (for each layer), they extended the method of Kobayashi et al., 2021 by considering the contribution of residual connection #2 and layer normalization #2 (Figure 1). ",26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
aa75cb5d1fcdad14f947645ab06b4db48b3cd30fa91947d3667b8a7637b43b2b1070fc11e4e9b623604de1ddb6198bc41812aa98ea7a58e4521a239374596edf,arr,Recap,Limiting the search MeSH space with information extraction from metadata (such as other articles published in that journal) allows for a boost in performance by building dynamic attention masks. ,38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,The proposed methods can help beat the vanilla seq2seq baseline in experiments. ,221 222 223 224 225 226 227 228 229 230 231 232
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Strength,"I found the paper quite interesting , even if at times a bit unclear. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147
3cb226b0d8814a65b174a7d0cb90ebfa0748d404cd08981e4a84a2a794c22f90563f97eb4e66f87b1c5ec1921001d1baefeca833441161438617557155e84375,arr,Strength,(1) The new training and inference strategies for sequence-to-sequence method are easy but effective. ,57 58 59 60 61 62 63 64 65 66 67 68 69 70
f228a370d578a045f11011442d077199a418ee0f7c5c17ba9c15a5b71ec4df8fc596f481d9e53c16e1bf811675a24952f71ae29ad67af786ced56bc2faac1a4f,arr,Strength,"2) The solution proposed tackles a relevant advancement of the NER problem in the NLP community specifically OOV NER.
",135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Strength,"Then, they synthesis the labels of data in a rank-based manner. ",67 68 69 70 71 72 73 74 75 76 77
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Strength,"- The paper identifies an intuitive issue of the current SOTA method (i.e., Gao et al., 2021) that uses embeddings from the same sentence, though with different drop-out masks, as positive examples. ",177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208
a10d35763dca42f9e79c8e0caa0c46187df3879026bdd9c437fa21cb43f4713e871f77a5508c7aefe0c3ef70f3c71cddc20c64e692664edfc6ade6954ee36188,arr,Strength, ,
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Strength,"The compositionality test also seems useful, and it is probably easier to interpret the numbers coming out of it in absolute terms compared to probing, since we should expect a strong model to achieve 100% performance. ",274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"So overall, providing answer prompts in addition to question prompts helps.
",392 393 394 395 396 397 398 399 400 401 402
3affb22d5291a0f1b271ca9dc4dd222ab62f7f4ab6ccfd912fe8e07e1bde6611b3087a936d228e699535ceb69c29ecadcf5cb58720a18c93acb946af3dd3394d,arr,Strength,"While automatic evaluation is known to be unreliable in single-reference generation tasks, human evaluation results also indicate that the proposed approach outperforms related work on multiple criteria that effectively measure knowledge precision and recall. ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
4b7c5fafdc37dc7cb22b9868c3dc5a3df61127f67fe8b48aaebe06624f82096f9a2fd1d81f57f86ecd7bfaae463ae744196e2c0e5f132cbd9ccff1065f620afe,arr,Strength,"This kind of resource is currently valuable not just for the inspection of LMs as proposed, but also for paraphrasing and generation tasks, and I see this dataset being a very valuable resource. ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Strength,2. ,80
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Strength,"Details about experiments are demonstrated in Appendix.
",141 142 143 144 145 146 147
eef4ebc16619c1ad49da471d617fb0eec96eb8d523186f9c9f1a22ec980f38dbdf50c068356ee8041e5d2bf8740d7773582cf2de2169474cba9a539a57666132,arr,Strength,"The paper describes what seems to me like an important issue that may affect most/many of the existing LMs, and the results seem to be consistent across the presented tasks. ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength,"- Good efforts are spent to build this dataset, with 18 annotators and 2400 working hours. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Strength,"Different levels of granularity provide flexibility for the annotation of new data and is useful to do automatic classification of human values, especially when data is scarce and the classes are imbalanced ",213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Strength,"It is novel and interesting and seems to be effective and it is really highly appreciated.
",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Strength,2. ,170
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Strength,"
2. ",277
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Strength,"Estimating the density function of the swift model is very interesting, and the author clearly explained the difference between this proposed method and others, such as softmax and entropy-based methods. ",92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Strength,"Since such text collections are at the basis of every other language task, and provide language models on which much of the higher level processing is based, it is important to have collections that are representative for the language (and speakers) that are targeted. ",90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
883cec982be6ead1ee077df92d0d08618b52f2c4d4c39b923d78fb412dcf88496ff4894080de73f3c786310afcab26fa9e04cafe7020c5561b3835c375a0fd0c,arr,Strength,"-Experimental results show SentDP performs much better on stronger privacy guarantee, empirically proved the previous theoretical statements.
",89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Strength,baselines are non-trivial on multiple evaluation metrics. ,229 230 231 232 233 234 235
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Strength,"While I have a feeling that ACL does not prefer publishing pure resource papers, I believe that in case where the created resource is very useful, these papers should have their place at ACL. ",306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Strength,-Some error analysis. ,201 202 203
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,As the authors claim there are not any previous language models specific to this area. ,108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Strength,"They discuss the different steps of their method, clearly detailing how each is applied and how it affects the accuracy of the predictions. ",217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
448a43302a3dc30dbf4a14d018e78a21db257918d1bb15611bcd87969a86b69e010c103017fa905e8468895697bf5b2cfc59a529a62020d11d3d4de13d97985f,arr,Strength,"3) A multi-task learning-based model and an approach that relies on style vector difference for controlling the training/inference mismatch in style.
",204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Strength,The analysis showed that the model gets better performance with more knowledge (up to 20) and the improvements on smaller inference models are even larger. ,105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Strength,Previously I only know Optimal Transport (OT) or Wasserstein Distance is used in Wasserstein GAN (WGAN) which aligns real and fake image spaces. ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Strength,1.This paper presents a new intermediate layer knowledge distillation approach with performance improvement and low computational cost. ,90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Strength,"
The experiments are solid, the proposed approach is tested against both BERT and T5 models on several benchmarks. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Strength,"The general idea is intuitive and makes sense, and the paper proposes a technically sound way of implementing it. ",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
21412b2c556d3d50fcf54acf27646c00528956d79cbc07cf51120afe37f86d66b6f14303525c6855037041e38d7696ac4e5ac21c515689e80c8acfe377506a2b,arr,Strength,This is a well written paper that's motivation is quite clear. ,47 48 49 50 51 52 53 54 55 56 57
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Strength,"The work takes the VLN task into a very interesting and practical dimension of understanding multilingual instructions; this is especially intriguing for Indic languages (such as Hindi and Telugu) which colloquially often employ code-switching between different Indic languages or between Indic languages and English (for example the word English word ""sink"" is used in the Hindi instruction in Figure 1, and a transliteration of ""wash basin"" has been used in Telugu). ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Strength,"The approach is interesting, simple, and easy to understand - combining edit-operation-based and paraphrasing-based techniques into an iterative refinement framework. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Strength, ,
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Strength,- The developed dataset is interesting and the task is very important to NLPers who work on mental health. ,89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Strength,- Good empirical results (modulo experimental caveat mentioned in my comments below) ,75 76 77 78 79 80 81 82 83 84 85 86
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Strength,"The proposed method can be useful to various applications in NLP, it might improve model robustness in data augmentation and domain adaptation scenarios. ",110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
4dd88ab5e2b781c47a44fea8fb474eea99fcc9e899ddc5770953faa4a2fcd1b8126ca5b649a34ca1fe3c1853be6b274a4edcffff0820a080b2af0c0e46e4373b,arr,Strength,"This paper verifies the significance of the problem on multiple datasets, and in particular, proposes to divide the negations into important and unimportant types and analyzes them (Table 2). ",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Strength,"The paper is enjoyable to read, which makes it easy to understand the main idea. ",73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Strength,The empirical results seem good (but I am not familiar with the state of the art in this area) ,164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Strength,2. ,64
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Strength,"Although the method is model-agnostic and simple, it achieves the state-of-the-art without any external resource, which is not always available for low-resource languages. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Strength,"I see few flaws; it simply seems like careful, interesting work. ",132 133 134 135 136 137 138 139 140 141 142
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Strength,The perspective is interesting. ,266 267 268 269
6c7386d38647d226e22fb6a21bec815d465a1023fc59c871b959b53ae367be17a28b2839533147dc589795577b8630217bf4ea6311ca501b3d89453b25741324,arr,Strength,"- The paper provides a good benchmark for a task that has not been studied much before.
",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
c8fee84fa31cfde12a304a1dcf59c98188b86bdb1028a7618bb7ac6ed4b32504bc78ab04180382a3cbd2acd88f7ebdd00b4641c9ebb3ec107707ccef6d37d3de,arr,Strength,1. ,90
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Strength,"-Table 5 shows good improvements for out-of-domain test sets.
",168 169 170 171 172 173 174 175 176
41ef404cc5f20855dc5e4e5bbad3ccaaeea15b6c43aa6d8c32cf01c43a13298a266cbe6488c57cdb9716a418abcd95f9d8b5f89d54692d69fe728178ac20b6e8,arr,Strength,"- The paper performs a detailed analysis of whether the task of scoring an essay holistically can be better informed using the training signals from auxiliary tasks like scoring traits of the essay.
",333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
4d39b07f0ccc121399951bc8ae46d791e02e901d65c5f8f75cdf895e2d1799dbea55950c9d9ce00ab277905c15dd332b187cc769e79b6e9f7aa51050fa30a9e3,arr,Strength,"- This paper attacks an important and up-to-date issue of privacy leakage and suggests a new objective for defending network, using publicly available dialog-based PLM and PersonaChat dataset.
",168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,The scope and contributions fit my expectation of a short paper. ,97 98 99 100 101 102 103 104 105 106 107
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Strength,"- Overall well-written narratives with clear descriptions of methodology and experiments, though a lot of information is in the appendix which makes it a bit difficult to switch between main content and appendix.
",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Strength,"This paper and the provided data and code are very clear and well-written.
",66 67 68 69 70 71 72 73 74 75 76 77 78
86457c43345f4b59482376208a496b21bd95a29782aa979e9a8d205335ace99114e4acb17624ddf75457a7545151b870e4da636db5231e613687a553c89d2052,arr,Strength,The paper accurately summarizes related work and reflects upon open issues. ,133 134 135 136 137 138 139 140 141 142 143
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Strength,"The proposed method is simple and straightforward to implement, yet it achieves performance gain compared to several baselines and got SOTA results on 3 tasks. ",79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Strength,Thus it is arguable that the proposed method will have broader applications. ,162 163 164 165 166 167 168 169 170 171 172 173
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Strength,"- The paper is overall well-written (though the organization seems confusing, to be detailed in ""Weaknesses"") and the figures are helpful for understanding the paper.
",34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
2065b40112433f7a79af8bea5d571e4747ada0a702ce8d1291cbc22d8acbbd5e59fd7b96e775b2acd67c2aee01abf5add4df0e32f402f969891f7cb524fe08e9,arr,Strength,"-The proposed 'rewiring' pretraining objective improves probing accuracy by a large margin without resorting to supervised training.
",117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Strength, ,
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Strength,"
The paper has a well written introduction that summarizes the current state of the field. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Strength,"Given that NLP as a field is extremely forward-looking, often considering something even a year or two old to be ancient history, this is a valuable perspective. ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Strength,Clearly mentioned the connections to related literatures 1. ,192 193 194 195 196 197 198 199
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Strength,"I am not familiar with this kind of usage, so the novelty here is good. ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
30aa157cc690ecbf3ee3034c035b2533e3c1a2e99c7ce2c797371c7c758de51b77204c36880a0163059bed31ff962c7a97d94be7c6d287e09e1c2e2a93ac4e1e,arr,Strength,"
• This paper gets good performance across several datasets. ",87 88 89 90 91 92 93 94 95
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Strength,-Sufficient experiments are conducted. ,108 109 110 111
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Strength,"The approach used for handling complex Hebrew morphology is novel and potentially inspirative for other morphologically complex languages.
",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Strength,The proposed method is more efficient than search or autoregressive baselines. ,86 87 88 89 90 91 92 93 94 95 96
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Strength,"
2. ",158
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Strength,Tasks for which pre-trained LMs do a significantly worse job than humans even with fine-tuning are relatively hard to find. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
db6797e7fe34857ed5981bd0ea20947288238d48d7f412cb23c85472a8f914f85e94f016ae1ec9e08eddb063ae1dc853307a20b749fae53c065cf305f7598253,arr,Strength,"The method is surprisingly simple, the results are convincing as they significantly improve upon the state-of-the-art on the WiC task in the few-shot setting. ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Strength,This might be an interesting method for other NLP settings beyond robust training. ,177 178 179 180 181 182 183 184 185 186 187 188 189
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Strength,"It is nice to see a paper investigating a specific linguistic phenomenon of theoretical interest in a non-English, non-Indo-European language. ",128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Strength,Provide the insightful result that two Layer normalization in the layer counteract each other. ,209 210 211 212 213 214 215 216 217 218 219 220 221 222
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Strength,"A sufficient number of examples to illustrate the logic traps is used, which is very helpful especially because they are deceptively obvious. ",440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Strength,Results over two datasets show significant improvements over recent state-of-the-art models. ,78 79 80 81 82 83 84 85 86 87 88
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,"- A new task that could be useful in the financial domain.
",80 81 82 83 84 85 86 87 88 89 90 91
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,There are some additional hyper-parameters to tune correctly per setup though. ,288 289 290 291 292 293 294 295 296 297 298
155fec04885f4a7a2e43bb0f534242dd62fd69926314f05496fb658cc059e0b5d9787b83d0770625e517a7307bed56a725d7ff215cd50fd7f047a86c29f23c10,arr,Strength,The paper highlights some interesting points why existing models might be unsuitable for task of punctuation restoration on video transcripts. ,67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Strength,The paper is clear and easy to follow. ,90 91 92 93 94 95 96 97
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Strength,The experiments prove the efficiency of the new Distinct. ,100 101 102 103 104 105 106 107 108
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Strength,"-Many baseline experiments are performed, including DistillBERT, BERT-of-Theseus, MT-DNN, and many others. ",138 139 140 141 142 143 144 145 146 147 148 149
d3a46425ecebff13b6927a610dc5f2d400c108f66a3a6c8e5814ad8aad6384feca274160a3a306196a4c30bd974c43ed64634b8554cf941d3daa4730cc21d4c2,arr,Strength,From the experiments we can see that the resulting pretrained models have some advantages. ,36 37 38 39 40 41 42 43 44 45 46 47 48 49
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,"-A further general conclusion is that most works on char-level MT focused on enhancing encoding, while decoding is under-explored. ",196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
a5dcd6bee1007207ed62a4c9d6b73660c34e600eeb6eec98e906ac5788ad1f1ee325b1edc2ad64ec907a678eb1486a00983beffe65749549642c40f6a6df47ba,arr,Strength,"Redirecting attention to the appropriately selecting attribution methods (during research task evaluation stages) can subtly reduce the immense effort and focus researchers have in outperforming previous works which in any case can potentially be premised on unreliable evaluation methods.
",401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Strength,	The paper studies the interesting and important problem of cross-task generalization (generalization to held-out unseen tasks). ,81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Strength,1. ,160
761253ace767fc010a488ba48756ad609cb1fbb8bb6b90dd6bb38679920b45b01c6710a90d6207eee6c354ef2838c12bb0173a52b91a2878008cc9625999b75e,arr,Strength,"- This paper designs a novel speedup method with core-set based token selection which is justified by theoretical results.
",63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Strength,"- The authors propose a simple method to use multiple label words per class by summing their language model probabilities, and does not need to perform fine-tuning during label-word search. ",130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
0f4cb8033e92de1eecebb650474462752b609f5a11cdf226e790163ec2a020aeb4d08d7d750bc75fd8d7c0be415881528a542492eeff9c184f1fd6b090129258,arr,Strength,Readers will learn a lot about stereotyping phenomena in language as well as the crucial details of corpus development from reading this paper. ,109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Strength,"Comprehensive experiments to validate the effectiveness of the proposed approach across different tasks (e.g., standard and simultaneous machine translation, storytelling, and text summarization). ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Strength,3. ,133
1d7c93153cb5e57842e155c6ff468bd1e7d170925c9b4ce13cc2a3fd8f767a48b5a83d784d2cf7c57169e9e46ac3b9ff5e92755d8fc7c65277ab3691a6db4bc9,arr,Strength,- The logic rules and attentions are naturally interpretable and can be used for understanding the reasoning process of the model. ,192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Strength,"Also the experiments are thorough and solid, showing insights form multiple point of views (especially that mentioned in Sec 5. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Strength,"
Releasing the code helps others to reproduce the results. ",147 148 149 150 151 152 153 154 155
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Strength, ,
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Strength,The thoroughness is almost unparalleled as a conference paper. ,158 159 160 161 162 163 164 165 166
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Strength,"
3. ",210
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Strength,"- The proposed method achieves SOTA performance on a large number of tasks in NLP, in distilling BERT.
",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Strength,-Detailed description of some metrics and results ,91 92 93 94 95 96 97
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Strength,"
3. ",209
0b700376f03b1c3df377fe0a191027d6dff597add85185cdf402bd12f05c6e6edbebdb6cfd2b502e3cb162776458a21933f543ef804eb6790056882b5e62d7ac,arr,Strength,-Strong performance on zero-shot settings as well ,177 178 179 180 181 182 183
3a14a02b9c496d9bcd7b06aedeaa8d9c48fa003e7be1b23f9cb631571dd75d894c70b500313f5f1e5ca1c867cfb04c23cad117d1072ae2d0ebbb7964c16ccdf3,arr,Strength,This paper proposes an approach to incorporate information from language modeling models into simultaneous neural machine translation. ,78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,"Second, according to my knowledge, the reported F3 performance in RUN (Liu et al. 2020) is 47.7 (higher than this paper's result). ",295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Strength, ,
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Strength,"The authors provide an extremely detailed evaluation and experimental analysis, and clearly demonstrate the efficacy of their approach. ",186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Strength,"-Experimental details are provided in the appendix, which is good for reproducibility.
",51 52 53 54 55 56 57 58 59 60 61 62
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Strength,"They performed ablation tests in the multi task learning setup, to understand what traits are useful for each set of essays - I think this is an interesting experiment I did not see before in this task's context.
",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Strength,"-The languages that were targeted are still being documented and they resemble a real low-resource setting.
",135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Strength,1) The paper is very clear and well written. ,66 67 68 69 70 71 72 73 74
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"-This paper uses several experimental settings, albeit only few data points per setting to conduct the study.
",421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Strength,"
2. ",76
d81677a8c643c5a3ddf00a01bdde9732dd9e033dc0d590d5c0ba2820905b94928bddda79dbbfb81802b7773039b24e94cb1bea7620a4fd84ec56f448a720731d,arr,Strength,-Short exploration of the resulting synonym representation space. ,188 189 190 191 192 193 194 195
95d0d98c551f861dc8a31c514dee5b6bb5de72f3a5cc59d8b77b924a289dab6d2af696ec44ab922d3dcad4be9940c4a7f72393b9d709504b1f5e0a02f41bb73b,arr,Strength,"There seems to be a rich prior literature on EEs in Hmong, Lahu, and Chinese and this paper contributes to that literature. ",148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
26bc970b4186bbf8cf20348fd2e0fdb330fd359e93edab4e2dd4cbce56b1d94c973887b5df4d5d7b3bed6b7d97c672d0a7f6dbc54014c8d32b2ed7e5e75ca084,arr,Strength,I think that this is more principled and clearly considered than probing methods which use learned peripheral models. ,161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Strength,1. ,81
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Strength,"Interesting discoveries are made, e.g., the authors find that ET is a preferred pivot than LV in LIV-EN translation. ",77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
3d2846d4c1ce6510aeb7b8c7cd44bd7a8c93e36c3fc1e0ee9d47226142da257159410e132ce023c72a675696e1fd5bb7abfcf5f86d469574a90000553ee066d3,arr,Strength,"Overall, this is a solid paper that presents a useful resource for exploring the ability of current systems to handle long term dependencies. ",134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Strength,"The experimental results are promising, demonstrating the effectiveness of the proposed method. ",166 167 168 169 170 171 172 173 174 175 176 177
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Strength,"The paper points out a promising direction of improving retrieving subgraphs for KBQA, which receives little attention currently.
",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Strength,-The authors compile a dataset (Spoken-CoQA) to evaluate SCQA problem with much bigger sizes than previously available datasets. ,171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Strength,It is a nice try to introduce the motivation of this work by an experiment on a toy set at the very beginning. ,118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
213b9cca0e60464a6df2e0460482e5abef613f236f1a37cf58a6772b76b033655b1d3233312a85582f5be4fc74d1987b77098222d27bc0768a3afab1930b14c2,arr,Strength,The analysis before and after    training is strong and insightful. ,163 164 165 166 167 168 169 170 171 172
e98fb117fe41ef1ad9ab1de71467e6a101280857b649e488d537b1d56694d0fda758df2344e2c13b1cbfdccc3a1fac74b6f2b64d4f219d1f256c93f04702feb1,arr,Strength,"Human evaluation also corroborates the proposed model’s superiority, though the improvement becomes less significant. ",193 194 195 196 197 198 199 200 201 202 203 204 205 206
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Strength,I appreciate the authors for the efforts of adding extra experiments and writing the response letter. ,99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
eb30dde3dc47f3562b84e87a5a5a99053ed6132d71aff1869b3037d09d9d40f79317d3c626808a078709460de2c049cbe0aa99eee589995016a705f6f9d40dd4,arr,Strength,-The paper provides an extensive analysis of existing MT systems on the basis of the dataset. ,72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Strength,The work shows that some GROUP robust approaches like IRM can efficiently tackle the problem of temporal concept drift as well as the more computationally expensive label-attention-based approaches(WLAN). ,111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Strength,-appears to have good command of the state of the art. ,155 156 157 158 159 160 161 162 163 164 165
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Strength,Strong baselines are proposed and evaluated against and a very relevant and useful evaluation metric of example-F1 is used to compare model performance while allowing for accounting for multiple different hierarchies in the labels. ,257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
fb8abed24b895c60af95d65f500024e37b39c870800b09362cb415350eecdb493573e965cb693012ce459c254f4446514a17effdbceccb50b7ce870bb3bc6119,arr,Strength,  Experiments have shown the method to effectively improve various base models for link prediction. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Strength,2. ,96
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Strength,Principal strengths of the paper: 1. ,243 244 245 246 247 248
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Strength,"This paper analyzes the effect of latent variable sizes, sizes of K in top-k sampling and different combinations of position embeddings, which are helpful empirical observations for training Transformer-based variational encoder-decoders. ",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Strength,2. ,120
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Strength,"
2) The improvements over the previous approaches are considerable with interesting analysis. ",59 60 61 62 63 64 65 66 67 68 69 70
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Strength,The comparison with other work is sensible as is the choice of baseline tasks. ,63 64 65 66 67 68 69 70 71 72 73 74 75 76
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Strength,S1. ,59
ce67bb03e40a4cb585035890d55be2d05240f7adac74d42a128163bf2da6fb5aaa06f54690655904e48dfa3e8e8d52de6d2b888a1a626b9b87ecb5f9584ab004,arr,Strength,"I suspect that some controversy because the author's metric is i) model-based; and ii) trained directly on human ratings, but the authors make a compelling case that our current metrics simply are not working for this setting. ",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
d1921e5f5febc1efa6ccd005802a9c3efc66b8840ed104fdcade7b07f9f498a3eee437ee46bfdde58663ee7bf9cdaab4873670ba950b1a71a31bdc9388fbba99,arr,Strength,-Extensive experiments that validate the effectiveness of the proposed method ,132 133 134 135 136 137 138 139 140 141
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Strength,The promise of open-source gives assurance of reproducibility. ,112 113 114 115 116 117 118 119
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Strength,Furthermore the analysis presented in the paper is concise and complete as well. ,66 67 68 69 70 71 72 73 74 75 76 77 78
e0111eb824f3bc8901645731c84d882dd0ac2f5052557e28e1b41ef6c2ace7e360932539c4132c61dd5efaaa60eec8d20a141bed6fed819083cfd74de2ebcdc9,arr,Strength,The strengths are as follows: 1) Very well written paper. ,25 26 27 28 29 30 31 32 33 34
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Strength,The paper provides initials answers to an important open questions the field of brain encoding tasks from language stimuli. ,58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Strength,- The task is novel and the proposed solution is effective. ,181 182 183 184 185 186 187 188 189 190 191
4a1c1a54db4c8630e04e4e5f045f69749e7bf8d6b6bf7fe1b5abc8f64b63aac51dbe6e0e4f0a4a667815ef7b8e80d00ca2eac00026243514c420f95834081e42,arr,Strength,"It studied how to transfer CLIP zero-shot capabilities into VLU tasks and confirms CLIP models can be good few-shot learners.
",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Strength,"- A technically sound method to improve Event Detection by presents trigger saliency attribution that can explicitly quantify an event’s contextual pattern.
",67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Strength,"Thorough experimentation, spanning 3 languages and different modeling approaches.
",106 107 108 109 110 111 112 113 114
be029c5b5b401b32dca6810ad032d5c818265bf0f870881a067b97ab5f5ab0a1ff6fdfd6efd2f5c6308d7214c27236e28e2cf59c0e7b49a683325d53fb6ab349,arr,Strength,"Figure 4 shows the different representations of CE and LaCon, and it can be used to explain the reason from a perspective of representation learning. ",170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Strength,"-A very comprehensive evaluation is provided with a good selection of datasets and both automatic and human evaluation which show the model’s clear advantage over baselines.
",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
d3b37745fdec7312511c9e49b025b2d0cecce17cbaf44ed08677185cd690cf916b28e414c20a903c10f10dc89a98693ee077bd84e93faa87cd33731b088d04d2,arr,Strength,- Important and valuable work ,72 73 74 75 76
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Strength,"
2. ",121
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength,-Automatic Evaluation (Section 2.4) and Human Inspections (Section 2.5) are conducted in the dataset construction process to ensure the data quality. ,184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,"This paper reveals a new perspective of out-of-domain generalization on the text-to-SQL parsing, which I feel is a practical problem and valuable to the community. ",131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Strength,They provided a detailed analysis on the results and discussed the potential implications for NLP and Cognitive Science researches. ,52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Strength,(1) Ethayarajh (2019) https://aclanthology.org/D19-1006/ ,232 233 234 235
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Strength,"
3. ",113
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Strength,"-for Table QA, the means of representing the table's header hierarchy in a logical-form is novel.
",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Strength,"
2. ",160
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Strength,There is also an ablation study to analyze the contribution of the individual components of the model. ,101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,"
4. ",287
0db51440a48c9e4de5dd6ddf46099151432764b515c4c534b6c3dd3c7abaae9e2a9c6fdd35a710d1cac40eb661eb2f84279ba5c7fdde3d94e78f0ee0c4fe015e,arr,Strength,- the authors present a new corpus with coreference and bridging annotation which provides an interesting dataset for exploring this task ,89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
1aa7fa614cb1a09ab64c839bf6b5dd108114982fa670d578ff519ad94713573af7a859e5884c8519f77fc5b714d66e4c035e91acc4eca2f5809bf761ab834e41,arr,Strength,"- The proposed lightweight model achieved strong performance in multiple controllable text generation tasks.
",114 115 116 117 118 119 120 121 122 123 124 125 126 127
fb8abed24b895c60af95d65f500024e37b39c870800b09362cb415350eecdb493573e965cb693012ce459c254f4446514a17effdbceccb50b7ce870bb3bc6119,arr,Strength,"  The description of the method is very clear, with nearly all details well-explained. ",76 77 78 79 80 81 82 83 84 85 86 87 88
0ac9820142b39e37945bfc25038d562d36d08e5407ab516a8f8eb18cc7a696601df7e15caa23159bf9ef420a1e65efadf3778d71d4aa95df26226ff49de26bb3,arr,Strength,- The paper is well-structured. ,61 62 63 64 65
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Strength,"
4. ",310
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Strength,The contribution of this paper: 1. ,78 79 80 81 82 83
5a2c468d42a1d327d15cde4be8dfa3b3f2024ba2dd4889191b47d642f341cc72dd9eaff4f056d7f9f33a4c085bca790e7fe3709f69568617ea9ab97b3d202a52,arr,Strength,The paper offers an intuitive extension of MCTS for controlled generation that doesn’t require fine-tuning of a language model. ,73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,"While this may boost research in this area, this new model can also help in developing new research questions. ",123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Strength,Well written and easy to understand 1. ,185 186 187 188 189 190 191
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Strength, ,
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,These results demonstrate the power of this model across a diverse set of problems and corpora (across the world) and the need for a domain-specific language model in this context. ,254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283
4983c10973bc21ac0b8b463ef670ca8459c7b43374d72e4a71c209ef7d013798a1fecdd1952db60b58c5355c0354c48dd7907e30998421c7c5c192810d7877a2,arr,Strength,"Especially, the boost in terms of the success rate @ 20, 5, 1 on NQ looks good. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Strength,"Overall the paper is well written and clear, providing interesting insights on the effects of moral framing on persuasiveness. ",187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Strength,"Through well-motivated and relatively simple modifications to the vanilla PLM-based KG-to-text models, the authors are able to achieve SOTA results on 2 large public datasets (WebNLG and DART). ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Strength,The paper is well written and well-motivated. ,68 69 70 71 72 73 74
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Strength,"The paper conducts rich experiments and presents several interesting insights, which have a certain value to the community. ",45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Strength,1. ,60
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Strength,"-Multi-reference and multi-source (multi-domain) dataset.
",176 177 178 179 180
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Strength,"- The experiments show the effectiveness of the proposed method in most cases, outperforming several baseline methods in automatic evaluation metrics. ",277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Strength,"This observation reminds me of the intermediate training empirical paper, where in Table 1 they find that QQP is a very different task compared to others: https://arxiv.org/pdf/2005.00628.pdf ",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
4d5fa3ee481b64dfb8c94afe7d4c2cc4accc18a0de05c6d384f60fe12b9e17d728296cddb1eca99970fa6e7fc7c8253a952411295d54db19877e743853abf5dc,arr,Strength,This will be valuable guidance for future research and implementation. ,146 147 148 149 150 151 152 153 154 155
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Strength,-The paper provides insightful studies on how knowledge is stored in pre-trained language models. ,152 153 154 155 156 157 158 159 160 161 162 163 164 165
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Strength,The paper proposes to leverage Optimal Transport (OT) to find similar samples. ,92 93 94 95 96 97 98 99 100 101 102 103
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Strength,"
2. ",116
a2b8425216b033d2765410e4f0cc2c075850a59fbd8c5394ff5a8fc7fae9bbabd75c9e5e269dbb434d4af5d4ded2ae34fcf7a5cf3dce546b75a8349a077a521c,arr,Strength,Multi-span question answering is a new problem in machine reading comprehension. ,39 40 41 42 43 44 45 46 47 48 49
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Strength,- detecting stereotypes and biases in the pre-trained language model is an important problem in contemporary NLP ,69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Strength,"
    - While the original CLIP paper shows strong results on the visual modality, the text modality is left mostly unexplored. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
1a78877afd22d0616b89584b687d567dc6f161f1e8c47d409b6753dea1110a268d1a5e116c54e49bc4737022dfa9d0b245f8527f4b57d3b54e6b78bab70498ca,arr,Strength,"The idea is quite simple but effective, we do not need to add new layers or parameters to boost task performance. ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Strength,"Besides, the authors confirmed the necessity of the components of the proposed method through thorough ablation studies. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Strength,"
	* The paper is very well written and easy to follow. ",72 73 74 75 76 77 78 79 80 81 82
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Strength,"•	The paper is well written; the experiments are sound, and the task seem interesting. ",95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Strength,2. ,80
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Strength, ,
4cc4700c648f621fe89d303cbb1db1764efbd3c86208ed01753a8c3f7a7f66b853ffb2f025681819abfb30354a784bb48fcf70f5b99df7f0adbe05153934bbe5,arr,Strength,"In the context of generating adversarial attacks, this paper successfully addresses the problem by adapting several useful search-based methods for its needs. ",164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Strength,"
1. ",176
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Strength,-the strategy of training QE with complementary tasks is novel  ,151 152 153 154 155 156 157 158 159 160
555b9b4626e46bff6dcd1dd669cac930e4e3c587766a39059797b4d5100a130d8c7aa4ee67cb74e7ebc5a9126fed58d4b54ceab34144da5a84f5d402acdf18af,arr,Strength,Using the discovery that quantization produces homogenous embeddings they create their contrastive token distillation method which is shown to improve the generator model performance heavily. ,68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Strength,1. ,127
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Strength,- Clear description of the crowdsourcing pipeline. ,163 164 165 166 167 168 169
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Strength,The main strengths of the paper are as follows: ,116 117 118 119 120 121 122 123 124
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Strength,"Its usage of variably-phrased prompts for relational information -- to me, this truly encourages robustness in isolating neuronal-capacities. ",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315
da389b316edeba40a6455a3d78a9801d6c40eeca422c96cb5ed9da63c8e6d26742ac851d37777d2b9f0ce187f8d6e9ff5457c3444e4fa409188e582e8cf878bb,arr,Strength,"The paper is thorough in what ARA experiments are run across different paradigms (classification, regression, ranking) and transferability settings (monolingual/cross-lingual transfer). ",76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Strength,"b) Experiments are comprehensive (covering a wide range of approaches: LM-based fine-tuning, prompt-based generation & transfer learning). ",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Strength, ,
74af24c1125fd63845d8b3d8cd1945f8ee33cf98b237e2309548d6ebe615ecf2d2efec22bd4100681a90c170d5f347dc81c7717571b7cf3c849f5a34f744eed0,arr,Strength,"
3.The author conducted sufficient experiments to verify the effect of the model, described the experimental parameters in detail, and compared with related models. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
54234d38c62b4cc488d849bd76221bc6be72b86c2e4a2097099f2aa66b9fdf046c7a5a76e32416cc19a86125d08f89f13e23f75b74af6e96e5cebe933fb3eac5,arr,Strength,-The proposed method for intent detection and transition turns are also correct and interesting ,123 124 125 126 127 128 129 130 131 132 133 134 135 136
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Strength,"Also, the inference speed is maintained --- comparable to the original base model GPT-2.
",263 264 265 266 267 268 269 270 271 272 273 274 275 276
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Strength,"The results indicate that using these methods results in significantly more diversity in the output candidates, which based on the higher oracle ROUGE scores, has the potential to improve performance given an additional re-ranking mechanism. ",155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
64d426bdd2237b1a76367942d93054e27cbba57122d341c186e2724c64f32ea70276be64edd40415fcfa2a55ffb540f5d6e8d89acd4ac1bf95878ac359286fa7,arr,Strength,"- The paper obtains good results with a straightforward approach.
",64 65 66 67 68 69 70 71 72 73
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Strength,The main research question is motivated by efficiently and clearly discussing pros and cons of the previous work and how the current work is related and differs from them. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28,arr,Strength,"
The method proposed allows to fast and accurately reuse human constraints to boost post-edition performance. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Strength, ,
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Strength,-The proposed method is model-agnostic where a variety of models can be chosen as the backbone summarizer. ,179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195
a08c0e0dafb5d74615009802dfc40b3801cc6a3f779b82e40b03a3f4c3f3bef3a4186e50fbbc8ec1a5364e61382882c08f2d7b7d4689d743a8b74728f99da313,arr,Strength,Experiments require a lot of computing resources and time. ,75 76 77 78 79 80 81 82 83
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Strength,"
Extensive experiments. ",93 94
d9bd95358dcf0881bb6ed180dd79569f265a878838b010134d2c0f3f5a90abed17f92e05a724ede37c041d901a18cb4a8cf5900ace47ae097547abbe69dd776c,arr,Strength,"- The proposed method is a natural extension of prefix-tuning Li and Liang (2021), which focuses on parameter-efficiently learning of conditional NLG tasks (e.g., summarization). ",202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Strength,The paper represents a compelling attempt to test and build on an influential theory of the cognitive science and policy implications of moral reasoning. ,73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,The paper is well written and easy to follow. ,87 88 89 90 91 92 93 94 95
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength,-The dataset and codes are provided alongside with the paper. ,230 231 232 233 234 235 236 237 238 239
52ea8e6e91e0a5b33e1b58dcc0e251c51a5fdc89bd5f48c548609a3b710f2a69058a340fe9fd77f0cee7817f075aaee98379c43c50da6fb11f3d5ad8320d2844,arr,Strength,-the proposed dataset appears to be of better quality than existing resources and contain real-world examples rather than artificially constructed ones ,86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Strength,"Nevertheless, it shows another promising result with smoothed loss landscapes indicating sound machine learning settings.
",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Strength,"Its demonstration of knowledge update (and erasure) via simple modifications to the knowledge neurons, further ascertaining their sensitivity to relational information. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Strength,-The proposed approach of using a synthesized language as L1 is creative and reasonable. ,212 213 214 215 216 217 218 219 220 221 222 223 224 225
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Strength,"
3. ",146
bbc7e938f5511eb8eb8e30da3703e87c3cd679b48fdeb1b7c4931da181700027819be3024fdcff95be8685f1e59bb362f0912ee5e679d30c3562319741bf906f,arr,Strength,This paper focused on investigating the relation between human and machine attention mechanism which is a very interesting research question. ,32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
be6cec72e91dff753fdb9c845d57338bd9d32961eeeacc641530b7a6aa22fa6525b9a716e40cbc57d6ae3361e2af59063cbdfa0ea75f5c5def773d0ac9671733,arr,Strength,not optimal) ,104 105
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,1. ,122
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Strength,The evaluation takes care to evaluate not only compilability but also the generalization of the model and its general fluency. ,124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
883cec982be6ead1ee077df92d0d08618b52f2c4d4c39b923d78fb412dcf88496ff4894080de73f3c786310afcab26fa9e04cafe7020c5561b3835c375a0fd0c,arr,Strength,"There are a lot of mathematical notations in the paper but the authors defined them clearly, explained in detail, also showed the some necessary derivations (in Appendix) to help the readers to understand.
",56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Strength,"Overall, this paper is well structured and written, with carefully designed experiments and analysis to show its effectiveness. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Strength,2. [ ,119 120
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Strength,1. ,98
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Strength,I genuinely enjoyed reading it and learned from it. ,90 91 92 93 94 95 96 97 98
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"I've checked formulas in the cited source: LeCun et al., 2006. ",151 152 153 154 155 156 157 158 159 160 161
aea5e354009988855fb1ed90eae3368a080653b4dc1b833313cd75a00e0ba3236f3b6f91f47b04ae511c7e9e99cfcba936159fb7f8630ca3cffb8ad2d6d5e1e7,arr,Strength,"
To the best of my knowledge, the proposed ""Weighted Learning"" approach is novel The experiments are thorough and convincing, especially as they include a human evaluation ",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Strength,"Moreover, when it comes to computational argumentation, I believe such implicit assumptions like the ones at the core of the paper are of enormous relevance and still a bottleneck in the NLP/Argument Mining handling of real-world data.
",266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Strength,"Also, I like the teacher-student approach (called Knowledge Distillation) which enable them to overcome the noise that came from ASR. ",141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
fcc2d390db2717ce8d77836ca10248ee73a8d94600bd9528cef5d26d16f18393f230b60463fae854e5f652936577b5b37ccc698e95ca831fa89d8e7a12079552,arr,Strength,"- In Table 1, Conf outperforms TP (model probability) for all language pairs.
",51 52 53 54 55 56 57 58 59 60 61 62 63
24cde1dedea013072fff85d4bf4c927680cb8964f789735ceafd74b11c97f246100d67ec2f07281c8b3473e05c68b8b452df437d66427d592fdef924e66faa3d,arr,Strength,"
3. ",262
802e97a5cf30c788ecd057534551263ee9b8004fa6a796e6e0e3992c3b55736b32c408efd5e716713ebac1b6f70dc54b8a38da4aac60da48935f1921b5950bc8,arr,Strength,"
•	The mathematical formulation of the task and the different approaches are nice and clear •	The baseline comparisons are also good ",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Strength,The paper is well written and easy to follow. ,157 158 159 160 161 162 163 164 165
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Strength,"The use of publicly available resources, including the dataset and the various implementations, ensure a reasonable level of reproducibility. ",363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381
d56327f333fa416b66ecd9e532a5747c6a61472772c62fce30b75fd6d878e381378a9bcfc9912f4140b9bf29f81b4bd2a3587355076e64f16f8c3b9af9888343,arr,Strength,1. ,173
696b485553604279f62f15fcd651910e1d2e7cff91c06112861936b446cc262d34329f49aaca63dc43347c04038603b687967d1ef0536226e754b0bed5ed85b2,arr,Strength,A well written and thorough paper. ,87 88 89 90 91 92
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,The paper is well written and easy to follow. ,602 603 604 605 606 607 608 609 610
3406e6c5f3945b41904f679288d013f0a61a5798a346d9090b1ff8655adc82320fd631652835300af7c312efefd0492a22270330d3314c42cc83412b338384d5,arr,Strength,"-Method outperforms competing methods in very-restricted-computation regime (that is, when very aggressively early-stopping inference forward-passes).
",333 334 335 336 337 338 339 340 341 342 343 344 345 346 347
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Strength,The solution to regularize this problem with smoothing technique for span-based NER method is sound and well justified throughout the paper. ,135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Strength,"
Promising results are reported when comparing with the baseline without injection of HiStruct information (e.g., longformer-base/large vs. HiStruct+ longformer-base/large and etc.). ",139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159
965bb5a3ad429397e09f06916178735cdbf9f5aed8c2b60c72d87a3d9d338f2d4ca3268441e9dcb732a06483a4c04e6a5de3b7b6d4961b98f2e3992276f45a18,arr,Strength,Demonstrate the effectiveness of pre-trained self-supervised representations for AVSR. ,99 100 101 102 103 104 105 106 107
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Strength,"Although the employed baseline methods are kind of weak, the improvement is significant. ",273 274 275 276 277 278 279 280 281 282 283 284 285
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Strength,1. ,52
6db5d3547297644e1a01b2dd191f13fced41cc86ff3a74d59ca05167091c7b4bbe9f67ec055106ee390fe9cdb497d99a303a97c2d53e008f5f89e93f722c3fbb,arr,Strength,"The proposal is novel and i aims at building a more transparent system, where the reasoning behind the final offensiveness label is actually explicitly defined as a sequence of steps. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Strength,There was a slight improvement in the experiment. ,41 42 43 44 45 46 47 48
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Strength,"From a CL modeling perspective - the authors have crossed all the ""t""s dotted all the ""i""s. ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,	The proposed SpeechT5 achieves multiply state-of-the-art results on spoken language processing tasks. ,135 136 137 138 139 140 141 142 143 144 145 146
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Strength,"
3) LexGLUE could also encourage future work to push towards generalized models that could handle various legal NLP tasks with limited annotated data. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
57be2198126878a18babe30d9bd4b0c9a717b881ff82c57c5fead6b67462b444fd061ddf8fef7717ff6d3195a2780116e2847a3eed67d6a06745d823de8d13b2,arr,Strength,"This paper is an interesting, relevant, well-executed, and well-written resource paper. ",105 106 107 108 109 110 111 112 113 114 115
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Strength,The new task is more sensible compared to the originally proposed one. ,124 125 126 127 128 129 130 131 132 133 134 135
9bc6d4dd35f310f39d10eced299931862d56f8b7fb6ef1f70faa2a076ccf69fecf47fc38e675c8ac44032eda2ceb815ad58fc66224b746c4360708b016ed0f11,arr,Strength,- The two-stage training strategies in StableMoE are simple and effective to reduce the routing fluctuation during training. ,201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,"However, according to my knowledge, the baseline model RUN (Liu et al. 2020) was experimented on four different datasets, including two used in this paper. ",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,2) The proposed architecture seems to work and yields performance improvements. ,76 77 78 79 80 81 82 83 84 85 86
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Strength,"This paper shows a bigger picture in the speed evaluation of NAR models, with more settings and test-sets, we can get a better understanding of the merits and flaws of NAR models. ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105
da61b78a56b46de33bf7689fd96f96be920301e62fddbf78071052d852a3b2ed293376a5a5d97c7a3cc116690755765a88a45895b9ebe23bd819728b5d5fce1d,arr,Strength,The approach does try to address the real-world problem of error propagation due to ASR. ,64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
278244beef48eec4eaa702065f5c8459af91a42a44afaa0282e4f5340bbed358cabb54f5e516d16bbf8aa9e6ce27a273fa48c3ce18cfd53e63c9cf9682eee35f,arr,Strength,-Table 3 demonstrates the gain of each component of the proposed method. ,65 66 67 68 69 70 71 72 73 74 75 76
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Strength,1. ,125
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Strength,"
All metrics and results are gotten from previous work and others are introduced in a sound manner, based on investigative findings. ",108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Strength,1. ,62
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Strength,"
2. ",77
0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c,arr,Strength,The paper is overall well-written. ,134 135 136 137 138
1c70e3101984616e0b4261c018caa01a791fb0d16096400b053c4c7e1ae3f9a2ff73caafbf97a49ff85c648c126a8962032f3ee59707d143d0f29d5ad9e66cbd,arr,Strength,"he analysis is well described and appropriate, and includes a thoughtful discussion of differences in observed behavior between word and sense embeddings on the various datasets evaluated. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
1616a1ec4c7080f25f27005712c7704d81e7a036d1982351322335d808a52b1105b12530dc00a9a6d0bdcf3c7f8b6c4cb3b0ab93f29f156600bc35e07cb100a0,arr,Strength, ,
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Strength,1. ,98
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Strength,"The ablation studies also provide a good insight into the effectiveness of GAT.
",347 348 349 350 351 352 353 354 355 356 357 358 359
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Strength,"Moreover, the presented problem is relevant to the CL community. ",69 70 71 72 73 74 75 76 77 78
3805bb3c1bb62fde1b50fcb9fb9b0a30909df091044a4b80def563ab966846051798d191a66c4a0aede43b6afd09436be1c15d0f272d34f03b25a24da892b49b,arr,Strength,"This is true for language pairs where translationese information is available, but also in general when one uses back-translation or self-training ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
bbc7d50e7c4592aede7965ad2efb2c10ddc356e8c699a6594d512f677e2b445182f6984b223cab77c78cf828973a49fefb240ca9fce6c28c55b8f8fa9d44883a,arr,Strength,-Comparison with a simple baseline of adding a global noise ,97 98 99 100 101 102 103 104 105 106
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Strength,"
2. ",184
e3d637ae00e884f73e2173bc7a3275fc64e6b4cebfeb5ce730bf7a0f5a5700b431143167c7893ae4b373f928b4104531662f851ff665d1d2174c5bf8d5d95036,arr,Strength,"Although the domain is niche, since the authors do an extremely thorough job of thoughtfully constructing their data set with expert annotators and guidance, agreement-measurement, and validity evidence, this paper should serve as a model to the community with respect to how to compile similar data sets.
",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
b1fb88206c3832e9f87e6f8115045f3478d45617776f8397f37664d4de722806db84bff9744f31328a47ad99443cf3b52355d950d9e6fa09b9747dbb3b9f4f21,arr,Strength,"
The findings of the diverse cross attention pattern, the conciseness, and abstractiveness of produced summarization pseudo-labels as well as the attention focus of the teacher model help future studies develop better summarization models. ",112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Strength,This paper is well-written and well-organized; the readers could easily understand their methods and statements. ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208
090711ce39f919422e42d87e2e3fa3cccbf75b88410abc41df2d59108aaf42fc60cad2dfe6ec51c72c72891fb40b2cbd8b2cadd48c6a89c6a25f7f41b73df96b,arr,Strength,"-The collected dataset could be useful for multimodal research.
",77 78 79 80 81 82 83 84 85
e41e88092bada9f75b4ce8778855411e128fea782712d728ff13b90f98386e6c97f5b383da31df5f5ad9aed07e2e3af42ad0fe8ce53e7dc9d81130c9d24a351e,arr,Strength,The paper is clear. ,58 59 60 61
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Strength,"-The paper is easy to follow and well-written.
",102 103 104 105 106 107 108 109
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Strength,The experiments presented in the paper are extensively evaluated. ,143 144 145 146 147 148 149 150 151
cef38cf1ce556879df7ee50de2bb4b1dd8f64fd063748c48843394191072c5e746d815f659c139920513eb500f984ec1852fd6fe10d93b440e5ecf8478be1c7d,arr,Strength,"Extensive experiments, clear and significant improvements. ",121 122 123 124 125 126
d0cc8331654d1d5fc3e0abc01c1075a74c2c42f1bb0863ce64825b34380ce2c045eea4b622f0750b906fda8d8a366fca26131b055b58fbc96a342e681f17cc3d,arr,Strength,"- The paper is well written and easy to follow.
",47 48 49 50 51 52 53 54 55 56
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Strength,It is a hybrid between seq2seq generative modeling and explicit edit-based modeling and tries to leverage the strengths of these different groups of modeling techniques. ,165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Strength,"- Long-passage QA datasets are harder to collect and relatively scarce, so the new dataset would be a valuable addition to the field.
",86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
12ec0f57b4ee64a40bb4c0eacd7edb0ae23929428bbd17607c8439082b8447542bc5708ba691d6ac06352d84f3a05bdf28e0db59cdf9cee8628f95fc0774e5af,arr,Strength,- Novel analysis detailing the frequency of hallucinations and the different response types associated with hallucinations ,59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Strength,"-The analysis is comprehensive and interesting, and some of the conclusions align well with the findings in NLP tasks. ",172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Strength,"
2. ",153
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Strength,"-The dataset is a useful resource for studying framing bias and multi-view summarisation.
",155 156 157 158 159 160 161 162 163 164 165 166 167
e41e88092bada9f75b4ce8778855411e128fea782712d728ff13b90f98386e6c97f5b383da31df5f5ad9aed07e2e3af42ad0fe8ce53e7dc9d81130c9d24a351e,arr,Strength,"​Well-designed corpus, experiment, and result analysis for an important task. ",27 28 29 30 31 32 33 34 35 36
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Strength,"
4. ",155
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Strength,"-The authors conducted comprehensive evaluation, including the automatic evaluation and human evaluation. ",106 107 108 109 110 111 112 113 114 115 116 117
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Strength,"
2. ",95
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Strength, ,
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Strength,"-an annotated dataset is build for this task, which has an indubitable value for the whole community.
",128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,"The experimental study, as well as the discussion, is comprehensive. ",267 268 269 270 271 272 273 274 275 276
e30201431866f3b1a09a1473e77c49c7cddd0a4ab6fe70f0911441538b1c7e8dd9d3ae744bf68f1d29cd4d221570d1185cdb54f7701c2de9d0c8e14a66c789b4,arr,Strength,"Overall, I think the paper is a nice contribution and can be of interest to the community. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Strength,Its evaluation of the robustness of the identified neurons by differentiating knowledge-expressing sentences from lexical and syntactic co-occurrence. ,317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Strength,Sufficient ablation studies are conducted to show the effectiveness of several core designs. ,85 86 87 88 89 90 91 92 93 94 95 96 97
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Strength, ,
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Strength, ,
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Strength,"- The paper is well written, and the proposed approach intuitive and conceptually simply.
",157 158 159 160 161 162 163 164 165 166 167 168 169 170
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Strength,"Though Flooding method works very well if we search the flood level carefully, it is a very tedious job and could take lots of time if the size of the dataset is huge. ",51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
907bb7593104224261d1df65e3f291dcb5c30e7705e8eb9a5e84fea2c946839b7b8600e4bc515e1f6739530691cf29d48e515a94e4c5e2afd08d9d6ba6d0de57,arr,Strength,The authors apply their method over multiple state-of-the-art sentence encoding methods and show nice gains over many downstream tasks. ,137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Strength,1. ,147
d3bfb0d0dd9547c28c9023c8ef3535b8e7cbb628dca2edb1bb760a964114a916bf35dd34abb10b152f79b8be9c90dae0d0d1fb9035738b9902b7d0c9011fd966,arr,Strength,The authors perform extensive ablation studies and show how each of their modifications impacts model performance. ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Strength,1. ,220
1576b8dd8d9c8f76255acbcfdd27cf9c945b7563f0ee6a97d4f46e0604057850c9754efe9f2924d190e2723237d36c572baf6e8971f85ed0dfab74289106c835,arr,Strength,	Better results of balancing decoding latency and accuracy. ,71 72 73 74 75 76 77 78
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,It feels like a good alternative to OpenIE. ,149 150 151 152 153 154 155 156
a6b8a37e042a271d7644c7181ddf5e17f9e6481a6d344996fabe5074cfe5825232992ec497d01c700ccafa7554178f92df43afba14f75b60020e230b83319ff2,arr,Strength,"The authors have put effort in creating a large training dataset, as well as bringing several evaluation tasks together to measure progress for Hebrew NLP. ",47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Strength,"For instance, in sentiment analysis and text classification tasks.
",105 106 107 108 109 110 111 112 113
ebfe58b10dee02a1cb830e85ec7993f381fa88e9d1e70ec9eba24417b92fdbe8d20ae561d42fbcbdb17d4380fde7845f5850c3fd769aa20c15003fe18fcdfbf0,arr,Strength,"-Reproducibility to previous versions is ensured.
",138 139 140 141 142 143
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Strength,"For example, the original BitFit paper uses the entire training dataset for finetuning. ",154 155 156 157 158 159 160 161 162 163 164 165 166
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Strength,The area is relevant to several ACL communities and could be interesting for industry application. ,156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
17895a29154ef932b798525a3fdd7daff03be79bde1e53998bfd0955be1720f0a3151d0ddc1d02683ccd1bdab897ee17ad96bd9cc0f54486f77e05bdcd142729,arr,Strength,"
    • 10 plus  boost of performance over baselines on public benchmark datasets. ",44 45 46 47 48 49 50 51 52 53 54 55
f4fd93843b665513df9be69b38341a6407312cea1e77fad05cc54c07c73031dab1459620984100d59aa8d1b90d9712d1ab1de2efdc7887b20ff3f33e13bff393,arr,Strength,See the prior review. ,136 137 138 139
363d19b7089db8a3a208da8fe4a459c889c0b67f39a57361ddb4b8daf9f2e2f7728c238bdbd68e0f23f98e75f789a6086d19c5934d1f16de7da44fc260ceb34a,arr,Strength,Extensive experiments are performed to show the advantage of the proposed models. ,116 117 118 119 120 121 122 123 124 125 126 127
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Strength,The paper provides solutions for both classification and sequence-to-sequence models. ,67 68 69 70 71 72 73 74 75 76
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Strength,"- A novel dataset that will encourage research and development on the task of detoxification.
",111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
089fa4b7f0e4265532d65b1eea05ac48c8b82e01358b15feea59cf8855580971154b1b47fe6ad58eed10e64e8b2d89d6aa582d55e183b9fe28b3b25ec81b4fa8,arr,Strength, Choosing the datasets covering four different jurisdictions and five different languages could motivate to build generalized models as well. ,90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Strength,3. ,152
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Strength,"S2: Novelty of the work lies in the creation of a Reddit corpus to explore whether the conversational context affects identifying a comment as hate speech, counter, or neutral. ",81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"The language (wording, grammar, etc) is perfect (minus a couple of typos). ",118 119 120 121 122 123 124 125 126 127 128 129
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Strength,1. ,41
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Strength,The paper is well written and easy to follow. ,287 288 289 290 291 292 293 294 295
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Strength,"
-methodology clearly explained and good evaluation.
",166 167 168 169 170 171
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Strength,"-A number of baseline systems are used, such as traditional classification- and regression-based systems (where possible) for comparison ",47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
0e30497ecba61ed356a72b0213bc87e06347be6b0164284ff6f25182bf1e310ac082f086cd5e0d6455085d4bf4025289c6f66bb8555e953606e080663f2aa9c1,arr,Strength,"Previously, it is hard to clearly define the bound of some ""style"", while this setting avoids this problem with some exemplars. ",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Strength,"They also provide a new document-level dataset focusing on 3 phenomena: tense consistency, conjunction presence, pronoun translation. ",297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313
06ef2506cddbabc6f971fd981c0115e074e05625f96fb064ce1622e6ab08a5e9791a16985be5e61fe376bc3c2b29830e39a4bdef10b30a4d56f36841397267c2,arr,Strength,The paper also provides a detailed and clear definition of this new task. ,222 223 224 225 226 227 228 229 230 231 232 233 234
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,"
3. ",196
a816dd1697f5524eb7e045216cd935593d31c1f257358ad67a2e01fbbaf92a12f666417c1c410aa8858ef985694d15444555daaf1179ec1b4b81fa3ca2adf65a,arr,Strength,"S1: Impressive improvement in both E2E and pipeline models, up to 16% and 6% respectively. ",52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Strength,"-Experimental setting is clear and well-executed, using several tasks and significance testing. ",189 190 191 192 193 194 195 196 197 198 199 200
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Strength,The experimental results are impressive__ ,237 238 239 240 241
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Strength,"As the paper mentioned, the idea is inspired by psychological linguistics, making it more convincing. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Strength,"The main results and analyses verify the efficiency, interpretability, and strong performance of the method. ",97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,"
4. ",601
d6fb6367ef7010836fe105bdb27e74b1faa76dd730c41be9ceaf2712af228d725c884676eaa86759d04fe2a2741b3591ac6810818af73331c9801e3a3d4ed6b3,arr,Strength,- The paper is clearly written and well-motivated. ,123 124 125 126 127 128 129 130
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Strength,"- The results are rather encouraging for a zero-shot model.
",190 191 192 193 194 195 196 197 198 199
7f07c676946fce33750102dff9084eb22690335cce66d938901042b61de0f4c8758de773a913eb4db0d502f321e734916ce7a38e97eb35d521121785ae758885,arr,Strength,"- The US subset, which covers the vast majority of the dataset, is indeed very large and commonly employed in Argument Mining, allowing for robust generalization. ",320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Strength,It provides a realistic learning/instruction-taking environment. ,116 117 118 119 120 121
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Strength,1. ,144
0e30497ecba61ed356a72b0213bc87e06347be6b0164284ff6f25182bf1e310ac082f086cd5e0d6455085d4bf4025289c6f66bb8555e953606e080663f2aa9c1,arr,Strength,"This paper investigates the few-shot controllable style transfer task, which is more reasonable in practice. ",72 73 74 75 76 77 78 79 80 81 82 83 84 85 86
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Strength,"Besides, there is also a research component to the paper (although the research component itself would not suffice for a long paper).
",340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Strength,This paper is clear and well written. ,267 268 269 270 271 272 273
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Strength,The authors present the debate using a line of thinking like a human in this paper. ,50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Strength,It relies on the solid framework of the IBM Debater technology. ,121 122 123 124 125 126 127 128 129 130 131
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Strength,"-Insights into which existing metrics today perform best, in terms of correlation with human judgments ",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Strength, ,
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Strength,1. ,235
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Strength,1. ,135
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Strength,"Well-written paper and good presentation for the method, tasks as well as analysis.
",74 75 76 77 78 79 80 81 82 83 84 85 86
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Strength,"
4. ",262
a94d622987e8d405f19ec3fcc83fb8245e20e1c0312b2bd8ba88bbdba88ca2da9d91c02b7f53d07dcd47ca998d2280e332a25de3b4446b07be3ab759a384de6a,arr,Strength,"The strength of this paper is that it uses a unified experimental setup to conduct experiments on endangered language automatic transcriptions, which have traditionally been conducted with different models and different languages. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Strength,"
3. ",148
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Strength,"-Demonstrate performance improvements against methods that are more computationally prohibitive or necessitate fine-tuning.
",92 93 94 95 96 97 98 99 100 101 102 103 104
dd23042b3a19ead6484687423764d8156f6ea40cec4ccceb6d27ccc6305223ed76957ad46eae750d95766cc378fb0b332d4fcd737dc810c4bee6e8823ca79884,arr,Strength,"The authors leverage two types of knowledge, monolingual triples and cross-lingual links, extracted from existing multilingual KBs, and tune a multilingual language encoder XLM-R via a causal language modeling objective. ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Strength,"The overall flow of the presentation of the motivations and arguments is smooth, making it easy to follow. ",93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Strength,"
4. ",177
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Strength,"-Propose a new taxonomy of related work sentences (S3.1.1).
",147 148 149 150 151 152 153 154 155
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Strength,The paper is Well-written. ,88 89 90 91
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Strength,1. ,91
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Strength,1. ,97
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Strength,"- The constructed discourse labels scheme is nicely detailed and complete.
",130 131 132 133 134 135 136 137 138 139 140
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Strength,- A novel approach that combines deep-learning with logic(ILP)  ,81 82 83 84 85 86 87 88 89
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,-Compared with different baseline models. ,103 104 105 106 107
ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42,arr,Strength,1. ,88
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Strength,"- The proposed method is intuitive and achieves good results comparing to existing methods.
",80 81 82 83 84 85 86 87 88 89 90 91 92 93
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,"Further, meaningful ablation studies are presented. ",70 71 72 73 74 75
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Strength,- Novel metric proposed ,158 159 160 161
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Strength,The results look strong (but lookout for some caveats below) ,145 146 147 148 149 150 151 152 153 154
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Strength,1. ,60
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Strength,"
The paper introduces an annotated dataset which could be useful for future research. ",103 104 105 106 107 108 109 110 111 112 113 114 115
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Strength,Ablation results are also shown which help assess the contributions of each component. ,164 165 166 167 168 169 170 171 172 173 174 175 176
15cebc13f46983afc2df307e9543c3de49d4f0bea1adcfbbe1b003ca287f1511cb80721c1ccbf929caad0b05394782fd9e3523bae2ebde66a10284a643bdf345,arr,Strength,1. ,49
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Strength,- The scenario investigated is indeed very useful as many endangered languages corpus is usually a single-speaker corpus. ,127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9,arr,Strength,The paper performs a comprehensive set of evaluations for cross-domain classification and provides good explanation of all the different experimental settings . ,154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Strength,1. ,98
ea50f866851bc980279933b91361218bdbef5b590e74e1434f5ac635278dd8bf8164c0e9ec061f3f26f042418adc92a494498a40b5eb37928417ade33231142a,arr,Strength,The proposed two stage training (pretraining + finetuning) is potentially powerful and provides a new direction in solving this problem. ,114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
38dbfe45b2ac09b26e98586f3703d45d0018c0b3041314a406292dcc678cd6d96a571c33fc968e3d99ddfe224c2856a096dc6dbc7a6ae54465912a5f4bcdb9e7,arr,Strength,-Authors also consider the training time/hardware constraints for each model ,180 181 182 183 184 185 186 187 188 189
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Strength,-The baseline models that the authors use are strong and recent. ,209 210 211 212 213 214 215 216 217 218 219
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Strength,"- To the extent of my knowledge, it is the first work that study model uncertainty (in the particular form of the variability of generated summaries) in abstractive summarization. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
3f55670117f852d49ec82b05651097f505030bccda7e569ee8cbb5028a58d9310de60ebd79b1333856c34d970949d8e8f9da80e4946c88b4fdba35981d418f52,arr,Strength,This paper designs an event-specific template for generative event extraction. ,66 67 68 69 70 71 72 73 74 75
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,"A synthetic dataset covering three domains (finance, sports, and science) has been newly created. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Strength,Research questions are well defined and have been consistent throughout the paper 2. ,26 27 28 29 30 31 32 33 34 35 36 37 38
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Strength,"It introduces more fine-grained labels, the tertiary claim classes and visual claim classes, in multimodal claim detection, which is the first step of fake news detection. ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Strength, ,
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Strength,	Natural instructions re-uses existing resources (instructions to crowd-workers) smartly. ,107 108 109 110 111 112 113 114 115
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Strength,The work is well motivated and enough related work is presented. ,47 48 49 50 51 52 53 54 55 56 57
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Strength,"-The benchmark comes with a rich ecosystem of baselines, a submission system and a leaderboard.
",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Strength,-Discussion of different vocabularies and tokenization in 3.1 and comparisons in the task performance results was interesting ,60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
7da87fbc09ca432853534fb954509bcfbb281e0157b3ab972a94cdc4b2de1506c33db6536c593c05371e635debb736d32c56dcfc075e48ed779db633476fefbf,arr,Strength,"- The paper is well written and easy to follow.
",125 126 127 128 129 130 131 132 133 134
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Strength,"The paper is easy-to-follow.
",247 248 249 250
3c69c73bc6af054c61a388e263b4764fcb6803cbf1ccff4783c6ae0d2305ba9f6a8a09c60caf98d77cf6debf039e1440671c5748cd270d6d84fa58e82190ba7a,arr,Strength,The draft investigates a problem that has not been previously considered in the NLP literature. ,24 25 26 27 28 29 30 31 32 33 34 35 36 37 38
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,"The setting of the experiments is good.
",108 109 110 111 112 113 114
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Strength,- Good writing and well organized ,29 30 31 32 33 34
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Strength,"- Evaluation on several different language pairs, which includes some diversity of character set / writing system. ",281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Strength,1. ,107
a2dbb4d1f528e4c6c48a51354adb882d3af65dffe69005a325d024c09982fd4dc72e38f8af529d3c0d8145db9095fa881f644d51f888c58b24b952fe51374be4,arr,Strength,Extensive experiments (with random seeds) have been provided to show the significance of the proposed methods. ,80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
21382763e074c2038343ff50e6e918aaf08b05b20610034ac8ad1a44cc57e35481f375543ea615000ed99556cbccd5c7465efd5019330d7e09ec79c3dbca0bde,arr,Strength, The error analysis is clear and helpful. ,58 59 60 61 62 63 64
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Strength,The introduction of Multimodal DST (MM-DST) is interesting. ,206 207 208 209 210 211 212 213
211261c10d10f85b9b896e332dd025bf6e68354ff6c14e3e6f5182d7a022616d626664247503843cccbdaa70b8fb3d6295ae3a6c41f4af8ce62735c38a791fa2,arr,Strength,This paper is generally a sounding work with the nice idea of cooperative loss. ,69 70 71 72 73 74 75 76 77 78 79 80 81 82
e6cb5ef05444c6a3c5d818ee69aa2e299991c9b9d19f559c71f61d53ce2819afc6356c0d544c0c671cb3da165ee1027c9e0a5c5cbeb4c2e645e2bde02ce33413,arr,Strength,"- The meta review dataset looks very interesting, and many researchers (including me) will be interested in playing with models trained on the dataset. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Strength,"The main idea is clearly expressed and the paper highlights theoretical insights and how they apply to real world examples.
",215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Strength,"The experiment settings, ROUGE score and speed are detailed. ",69 70 71 72 73 74 75 76 77
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Strength,"
4. ",208
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Strength,"
2. ",143
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Strength,"The paper shows how the state-of-art model performs poorly on this dataset raising the need to develop models which can deal with the practical challenges posed by the dataset.
",276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Strength,The paper is easy to follow. ,159 160 161 162 163 164
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Strength,"This paper presented a fine-grained evaluation set for stereotype detection, which aims to alleviate the conceptual issue of various stereotypes.
",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Strength,• The paper shows that a machine translated data can be a proxy for a human curated data ,293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Strength,"- Very clear and useful survey, accompanied by a formal definition and assessment of the desiderata for a proper evaluation metric ",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
2657a42b67131e9d0624d9f7e4de05db53bf2f459a325b9d3bef0cf25d163744e7f0bfbdded5ee0147497f4918b061d944936bd4244f66019d894a3ed76373b4,arr,Strength,-The authors provide sufficient experiments and ablation studies. ,62 63 64 65 66 67 68 69
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Strength, ,
ca178041ce19d9f64300b89d7168b8737f071bedfaec410be45427d6f3a936ed1c9887e942f9d20924dc6fc29cddfd9615a43cc5a35147a4c6d051fdd272c28c,arr,Strength,The experimental evaluation is extensive and it provides many insights. ,79 80 81 82 83 84 85 86 87 88
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Strength,Bioinformatics 37.5 (2021): 684-692. ,192 193 194 195
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Strength,"If the pre-trained model is released, it would benefit more research about utilizing multilingual entity knowledge by either feature extraction or extra entity features. ",107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
7bb3a2bd4904204c7a7e8c21d90da7ea82f935a368ca2ed42d859d6c1556c0886b83d74234b06f0b40f45c08beff47d157949cff9f32b0365be8f343b53b8565,arr,Strength,"- the paper tackle an interesting issue for the ACL community, and in particular, for the Argument Mining community. ",78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Strength,"
2. ",260
1aabeed5142e70ba517fcdcd99a98ec2b8cc181c3adc2d7e3835fc86b76f87ba809793d12e3007ed92591665ff31057928e7d9710e69f1a4790ff22521276401,arr,Strength,"- The approach is simple, powerful and flexible - a good idea for applying powerful pretrained models to longer text without truncation.
",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Strength,"
	* The mathematical development of the model is concise and easy to follow -- enough detail is provide for re-implementation. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
27ade04e48adbdafe292dc42dcd0079bc6cc9b986ef34831a41b64a820b26ddaa9a4b2abf509b1a98ac938bc6027ffdd605351274f9278e2fd3b1217a1350863,arr,Strength,The task is well designed and motivated. ,161 162 163 164 165 166 167
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Strength,1. ,79
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,1) The experimental execution of the paper is of high quality. ,47 48 49 50 51 52 53 54 55 56 57
da9f859a7a13fea1941d46d3cbfe47c7dfbc6325bf93b3f0117dada3fb06c50dc3c9ca15c4ad8d7ff3525640c9e43c457820bfa459301a5e25a2fc32aca79ab7,arr,Strength,"
1. ",184
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Strength,Quality criteria designed by the authors for these experiments do a  good job of eliminating ratings from low-quality crowdsourced workers. ,271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Strength,The paper is building on previous work in the relatively new domain of PLM knowledge probing (most citations are after 2020). ,186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206
41de6104b78ec0e5e0276873492a96de869f17ef90ebccc50f6e3e25475799fc3b2ae88f77fbd445dd127764a4e5a4492d9c47b4ca4db67bbc30250831c0ac5b,arr,Strength,"While NLVR2 is not saturated (SoTA = high 80s, human = high 90s), there's no reason why both of these tasks can't be considered in parallel. ",83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Strength,"-The authors show that, while the benefit of a stronger vision model is not obvious under standard MMT task, the vision model can help probing tasks.
",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Strength,The performance on two KBQA datasets is impressive. ,161 162 163 164 165 166 167 168
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Strength,"- Further, the exposition of this problem in automated evaluation is carried out rigorously by conducting a user study where humans interact with different CQA models - and the resulting human-machine dataset is another important contribution. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Strength,- This paper introduces a reasonable-sized dataset for QA in narratives. ,80 81 82 83 84 85 86 87 88 89 90
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Strength,"This paper has a complete logic, from problem definition to description to experiment to analysis, explaining the main idea of ​​this article in detail. ",42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65
a40d8ae07e3e76a77ca4f5a264ffbd75a5ba5c324557ec5e1ea3fa28b9291a45f9dbc7a16fe6e707c2b8c29ea3afbadb0fd88d29e8f49371789b082d8c27476e,arr,Strength,"- Addresses knowledge distillation, an important technique with wide application in machine learning, natural language processing and computer vision.
",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Strength,"Because the paper encompasses essentially 5 independent datasets, it a very substantial body of work. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,3) Overall the paper is well-written and easy to follow. ,87 88 89 90 91 92 93 94 95 96
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Strength,The method seems to be well grounded in a theoretical framework. ,125 126 127 128 129 130 131 132 133 134 135
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Strength,"-Clear description, detailed explanations, acknowledgement of potential limitations, good insights ",110 111 112 113 114 115 116 117 118 119
94d472d4e386f376d900d70bb07d8a7f8c8af01e33c50b35a8a4fd8dc6550e41e2dc8b1fd5eb9d2bac041ecc03226c4673fcb17f6dca642e209b855a1cce7ff3,arr,Strength,Strengths: 1) Detecting unanswerability in MRC questions is an important research question and using uncertainty measures over output probability distribution is a valid experimental endeavor 2) The insights obtained via the analysis in the paper are interesting ,196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232
a10d35763dca42f9e79c8e0caa0c46187df3879026bdd9c437fa21cb43f4713e871f77a5508c7aefe0c3ef70f3c71cddc20c64e692664edfc6ade6954ee36188,arr,Strength,"-The authors showed consistent improvement over strong baselines in several datasets.
",70 71 72 73 74 75 76 77 78 79 80
0e4cddf9f9f1024124f39aa563fae7995158e482a0dfcb0b75dc8df84e93e17cb0d29eb75d8222c361f0d263a909059ae6c03dd9dd22e8f2085996fa58243af4,arr,Strength,The implementation work is well described and highly reproducible. ,206 207 208 209 210 211 212 213 214
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Strength,4. ,145
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Strength,"While the idea of hierarchical modeling the input documents has a long history (Cohan et al., 2018), this paper has approached the problem with a novel way of utilizing section titles, as well as hierarchical position (HP) information of the sentences. ",89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
d8eba0a50dbf0d510674530ccffd1a8086be10e7ce3a069173ca04bfed6e539caa770621b48054d2d78fe897e61a2da069a2f544860f9272e126f2146e839a97,arr,Strength,"Applying the method on top of XLM seems to result in good improvements over existing techniques, except for MASS.
",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
8f644ad52cbea4b490c7523c970fb6c480f03b29b34a8685776a96b39e564b9cd475ec4883a236cea033b23df9795d8b15347a384842e3a0a6a261776dff0665,arr,Strength,"The ablation studies are convincing, and the results are promising. ",56 57 58 59 60 61 62 63 64 65
148e732f32b1256cfe3caadda83dfc870ab2ed5fa188a27d5e0f4aa8dc767df9f7b2dfc8bf3c999c8e223fecdc8b3b4c365b18dd9732f7f3827b2e300ed3d849,arr,Strength,- The paper is written well and much of the method is quite accessible. ,56 57 58 59 60 61 62 63 64 65 66 67 68 69
4eeedac91e83ad9a9dd5c33f4eb351f59106fc0d805db0f6728c7915e7a2d23a9568c1c771f1a7ee23acac720540f9a4e5ffb3c4d4d5b38e272dc530e0fc4ed4,arr,Strength,A good analysis of using QA as the pre-training objective rather than MLM. ,96 97 98 99 100 101 102 103 104 105 106 107 108
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,-I believe that the survey of existing literature is very comprehensive and covers most important works in this area. ,54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
f4d5395d46a0f2f0866fa4410edd21d000d1791f07ef488bea12fe58ae905b9bb44fd8d0b92f1da10bb6456a4dca4cf8ca35d0350654cb42b3a947b8edb49b7f,arr,Strength,"- The description of the proposed approach is clear and easy to follow.
",64 65 66 67 68 69 70 71 72 73 74 75 76
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Strength,"
2. ",140
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Strength,3. ,196
21d02d860d3c41a735ba26f974a0e310c16baafcfc7a8ce82f79b125122ddf18c34e8c4a93e91bfd5acec84719467f191b3c255adae45ad158f391824de7d33e,arr,Strength, ,
164a2a4bcf38ea9d10889f35373e43faeed96e075c0cfb11ad0e670ee81c3a89728bcf5d695ac8e65b152684176158fd265b9f7dd8f83a1fb4ae13a4160094db,arr,Strength,The results are comprehensive. ,78 79 80 81
1dd29ceec33836eb1c7b716ff5afa91342e5f1f6bdf61d45cc0f5b2aff5870b670a48843f1a4a49eafbe3749ede52ee8dcfa3d975754d0db66c299d1d3fe021b,arr,Strength,Interesting idea 2. ,189 190 191
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Strength,S3: Extensive experiment results are conducted. ,110 111 112 113 114 115
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Strength,-Approach appears to consistently perform better on the Missing Slot Error metric. ,79 80 81 82 83 84 85 86 87 88 89 90
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Strength,The paper introduces a new model for computing local coherence that outperforms previous models on three applications. ,50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66
364a28a87cf32839809cd6b243ee6bf12b5a6376bd31911dfc05752c4cebcdfaa0de227cb9d6a4677894beae6017f577d16db42eb5d5583d42afdaf2271e86d3,arr,Strength,"- Commercial motivation for automatic skill extraction is understandable and open-sourcing an expert-annotated dataset thus will be beneficial for the community.
",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Strength,"1) This paper introduces a conceptually simple and intuitive idea of Modality-Specific Learning Rates, which empirically works well for late-fusion additive models; 2) This paper presents layer conductance analysis and shows that layer conductance disparity between modalities are mitigated when MSLR is applied; ",90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Strength,"- The authors present a diverse benchmark for BioNLP in Chinese, comprising eight different data sets. ",53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
01ad9f64bb9ed7914538870cdbbd3c82e95fd62891aeda62db93ea449a649b1916a0f16d79ed40e9d1b75779c062c3bccb0255f2af2ca8a5f383eb7dfc4839a8,arr,Strength,I really enjoyed reading this paper. ,90 91 92 93 94 95
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Strength,"Different to prompt with few-shot samples, this framework selects the most high-uncertainty data while keeping diversity can be better utilize the information from unlabeled data. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Strength,The paper introduces a very novel and very relevant problem to the area and presents a dataset for the same. ,122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Strength,This strongly motivates the paper's subsequent modeling endeavors. ,228 229 230 231 232 233 234 235
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Strength,"
	* State-of-the-art results are achieved on the LAMBADA dataset, and the approach is additive on a number of other tasks. ",111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Strength,"
2. ",91
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength,"Besides the hierarchical tables,  ",180 181 182 183
e1272fb808dce19b87e53d9978fc22d89103c6067847e3bb24f5010baed38676fc34e894621686463eceb89666c05f06e925bc83838c6c4ed54263fb3041ce9d,arr,Strength,1. ,97
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Strength,-The authors will be making a new dataset public which would be a useful resource for the community ,162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength, ,
ce397a79b9eeb1079597d355633d6a8206fe5b47a1cbe8f6025b51e95b871d239039e086bdc2671c8cb11f1a0ec1062f294ab73d4265df71edc20657e258dacf,arr,Strength,I also think that the extension of the RAG system with a re-ranking approach is interesting for the task. ,124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Strength, ,
6b76cb35bc2bd13024fa5031e7733115a1278893aa5eae6d2154a3330e74e75d15dc13b52c93f40283b13ef2fbe9cb7d7d1a390d1edecdf353e789a8db9ffa24,arr,Strength,These answers are used to create the affirmative interpretations. ,145 146 147 148 149 150 151 152 153
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Strength,"The authors also find that in the finetuning process, in-batch negative samples have a bad influence on the performance. ",65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Strength,- A new multilingual use case for ToD that can be useful for investigate the behavior of speakers living in different locations. ,74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
046eedcedda44a5647ef7e7f3b013f1e94c5b64d5dffc205e6e87fa2f9d4a06a90f532982c89febb07eec523611a711006ed4830d48335621c6f8955096c6bb0,arr,Strength,The paper is well written and time is taken to explain all of the topics well. ,73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Strength,"
3. ",185
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Strength,The improvement brought by HASHEE is very significant and surpasses many strong baselines. ,242 243 244 245 246 247 248 249 250 251 252 253 254
0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869,arr,Strength,"
The idea of using example-based prompt for seq2seq fine-tuning seems simply focused and promising, which can be used for other seq2seq dialog state tracking settings, and may also be extended to other dialog tasks. ",137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
4b71ef5ed6c8af64772bcb6d6274a4af5fce058df82ca4593e4825002ce1701218b9be982e81fee4742e9ec63a3dc1da828bf095a8211e0f20b690ab084366fb,arr,Strength,Thanks for adding this - I was happy to see the results. ,91 92 93 94 95 96 97 98 99 100 101 102
05ba17b12c642edea83f5356e76705ea5a46df33ab99029966e87e8756d9a65f6565a009f23a020702d284bfd96e94a04ac5a833f31266134b1bdbf695f6e4d7,arr,Strength,The figures are helpful for understanding the different approaches and the proposed approach. ,171 172 173 174 175 176 177 178 179 180 181 182 183
7729b516d59a80fdcc230efda3594e7d74199b23fd1c8974e00b689d1986a774d0e91cdc18f67334ff5251574a41be2b1aa7c5c2ab713c5070debaaf89a6617e,arr,Strength,"-The authors show empirical success of their approach.
",142 143 144 145 146 147 148 149
0a5b410ba117cc9ddc6bb41d9c83d86e2e1d2a15a2b3a22d69803e9bba81a7bead1f8b59d3c63553e3a69616a6210727e0f5336ef2d2bd6be906a0a79414116b,arr,Strength,New dataset (and the first of its kind) for a relatively understudied task of ARA. ,116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Strength,"The proposed method also improves the performance, which is an added benefit to introduce uncertainty. ",118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Strength,"There is a wide range of analyses that support the claims of the authors, making this work fairly solid. ",145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Strength,Report 5.1% absolute performance improvement on new SQUALL data split using the domain knowledge. ,153 154 155 156 157 158 159 160 161 162 163 164 165 166
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Strength,It shows the advantage of the proposed approach. ,102 103 104 105 106 107 108 109
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Strength,"
2. ",140
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Strength,1. ,132
0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820,arr,Strength,"Firstly, the paper is beneficial to the NLP community, since it will bring NLP community's attention to the temporal misalignment problem. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Strength,"This paper provides a clear, high-quality annotation process for building up a predicate-argument dataset and it firstly introduces non-canonical texts, e.g., ZX, PB, PC, into the SRL task. ",110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Strength, This paper is well-written and well organized. ,160 161 162 163 164 165 166
f787fa8cde25eef91261df6ccc2e98ff30437a9ecd715b2cfbb913812c273c45d161b47fdd1c730c4e151be663bc118c6ccd02283b2b9e935a5014b0aa4c5807,arr,Strength,1. ,58
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Strength,- The insights derived for different modeling strategies and how they fare on human evaluation can help better understand differences and relative strengths and weaknesses of different CQA models. ,364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392
a59147f405b420806abb8f55cf417c2afe89a1a3aee1aaf0cc8ed31594691962febc00d35d85c018f8dfd11c675018610d2db4f45f745e2a1886d6409a152264,arr,Strength,- interesting user study with conservative and liberal audiences ,83 84 85 86 87 88 89 90 91
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Strength,"The authors connect their research well to previous work and, to the best of my knowledge, the related work section cites the relevant work sufficiently.
",178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Strength,"
2. ",158
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Strength,"In response to one of the earlier reviews, the authors have added experiments with Morfessor, which is also highly laudable. ",155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Strength,"The proposed method (i.e., combining partial weight sharing and compression) is novel.
",111 112 113 114 115 116 117 118 119 120 121 122
ac032c5ee706b2140d9bc0c18da0b4a84dde97dddeef31f3ec59cbab610782831f9b0983369a49f9d3f4dba22b2cce257aab07e6019f9b803484524a43895071,arr,Strength,"The framework seems like a useful high-level contribution for testing NLP models, and the graphical model formalism seems like a useful formalism for visualizing and comparing different testing approaches. ",220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
ce67bb03e40a4cb585035890d55be2d05240f7adac74d42a128163bf2da6fb5aaa06f54690655904e48dfa3e8e8d52de6d2b888a1a626b9b87ecb5f9584ab004,arr,Strength,"In some sense, the results are not surprising: of course the learned metric does better in the evaluation setting that it was trained in. ",104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
3b15e747f73612a95dd26fe39bfd033c9467dd72b4a86155882deec21f871e5c45224bf5d7dde89433839928db505d7730508ab61cae08d59f00ce013ac5450b,arr,Strength,Table 6 shows all the three backbone models benefit from the multi-stage strategy. ,196 197 198 199 200 201 202 203 204 205 206 207 208
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Strength,They also promise to release the data later. ,272 273 274 275 276 277 278 279
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Strength,"As it points out, researchers should try to adopt appropriate evaluation and analysis, and make credible conclusion about the limitations and capabilities of systems used. ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112
a0978ce3bfde73b6ed5cc30f72e8bf3b3ea4514b297d74fba6d6f7334bff292ab489aa2761182e12e92089f887085cc36837077012671f38ee00c899c11aa364,arr,Strength,"Overall, I think this paper is quite strong. ",116 117 118 119 120 121 122 123
4773827da540051debe65ab52a9b26ee346a3f259683316ae6f62b7d6d506a5947312df950b2459a8f7a107171c9ca75378b393537153fa31bf23c65e23e5035,arr,Strength,__1. ,153
919d93df080f1ef6cc593896bbfdfb9bf338b159f8f738972de24aadba271a0d8180c9e65474a388a6057ad883d71d783dce1618410ba18056a06e5b60138640,arr,Strength,"	This paper uses the Transformer structure for KG link prediction and question answering tasks, and this simple approach seems powerful. ",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Strength,The codebook update rules/policies are straightforward. ,73 74 75 76 77 78
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Strength,-The experimental results are strong and the authors provide additional analysis investigating their proposed methods. ,190 191 192 193 194 195 196 197 198 199 200 201 202 203 204
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Strength,-Nice ablations ,79 80
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Strength, (But not all: see below.) ,230 231 232 233 234
1f3ed846cf117ae2eecd5e3d9d19a85c37510c11c3463afa9ded734ea9f7dc0569a0ad64808fed511202bc3a62103801e85b7e7d14a8617220cf2ec989190cb1,arr,Strength,The experiments are thorough with convincing ablation studies. ,132 133 134 135 136 137 138 139
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Strength,3. ,193
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Strength,"This can make the work much solid.
",213 214 215 216 217 218 219
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Strength,-a resource annotated with their new framework that is made accessible for the research community. ,245 246 247 248 249 250 251 252 253 254 255 256 257 258 259
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Strength,"In addition, the included error analysis is helpful in identifying and motivating future work, potentially on when to reduce the aggressiveness of path merging. ",242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b,arr,Strength,"Namely, the amount of good vs bad samples is an interesting insight ",189 190 191 192 193 194 195 196 197 198 199 200
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength, ,
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Strength,"This kind of rigor is unfortunately often lacking in many papers on transfer learning, and I was pleased to see it here. ",155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
b534225047f18bbdcccd60249fa30bedb5b51bb7a1afc32075873c3a1d3be5b2821444eb29f42e68ea2f10fccd98a61f4f601df9f9be57ea6adea3f3d9267a3b,arr,Strength,The authors proposed a Locally Aggregated Feature Attribution method ,23 24 25 26 27 28 29 30 31
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Strength,Author perform additional analysis on the change of bias terms and find that tuning a subset of bias terms also lead to marginally lower performance than finetuning all bias terms. ,136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165
a7425617c20ec8b82cabbab5886a8f2876b0866ee40516e5d13aff840b8005e8f64ad2975d235365aba44f584cab472e792baa7e8d87f4ead4e28be7bc5e420c,arr,Strength,Ablation studies also show that NAUS is better than an encoder-decoder baseline. ,73 74 75 76 77 78 79 80 81 82 83 84
01a966ca7689800bb527da97e4518d9ec6c5d42ac4708085dd24321b2ec88f0e7c02384976698b0fa9684b1f31edc56366599541f0bfdc819906d0ee7f5c0533,arr,Strength,a) The paper outlines a novel transfer learning approach that employs prompt-based generation with pre trained language models; ,125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Strength,- The authors present a novel calibration technique in multiclass classification setups that leverages the entire train set (rather than a held-out calibration set). ,407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430
5e51a2ad4a8b7f52d8e38c3fb475a77f4cda084e63590f1df77c30688ada697ce19e7579ff1edeaf1d989dd2a36613e13c473e79ad3ff4f2cf35950a55fce4f8,arr,Strength,"
More importantly, the proposed approach is simple and can be easily applied to existing production enviroments. ",77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Strength,"
3. ",157
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Strength,"Unsupervised system - different components (models and datasets) can be replaced, which makes the system less dependent on pairwise-annotated datasets. ",191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Strength,And this method has been shown to outperform a lot the vanilla multi-task learning and also outperform single-task learning in some cases. ,106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Strength, ,
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,I think that is a reasonable and straightforward suggestion for future work. ,215 216 217 218 219 220 221 222 223 224 225 226
a6f83f54bd43db725bd0f67fc819f1c0b0bf631d8badf27f63f1eaca61865c0f943ea31260da63ebb8157c4b7131d3f08990bba93564e11293c433f2a1cd5109,arr,Strength,And the results are conniving by applying automatic and human evaluations. ,57 58 59 60 61 62 63 64 65 66 67
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Strength,"One question left unanswered is -- if the selected similarity functions are the best choice for these models, additional ablation is welcome. ",119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"-This is the first work to investigate the use of generative assistants for crowdworkers doing the data annotation.
",403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420
a08c0e0dafb5d74615009802dfc40b3801cc6a3f779b82e40b03a3f4c3f3bef3a4186e50fbbc8ec1a5364e61382882c08f2d7b7d4689d743a8b74728f99da313,arr,Strength,1. ,63
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Strength,Visual analysis shows how the predicted label changes with the generated interpretation. ,231 232 233 234 235 236 237 238 239 240 241 242
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Strength,Paper contains extensive results for a short paper and is easy to read. ,90 91 92 93 94 95 96 97 98 99 100 101 102
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Strength,"
3. ",159
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Strength,1. ,60
4aa14e9c828abc596357fb1d4565dfa3ed88efd4e4b914331b6439e4bc43a902348c83b1d6778bb95579cc25867623313189d9681b2ac961e4d57530af8d33c6,arr,Strength,	The experiments show that the proposed approach performs better than the baselines. ,69 70 71 72 73 74 75 76 77 78 79 80
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Strength,"The figures are well-designed and help readers understand the algorithms.
",124 125 126 127 128 129 130 131 132 133
0717df21c948fc36edf5f14e8f8c15c7640e5a653f4dcc12c1c89a96aaa861c6aabcd3ec512d9dba6e71a5031f90b6cbf3411e7d555480e0e93fd160fbe0df95,arr,Strength,"The paper itself is well written throughout, and the inclusion of the appendix giving details of the other settings that were explored is a useful extra. ",169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Strength,"Baselines seem good (though admittedly I'm not an expert here) and particularly appreciate the human judgements baseline for original (i.e. non-TTS, human-spoken) speech. ",287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,Both datasets target the domain generalization of column operation. ,187 188 189 190 191 192 193 194 195
89eada3482fa6a3f6a91b917f657fe02cf1194ab05ad493f2c98defa704cf823661f722f36e11820781b4469cf6fc5b7b59efbf694e7632fe51309ea9a35b908,arr,Strength,1. ,113
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Strength,"-The observations are informed and faithful to the results, and are clearly presented. ",256 257 258 259 260 261 262 263 264 265 266 267 268
eb650fa05410ca9417c00441a5b3f0ab2c0f012054bc332b6b71e12f20c6e3bd86a35f2929d7d8576cb7cd82ea438dd1501b3b750bc0263ddf275343ae614aaf,arr,Strength,1. ,125
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,"The experiments are designed to include several types of problems, such as binary and multiclass classification, sequence labeling, on the other hand, each problem has been tested on several datasets. ",209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,This paper addresses some issue raised by my previous review. ,344 345 346 347 348 349 350 351 352 353
51bbd4cb34fd8f1bf81c9f30876025a7246384f3a39c315255fc365eecda86883518ed684b7dc875169e7200b5c155aed9e03439fb1016766f41c170673e80f4,arr,Strength,"Several analyses in the paper might benefit the community for tackling pre-training scheme designs, such as how representations would differ w.r.t. ",248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268
747249d6df576d913b4dd001992510d9682657fee6f4ea775a23731979bf7af0362f975f45b8c27ae3b04e093fa81069cf32428adf42b4026a447055a6907e27,arr,Strength,"Moreover, this work provide a benchmark to take the first step. ",103 104 105 106 107 108 109 110 111 112 113
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Strength,"The different sections are well structured and the explanation of technical details is clear and concise.
",208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Strength,"However, it is not clear whether the annotators are part of the authoring team and this should be disclosed on first mention. ",166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
a8853b09f92393e417af7fa39fe0ff893ee5a5c0a2571ddcfad21ea9db7f70d14a871c9bc38a77ff7624721950c17218e1bcf3a12f84b7c86900b8c6abfd9b7a,arr,Strength,"- Improving out-of-distribution model performance specially in few-shot learning settings is an important problem of real-life need in the NLP community.
",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Strength,"I was very interested in the result that a simple and well-justified modification to the parenthetical language actually reveals nested structure to be valuable.
",114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,It could benefit some downstream tasks like text mining. ,140 141 142 143 144 145 146 147 148
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,Relation embeddings are injected into the self-attention mechanism of the transformer to guide the model to specifically attend to the corresponding header when generating a cell value. ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220
6279747572b802d4062cb5fdfc380e494f2000b5bb1c8ed39b4bf52d2e81d9f088f79e842c630b899ae0adaf76584d814a4db1d897f578abe9be351afe58de1a,arr,Strength,-Provides additional value through interesting ablations and extensive analysis. ,131 132 133 134 135 136 137 138 139
f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297,arr,Strength,"This paper is technically sound, and it's clear written overall, with good experimental design and ablation study presented. ",44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,### Main strengths ,287 288 289
ac12f092fedee748b297368438857f227331443549eca985d8595d2b311c345a19c8847e4f88785dbc4eef768c1a29304053e81243aa58b4a85a15c6ab798ae9,arr,Strength,"
3. ",83
0d9b3952c1795a766a9ae820b322653dd683f4d0f5193a534d5fbd783821da175d66ae51dce6bcf5a111835f10c03338d24668f0c4132f25aef79b2b8f5f862d,arr,Strength,The idea of mapping the sentence onto a fixed number of pseudo tokens and then maps it back is very interesting. ,29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,"This is very important, because understanding the senses of words is a fundamental problem in NLU, and sense embedding plays a vital role in this direction. ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Strength,"
2. ",142
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Strength,The conclusion that encouraging continuous prompts to project to semantically accurate instructions (Appendix B) provides interesting insight into the function of continuous prompts. ,326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348
17c7cb1d81372d0e1dc6209b9c16c87efa581e17d29a5b90292ccf2ba56a9718ca1738f7a4a74a7c105d8726eb648c915ad65193c867806f40d6240d1f392ded,arr,Strength,-The method seems general enough to be applicable to other task-oriented datasets with intent annotations. ,110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Strength,The paper deals with an important practical problem of how to optimize the usefulness of Open IE triplets for upstream tasks. ,156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Strength,The experiments and ablation studies are rich and cover most of potential research questions. ,336 337 338 339 340 341 342 343 344 345 346 347 348 349
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Strength,"-The paper showed theoretical relations between accumulated prediction sensitivity and group/individual fairness.
",54 55 56 57 58 59 60 61 62 63 64 65
d684cce5e50cb1b241f9db3a61d3ec32a8b2099f0c5003f8490bea7631aa3a016406faffa33f6a2c845b75e928b26b841fca9549635777c749b30c398804b2f3,arr,Strength,"The idea is nice and, as far as I am aware, novel, presenting insights that are both useful and straightforward. ",41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Strength,"The proposed methodology is technically sound, and this paper is clearly written overall. ",46 47 48 49 50 51 52 53 54 55 56 57 58
77c0de7520f2bc8b6afac05c1715c78f2a1080cce863cb2b3bf3319907aa22376dcda2b04f02ed7f201e0b8e461bedd1ce5cc172378742b8a51b064feb7c6019,arr,Strength,"- The paper shows that adversarial robustness of BERT-base against common attacks can be significantly improved by training with a regularizer instead of leveraging adversarial training, which is computationally more demanding.
",124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Strength,"The value of entity-level annotations for hallucination and factuality for XSUM will be very useful for future work, both for training new methods and allowing comparison across a common, fine-grained benchmark for factuality/hallucination classification. ",147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,"The dataset comprises over 30K sentences in **Chinese** that were annotated by at least two annotators (and checked by a third annotator in case of disagreement).
",298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Strength,"- The topic of the paper is potentially interesting to the ACL audience in general, and extremely interesting in particular to the Argument Mining (and debating technology) research community. ",39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Strength, ,
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Strength,1. ,101
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Strength,The paper is clearly written and easy to follow. ,39 40 41 42 43 44 45 46 47
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Strength,4. ,381
fbced420613c26219143afb780dd430bc86caeb1d668e8cf2ebfb3cd42b66803998d17f76f87f24c5af1f6d85ee9e1301978d8fbdfde62c14001469d20758faf,arr,Strength,The paper empirically investigates how the method performs with different training languages settings and gives an interesting analysis. ,173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Strength,"A collection of cross-country and multilingual hate speech is provided, in principal, reflecting the current social and political situation in a country. ",159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995,arr,Strength,"- The paper is very clearly written.
",94 95 96 97 98 99 100
a331c73408dcc74e2e0cddb0cd29ec5d9d58a7772f24c2e2d84f8bcad13f7bd53b391ff113fa24c42e5dbf0a4d22f7f3d682bb72d24f7bb7bc1eabc0a3cfe765,arr,Strength, ,
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Strength,"The paper contains insightful empirical results showing the high value of using human summaries in the process,  but also shows that machine generated summaries can also be useful. ",61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength,There are some other strengths as follows:  ,157 158 159 160 161 162 163
da6008c2bf458c661d5db072d4a625db2e3a9d4f034642eee0355748cf8ba843e9accac0b2b5b22ef8ea4bf060ed1bef2a5ee652d94a1d9c669b3f9b2aa32b1a,arr,Strength,"
2) I believe that the legal NLP community will definitely benefit from a standardized and easily accessible benchmark to help facilitate and encourage research on legal NLP. ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Strength,The challenge is 2 fold in terms of being single speaker and also being limited in terms of amount of training data. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138
afd3a6d8a0a1701f3cfb9f4f4d33c7a5cdab956dc0e3277b0fc691fb05366e612fb54cd58de85735547a3e57573b4c0694c65149392f6c83b32985764a11eeaa,arr,Strength,It is a good practice for ExplainAI that try to understand the learned character-sequence distribution in the high-dimensional space. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141
b2900de8ed20655563bea0599f00a508feaf2470a254279bc7cadf494469ee183c7990df2e9d40016e981165028a7b89e3b544576c1d8331c2c5266c7ac872f0,arr,Strength,The paper clearly describes the problem that the authors are trying to solve and provide a very good evaluation to support their approach. ,278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Strength,"- The task is relevant to the community, and efforts towards easing the life of area chairs are appreciated.
",111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
b986f917808d098b3c7153bbacd30f309adf77caabf55b172873ff35047c7cb05a6cf17a2e96a01a1cad1da837b32facb04fd26653e58043ce06fb74d512353e,arr,Strength,A well-written paper with a novel idea. ,41 42 43 44 45 46 47
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Strength,3. ,93
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Strength,-Well-written with a clear structure ,117 118 119 120 121
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Strength,"
    Schema pruning is also a good idea. ",162 163 164 165 166 167 168
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Strength,They report results using multiple metrics for word-level QE. ,345 346 347 348 349 350 351 352 353
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Strength,"The proposed residue detection method is novel, which leverages the residue of sentence embeddings and feeds the residue into a linear classifier to identify adversarial attacks. ",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Strength,"
3. ",140
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,"
2. ",478
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Strength,"
3. ",184
909d810280c389fbd65d9ab5193a36916d1a35e5d47692e9152de3d8527715d28852c525bd8b0383fad6a91ab83691c7a06f221f01a62ff712995ae103c4b842,arr,Strength,"-Has potential to improve community practices, in particular making it easier to use better evaluation metrics when writing generation papers ",195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Strength,"The idea of using articulatory features is rather simple, but results in substantial improvements in terms of training time (in case of training on a single language) compared to the ""traditional"" training mode, and, more importantly, it enables the use of meta-learning for low-resource TTS settings. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
bc6b2a09a1aa8ae1b059b4b757d1c9540233d3b49f5a150a2894390df7c14436a0824e05146bda04d5025821b0e00df7181f41219c6912f15b9f641ea5aa097b,arr,Strength, ,
83415e9e4c2f38b97fecb3a72646a1dd40b42b8007a0bfcb79ba6afd3015ffeb31f9bd91a56d477b962e27f02a41cab1d761ffaa0acad9f18e62a0e598cb7774,arr,Strength,"To promote the robustness of pre-trained language models, GAT with FADA is proposed and achieves better defense performance on SST-2 and IMDb against three wide-used attacks. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
46fa0e8ff8319c78c4d0e419f2735ffb60477afbb10340d2ffb687308457f82b39c8a3c13529ea51b4fc87a1cff65ad6659a61e1db517917d1ae054d8d4bcef5,arr,Strength,-Baseline evaluation with many different models ,134 135 136 137 138 139
1590e6fc469f7d0535861a66fe0ff32cef41d9dcdf274453705438c66de5c37b7b601b73d21a165c6db0fcf6cccf46b1ceaa8af2fefb76d9d350049e26735763,arr,Strength,interesting idea: Attention Divergence Loss. ,110 111 112 113 114
a42c480628723affbe6a3d6044ee9416d717cb6c2075135233c3e2960e2cc480a0cd0b4faf5d44572bb15d6197bced37707077a2c1ced77ebaa05dd8c2b5e70a,arr,Strength,It seems larger than a standard paper. ,161 162 163 164 165 166 167
74644b8c9ecdd5fa9ec1f11bf74bb24a859379bf32c3d6cbacd875a97578143afd0288863fc70dd959eddb1a9aabaf66d9ae02d6c1917377dd7d9427c44bde88,arr,Strength, ,
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Strength,"Hence, building style transfer systems which can quickly adapt in low-resource settings is important, since it eliminates the expensive requirement of hand-curating unpaired datasets for each low-resource domain / language.
",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Strength,-The curation method is cost-effective. ,96 97 98 99 100
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Strength, ,
74644b8c9ecdd5fa9ec1f11bf74bb24a859379bf32c3d6cbacd875a97578143afd0288863fc70dd959eddb1a9aabaf66d9ae02d6c1917377dd7d9427c44bde88,arr,Strength,-Strong empirical evaluation and results ,75 76 77 78 79
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Strength,The improvement brought by text smoothing is very significant and surpasses many strong baselines. ,173 174 175 176 177 178 179 180 181 182 183 184 185 186
bfef226d24e52a451834ea5efb31989006f603e100b0b30b7bae2562284a75f72600bea612fbcfcd1760d62831fe50926df17af4f09c0c302c738ff66bd800cc,arr,Strength,"I believe that this paper can improve the way we evaluate attribution methods, and can be beneficial for many in the community. ",108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Strength,The improved results make the comparison on the benchmark more meaningful. ,177 178 179 180 181 182 183 184 185 186 187
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Strength,"
3. ",203
1da2bd4a793d8b2b409fbd4f0925584ed357c4221a77efe9f32db585454aa7fb65a1eb1d4c77dbd392ac9cf6a2c49322cf40eb876d51b54df016d20dbfba115d,arr,Strength,Extensive experiment results show there are some gains for this method compared to some baselines on four generation tasks. ,109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,"I also liked that the evaluation was performed by comparing the generated paraphrases with the input sentence, rather than the reference paraphrase in the test set. ",533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
20a7357f69396b2ed4763eb65b591e82a4863399650698a508e81b51c5cb3535beb9a5304fc63ce8863548101c926e6214e66a28d86bda5a08043ba02c2333e3,arr,Strength,"Paper shows the weakness of two SOTA Text-to-SQL parsers in handling column operations by providing two benchmark datasets.
",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
3157d8a8980d26bab69c208803b2e28cfb897da55fe2f26c7bc2b13323adf33ac953adff54c60aa83ba1dc97c6fb586ddc58637cbcaedbd7899bfdc4c3c35021,arr,Strength,- the problem of the previous Seq2Seq model for the ABSA model is reasonable   - experimental results are rich to prove the effectiveness of the proposed Seq2Path framework. ,62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Strength,-The dataset is potentially useful for the QA community ,187 188 189 190 191 192 193 194 195
07b8d0d3e1080fd2c4547bd0dd4ab96ce6d41c2b222b049ac378b1c0825f0d4c019f9f4b7c1e9150a7f33d284bc6cc535ea36e61b2fdd17c6a1e967b4d27925f,arr,Strength,The analysis is detailed and informative for future work. ,93 94 95 96 97 98 99 100 101
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Strength,The proposed method ED2LM archives a better MRR-Latency trade-off on MS MARCO dataset. ,81 82 83 84 85 86 87 88 89 90 91 92 93
0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473,arr,Strength,"
The conclusions seem to be of interest for the community and can stimulate useful future work directions. ",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Strength,"- Collation of existing data into one resource and creation of a standardized multi-way evaluation set for Livonian will certainly assist further work on this language, and is appropriate for the ACL theme track ",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160
e640aeb3c0d1364ba9b7f6cf9726d81ee1b7658aac82daa164eadeb99fe8ab7abfeb9a3f325a392088645947b59609be4db7ac346f54e31d2e0ac5cf46b41b74,arr,Strength,"- Clear experimental findings: visual information relevant for sequential procedures, but improved models that more effectively use multimodal information is required, such as to come closer to the human upper bound ",180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
3331de31268882a7f2c7f5cf76382e4b1f38ad320414db4103ac099eca3e6c01c6054f81c6da2f472d8f8d4638bccadaffad27db112426078538aba688f493da,arr,Strength,-The proposed model improves over all baselines ,225 226 227 228 229 230 231
5aa9b857d1598a40a3898382462799cbeb55e1bbc82d939b4e8f69c406805f88a713d73f73c5c4ca094d603405c5c1aac9d5d2beec16005584a485e12190ad0d,arr,Strength,"It is mostly quite straightforward with its presentation, objectively showing both the positives and negatives of the proposed model without trying to oversell or overcomplicate it.
",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Strength,"It shows that with the proper objective for pre-training, the pre-trained models could be more performant on zero-shot and few-shot tasks even when the model size is much smaller than those giant pre-trained vision language models ",136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
2dc38b3a3375bd499d4e33815b4d1eb2736c66905f234af908bd514e1fb4506577286c4c1c8a107309ed1a3354a73a90bf58cefbada74c8f21b7ebd8b1229764,arr,Strength,"The proposed method may seem to be engineering, where a small amount of manual effort is needed to design templates for schema expansion. ",197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219
98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8,arr,Strength,"
2. ",316
0ec1053d54796416d1ddb97617f2ecd8b9a2c21aa08140e88896aa3a998110f90c4373185b3eefd6d8f1906b997774d340ae0e877544fd4f439dd74ea78fea3f,arr,Strength,"
2. ",229
86821d8c493ffc15ffecc911da6e92cfb9fce61e49e60eebd529f447645b51140aeece5cfd64ac1e54c2605b13e7785f6962d5a7b536d4cbbcfe7562726a8cb9,arr,Strength,"This is also the first model that proves the shift in semantic and lexical dialogue of the speaker, when other studies do not provide this, and the empirical results clearly show this. ",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255
f9be3cb8b9c23c80cf42e8b5d1db6905e3c5fa76a674b3b8ca058014259a783acb014067e05efdaab6f4574618a1786384de8416f8c539892fbf7b7c8bd34b53,arr,Strength,"+ On its face the paper is right in its main point that evaluation criteria can be exploited to   produce inconsistent ranking of attribution methods, and in general the use of evaluation metrics   can be problematic to research in the area. ",99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,The paper is clearly written except for several typos. ,234 235 236 237 238 239 240 241 242
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Strength,"Well-written and clear hypothesis: redundant encoding of syntactic information poses a problem for drawing conclusions about whether models rely on the syntactic information encoded by probes.
",149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
fd6f572f1c5279528023a42eb9fbdad249b1f1ebfe7c12bbfa276ed59b3018998128a948f482055f07ab0c3ba4b83416a21640418e95a7517111b6d650e0a6f1,arr,Strength,3. ,144
43983cb662197434390892d262d06305ea5af88fc94c64786287e7bd62f45de59debaacb60e5c84a8969c1137892ee7b60ea616c9cd0f3fb5667f1c27964442b,arr,Strength, ,
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Strength,It is constructed under solid methodology and the process is documented in detail. ,184 185 186 187 188 189 190 191 192 193 194 195 196
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Strength,"-The authors proposed a novel approach, DDNET. ",209 210 211 212 213 214 215
94db9840113bd974c51f0c3b5f1da378eede1ee81c8826deb9a661b1956b64620e4dd2d44f1c7883c4477a56c6c9c3883b029b3ec37555b41c881fb40da698cf,arr,Strength,Extensive evaluation of fluent but inadequate translations for En-De revealed that the bias is not only an artifact of the modelling technique but also the annotation mechanism. ,213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Strength,"
	* Illustrations clearly demonstrate the problem and solution. ",83 84 85 86 87 88 89 90
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,3) The findings are novel and actionable: ,143 144 145 146 147 148 149
41157292909defe5ce7f6f20b79930a8303a99763c88fb291783fd4babc99cd38b3ac7233caefe2fa7723eddfd328f19264f7b7f823fc69510b6451413fa7dca,arr,Strength,The paper is clearly written and easy to follow. ,268 269 270 271 272 273 274 275 276
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Strength,"- To my belief, this is the first work that analyzes the discourse structure of long-form answers. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
0a0e6d9a373583b70a5485ad425a2392b5316f4c87a2b950c045f68af30f3df4e3bbcfdc601cd33dfca112050f72f410666a07fada676774c3fe147c94793e49,arr,Strength,The mutual information discussion is well-motivated. ,144 145 146 147 148 149
8ef3fa547505100a7155ef38240ef5ca45862481fec01c740b08a06955216ff989e9a02a353c520fa4c22462ab04f36a7e8e5c394f29bb81dce5536e9e169cff,arr,Strength,"- Well-written paper, tackles an interesting application ",155 156 157 158 159 160 161
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Strength,"
3. ",135
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Strength,"
The paper also focuses on the notion of factual hallucination, which is often treated the same as non-factual hallucination in works on factuality. ",181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203
282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722,arr,Strength,1. ,25
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Strength,The authors identify an important challenge with existing popular benchmark datasets/tasks for task-oriented dialog and propose a way to solve this challenge via data augmentation 2. ,127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
7075eb05a7f3e433a7b8cba6ee73866ee4976dc2da0e5ebc79a7019abe84cc28a909e0e99c0e814b0e8a7535b4b9f9839e7fd1d3d855b902f6f511fc6234b852,arr,Strength,"-Performance reported in the paper is very strong and likely to be of interest to many practitioners in GEC, especially because it is obtained without auto-regressive decoding.
",234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260
2eb4344ce741b472e57335138b62c37cfe25eafec0ffbaca887b8360b11fd2983839db46a0cc21579fd32a4bdea26af8bac805bc22e054242cb22415dea44ef1,arr,Strength,-The authors show large performance gains over previous work. ,82 83 84 85 86 87 88 89 90
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Strength,"-The proposed modifications improve against the baseline MLE systems in terms of accuracy/F1 across many tasks; that is, the calibration term appears to act as an effective model regularizer in some setups. ",490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"
2. ",90
5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec,arr,Strength,objective and Data analysis parts are stronger. ,19 20 21 22 23 24 25
6948377b128ce8c60c32a0fc8cf7ffe45ae2fc1ded70405ea0ede6d577ec7fa193db3011dc9221756d0eaa8b73003124d81f069f9da16fe2d894c05637eefab9,arr,Strength,"The proposed bandit learning approach that learns from user feedback for EQA is novel, which simulates real deployment environment and provides insights for further exploration in bridging the gap between QA model training and deployment. ",156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Strength,-ICoL appears to be an interesting approach showing improvements over MoCo ,63 64 65 66 67 68 69 70 71 72 73
4c402a34bfd0f9669014df819a3a729136527abfde2ea31848f9fd351f86373bf48a06b3a25498835ac1cadd3e4f5753958227283a71d9c97167781d7b7b02c9,arr,Strength,"-Finding that reference vs dominant citation types differ in their citation span lengths and strategies to generate, and contributing the longformer-encoder-decoder model towards appropriate modeling of this goal. ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
1e1d69c391f257d35080fce1bae332c727b6f405b06665a731904ea571266f56a70259babd6ba6c0d3a063828b866009ecc5a6b20ae3336df51ac207902554fd,arr,Strength,The method of using contrastive learning and knowledge distillation is interesting. ,30 31 32 33 34 35 36 37 38 39 40
843c023710442ecf3c0ddc5241527b8974fbb7a8d66862d54a37f6fc571b8dadd628512fe83c8af4f76bded68c6feaa22401e38073b19d3afaad1d633a9da48f,arr,Strength,I think it will have a positive impact on the research of NAR models. ,106 107 108 109 110 111 112 113 114 115 116 117 118 119
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Strength,1. ,71
d5d309540d05687f83ab4cc8825262106a31d1b5ede3d4807751919108dd3ea809454342e26755d6c05bdfb72a4352e3738c4de7da7f1dd4eaf5dbddb861d798,arr,Strength,2. ,117
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Strength,The illustrations are very informative and     provide a good overview of the tasks. ,143 144 145 146 147 148 149 150 151 152 153 154 155
086c68303939dbb31a634b50a49ef47789ef060639e7701d07594e78aa9a9c6c401855d77457ce497a1b73242782c8b53dd2d2ee1255ed4611f550d442bc4b05,arr,Strength,- detailed description of approach and methodology ,48 49 50 51 52 53 54
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Strength,Propose a schema pruning method to prune the relevant columns that the final parser needs to look at. ,144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Strength,The paper is well-organized and easy to follow. ,87 88 89 90 91 92 93 94
5e3486ca3ce459c4bbfc00392cf8cbdbdff7c2e1533100ecb6dea298e880a3ea6ac1ff9c580cbf727c63835f97f28080a98b6b8f73f760a40fea557bb239f616,arr,Strength,The formulation can facilitate in-depth discussions based on metric aspects and allow metric users to choose one based on their demands. ,159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
2fcbf792854adc3e835bebe1dc036f6f69d674be2ed2dd0d109bc27164c3de5de3ec5f4996cc7883a351e3340f373941b0c6789ab33d8d5e5a5410c6d5cd8fb3,arr,Strength,"The paper addresses an important problem, that gives a new way of assessing the representativeness of a dataset for a specific language. ",68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
2ea1d4c58dad5df2829588b117f4cc70bb1a2c104c9a327f31a11d4a897674c3dfd6fa849b1aa747cec96c59367591f4eabf813fd201d598cb3f7f7da4ca97e0,arr,Strength,The evaluations cover two types of adversarial attacks on five datasets. ,121 122 123 124 125 126 127 128 129 130 131
4aaf67bb39a536f9c69db39faec8fdfd2a3368a601e2e17070610a76bca035c18409744aa4344e6e32a0666894537b13494f33fc051ffb579273744ca1f6582a,arr,Strength,The dataset and model designed in this work appear to be novel and would be broadly useful to the dialogue systems and multimodal learning communities. ,39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6,arr,Strength,"-Experimentation on the resource provides a basis for comparison, and preliminarily looks into the contrast between contact languages and typological relatedness ",161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Strength,"- The paper proposed a new fairness metric accumulated prediction sensitivity to measure the model prediction change with respect to the change of the protected features.
",28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Strength,"The authors report multiple baselines and will publicly release their code and models.
",235 236 237 238 239 240 241 242 243 244 245 246 247
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Strength,They also introduced in an accessible way the concepts and terminology that are relevant to this research line. ,83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100
73837843c65a425ff419296a34871a445f1e2fee4cb8940431054c5ec0c1beb405f43cdd40fd27e52cf27aab7574eb4f160655995346c0889edc41328e588bdb,arr,Strength,The large gap between human and machine performance suggests that this is a challenge task to solve. ,113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
fc280bbea3dcf0362b1b11d51865a27c48ee3f30fe6b1e4ad619caba80fa9d5b4963dfb14cfc03c30ff79091ab07d452cedfb5359ff6bfecacd6808a5941cfaf,arr,Strength,"Overall, this paper proposes a simple yet empirically beneficial method to apply modality-specific learning rates and this improves late-fusion performance. ",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152
808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6,arr,Strength,- defining an edit intention taxonomy and creating annotated data ,31 32 33 34 35 36 37 38 39 40
a4fd8920152e81ea4015e5fbd227a306870e7afeb8f2567b1c0035ec89a13f0fffaef9efc8d7ccf5e4452bf1ac3a31645828572098795e9643cf07810c067d1e,arr,Strength,They created a new pinyin IME evaluation dataset called WD Dataset and it would be useful for further researches. ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Strength,"+A well written paper with clear organization, goals, and results ",52 53 54 55 56 57 58 59 60 61
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Strength,- The paper reads well and is easy to follow ,64 65 66 67 68 69 70 71 72 73
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Strength, ,
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Strength,The idea of having a modular controlled text generation model that uses blackbox components is interesting and novel. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Strength,"The experimental results are strong on a well-studied benchmark, GLUE, and the analysis are also extensive and thorough. ",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
fa4054a7eeb47c2a4dfffc98bc638ef12f0c6de1c70906b54ec9034c2c67daee11d1da260efb09d8266b38c19eff00fdbc798e9d844e235317196a49f1aaab21,arr,Strength,"mix-GLT outperformed the baselines even without KD from AT.
",172 173 174 175 176 177 178 179 180
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Strength,"It raises an important question of the practical advantages and disadvantages of character-level approaches in MT, and presents a thorough literature survey, analysis of recent shared task submissions, and extensive empirical evaluation. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
850e20b46914cc63e8dd837b650bec2cc89d27f84843c6af5201409f09ebe6a4a3967b619dcbcd226b53551059ba16ea7a4f0d3e0018fcb06a3aca3a41c5eeb7,arr,Strength,"-The proposed methods perform superior to baselines with respect to calibration error on more tasks than they perform worse.
",471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Strength,"- The task is quite interesting and it is important for updating resources in different languages.
",43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Strength,1. ,41
883a3b3698172d7b78d132279f4c53b31c578e8c3af604bec08748a97dbe97802237e96d22453c60caa1d75a0379c182e591984fa9dacad645f1ee9be5963b6a,arr,Strength,The author introduces an interactive mechanism into the VQA task. ,73 74 75 76 77 78 79 80 81 82
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Strength,"It is one of the initial works that analyzed the group robust algorithms' performance in the context of multi-label classification.
",49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68
2f3ae15fda7644fb28fc06739a769e91682032b1f960bc0a941437a79113405400b59335c8602c6ade6788169612207fdf0c2fe360a9129d4bca82928145b732,arr,Strength,"The paper describes many distinctive characteristics of livestreaming video transcripts that are essential to study for the task of punctuation restoration as well as for the field of automatic speech recognition.
",245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275
c6950904227f5ab8e9811e50b0723baefe901d1173d4a9ea3e7138cdeab1c5706ef17cb872b3567b19eab0f232ac18c70c5515e5369c45567355ca66659fe021,arr,Strength,I have provided some detailed comments regarding that in the other sections. ,238 239 240 241 242 243 244 245 246 247 248 249
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Strength,"The work seems well researched given their knowledge of CL field which is showcased not only in related work section but also the mention of alignment/uniformity, preventing degradation in CL models, regularizing label embeddings etc. ",180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
5dbabd3e6a6001f1e43cb8276d370cb4983d626289a5e91e6ff9479abeeb970446a4a817fd5a576b86599ec777caa72efc3e5488f484a6bdf700ece288664d82,arr,Strength,"It is based on a pre-trained BART model, and the proposed Module Indicator/ Boundary Indicator can help the base model to better combine information from both the context and knowledge in generated responses. ",115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
58449473f83ef41c2f1e94e8cf6cf5e71a8495031a5ee85bd0d0eb8c3410f0a609f5ba7252346baa1046878d231fa2310909fcdd153afab18576bfafeeffa115,arr,Strength,-Cross-domain experiments that focus on domain-general intents and slots are interesting and insightful. ,288 289 290 291 292 293 294 295 296 297 298 299 300
a28caf18ebbeb3bf9ec2265042966205e211f4515c2cb1824b93e9c9dbf8394f50d932b5bc5f9d0696e8c08bf2df858f1d60c9ceef54e27fce09b344dca0b6b3,arr,Strength,The simplicity of the proposed method is a significant strength of this work. ,221 222 223 224 225 226 227 228 229 230 231 232 233
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Strength,"
2. ",127
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Strength,1. ,80
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Strength,"
3. ",269
308a3dae511df165c5bafdb5ac87fa3882179218cd92d71a17954ba8f255214d06c106ec2341c49613479511484a01359e8b2cacb280fe807ffa5b2449a80c72,arr,Strength,The usage of the new benchmark is well motivated as it provides more in-depth evaluation of speech models on tasks that are more diverse and include tasks that look at very different aspects of voice signal. ,123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
e0111eb824f3bc8901645731c84d882dd0ac2f5052557e28e1b41ef6c2ace7e360932539c4132c61dd5efaaa60eec8d20a141bed6fed819083cfd74de2ebcdc9,arr,Strength,"
2) Novel dataset with helpful guidelines that are made public which are very rare 3) Baseline model has been provided as well. ",35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Strength,"The related work section is adequate, albeit incomplete (though I agree the missing references are very difficult to find).
",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,There are experiments compared with decent baselines and multiple benchmarks and there has been a good attempt to evaluate the new technique well. ,201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
55ef0fca438c05ebfbe6704fe40936e0a61f015444457a6751ba711e5731b8de9ec289dce0cff38f0e95c9fbf1b2abde4d8711a00a30c3c7edf9900957c9cfff,arr,Strength,Interesting intuition of applying prompt-based language model for data augmentation. ,217 218 219 220 221 222 223 224 225 226
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Strength,"
4. ",179
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Strength,-This study is open and transparent. ,248 249 250 251 252 253
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,-The replacing of number fragments is interesting and could be useful for other related tasks. ,115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
9369772dc98f529223d5a6b71ae8305b2df2197c2f889432b8019841ec75d142dfb9b9aadf9de8545748e85e33346596c49a141e841ecf79e00dabe891c7bf75,arr,Strength,The authors propose an unsupervised knowledge distillation framework for cross-language named entity recognition and develop a teaching and learning procedure under this framework. ,66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Strength, ,
82ec5736c2f53f3381d21921137cecd857ade8011dce1a4d5e9127c8f3b6d57eda3d503bf6f9f69232e82bbfce51e8ddc45f7d8341c2decd8a83c740413c8d01,arr,Strength,"Certain influencing factors for transfer effectiveness are analyzed, with further qualitative discussions on best source language/language-pair, which may provide some useful information for future work and relevant applications. ",99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Strength,- Setting up benchmarks is highly important to assess SSL speech models ,152 153 154 155 156 157 158 159 160 161 162 163
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,-**Empirical results:** The authors show how an SRL system performs on the task (in-domain and out-of-domain results). ,408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Strength,"Through experiments, authors demonstrate the challenges of current techniques in a simple (yet telling) task of predicting the outcome of bail applications. ",213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Strength,1. ,68
6187bd8a3be2835d889ed91c85d27c1ab8c74d9fbd1fbb729dbd80786b1c5954748b996a2d72a5cbf4f44b046ba4934a5528b78c3340aeb121f7864f4a7d4f79,arr,Strength,"
2. ",272
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Strength,"The authors propose an algorithm to find the unargmaxable classes which is a combination of an approximate filtering and exact search.
",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,1. ,76
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Strength,The paper is well written and easy to understand. ,89 90 91 92 93 94 95 96 97
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Strength,"
2. ",89
70873263db44d699ed7ff42a825a15425a96c66899479c2b26a739291755923ed16b1f2fc588b7faca6255af263567a20438f83bf0cf7597bc2ec2e0d9543f35,arr,Strength,The description of the experiments and the discussion of the results are clear and succinct. ,111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
42ab122400706c4e18248fce55404d664ceb731dac04e53a985f233cdf9b596cd8cb5f6f289a0ec5d08d96b757ef5aa22f5dcaba024929f3a0b99c6c6de3c0b0,arr,Strength,1. ,38
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Strength,The challenging issues discussed in Sec 5.6 and Appendix. ,81 82 83 84 85 86 87 88 89
03d50264956d1b95e18b6b73c37ffb71ebeb7a23cd5e397e26f76fa2543da31df5b4b30a00fea5fee7c9e3157c8a52e14e63e37cc1e1640950ebb790676107f3,arr,Strength,    2. ,80
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Strength,2. ,192
96ec9be29428e0a17ca105d58c549b165b515306b77c29af12c34660fabf6908fbf2415ceac54922e153db5cf90e391ae19dc0df99d9a41b946bd2a6553afcb4,arr,Strength,Combining Chit-Chat and Task-Oriented Dialogues is a less studied direction. ,64 65 66 67 68 69 70 71 72 73
48f9a3caf3ba774261a573d0f6d388287ca71ee6c2c330c03bb7a3743d9907c768fa31f99b02454079066176e7d9c25999903d361aae8b3f808f7164a1445fcb,arr,Strength,-The experimental setting is well described and the applied methods are technically sound. ,108 109 110 111 112 113 114 115 116 117 118 119 120
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Strength, ,
a10d35763dca42f9e79c8e0caa0c46187df3879026bdd9c437fa21cb43f4713e871f77a5508c7aefe0c3ef70f3c71cddc20c64e692664edfc6ade6954ee36188,arr,Strength,- This paper proposes a novel and interesting idea. ,45 46 47 48 49 50 51 52 53
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Strength,"
4. ",143
3c49820f93e3e8370d520d51b07e26d10427c0d1c93f60ce29a95bbf4f3aac2ea859a90b3903d6fd36f0e22c8a909a6e90a5342f89577d14cf7222d669d58497,arr,Strength,The paper is overall well-structured and the methods are explained clearly. ,86 87 88 89 90 91 92 93 94 95 96
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Strength,"- the paper is well-written and includes several experiments, across languages, and experimental conditions and also abalation studies and interesting discussion about the results ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132
7566deb6096584a7083b4c4d482f841af8a5da6238fda87877fb7ebd73aff60d57e4e191842789d4fbe52284b5a918f8a9756b3091bb36a0fc422820f890311e,arr,Strength,"The approach proposed by the authors is thus interesting for the research community and could pave the way towards more cost effective translation QE, fine-grained methods for explaining QE models outputs, etc.
",259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76,arr,Strength, ,
1284e8772390636549c1dac72d685525220b5422e9291f23c7b07de602465889f518be29b0c17896d5037af4b4cc1d8f1e917282bb224f407618741567d2107e,arr,Strength,"-Provides an excellent overview of prior work on NLP and comparative linguistics for South Asian languages.
",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
57b7cf5a90c31b190f7076d107802b5f5bdcfb9d3f4a8b4f7255ca965eca425df62266643ed74f674c022ad1a86f662cef3f3e4ec30a19e1723e563c558c1f17,arr,Strength,The paper is very well written and very nice to read and easy to understand. ,362 363 364 365 366 367 368 369 370 371 372 373 374 375 376
a0926a0cf87a203884f51990e4897732720876a9057cfc4e916b2dc40187fe7a1785e14cd098539b448b36cfa6120568ff2f1b1f2b645654c274b4cba5e97b65,arr,Strength,"
3. ",104
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Strength,"-Tested on seven classification tasks in the BLUE benchmark, the method performs better in general than earlier prompting methods on few-shot experiments (n=16 examples in each class in train and in dev).
",182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
a12d4e4c3013ba70c94a8d2bb31f9b31ba1ab30a5b1575a9233a80823dd1619599f31acb7e0f5e8014e69c49ad64820c1484c419e75a7562a5c5d0fc435837b2,arr,Strength,The final comment in the future work section about the connection between the difficulty of model training and the difficulty of finding the unargmaxable classes is definitely interesting. ,251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278
a14ce9efad30211565068ea00e48f44bd0abaed526df6b5ea0ab1c7e9fc1dc7b5c65ea905e5acd113d1363401e708fe0106cf0f21cf45b71f3a232cb1faea6ec,arr,Strength,A simple approach uses different proportions of sentence-level and document-level data to train and study its impact on translation performance. ,78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97
03cb8483ba66064a3c9b4a132af185e861b3dd292bf0b90105956dfbf7cc7e88e5bff423e0904e34b16baa401f61c0938331c4795c5fcfa86fdf99d4eb48c7af,arr,Strength,"The paper provides a way to remove structural bias for the NLI task, examines the cause for its poor performance and proposes ways to improve it by balancing the bias-performance trade-off.
",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Strength,- This is a pioneering work to explore the privacy-preserving transformer inference with HE. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117
2851a25a648fa21a3e26f747971cab36b2ab24c5c4010da31caeeba63bc506e05a214f5d152f9b456fed1e0640e46419dff832018ba7b049de3a269d20b0e9b3,arr,Strength,"-The paper proposes a simple method to make PLMs more suitable for retrieval probing, hence improving the probing results. ",158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
bf4dd391d2c040db6b314ae75e8ac18213b8769c6aa163fdd53a883921985423d9584cfa38c32ca593149520bdec74074db5c2677e143c7d30ffa03395b7e45f,arr,Strength,This dataset will be useful for addressing hate speech from a multilingual perspective. ,181 182 183 184 185 186 187 188 189 190 191 192 193
04e97d4c546e9c4af4d723abfb39a7fd257a1e4107ba6b6f800781d793026e08ec305afd199483d4c061cdb15a2ac405f16e43bd49679780f20a937504822a47,arr,Strength,"The paper is clearly written and mostly easy to follow, the proposed approach is well motivated. ",75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
9246e12b2a95f6161b574599c154e2ddea27ce7460610439fdb720ead86cda0529ac5d89cd5a1d80b6ab6fd04bea323a00cb9227339b62fae53b9c891c274944,arr,Strength,Paper manuscript is well written and structured. ,146 147 148 149 150 151 152
bae051cda3d9a5a252fe0afc5242246443a1294f45df167401fe4b7d7b00ade33bfb200008e4b55070d7906002ff37d802176d11c63bb3c3ae46e476e260133f,arr,Strength,"[2] You, Ronghui, et al. ""BERTMeSH: deep contextual representation learning for large-scale high-performance MeSH indexing with full text."" ",174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,"
4. ",224
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Strength,The authors show that a cloze-prompt-style fact completion task can effectively be solved with the query and answer space in the entity vocabulary. ,117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
58a851a5e8bd4338e751bd63f301990b343577dacb7dd93bac5f6629c470a9efe717c7d668c23cec1633763c45b922db06d87ee8f2fa43a730f25b00bf044d8a,arr,Strength,"(1) The paper proposes a training procedure adopted from MAML so as to fine-tune a TTS model for low-resource scenarios.
",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76
03548accf24c981108bf2f531cc21dbe1ea9713acf7b0ff6d5cfc35d78814585fb7fe4f59f5e985ab872ad28427e510469c4ba19ff0f0e37c2f197b935dece02,arr,Strength,1. ,124
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Strength,"With regard to details and organization: The authors re-organized the paper, and clearly stated the details in the proposed framework and dataset. ",128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
cae04ea5a5edc93df8355c570815cbecec45d18562b5e323e53d02cb9a95394dff757192c80981f891adf14462e54a81f0786e4017a672b721801666e52f162e,arr,Strength,"1) This work applies the graph-based semantic parser PERIN for structured sentiment analysis with task-specific adaption, which refines the parallel queries process and gold nodes mapping. ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Strength,"
  * Experiments across many model sizes and architectures, including encoder-only models like RoBERTa instead of just the encoder-decoder and decoder-only models we see else where. ",618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642
2b254596d32b539cb9c31d2ccba540b29222f2e14c8f01f1a51bbed21344f5bbdf6a5d20e2168e799b9656c14fdba9cfe8479103ad8a4e1035833e903a04d5af,arr,Strength,1. ,115
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Strength,"- Contribution of a human-annotated dataset for grammatical error correction for Chinese.
",164 165 166 167 168 169 170 171 172 173 174 175
bd9e1f80c81f4619d7b93cff38f4ca9e4642566c30cfbbd2b934b29262b4770edd6afc39af1d95c895d124f3b8631b150c371e4af90609ab6780222f71ce8fdd,arr,Strength,The results seem convincing. ,16 17 18 19
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Strength,"
The motivation example in Fig. 1 is pretty interesting. ",93 94 95 96 97 98 99 100 101
c2d126038dff3afba3321b5c9186be9596f207af2f63758593aec96b3531490fcc0d6c6a19ccc3950a07c37023adab30d77cdf24f80b7fd03c0c1289683c9e3a,arr,Strength,"They run multiple seeds for the pretraining objective, allowing them to perform statistical tests over pretrained parameters. ",138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
d0adbc683b1920556f2f658448daf2792434b209a9960622144d3cf741857c04c0854fce75bf2591fe5e861afaa3a58b2593abb0ea1927e3b4e1168cb2175c86,arr,Strength,"
2. ",83
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Strength,-The authors provided a very detailed analysis of different components of their methods. ,128 129 130 131 132 133 134 135 136 137 138 139 140
32528ea92c39b9389b0f8f7f6bbf216f4e7af7362600c7ab871198c6eb3b2151b22039c196d0d61bf70af1db62ed229cd72e68140bcd3875e3d62240175aced5,arr,Strength,"Detailed analyses to show how each component (e.g., the hyper parameter N, local constraints and refinement mask) works. ",183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200
cbcbf4f35b926e4ec882b9a55de840f3c0d42a6c79f65535b168e644024368d28c28b49595f939c5488c78879a53b870b61c40314e0173cb583d8c09d8567a8b,arr,Strength,"There are several novel contributions, including (1) that prompt transfer can speed up prompt tuning, and (2) that induced neural activations are a strong measure of prompt similarity. ",101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Strength,1. ,91
6d5b5cb633d8448fcf573f34a5f4af129cdd66f386a6bba3819cdb20d6b38842c2e179126d0d0ab97a9b80bf8db9b7f88b661bf796f7652edcdacef3516cae15,arr,Strength,"-The experiment results show strong performance, outperforming recent models on three Chinese NER datasets. ",123 124 125 126 127 128 129 130 131 132 133 134 135 136
e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e,arr,Strength,"This paper proposed a new model architecture to improve SPD, with its theoretical guarantee. ",30 31 32 33 34 35 36 37 38 39 40 41 42 43
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Strength, ,
d702266401cd2a77c941a20b270c580fe07ebddfacea9118330e1453d987198958ba943d32e8658dc342233045372c3a3db39a964679c0429bb0cc2f1571a74e,arr,Strength,"
The paper is well-structured and well-written in most parts. ",130 131 132 133 134 135 136 137 138
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Strength,-The insight that multiplying the image- and textual CLIP embeddings is beneficial ,168 169 170 171 172 173 174 175 176 177 178 179
35d102a8beb922f72496e036da9794f1ce61c584825b7122fa49dca78df6b88ab08710c080d45d4eef50b206c12c4d46d03a173bd5931bd7fb49e1adf7bfb08d,arr,Strength,"Some previous typical models are evaluated on the new dataset, which can facilitate future works. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
74422589ed375a739e9cded681a52f9ff22834c7cdc647b63086b3a47b6ba43b927827b977434a757af9a870b9580010b82d44b20b80b0474d4ab2ed77fcb21f,arr,Strength,"In addition to the reduced number of model parameters, the inference speed also increases. ",96 97 98 99 100 101 102 103 104 105 106 107 108 109
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Strength,-The paper studies models trained both on different sized datasets and on different languages. ,263 264 265 266 267 268 269 270 271 272 273 274 275 276
7b6573d6b9c2ee5bc9dd81e24d1fcdb60b22bb4e39ea121d42cc631ecb70ff703768042f87cee8a181e786c8873bbf6fdf5d729d59e8c9e7b8b4e31a8c4f0bd9,arr,Strength,Empirically this work achieves similar performance (using statistical tests) while being a few times faster than Nogueira et al 2020. ,173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Strength,1. ,191
939ce6eb49e6445ca0cffcbcd4a5ba871c31530929873adf2e9e4eb1911ca9ed92a328b2b4bb2ff3f1c5add12e2ba2e37909c5c3f0a13c3cb3d9709957bb0516,arr,Strength,"Generally,     it is concise and easy to follow. ",135 136 137 138 139 140 141 142
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Strength,The writing of the paper is clear and the motivation is clear. ,99 100 101 102 103 104 105 106 107 108 109 110
26e8a5a6daf9cbf400c7d59f2697cad70c104233f31b8e9aa49167d0d14f6e38ace18944945fb75ac80ee8effed0cac3d03889d1030048d7e9ef5544cb8814f7,arr,Strength, ,
06b82c4720d419bb56d16f5272bfa123c4037299b66dd31b20e9cb8c4a7651de5fbe198e06b99a6276dc60d3f4189c857529134deb1b8b3651233850caacce54,arr,Strength,-Good results based on comprehensive experimental settings. ,103 104 105 106 107 108 109
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Strength,The baseline used for comparison seems strong and valid. ,357 358 359 360 361 362 363 364 365
e775acc875915a0dd898817152efd4e5ed6a618e4704a2b66369412f0aed265c8b4648b81b840e2f1b8cc8fb0450634bc4ebdcc423402c718c18b03f38db0d70,arr,Strength,"
2. ",104
a06180e20fd21ca2b631519a77f9e26b386f00c5c63f9b1f064c3fad903a26e6b8f1e0ab555b68dcb2a82e86e09abf42a7c451b828ce83c2c2c09819bc4a3c1d,arr,Strength,"The problem of combining open real world knowledge to make inferences about the visual content in an image is something which can find a variety of uses in real life and is something that comes easily to humans, but is extremely hard for our present models to solve making it an interesting problem to enhance the capabilities of present day computer vision systems to take them closer to the goal of AGI. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213
418040bcb27410fc18ce88e2a6808ab07f2aa7910448eeccfd9f3a3b0f785f5c95cb439fe1e6a3a8d9e7c639b9079c52d2ef53e05312e0a3508fdf9ddc78a86e,arr,Strength,"In comparison with the previous version, the authors successfully improved the paper. ",74 75 76 77 78 79 80 81 82 83 84 85
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Strength," * Experiments on many different and diverse datasets, 17 with a good mixture of sentiment, NLI, EJ, Paraphrase detection, and Question answers. ",596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617
1bfa77206969b120204949e9b10f8c5980f90a790345b5534a5dcddeddde766b343d4e1882210ad7e60411172d79f393bf195c23d3ab4a6dd1b955bf4a8c4d26,arr,Strength,The overall performance is good. ,50 51 52 53 54
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Strength,"- The proposed method is simple and effective to achieve lexical and syntactical aware CPG at the same time.
",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Strength,"The data annotation process is well documented, and it's nice to have both a silver dataset created using a rather less noisy distant supervision method and a gold dataset with human annotations. ",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183
0eca541313bb789a31f0a7e5967fa597c64bfcada1c25d2e5dec25887158a31aa4c1ed517dd7fc417b521fee28b2bfafc7811c9535ddf25b887cd53958f47afa,arr,Strength,+Reasonable choices for different aspects of the process and justification for each of the pipeline elements. ,65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Strength, I think people will be interested in this paper's observations and proposed solution. ,257 258 259 260 261 262 263 264 265 266 267 268 269
86ca1ba300de668d673f124abbe56095cf9c0bb9f5fe37005ee85b7120fca15216a1db9312acfd5ca37b43e218d77597258c1953c01adb538ea8be7c59ab7aac,arr,Strength,The proposed unsupervised dense retrieval model achieves remarkable performance com- pared with supervised dense retrieval models on BEIR benchmark. ,61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
663a3c9d5c721bdf25256a5b8c4ff5a21560335e0899d7ed05379b8ecd4d426f82b6cdfb14b9af0df1c02ade7486fcc5d2daab3c98f8da03b3350b786b35e906,arr,Strength, The machine learning experiments are creative and well-chosen. ,97 98 99 100 101 102 103 104
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Strength,"The examples and statistics in Tables 1 and 2, along with the descriptions in the text, emphasize the effort that was put into obtaining sentences that make sense for French (such as adjusting names, culture-related concepts, etc.).
",203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,"i) The controlled generation approaches typically require specific information like the syntax of the desired target sentence defined in terms of parse trees or POS tags, which might limit their usage for downstream tasks. ",332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365
a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9,arr,Strength," Also, they add 2 more topics compared to previous work. ",114 115 116 117 118 119 120 121 122 123
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,"With the help of the task-specific pre/post-nets, the encoder-decoder network is shared across all tasks. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Strength,"The additional experiments are sufficient, which help the readers understand their method deeply. ",209 210 211 212 213 214 215 216 217 218 219 220 221
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Strength,"
3. ",143
13677691ef6650a9852c1b70be41d53bf711afd4f38cb9f07d57eeecfff80470d4d81c3da67529e5f1c01088c2885a39cf5e77438cd40300ce91b380bf1f6369,arr,Strength,- Experiments are well established and clear. ,136 137 138 139 140 141 142
e965dd1f90d06352cc1b5b1492c25df89fc8e0b54f7a866be660c27554b7cc690ca3f011ea1c84ddd11e5408fb4174371734811cb282247b23ed89ae55ef9dc6,arr,Strength,1. ,126
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Strength,"I found the examples in the paper to demonstrate the Square One Biases (including architecture biases, annotation biases, selection biases, protocol biases, and organizational biases) pretty precise and helpful. ",94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Strength, ,
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Strength,1. ,41
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,"are adequately chosen.
",101 102 103
d1921e5f5febc1efa6ccd005802a9c3efc66b8840ed104fdcade7b07f9f498a3eee437ee46bfdde58663ee7bf9cdaab4873670ba950b1a71a31bdc9388fbba99,arr,Strength,-Well-written paper ,142 143
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Strength,The approach seems to work very well on the datasets used by the authors and to achieve a new state of the art in the OOV entity recognition task. ,61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89
1f3ed846cf117ae2eecd5e3d9d19a85c37510c11c3463afa9ded734ea9f7dc0569a0ad64808fed511202bc3a62103801e85b7e7d14a8617220cf2ec989190cb1,arr,Strength,The additional two strategies designed in the paper (region-based sampling and momentum-based memory bank) are well-motivated. ,116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Strength,This paper studies lifelong learning for model pretraining. ,99 100 101 102 103 104 105 106
c06af5ec8047eafe03fbb6f0f9d2eef4dea29e8c600ddf5d9e891be5dcec41efa450869d3bb116e756d4cc3e0799cbbe368ed6046692f8bf3cc7a4727be050df,arr,Strength,"With motivation from the toy example, going into the experiments on SST-2 and IMDb datasets, the results are very interesting and provide good evidence in support of the efficacy of the proposed method. ",269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301
af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07,arr,Strength,-Paper appears to be well written; ,80 81 82 83 84 85
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Strength,"
The paper under review proposes a smart method to trace gradual phonological replacements like lenition (t -> d, k -> g, etc). ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
9322fb74f7ab53a6795b49fe971a7c7b47f0a6b096390f8d87e46b4d9a732a3f1f6b1afaca5ea79f9ad759a2bfd4902ca96e2b15b7ea27814f3d9ba82f767985,arr,Strength,"
Authors also have done an organized investigation and framed a methodology for quantifying the effect of attention focus drifting for Trojaned models and classifying different token types. ",109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef,arr,Strength,2. ,69
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,"Otherwise, the comparison is unfair. ",290 291 292 293 294
68a64013029ef250db764ebc154c1e2f8acc6cb4cacd62f781403688196c59364ca6bfa5f5d66708c48d27c19519bdbaf6833e5d649813d7405518a8917df086,arr,Strength,"
The methodology seems appropriate and sound. ",77 78 79 80 81 82
05863a5e5f65f2fa56dfa60f4367481321306b79397553962367507ac177cc65f8dc5fb9e229798a05238c118df15c9628118b510e822bb4876902b10ba1d976,arr,Strength,-The use of polarity as a proxy for framing bias is an interesting research direction. ,168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac,arr,Strength,"In fact, the paper extends the computational change detection field from only semantics to phonology. ",144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
4ae7e5a89a0e881843d18cc1c0169625207a448fac7fe4b51559f0670a0498ca666b257ac17ffe9a22f6792232e971a2ba6c9bc01db1e9d569893857c9ed78e2,arr,Strength,3. ,324
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Strength,-A series of relevant ablations are presented. ,117 118 119 120 121 122 123
a47173d3ddf05abf2848f8d8f4b62e27a29d96f9ee08c41df22aac4a0d916604519328d5e7d92571d7a7539191546b9171a6d34c663f3d4359fd891400490220,arr,Strength,"I imagine the same would be true for many folks in the ACL community.
",99 100 101 102 103 104 105 106 107 108 109 110 111 112
3573c1783420e05e2d9c850b934b303abd649827c3d6e6e311e49c216fe279a4b1ff0d538eb7c10a51097345be3e68d9acffd53abcd13cea909999e95a4336e3,arr,Strength,"The paper proposes using feature attribution methods to a extend a sentence-level  QE system to a word-level QE system.
",277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"Speedup isn't observed here as much as the increase in downstream task performance.
",352 353 354 355 356 357 358 359 360 361 362 363 364
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"Additionally, this results in significant improvement in model performance on downstream QA task, which is almost as performant as adversarial data collection without use of GAAs.
",309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Strength,1. ,88
543343cfc7a6dae035ff88584839d5682243ade35473df1cc834171f7874c916ad90a45c89d7d652ba5926ff52de9e7fb3ba4b9f9dbbd446d0b2743de5d313db,arr,Strength,"
The proposed baseline based on density estimation achieved the highest AUC on 21 out of dataset-attack-model combinations. ",198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Strength,"From my perspective, the strongest aspect of the paper is the annotated dataset. ",134 135 136 137 138 139 140 141 142 143 144 145 146
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Strength,"
4. ",98
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Strength,-The experiments seem sound. ,252 253 254 255
7d67dcb3c0915c610966de8dda039a0aac770a85ffab1827c2aaaa109c3fd8dd46c6878e1e47f1df147297581639cc911b34dc4f0d3f7246a0698a56dd450756,arr,Strength,Evidence: Table 4 (QUIP + Cross-student vs QUIP)     3. ,229 230 231 232 233 234 235 236 237
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Strength,All the experiments are easy to re-implement. ,151 152 153 154 155 156 157
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Strength,The main strengths of the work is two-fold - ,116 117 118 119 120 121 122 123 124
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Strength,"Overall, I think this is a nice paper, with a few clear opportunities for improvement.
",173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
e41e88092bada9f75b4ce8778855411e128fea782712d728ff13b90f98386e6c97f5b383da31df5f5ad9aed07e2e3af42ad0fe8ce53e7dc9d81130c9d24a351e,arr,Strength,"Also, interesting use of the corpus + systems trained on it to analyze existing systems for toxic to non-toxic text conversion. ",37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
09290c223be50fea039c864dd823f730df75ee85f0c590eb06167f3ba064f1c299ebd472613f539a5f6768e3f515e0089b07712804763a944f30fe81a6d7bfbe,arr,Strength,The paper is well written and easy to follow. ,115 116 117 118 119 120 121 122 123
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Strength," It’s described as a “competitive baseline”; that feels a bit like underselling it, as there’s already an existing baseline (FGWS) in addition to the common-sense PPL, and the proposed method is well motivated, well investigated (e.g. in the analysis of error bounds in App A.2) and performs well with respect to these existing baselines.
",143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Strength,It is intuitive that the inference and interpretation should guide each other and be dependent. ,162 163 164 165 166 167 168 169 170 171 172 173 174 175 176
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Strength,"
4. ",185
92b7e51465728e0c2c8a96a9f5656245bede1396a6d5747f20ab6b46bee05ee953b654b35a57fb6ffa12b90305aa00aa5a953a0eb345fb845807b17ce525b5f9,arr,Strength,-The paper presents the effectiveness of active learning on a single model for multiple languages. ,93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
c9c950ac880f0d3f959786b09ea150c5bc5bf4cd5f6eed349758e0db6504590c079509a4ee1f91f0b5574c8c6f23bd8b311d34d151298f22464ab32222dece48,arr,Strength,This should be valuable to the research community. ,339 340 341 342 343 344 345 346
0483e42a23383462a9176b05a14c1c4813f4ec64f35f470307774b37e1bb5c1b720cb37e62341f0279aff5fb6104aeb10d479280128a5c1e0251f70ec4c35e28,arr,Strength,-Their proposed efficient Transformer model (LongT5) performs better than the model with the original attention mechanism (T5) across different input lengths. ,153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Strength,This work combines an unsupervised approach and NAR generation on a summarization task. ,48 49 50 51 52 53 54 55 56 57 58 59 60
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Strength,-positive results ,172 173
5553e734ee561dbca52b70b1015335f374318859334691ccb27ca71d7a13634681d54908da57e0f1b2e5ed228f1dbaa2098ceb8f084fc6e9fc86977f539ea23f,arr,Strength,"- Experiments on multiple downstream tasks, suggesting a  benefit of cross-modal contrastive learning with additional sampling strategies ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Strength,-The paper is easy-to-follow and understandable in most parts. ,94 95 96 97 98 99 100 101 102
c2a349441a32e604b97f48a3fadc9b79306bd9b4da5b287af47e32bf65d87caca2e16816aa69b2181616018360705af16c43b45015161cf006a34d3e489b9145,arr,Strength,-Interesting topic of offensive span detection ,35 36 37 38 39 40
03eb1b3037d43f1d0e8f00b17dbda971f9bcf719a0fd8ba58576d612b9fa14f882a7e75a2f724c6afe76cb89e746ee49b1352d6b2fb275ca47aeacdc751dc8af,arr,Strength,"Employing the extracted commonsense knowledge to guide the negative sampling is somewhat novel and interesting.
",69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,The released models will promote the development of the related community. ,147 148 149 150 151 152 153 154 155 156 157
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Strength,3) Experiments sufficiently demonstrate the utility of the proposed contrast sets. ,98 99 100 101 102 103 104 105 106 107 108
de6e9e582d788888209c33864f2c33f88969183462f118433c3de339f4ce516a54325de9505b8b1a5a2b61556ea1a770e0df1cc61d70950bf871a83727eb24a4,arr,Strength,- The annotated dataset could benefit future research on discourse analysis of the peer review process ,141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
94fa38294cafb35dbc4fc5ee47ce2edb7f28acdc579d09e347eda793735579d90260a72dfdf5123f5ce1375483e0c01abcefdb0cedb2039dfd120f16371e66dc,arr,Strength,The approach leverages knowledge distillation and dual attention techniques to combine text representation and audio representation. ,216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231
1ff96046139ba88b3ff79fceee88f0499d2b0c10c65aa9f685545818d86c143c98453ab537eaa427931c27e4cbd3cf4918e8aac6cec749ad141ce8d05130b243,arr,Strength,"
3. ",281
9b00457f4a1c03fcc3bf62a652f1b43d6fa633d34ea08ea7ff3844575be18756ed71f720447f2467791864ec2aa0663e5cde48d10bd974dc82224d9bae7aa2f5,arr,Strength,"My expertise in MT is limited, but the methodology looks well-thought-out to me and the experimental setup seems robust. ",174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192
7857e9075c709a7704a6fdd434af951ac67f25b4d13c1b2ce04da7adc5a47e5319f650fc743ce47578cd458503cf3f4f36bc80b61d81ef7058feaf8060b58c32,arr,Strength,- Evaluation on both synthetic data and a real-world case study ,162 163 164 165 166 167 168 169 170 171 172
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Strength,It also made the proposal very well-motivated. ,305 306 307 308 309 310 311
20e43a0613cdb728b178bc6ee7a9404d334de1188a7b263b5d2cb14704cd60ad8e52984f1cf1ca942eda7991044795d171860d6de7d69cbc384ebebd6f4f0bf0,arr,Strength,The approach is well-motivated and the authors provide a clear picture of how the paper relates to previous work. ,67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,"In all these experiments, the ConfliBERT has consistently outperformed the performance of the BERT model. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
ece4ceaf28899de39468ac76060ec6d12d8b3e572da4063ac2f49469ba5073d70d6aa181e21e1ee883b76bf4db145626fc741d8ec10457c5d7ffeec69f311652,arr,Strength,3.The implementation of two distillation strategies is proving effective by ablation experiments. ,152 153 154 155 156 157 158 159 160 161 162 163
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Strength,"The proposed GCPG approach obtains significant better results than previous work, and appears to be simple to implement. ",221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238
83332f14ef0ffd2354bc32ea1d7dfbb006f42a55ab41e5f87cd0ac2a434cbcf857f34c9393aa362aeb06a1c8debb6f22b265f480d7cea8567ef5a70ea974086d,arr,Strength,The paper is written well and the results are presented clearly. ,84 85 86 87 88 89 90 91 92 93 94
46c5c8a5c4f4c5d7e9293777e0665330bf22d54a80fb391f7119cea4a0292283b104f562f2b885a97d70143031538e86560626c444b3140c6a7093d125225223,arr,Strength,"Cross-lingual NER is a challenging problem, and the proposed approach can be easily scaled to more low-resource languages. ",167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Strength,1. ,200
f5450641fc7e1c553fb3526d0e3e2401d874e29587f785b72f4dd67a6d6210f803c4acbe0c2334f929b3b3301af4903c63b82cdbd5db63fd0e4d9b09a505f82c,arr,Strength,"The experiment results in table 1 and table 2 are promising.
",76 77 78 79 80 81 82 83 84 85 86
2eee4a5d194e4789580dfae74d057d2cc28cbece95a4dda7c0c7e440c1b512ce05bbf1b02285f34702633cc248401e1052170fc6a4477cfec129ac591aef5ada,arr,Strength,I was one of the reviewers in the previous round. ,94 95 96 97 98 99 100 101 102 103
3076e22c80c84ecde98bf48a17760bc2a15b5119149d6987e949b462414b879b2e39bbd48333c5380e15bda1333c544333c619e7349909d71ad67a362624e94f,arr,Strength,-The observation about MT-DNN’s degradation on QQP (line 237) is interesting. ,150 151 152 153 154 155 156 157 158 159 160
759b93caae756ac8b1f80110b9955e713039b05fe0fadb6e3ed4d5078bc3c54daa3eb092f79126acdb48ad3bbd451b28c456d516fc9ae2bde5b6761d51047921,arr,Strength,"
3. ",89
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Strength,Results show that the proposed model can extract more diverse phrases. ,53 54 55 56 57 58 59 60 61 62 63
77e7e68c6c9f8fbce55b0eb66fb152a61bd30edfc4608610b1a81bf965cb14cb3e7abf535e50e5e438081ac30b0aaa57dc69032663b4588f4f73a6c948ebce2c,arr,Strength,"
3. ",87
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Strength,Comprehensive study and well written ,186 187 188 189 190
f3961de5b71adfa56601df031143145da1b84804e306e47e79b7bf4df93f663c297c1729f462a4d713631949ff9b6816e07c18c97fa6692aeb330e7d90e10044,arr,Strength,"-In my opinion, the techniques that are compared (e.g. Lee-style, Canine, etc.) ",89 90 91 92 93 94 95 96 97 98 99 100
28224ff4d7b034bc6b591eea7f83b30d1f9839fb96acf3d804e1f31d39f2f1f2fb28ea3e0597332bc5d531184f028caf4e0d8b07e03fdb49f330f81f3d18d6e1,arr,Strength," Gao et al. (2021) instead only keep the best label word for each class, and perform fine-tuning multiple times during label-word search.
",160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
79c17105f5c8d45c44c56b028732e1a935c8d3c2b6c4cf514e0fced63e87cfe3af95e151c474115004b4e4b1d80f8718600760fd5885b52ecd0ad01dae985528,arr,Strength,"The idea of the boundary smoothing is simple, and can improve the performance of the existing NER approach.
",66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83
5cc904d7b7e8a5395ee30f1c08e0d4f28e0994af11ccdefefc8cbb1e47409f4476ddc6430ec5141938598c401900776386967a4d09c21c3658849789912529d4,arr,Strength,"- Simple model, works for many languages.
",87 88 89 90 91 92 93
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Strength,Human evaluation is also conducted. ,243 244 245 246 247
6009657cb5982238bd67a0f1aa37f7fc5ad6ad71f9cb26e8f6af75969ddbdc1b60b57265bc7f9c233fd94bbc8bc5804029022bac025fba3874a9407e48666751,arr,Strength,"
2. ",66
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,1. ,163
835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196,arr,Strength, ,
178fc26935bf42f6c5c29de8cfc31e55c5c549ef201a080b76e85275a7e67e892cd478df9d4926ab99d3541bdeb112d6025ce2ae4e872ba5d2ccdfc2c5a05036,arr,Strength,"
2. ",74
facd5d9a648b5bb76a254a7daf33a5ea41ddab1060fc3345ac18d7cf3bc6f0edff32da540c232b5ecabdfee1692ab51e54e68ab7e7093654d516828c9ce74677,arr,Strength,Experimental results and details in ablation studies show the superiority of their methods. ,78 79 80 81 82 83 84 85 86 87 88 89 90
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Strength,"Reducing the decoder depth for improving lattency do not appear so innovative to me, but it is at least interesting to see some number for the BLEU/lattency compromises this implies in a real large-scale setting.
",176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210
0f8103add9d5c982db7a11a283a509bcba2fd6db90ba131b4d06bfee67fb49258888c6d5d52c8180c4088d6b4393a3b2426b78358824b10903060fbb79bedc49,arr,Strength,-Incorporated constraints do not result in latency increase ,114 115 116 117 118 119 120 121
532fc491f93f0c284582f3e9486ca8322ab9bdb2049bf4ed09f49b8c90259b96f8d87aa1e4435b82edff75935ed83b869ff07ab82a9cc497001bf398c8ba911d,arr,Strength,- The paper is very well written and organized. ,117 118 119 120 121 122 123 124 125
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Strength,The theoretical validity of the proposed method is argued in detail with a lot of detailed information in the appendices. ,97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
d598c7732476060a99b281799a6b7b9ea18e9feaffac0dde2bf5b72840843d0e6cfda2d840f854f200bd74d457d6b8cf43488630e9844486430d34c6b221a834,arr,Strength,"The idea of using the generative likelihood of queries to retrieve documents seems to be novel.
",64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Strength,"It's really great to see the authors put effort into component analysis, e.g. notable mentions: 1a: Table 3, comparing the NCE compression to SVD and PCA (it's an arduous effort to run SVD and PCA on features on MT-tasks size datasets). ",71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
58ef2606ffcc1a9d790427b7220378a346d698c7023beb399bc0cac18ad2bfed6d2e46519b035dc01c3bd41a82f0fbadf549fba3848249ad7145d3431eeab653,arr,Strength,"- It’s a good, effective proposed detection method. ",135 136 137 138 139 140 141 142
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,-**Resource:** A large dataset with manual predicate-argument annotations. ,290 291 292 293 294 295 296 297
48f30939f1c93ebad4378313b0483dfac21bedf68059ac036fb1de53773bbb6eeb247aed60ae1a9d072b78cd7b03e2db4b5c39b7f480db60596ba090e866b53f,arr,Strength,"The paper is well-written and easy to follow.
",112 113 114 115 116 117 118 119
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Strength,The paper proposes a framework that pushes the state-of-the-art on the CronQuestions dataset significantly. ,91 92 93 94 95 96 97 98 99 100 101 102 103 104
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Strength,The paper contributes a large scale data-to-text generation dataset WikiFluent. ,228 229 230 231 232 233 234 235 236 237
8b153255696c4dbb18f90dd93c19a0f67001c23e5f3bc938e69a28cc738cdcaf0fef16746c5d4683f778f6170cb5c0cd4bf6c1bb1559b8f2b26c0595d22e0d0c,arr,Strength,"-The proposed joint training with span number prediction and structure prediction, and span adjustment module can improve the QA scores on MultiSpanQA compared to a pure sequence tagging baseline. ",114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Strength, ,
7e23ee6e56ace10f42339e73b598425e2f2f0f8539fed8f42a514d3a80a537553522ece6eca40ded1d3e587222531371a27d268cbb3ba00f80c3ba8cb0bf286d,arr,Strength,"The paper explores an area not yet much studied in the field of MT - using multilingual models for improving document-level MT, and presents interesting, promising results. ",132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Strength,"This paper is very well-written, and clearly articulates the issues with not only beam search, but BFS approaches generally. ",106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124
270a173af727771a44a103092114e752cdc76c7bbd3ecc6f3a03eae3891ea2bf4cbb9b963382d1d2d8cd4d2a86f864c5bb71e3230ce34645d8e6f704e3db1061,arr,Strength,The idea to establish a connection between the continuous prompt and the discrete prompt is interesting. ,89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
cd54453bcc2a38395d51c0b87caab0982cc265f866fa755023c2e1dfef96cc8130d4ddc3d6cc08427cec568cd8abefc795f28845813e912744009b5badfbfce8,arr,Strength,-The evaluation is conducted on multiple datasets. ,66 67 68 69 70 71 72
69bb60db767b1f3b654e386328ad7e999ed4c5d859acab874093065396063803040a6b164a1c8184cc3682fc0d3ffa3b3f6860661c61bfd5b9881aaa251e9984,arr,Strength,"Double edge point] It's an incremental improvement to K-NN based MT approach, little novelty but large engineering and execution effort, backed by good experimental design ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
24bcdd395c9d074324f11b34d7704ed7f9658bd6c815e6ac6cb98f512cfdf3d803f6207c49cabd3a7142e4419e5fa10772d3ac37320b9e45e7de00ce788f847d,arr,Strength,"-The paper is well-organized and well-written, it is easy to follow and understand the workflow and the contributions.
",147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
e4459891946c3b9dedb949ff16915fc1abb03b97481eacab1c146ef95f3eb1d79d169e90609c7f0356fe38dbdbcfe03279ffb36641fef135251110a52a730848,arr,Strength,The paper introduces a new dataset which could be used by others to make different experiments. ,60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Strength,"For example, Figure 6 (b) suggests that scaling PCFGs to beyond 10k pre-terminals might further improve modeling performance. ",367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Strength,Clear motivation. ,77 78
c6f5a1420bf8d684270f93ad64f4438845318e3edad19824dc219996ac88e11d4864f63ac52b50abf072b9443b52267be58c45703df5a45fb0489243eadaa697,arr,Strength,  ,
19eb70ecad8d0e4be400a93817ad5d9503e06c66b4c7ecf086578690e30c63fe7f59cd51dbe11b28e99e5c0a40c1c6790e22bdc0f9ab82e2790b6d9daa378d6b,arr,Strength,"The paper presents statistical rigor on the technique it presents as novel, CrossAligner. ",63 64 65 66 67 68 69 70 71 72 73 74 75
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Strength,"This paper focuses on the problem that the sentiment word prediction errors of the ASR models corrupt the effects of current state-of-the-art MSA models, which is valuable in practice. ",92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
3fc189ac8eeb0d461cee1f961009dc0a8e386e21214549d5df3eea92c7bcaf7fa82d2bc9db5419c090668f7977eb65232496c9d5582d6a20bf086dfd958a906c,arr,Strength,1. ,317
ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9,arr,Strength, ,
1b46053fcca8334550cb43d651abb7de45548ed6c394b8e2537e26c0d5f0fda5b398db6a469dd8a8300d9f88279d5bcdf6841f3609fab5d21439e802f393db77,arr,Strength,"-in addition to creating the dataset, baseline performance is established using existing models as-is or adapted for the new dataset; along with some error analysis.
",133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
dbdc9d651568ad0167e6ae0f196e85eac0634cf2fa514717df2bf63857f999db1f31460186f8812fbb865f7861e8dc25e6a15248b3c848e9647e5f890c0c4415,arr,Strength,"This seems to me like an important step in developing low-resource TTS, but I have very little knowledge of state-of-the-art TTS system and cannot provide a good evaluation. ",126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
29d68183bfd749eb98ca25d8f3275d06762a252d2ae2c8714416e61aa6c8f672e5f150c66a611c28326426aea82ea5c9c3c9e04c94b37970ae669deabeb0a5bc,arr,Strength,"-This paper shares intriguing insights from various experiments.
",56 57 58 59 60 61 62 63
fa60f1a1f132578809b55d458098cf7c2899fc3d35febeb6386f1aa13aeebf1576a62ad3c3d55342cf4bf1db6f8e0ce24aaa678fdc064d0586ae23e1e6edd720,arr,Strength,"This work is insightful in pointing out that by performing message passing only in the rank space after marginalizing the original state nodes (which is a one-time cost), a factor of the number of states in the total complexity can be replaced by a factor of the rank size. ",216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,"This paper finds that likewise word embeddings, sense embeddings contain social biases as well. ",306 307 308 309 310 311 312 313 314 315 316 317 318 319
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,The methodology consisted in assigning each annotation item (sentence + predicate) to two (paid) undergraduate students who were trained beforehand. ,345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,"This paper introduces a novel task, text-to-table. ",123 124 125 126 127 128 129
616f1e9160debea4910d2e381d7793d0fdf92e90a76420060d99211d5c9fea7770d1ef76fde0ec0be8ad55122fb82e378ea9c27f5f8749cfe3c90de2e692badc,arr,Strength,"The new model addresses several key problems of previous work and appears to contribute a very logically motivated extension, modeling the structure of the required mathematical operations. ",51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Strength,The paper is well-written (extensive analysis in appendix) and tries to cover a large ground of work (defining task + providing synthetic dataset + novel model architecture) ,130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,This technique may inspire related studies about cross-modal learning. ,125 126 127 128 129 130 131 132 133
fff3315bb2fd5fc714c31f0028a468c8fdd38bb6414832ca54d6e8dbbb7effa8b8418b112cc9e3f0a03c52067ad3d469e98d2c6f51aecc17acfb130add85b085,arr,Strength,"The proposed model SWRM achieved improvements over other baselines, especially when the ASR model performed poorly. ",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137
ab89f54929cacdbf98c0dc1870337be76003e140f4aa2692310e7ffdd1b9fcd2029d63f67579ba7aa7cd4ed95a73a63f7734bcd92632f7934d6248f6426fcace,arr,Strength,It also contains well organized related literature. ,89 90 91 92 93 94 95
df15fa78d3331e468f13cb18ab0eff830f0f65e2611ec4c8709ae57c17d54057fdafa4981ebcef3ea40e9d61d35e7d80ab9fbd01d5b4687cc1bc2cd63d02aeb6,arr,Strength,"
-The problem is well-approached, although it has not been motivated much in the paper. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116
1209e8c920cbbdbdcf9b9a9caf19d1ba8569ef8454ca0493b21178e6defd06319601bd75783c53510b07d26af8a89620f403c3e600251cb4cc785779b71c6fdb,arr,Strength,Interpretability and controllability - these are quite impactful characteristics of the system. ,212 213 214 215 216 217 218 219 220 221 222 223
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Strength,1. ,117
007b93f0c37668d86e7d736d9a0361f703c7f0aab6f5722e8556663989d187c59735da6e1a2e6615a11597e3e1eb415b46c6507923c698e896ef29f8ba3c3b42,arr,Strength,"In Automatic Essay Scoring research, it is more common to develop models for a holistic scoring, although in general, there is an agreement that a score may have many dimensions (e.g., content, spelling/grammar, organization etc). ",87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
9366c6f19b029f72c3e59b1401d086760e9ec70a5075abf155215327ce1ff62c6f748436952cff90ef7ad247fe69821ef372c9d8516f81ad3ca76fec8644d629,arr,Strength,The paper has not changed materially. ,201 202 203 204 205 206
e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990,arr,Strength,The paper has been structured well to answer my questions during the reading. ,113 114 115 116 117 118 119 120 121 122 123 124 125
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Strength,References are given where necessary. ,176 177 178 179 180
1f3ed846cf117ae2eecd5e3d9d19a85c37510c11c3463afa9ded734ea9f7dc0569a0ad64808fed511202bc3a62103801e85b7e7d14a8617220cf2ec989190cb1,arr,Strength,The paper proposes a novel and effective framework to combine active learning + self training in NLP. ,99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Strength,"-Section 4.6 is interesting and the results are potentially useful to determine whether a sentence describes a relation between two entities or not, which might help improve auto-labeling quality in other NLP tasks based on distant supervision. ",229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,"It is very beneficial (as in 2), and most cases of the dataset are of good quality. ",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Strength,"The fact that boundary smoothing addresses the over-confidence issue of target span predictions is quite meaningful, hence again a plus for this paper. ",264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,A nice advantage of this approach is that it doesn’t need additional parameters to the added to the baseline Transformer model. ,267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
02d4ef5de02582e219db1a79f3352c4d10e4a255a819912f34a178341e47d60d8e7f5d3210d0a909900bb93fe6a31ca7f7cc8b7bd40d0d4ecef07aa4fb0bd872,arr,Strength,-intuitive choice of complementary tasks and building of the NN architecture ,161 162 163 164 165 166 167 168 169 170 171
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Strength,- Claims well-supported by ablation analysis and experimental results ,314 315 316 317 318 319 320 321 322
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Strength,Combining deep learning with ILP is interesting. ,53 54 55 56 57 58 59
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Strength,__3. ,167
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Strength,NMT for endangered languages is a critical and interesting research direction. ,53 54 55 56 57 58 59 60 61 62 63
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Strength,"Thus, JGA underestimates the performance of system, while another commonly used slot accuracy metric overestimates the performance. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101
08b469f02d27a4b8a5935a4c3b4047690d0eac73be4055b0a3098fcf8eb09983b46e45745d2aaaf18776913247b065b0dde7791968355639e05f9f96d410cb1b,arr,Strength,"It proposes a multi-resolutional data processing step which iteratively split document corpus into k (1, 2, 4, 8,...) parts and feeds them to the sentence-to-sentence translation model. ",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296
b4e81da505ebef5ace8e442e01cccdac5908d729ef226a19898d890b25f745009f4d2b3dc5d8c7dee53e6ca4d4d4fc3ea27434a9079229938acc30a8d4daf193,arr,Strength,- A comprehensive comparison of models on text categorization datasets demonstrating the effectiveness of a relatively simple baseline model ,80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98
7c6fa2d43e7c8ae3ddd6df7867dbaf0d7e8fcc695f11b89238410f74be5ce7e6a7389d35e9c1dc3ea6d0a6c20e35f9eac77d9a4277388f68d719a9dcb096b9cd,arr,Strength,See the previous review. ,10 11 12 13
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Strength,"However, the experiment section is much less so, see my first and second point for weakness.) ",327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Strength,"
3. ",188
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Strength,-Insights into the value of Optical Character Recognition on performance ,192 193 194 195 196 197 198 199 200 201
f9d2c04ce99e3997b4a0ec7dce59178a5c9408b3d278ae129cb42eb387b5c7fe6f0d9949493739482f27d4afd072559ba4223d739608d6ac872911c0ecd60c2b,arr,Strength,The empirical results are quite good. ,140 141 142 143 144 145
e32028fea0e2a5b69ee874b1229abce47dd7e1e3581ec450975a27d111146734822a71ca9bb71cac9fd490ff691193089130c40fe7fb051b6f178a9e1ea9abd6,arr,Strength,-Insights into the value of tweet text clustering ,202 203 204 205 206 207 208 209
a3834a569f77482c154859425a610a944a5ab05d6eead3497e1af551e64d43d375ac91d1eefae9f4a61174883aa06ba99480a2ca153edb1191f6d7580565a572,arr,Strength,"
2. ",135
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Strength,"Another point is that different from other models that are aimed at fast inference, this model enables their application on a seq2seq setting. ",123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
88ed4aaf6d48ced87c005d808b0cfa4d8f384776fc224a1b1971b299b60ea7ee7a2ad281f928cf9c0e9e19f56ddfb72529ddb77f311f2a6081c62a06e87ba70a,arr,Strength,F is very clear. ,90 91 92 93
90f1a911459b14b0bed31ba05dc40f9b1d46984a98192ad15409a50f28d494a38b4a779898d7f28dce77497b9de217a56990cfdacd160d11aeb35d551e14822a,arr,Strength,"-The proposed method obtains impressive improvements over the baselines for the most part.
",189 190 191 192 193 194 195 196 197 198 199 200 201
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Strength, ,
3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10,arr,Strength, ,
6904cb342e56487e5564c17b554e3459e7c75d0f30b90aa919ce1511bf0ec97d1478bd9d4a1639c0b52fd250bea866abdb1b65e0c71ed8bda0fcac5c3e5d6211,arr,Strength,The new dataset can be very useful for the VQA community and greatly promote progress in this field. ,85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
59538f3e87c3e8f2a66537e5d0cecf6d32fc7d17905cb608f66644496dd8e5dafdf0cfd513c59da774c4de1431edb56b951a4ddb53893aa5ef2c51a46bf4480d,arr,Strength,"
2. ",72
6cdc13ea84ef615cd7e960e589a268df0d01d92068b8711c7aa570e9977e46aa8397e2a0d56caf9d9371023139c5b2b9c3f91ffc2d406fd6f51f7b1b80836e17,arr,Strength,-Results on LRA test set demonstrate that the proposed method can be used to further reduce the space complexity with big bird or performers ,158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
2a9d16fb890611d1da1586df109d5ea3883ac31d59d259fe86e6bdc41f41585225d71ca9f5dafe832a3c8d2a9decebe1741bead124515d9bf5a5efb4603e7c68,arr,Strength,"This work is well motivated from the need to generalize unseen documents, and shows good empirical results. ",153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169
d8202d06a56e9216595f81b97d4ba5ede424fe3a34b5e489ed1ea3fbffdd11a04d1edb38dac0cfb0cf09583ce23405bfcf0d14d60af1688ca8884da50c681b37,arr,Strength,"- The major takeaway is that the use of GAAs in the standard data collection process results in annotation efficiency, as measured by vMER, i.e. model error rate on the collected data, and time per model fooling example. ",271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308
27c3d47c22badb94c04576feb2aa36afcd97d576b172fa38b419903e8fa28db72bf1a3fdc56aa335ef485952650c9ac79c49539a617a48092f2e72de9e570ab8,arr,Strength,-The approach to constructing syntax-similarity based exemplars is novel and the experimental results show the effectiveness of this feature than POS Sequence and LCT-Truncated. ,76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Strength, ,
a13160e3b784b9fddc636569f73cd6ea60629b576b812f9f4363151304c642baac3520c486f1d36ca31414d89b9b50645cfbf6a7911fe45a43b78f3fc14e5fb0,arr,Strength,- The authors propose several probing tasks complementary to Caglayan et al. ,62 63 64 65 66 67 68 69 70 71 72 73
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Strength,	Code is provided and well-organized. ,153 154 155 156 157
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Strength,The paper is globally nice to read and introduces an interesting idea. ,79 80 81 82 83 84 85 86 87 88 89 90
d63319b2d2727d6648754aa173bba323937bc8de1497005fbd4a5a40d6525220951e156ad91c3405e152db531f7b9fd9aeca5dd4e82ba740a52d5d3ae2e3e6f1,arr,Strength,"
5. ",294
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Strength,- Thorough analyses and breakdowns across attribute types and distributions;    this made the results much more interesting and useful. ,140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956,arr,Strength,Interpretabliity is one of the major issues in the cross-modal learning. ,52 53 54 55 56 57 58 59 60 61 62
79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70,arr,Strength,"The experimental results are promising, demonstrating the effectiveness of the proposed method. ",201 202 203 204 205 206 207 208 209 210 211 212
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Strength,This paper extends this line of work and formulates the entity linking task as a coreference resolution task. ,140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
229c437e49835ceb94b3a0444b9800b1880c6d91927825a1ecc132c4ead1fb0c238f3426b2965d766fc436f506bf4601cf2ffa9a5af4c0cc1faeaf7719ae4daf,arr,Strength,"They developed Vrank, a novel reference-free evaluation model for story generation evaluation: it has very good performance on both visual and textual stories. ",239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"There is a lot of evidence that the approach is efficient: diagrams comparing it to state-of-the-art models, the code, lots of fresh and influential sources cited. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"Seems plausible, although the authors got rid of beta and took derivative (meaning 'derivative of a function') of y, and I am missing how this happened. ",162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187
2e42e7a204fa5d021f07456b1caac58d6a7899db82a854fe3e3e880f8a2528c6da82540053789b7003a50e4718b80a8ed74f2a6cffaa56545ec081f8614a2d90,arr,Strength,"  The experiments presented are quite extensive, spanning multiple datasets and generally demonstrating that the proposed methods are effective. ",235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
0d20ab1e52c967fc2b6ecd5084040c53b37a21cba1b83a8817be76caac2836fa048bcb7422a15838798e562ca3c095c423dd8a9d0e9ddf698dc8b5a0b845b1f3,arr,Strength,The strengths of the paper are as follows: ,166 167 168 169 170 171 172 173
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Strength,"For example, prompt crafting is essential for zero-shot prediction, which inspires better prompt searching. ",191 192 193 194 195 196 197 198 199 200 201 202 203 204
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Strength,The presented experiments clearly demonstrated the performance superiority in two different types of text classification tasks. ,146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Strength,The paper explores an interesting topic of personalized language modeling. ,117 118 119 120 121 122 123 124 125 126
c4658267362eaf0381ed7da20a5eb33a3928a03dc88d39a4b73c876e365011c1db0852fbe8e2485b9b19903f7b772a9312ab155d23c7f21c9b2904a5abce7b6e,arr,Strength,The authors have added experiments to compare negative distillation to baselines outside of the negative training paradigm. ,86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102
b9180336235e32229e3d5db6d509179a89c4af064e31f823bfc9b1f2c30afe037c6bd6714829f516cd1924a7b032c6ac3bd52bec91bcd9b6d03e185642a5ad75,arr,Strength,This setup is less studied in lifelong learning literature. ,107 108 109 110 111 112 113 114 115
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,+ This paper proposes a new language model for a domain. ,97 98 99 100 101 102 103 104 105 106 107
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,It is a reverse task of the original table-to-text task. ,130 131 132 133 134 135 136 137 138 139
c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db,arr,Strength,-Their proposed method is so simple that readers can reimplement their method. ,156 157 158 159 160 161 162 163 164 165 166 167
e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a,arr,Strength,Significant advantages of the proposed method over several existing methods are shown in some experimental results. ,81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
6b9e6be45c7620d0c5fccd2b2e663d00fe520937a5949233373bb5143bd5ca8c87de9b77877c05428c38eb98660424a76f9424b3c2cd8b1b2286db521bfe5757,arr,Strength,the experiments and analysis are impressive. ,61 62 63 64 65 66
3ad7968944d1e22977fdf3e4d24a19b5b0552964051f860f0414eb090d0def5b7d6bd878079e78a13e5affb8e8b94720db69d27f77ca82511aa4fc9fd9ff79db,arr,Strength,- The idea is straightforward and the results presented are solid and strong. ,123 124 125 126 127 128 129 130 131 132 133 134 135
1d40cfb665e0579b4b25ae816c69ff8534288c8c95c1006595190537bf9185a517f5fcfd02a845395681d1437cff6a610c71d52bbf254543a0d28a8e368ec6c1,arr,Strength,"Specifically, readers like myself who are aware that LMs _can_ transfer from L1 to L2 without the same alphabets, are interested in knowing _how_.  ",188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
35b575479428229666d5a876848bcefc7c9c4a0a43dda8805f608913e1244f371ac80a6e25040e10e408ec135575bd6b85c5394b274ee35499c198d410065588,arr,Strength,-Improved scores on WikiHop and MedHop subsets compared to prior work ,102 103 104 105 106 107 108 109 110 111 112
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Strength,The paper is well-written and easy to follow. ,64 65 66 67 68 69 70 71
264cb031349df77aae892fcec24ac8091c98df747caed53f30a86441fa9a17de6ba0a4ae3b5dc57307d9d0c1eed83b62f06e5dc1d6a373448f0eb4d8d5c65477,arr,Strength,1. ,36
5ae14ebd325342b481be21c26b53d15b2d0177dc899e64bb6b68923ae2721189571fcb03f648347294bf87bf185587f503ae82e99d5b59edfe63b1f8ce610491,arr,Strength,"The authors of this paper are correct in that most multiple-choice data sets like these don't include a ""None of the above"" option, and that most standardized tests, especially those that are adaptive (e.g. GRE) don't penalize test-takers for not answering a given question. ",105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148
973824caabb9511d6a7d00d13c02b2efb77c24d1aeee496a995acc8bd2b71701208ea5fa50d4bbd9e2b27ce2b41621951acb51c50ad850b337698d35f3c28910,arr,Strength,These insights can inform future work on CQA modeling and some solid recommendations are indeed put forth in this work. ,393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412
7ee102243dbf8de1d8e6a4df72d144a8eb5872685d4cb2686aca33dad00eedec4b7db39790881b7ac8dd76c80dfb35969d2786a17bee7fb1d4b4283826284e11,arr,Strength,- Experiments on ACE-2005 and MAVEN benchmarks verify its effectiveness. ,89 90 91 92 93 94 95 96 97 98
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Strength,"The survey covers the debate extensively from multiple angles -- works that directly build on J&W and W&P and works that either provide theoretical analysis, critic of these works and mitigation strategies.
",185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91,arr,Strength,Results are presented across four datasets and compared against several relevant/recent baselines. ,58 59 60 61 62 63 64 65 66 67 68 69
f5c1fe52015eca7bc9dae98faca96c2a7f615cf0e55b29913e80a53e2525061be51d5fd1b29c33f81abdd08822ad48257b55dfe446e63c40abef3a20df280d60,arr,Strength,+ The re-formulation of existing adversarial example generation is very insightful and will make a good reference for the community. ,285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304
3c700b87b28663e2240f3c1c35d19f41294f37cc002b8029603ef4f54d9d968c949cb010838cddcb298ea403508341a8703094385f49d73d8ff0a789c613ac86,arr,Strength,"- The motivation of adding the auxiliary tasks is clear to me.
",53 54 55 56 57 58 59 60 61 62 63 64
c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1,arr,Strength,"The empirical results (e.g., success rates) look strong. ",209 210 211 212 213 214 215 216
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Strength, Both into and out of English is covered. ,298 299 300 301 302 303 304 305
b2323ea6a2acb0917ab467ff7d423388eb4b0dfc86d7c8212fd0e7be8e28a8ee412b309650d8da93c85b6a9ca783289087b8e0cc704833f59182677549882a0a,arr,Strength,The proposed method directly and naturally addresses the trade-off problem of multi-task learning. ,118 119 120 121 122 123 124 125 126 127 128 129 130
4ae737b1ea00a29f1af690d68563363413d8b8a5362f88f339d751f31c0dbf3e4171c302bdb7f900dcb786b000c40f831e9d133f1ef5e6b191ac97dedc6f9e3d,arr,Strength,"However, there are sever issues with the paper that need to be addressed. ",200 201 202 203 204 205 206 207 208 209 210 211 212
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Strength,"The paper's discussion convinced me of the quality of the translation, even though I was skeptical at first whether translation can work here. ",180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202
a2dbb4d1f528e4c6c48a51354adb882d3af65dffe69005a325d024c09982fd4dc72e38f8af529d3c0d8145db9095fa881f644d51f888c58b24b952fe51374be4,arr,Strength,"Detailed ablation studies and analyses have also been provided to show the impact of dataset, pre-trained model and sub-tasks;  ",96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114
217a8d9fbdc29525938d0d7617a33310132b1cdea2c27638c8dac3ce9630355e12e631a78648efd9aeef02bef0a31d93dcacfc368754740b0522e182ed8caaff,arr,Strength,"
2. ",81
7e2200824612618fbf0a558af825af392cd8713b22b910256bbc865b254ddebb2f3e41e0ceb81dccf49fb193be3ff8ce8cf46121c365b4bd8a37f9a76c6358b0,arr,Strength,"
3. ",144
3d3b2e1f9dc0097f668b2e0bad96fffa312bde0b377e2a3b205ab87170bc2b8ebdfa1effa0cfa73cb13dc22f998c95bdd64e6d300499b60c02fc67557604fd95,arr,Strength,The paper is written well. ,98 99 100 101 102
993a4fa71106b965ffcb5e7c864e68039f6469b258d5aa0bb55f596f9d6badbaa9668fa2d3343c79bb586c8b741bdf5cb1959aa02a293ac978bf0828d709ab5a,arr,Strength,Strong performance on three different types of QE tasks. ,67 68 69 70 71 72 73 74 75
0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1,arr,Strength,-Extensive experiments on different scenarios. ,113 114 115 116 117
9897fd47f27a5635f032746e70df176df4cc22af4388de5be20fd85500491c65361dcf5993d53ef1a5d551443baa5ee0c2770c2778652861390170ef3ac41bf5,arr,Strength,"I think combining these ideas is indeed novel, and the authors also show that the suggested solution performs better than an end-to-end solution based on table filling alone. ",224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
4db1f42565b77cdf62fa416f06b563a7393032a712012b7bad26e3d05a4202b7e06673ed593490a7e25db57e7ae782ede2dd1d62f45785e1c3a77bdb2e5691f6,arr,Strength,"
5. ",232
a8a1cf2a07b35e928f4936d3347839f2dd6c9ba0cc09e1e10673ba58d8adc188f3125743bb319cfcbaf4c2f37cc62c7ec3bd9887e632b685f1d78722473aa27f,arr,Strength,The proposed modification to slot accuracy metric is very intuitive and can be used to better compare DST systems. ,102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
f9d269c23f60eedad27e62a19e6ebd7fd010adf8438300f82e884864442f16143fda1357243da801d6d4ee66072057c58d1ddd9e11831a6ebaa4fa48739c3622,arr,Strength,-The proposed framework is straightforward but logically sound. ,98 99 100 101 102 103 104 105
934822c7b982ef5cfe17e7d1a2c33eafa60d1ef26762879d7a09251d7b327197a9e94d1a9c3709b4dbf11194a20aba20b0b3425f336f4d6e1e81b2096cb47ed1,arr,Strength,"
Defined two important factors: quality, importance, from a theoretical perspective, to better understand the BT performance. ",55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70
71abbf4878652a7d1e9b29afe0137cd6e0b0862fe11ae99008da992f29e06e348c3a58132c73974a81a4470299a6f996e3f59faeb320f64cd57eaf52164895d5,arr,Strength,"This work introduces a new, large-scale dataset containing legal documents in a low-resource language. ",157 158 159 160 161 162 163 164 165 166 167 168 169 170
67378d8e10dc9158f3d5f981f5a4fe8492dd9f8b9a19060d81a5931a482a2e9662f9a413acfb54a018b2e3b4b5cea379b2e4b96137f6fb4342a1a4963f7c3cbd,arr,Strength,"The methods proposed are relatively novel, and show to explore significantly more of the search space than beam search, and explores in a more principal way than random sampling-based methods. ",125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
2ef61eb78fdf47c12059e3bf2786a28e20519dde0d8c39af578c9417e7edfb95ea6fa68330fad66de90bba4a0a8891b61269c70b91cd5c981cb6341197744b46,arr,Strength,"
 - The approach is parameterized, allowing it to easily scale to various operating points (trading off storage for performance). ",129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
70c276a941604f816f20431d12c06be45f7854f0691251ae78bef0a03badc35d74f7bea9f4e0a12885238dcae74a86455c3ead952e19ca136e4eacaf490adc28,arr,Strength,	This paper focused on an important problem in estimating confidence for poorly calibrated NMT models. ,126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
308a3dae511df165c5bafdb5ac87fa3882179218cd92d71a17954ba8f255214d06c106ec2341c49613479511484a01359e8b2cacb280fe807ffa5b2449a80c72,arr,Strength,The proposed set of tasks is well chosen and can provide a useful extension of SUPERB benchmark set which will allow more generalizable conclusions. ,159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
e6004c2ee71daf9051207f1b01dcda22334c7706d3d68dff4e49cf02cb41a2c7fb649dffd370c0ead75e629097421399bf1e9cbe077fddbe20fd61566985668a,arr,Strength,"- The idea behind the paper is intuitive and straightforward.
",29 30 31 32 33 34 35 36 37 38
d60ff492ac6bf5bdf7d28a9a93c1bb33a8484c0369070afcc4da9a0a87725aa38a8440a708841aa1603bcaeb528ff9730ffe1fa22f4231e5afbeb10efc8218d4,arr,Strength,-Cross-corpus and cross-lingual experiments are done to show generalizability ,38 39 40 41 42 43 44 45 46
736b12f6224f77a15f1d6d6713b3ff42292f9ea6e03993106263c03974258e977bfd814a85a79c3fec76a4bf5b26732882280b725f193d64846974b9f6d517b0,arr,Strength,"Even if I am not an expert in information-theoretic approaches, their approach seemed intuitive and explained very well with meaningful examples. ",127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147
31909b71e83378dba8a454ced702369ea4fa8ff0f365f92b534de6f10bfdda989d993d9308750d5fcb88ab6f18c26725b936bb5e69c7bc797b13e99e59b03841,arr,Strength,1. ,123
1610d011c9b4387992fd53b6494c5743d5bab835302c9990921da95c6773c6eaded9f4786a4459f5c497f65318e23db534f563aa8582440464166cf79b55231e,arr,Strength,"If the method in this paper leverages T5 as the encoder, it should at least try to employ the same one to the most advanced baseline (e.g., SARG). ",262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
1a43bd325a6abdae5c2b659964ce8941e40e52eaf9c58d5539eba732d5e7bacd90e16deb5536475f6af2b7dc195ba84db49e51c82b91b852ac249b3c4fb6a31c,arr,Strength,"This paper gives math analysis and derivation of the formula, making it more solid. ",85 86 87 88 89 90 91 92 93 94 95 96 97 98
27b39805e4e0c55ff684328552565c093014920ba218859a853c10e8f92d9ba83d9fbcd45e7cd8d44e8b3b35577f443781cd669340932655f6deacecfe6e7fe8,arr,Strength,"In the case of NLI, this work agrees with past works in finding a negative result. ",256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Strength,1. ,121
38eda9b605f5b516242d6ac820e3d22032c571c911c39793f73279d746ec3170cc5dadf78b950e61d423fb6eebdb5cc682d305c529553a95c539950c8da38a8e,arr,Strength,"The task of related work generation is very important in the academic research domain; The baseline model that does the joint-related work tagger is interesting as unlabeled data is used, compared with the previous version, the description and novelty are more clear. ",58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99
0b48ae9564885ff86bddb8640b135ebc0c4eddc39764c6cbd99e8664caecac0f15ede370f7960dc4e61f47ec605b8d5970849b0d8f5d0113f3607763fe5717a7,arr,Strength,"Overall, I think the paper is a solid work. ",301 302 303 304 305 306 307 308 309
34a654d252d0bb72f0bd405e28bc8a2c52097ce0c2fc0293a544b3bd1929cfc5996e389971dc43791136d5d78b742372f89326f61ab0ae0fdb56d762335f5639,arr,Strength,It provides a meticulous and linguistically apt analysis of the role of negation in natural language understanding tasks. ,57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74
4e676df011164c733ce15f204c348342406866c7015136130ed0b6877bd3cd99fc754841a2da5fef0564af9afff6b925a4b18204cd70d63819d02b26468eefc9,arr,Strength,"
2. ",114
4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80,arr,Strength,1. ,173
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Strength,"Especially, this paper would be inspiring for researchers who are interested in non-standard circumstances (e.g. non-English, non-standard architectures, non-accuracy/F1 metrics, etc.). ",154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
d32ecc3e071e982db4b1a0f762108f2c0dfe984b0cfaf3b57ccf4e8cff7cf517537f06e031e96d15cc310ec990853d72770e2cb655bab27d40cad5106bd0a341,arr,Strength,"
3. ",117
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Strength,The proposed method is novel and interesting:__ ,106 107 108 109 110 111 112
f587ce83feaea1c1d2ac6b1f4d7d7b7daf42c0e37cdfbb6118d77f213e3fa57a14114915315c888dda774e81cc8cb43f0fb4f1e3fe9326aad776cbbec3dce449,arr,Strength,"This paper provided details on datasets, hyperparameters, and implementations and is easily followed. ",154 155 156 157 158 159 160 161 162 163 164 165 166
2ddada6f901dd8ad326b27b309f2364352ef26e9d13e71e96e487268cf98bae91ac8ac79dae1e7c8282676d65315763816de11da22c7db635042708d9863a2b8,arr,Strength,"-conducted a series of solid experiments to demonstrate the effectiveness of entity representations in multilingual tasks and provided in-depth analysis on entity representations.
",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
a62cf505dc1353e9c6578ecc04f8152b8880014efe8fd6ce2bd5608d2524e27d49d154f12808007e18ad3a905ea956a1475956bfb8a221d51972d830addeb8bd,arr,Strength,"- Novelty.
",483 484
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Strength,"From this work, they contribute a dataset that can be further used. ",80 81 82 83 84 85 86 87 88 89 90 91
90fd08bb12ac39d88c9bcbaf9e4b90216cf152f7391b9c8139538d88d38a65410856a94255acb0a49ae597619b6babb58abc178d2eb9cd25fd1efb9ae74d0e86,arr,Strength,"-Results are presented on four datasets with varying degrees of training examples, and ablations were performed.
",63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Strength,1. ,109
62abb48743e2d28d289c62e00b5b3ad39ac3e34f44188b4f43b5a11e9b37cab1fc4111bf727cc08aaf0dda32b10574fa369876a26e6defafe157b9391a0f99d4,arr,Strength,"Paper is well written and easy to follow in general.
",69 70 71 72 73 74 75 76 77 78
a872bc9c1e4be3ba277d4b095016a806f5abc5ec21c5c1dd5462423499bac08928b1c11136ec540f6eacf9898531eb6456f931c2bc0236284b4991cf4f90b2ad,arr,Strength,2. ,184
3b7abb0934c42ac0f248c37cd980b1fd8cb472be2563c43775260b1a7d765728f8f85a513beba740c4a5c6a50e70cfcb2fa3fe097f7606711ae41ec14f73aa8e,arr,Strength,1. ,124
1ef6ccfd9e3537ad291ef842c8c6cf501be507c31bdd303a71e6c99d57931bcd905bc77f1b75112a96099d13213440fa5d49c5d4a71cf60f91c36b8e4f8106d3,arr,Strength,-Novelty: The proposed framework is very simple but not naive. ,96 97 98 99 100 101 102 103 104 105
7e09b61c2285ad6b5a034cb9db9baba649550cb3bd0b09e85f65bd1b0e4591675e81d999dc33da4a5800342f12d91fd5b687873eba720349e702331426cd02ef,arr,Strength,Improvements to SOTA maintained through various tasks and benchmarks. ,376 377 378 379 380 381 382 383 384
770026b8f19c8c72e3cefcb6c82ba346bd7cebc956b9c340177f3257ad87ccfd573b9b884798b2b3b1e9c1eef0cd1ffa4123637d211b95baee3eddfaf8963b15,arr,Strength,"
4. ",177
09042c84901c6ef5d7657477eaa05707b16aabb2ff86563542a35f76c67fdd97648d4cf84c7194b92056db882474ac64e74a1334f08ac4608cc481f060a7e726,arr,Strength,- The paper is in general well written ,121 122 123 124 125 126 127 128
43d85d8b36e1f938074a27b7443b55ba1168eb37e1d4354b51835005601e3faa3afb21277b240f848b629498a59ef8d69728ce58588d0caedd4d1ff7562874d1,arr,Strength,The idea of a ranking constraint is very interesting and as far as I'm aware is novel. ,46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62
0864d17ce562e1608d580cfca01d15e4e1ee2bc36f8284c0b8b2b4152675e6e017f9acc73c6943f475d4961ede2b546160cd681654c72f9aa1c0deb7ec74f9e1,arr,Strength,"-Unlike previous approaches, the proposed model is able to give answers to two operations. ",59 60 61 62 63 64 65 66 67 68 69 70 71 72
f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8,arr,Strength,"
2. ",79
ef0069c46d65c88106729e04d348067453fa4ac6fd81fbd99f165749d1c8cb94d941951ffc20f0077c6cc61c0551ea0fd8e35eda8fe37dc029d2f08826d6f91d,arr,Strength,"
	* A number of novel metrics are introduced. ",131 132 133 134 135 136 137 138
23f6971e79e116fe974bff7b07d482f1885af95851618a3d58c5d2d5d56c703094b07e02dd06e509d66ec737b89cc503c91998421d8792a24886dea28d3bfaf1,arr,Strength," Propose two new benchmarks: a synthetic dataset and a train/test repartitioning of the SQUALL dataset, both capable of quantifying out-of-domain generalization on column operations. ",84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535,arr,Strength,-It is well written paper. ,139 140 141 142 143
18fd3b2c5a51dd2d669f467ba0e1e069b29883fddd16ea0eab99a3f8d0751457c2e05fe22f99fc97ede5c21b376e7ab58658582352d7d1f30c3a1c5e4ce8217d,arr,Strength,"1) The paper is written well and is a pleasure to read (although some details are missing) 2) The paper presents detailed results, which outperform the two baselines in both monolingual and multilingual settings. ",57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
cb1661f19db1f1d4b29606d1f705743caeb32bbe554bfc35f53b7b2e2d2f52ff97bea4acce68f8ddb841793506df7d447f3546b8759a05474cbd1678e5da2edc,arr,Strength,Lot of earlier work focusses on BERT based model. ,158 159 160 161 162 163 164 165 166
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Strength,	The paper is well-written and easy to follow. ,144 145 146 147 148 149 150 151
37280326dd784256b0f392b38a62f06359a09c4159c5463d3d51d9ca70d2a69b91c3e0beb1b7816558eaf5174963d9bfdf4e72618996ec5dfba32675cf1c9bd4,arr,Strength,These can serve as a baseline for future research and they provide some initial insights about the difficulty of the task and the robustness ,288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311
57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c,arr,Strength,"Based on the evaluation results and the given audio samples, the proposed method significantly improves the quality of amuteur singing. ",192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211
c6e68ace9c7dd58c39160972207bd05fde2a14e0f3550613d0de5256d3fc80a07e8f3319fcdb91d97dfb1e9eed12479fae0a07a93fe4e1a075484af8a3ee6e9b,arr,Strength,The affinity-based graph construction with mention-mention and mention-entity edges for entity linking was already explored in prior work. ,122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
fd753407dbcfb49e603c208e282b97d0d8edea09f6a9245d2ab65dcd7d558498532f1bbc2a59544cf26949c2b50948dc2dc740b5a979c6dd21aef611d62a7fe6,arr,Strength,-Code is available ,164 165 166
08afb6e46460902c8ff65f0edb3dcae43d21a721d44a331d53a061e3fea8f8b4f78cfa27450d6ea1bd098dc8156bb4b09330f0c74487eb7bd7ad96ae2aa7d48d,arr,Strength,1. ,98
0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18,arr,Strength,"1) The paper is well-written and well-organized.
",79 80 81 82 83 84 85
c41a369099b82fe372383d92181c053f35d283169531ebab480287392eef0cf0a033b914330d8bf69962d692d339f756043500bd9a0f0b0ee791831f511440ce,arr,Strength,The research problem is clearly illustrated in this work. ,97 98 99 100 101 102 103 104 105
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Strength,"-A very good set of benchmark results on the new dataset.
",186 187 188 189 190 191 192 193 194 195 196
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Strength,"
2. ",122
8d7f381bb67845a11cedbc8d4e18f2c6d0ea7eabc1b0c22e7b12b2218c71c1196719bfd024d1dc68b8f53969f88e935fc83b7fadfc2e49f59f9cf19f0c82ceee,arr,Strength,The proposed probabilistic framework is mathematically sound and explained clearly and completely. ,188 189 190 191 192 193 194 195 196 197 198 199
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Strength,1. ,76
3214e7021970e65e4af03573fff686ed9bad3d1ec46537add4d2dd4abbe7b6856506abb1bfac468ed580ea33beb6d7becb473536ee8026b46f109f85ed6f0fe2,arr,Strength,The proposed reinforcement-learning based multi-task framework shows superior performance over the base model. ,74 75 76 77 78 79 80 81 82 83 84 85 86
4ed3080841b0dcb740254eca0b55df04d76059c6702e320ca95cdfdd81b161c85c62a2fe003743c52941a08d76169471eea91799c0857f084f36406c789b2450,arr,Strength,"I do not see any technical flaw in this work (considering the restrictions), and I like it. ",74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90
64aa79fd5ff9c7a1574169d784a23da9b0ab9df456f7df85bb596dc6bc10c1ada7e52084ec17a752fa459176bebd6a68abf704dd0c9e367e4213dcdc67ac33a7,arr,Strength,-It did some initial studies on how machine-generated answers and human-written answers differ in discourse structure. ,103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118
45b4eda89877a3cec613f3d96bad6fb6dc5eb9b89a0490c5a914cc52261e72429408e21e325ad3cc89762b0f99ce84de8e432647257b3d276f9232491a3bf4c3,arr,Strength,"
+ There is a lack of a large text corpus specific to this area. ",142 143 144 145 146 147 148 149 150 151 152 153 154 155
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Strength,"The motivation and research questions in this paper are very interesting in the explanation domain.
",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94
f114c485f3a154bfe4b17b697076d38bd97d6577ca6259df1cfa8c27362b8c18dd1c2a1e8107e124425212b7ce651160dcea0cc2ff455fafb4278e8de1aa586a,arr,Strength,1. ,86
c139a68e1cc57071a551aed2e93e04883f7538d202c23f452ebbe15a38dbf24c5a5c79bced7f223849d8a5399514ca784ff3fea124d58130e66ee37f7ed1e9b5,arr,Strength,"Without any knowledge of French, some details may be hard to assess for readers, but I don't think this anyhow avoidable for such a topic. ",288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312
f50c6edd6f7d33a87cd3ca0f768b3ea2e5f143c7b33128fc10a07f6aa74f835344dc2d1b88a5e003a20aa8982989d1238934cdba7b7fffb7dc7e462ad73dc5a8,arr,Strength,"
-The multi vector approach makes aspect similarity feasible for production environments due to scalable inference (with ANN). ",148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164
346582f5d9e2b75a39a4711cc113a66ae780133986cf48f339cda5219e5808715b9664ec085a5bf6912326817edf962bc9a97367731d58f60bcb399c7603e29b,arr,Strength,-Ablation study is comprehensive ,221 222 223 224
1a0b7f5493a56decef8b7002e14fb55b8408d53ca9ff0d2c1e8ff795023714924a59741178c1deef36469781120330485cbb92e8f3dfaad6d3b6127159c51e54,arr,Strength,The ability of null prompts with finetuning to simplify prompt engineering for LM to the scale of 300M parameters will also be a technique of interest of various practitioners in this domain ,203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
ae97f0c9dfb463df7f69b60b7297495113e32a1370beee6732301d7e4d2885d67032ee6207ac850d25d471747b5c24e08c534f35ddd572f7c03cd453803a3517,arr,Strength,The proposed methods are easy to implement. ,128 129 130 131 132 133 134
0bf79665ef5fe2151f794891f29a4988fc1a1194a757b5af8c216096e4ee2e264afe39298b581bb4280929385dd4a13cafb530c6777cc9f06999f89520a9e358,arr,Strength,-good analysis about the properties of the dataset ,71 72 73 74 75 76 77 78
569724b6337e28b97edaba29d9d2d648cf3d7547edf45c5b08c8eabaf04f8a063008db38e57d23eed6d040937a62023bf5cdb7100eee90b5bb7a4b46a3688342,arr,Strength,"A new sequence-length configuration is proposed for gradually reducing the sequence length in the pipeline of encoders, showing its advantages over other alternatives. ",122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
c013853901da324e01ceb977ae6f02ebad52bb40bd44bf0e41142e7a57b61e3ff5fff96b2a60744095fc2be6d4f9f921c01ca95af48adafafd2288bbc05884c9,arr,Strength,1. ,101
9cb9dbc88b782b8f6bac90072a56355dd2912d1d4fe4bbbd9b03a19146a2c7943b9b6595fbda03f346b4d649e09e19dc0a969ca6f7f799d03c183dfa679ca194,arr,Strength,"While my impression is that most of this gain is due to use of pre-trained transformer models (almost all prior work in this direction uses LSTM-based models), this work unifies this prior work into a seq-2-seq framework. ",146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182
f9a7f56bb8afd06bf59e954ee57ca25e221fa72043b16926b31c13b979b33be207b0da6c838a1b5d93daf2141ed3f99b6f9a7f6df39df61701c2e11d2e34d7d0,arr,Strength,"The paper discusses whether stronger visual features help improve the performance of MMT, and the answer is positive.
",86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
d35b383d873b104b6b6e710b3a2202585f3d714517985ad990eab04627e8bab826ef874d33436fd3a67278b2084941d8286d3e11380856a047e12ba92aeb1ad4,arr,Strength,"Apart from performance improvements, they also improve training and inference speeds by finding a way to narrow the search space. ",121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140
8e0619c3528a101f455dbe3971128ef7fa625e53969d47564b7f3c64952b759e42e31db7db777e856afbc88224e12e9acf9152f3bd09f0098f80335f6ec58486,arr,Strength,"- Reporting bias is an important problem to try to quantify, given NLP is   assuming that wikipedia trained models are good representations of the world. ",80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104
39cfecf18de21fd5ed75ea20882886bcc62b45ca973e1c6a139612c22b7399695443caa2b7b4f9fe702193168fb2cb774ed4ee7e340b36db95e723c2835ba755,arr,Strength,They train a multilingual language model with 24 languages with entity representations and show mLUKE model consistently outperforms word-based pretrained models in various cross-lingual transfer tasks. ,90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115
0f81aa2179161e304a3acefca345219d007d70011d38773c3f909f6fd316b0a593f15352a87a70bd735ae38aff521b4db33020f6b97409f3af9e8af2b5be367e,arr,Strength,"-Thorough comparisons of ConfliBERT models pretrained from scratch and continual pretraining, as well as with BERT ",88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103
81680af5af05010ec42e972722e1de12e2b857d3ed9217204b26f174ebcfc7d1cd0861ad2ac955faddc461bdf62c8aaa4ba7d6b6e7773dcdfc23ed26011f6aaf,arr,Strength,-The results are highly interesting and of great relevance for the community. ,136 137 138 139 140 141 142 143 144 145 146 147
6ecfd29883f4de0596f01657286eca384c81d9340152dd210fe2cefab0b1e738a3ef1bad9c36497cb3f2de154898006c9239150ae44550ebd0e44f4330635be6,arr,Strength,The theoretical analysis can demonstrate the sparse progressive distillation can be well optimized for PLM pruning to some extend. ,194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212
7f02b5e5a8d97efbde8c6f66e1df0d06cf8d072bc5f2f468ebaf33f7c3a4c57197edd42d7ae0d32f2d86d56fe48d56228aced4a79f4e543479db29fe4991362a,arr,Strength,The paper conducts extensive experiments in out-of-domain setting explanation methods comparison based on different models to prove the post-hoc explanation sufficiency and comprehensiveness show misleading increases in out-of-domain settings and select-then-predict classifiers can be used in out-of-domain settings. ,96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Strength,S1: The paper is well-written and structured. ,64 65 66 67 68 69 70
454ac9163c957dcc7ec3004b0c2b2512e312c4b1ecdc35584ad75bf1515bf3b62bfd241bb36dc38116886fb575f4e3d5a060a5659d2cfff9494dbf03650de818,arr,Strength, The proposed solution addresses that issue by means of contrastive learning between semantically aligned paths. ,200 201 202 203 204 205 206 207 208 209 210 211 212 213 214
ce8f55e360259259ef79060481821ff273f34459af7816e3fdf94343755e7c1c71d255cf6aaf59122dbe315d17986fbcbff9a6c931c03fb0589383aa04ce3dbf,arr,Strength,Analysis shows that different prompt design will affect the zero-shot performance a lot. ,144 145 146 147 148 149 150 151 152 153 154 155 156
72238c64b0133c55bd0340f893e806207fb2a6a4bcf8b1a82f5be251fd1808a8f6e89fce4d8859277837186b53f01bac53e307a70b0666cb60c68d77651e7c30,arr,Strength,Well-designed experiments and ablation studies are presented to show the effectiveness of the proposed approach. ,59 60 61 62 63 64 65 66 67 68 69 70 71 72 73
3014c7d4fe2505a0dabe0d80368f4377f107b17ffea8e19c24c451662125ba7960ae38564611b909bdeb9809e2f259a85769ad3e08403a447b1ea6eea3713eb4,arr,Strength,"-Insights about better evaluation practices.
",181 182 183 184 185
fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d,arr,Strength,"The related works section is particularly well-written, with the right level of detail, even though some references are missing. ",91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109
0711fd7db80f8adb12c7af75880938904ac072de706cf04edb8ac8cdb1de1745eb8e2645ef188d30158729a4e038ec541d6b64f5d6d670ad595208692660cde9,arr,Strength,- The paper studies an interesting question of low-resource adaptation of vision language models to downstream tasks. ,104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,  3. ,255
c699ea82d7e1a59a1d1150c2e72b55ab4bf610e77fbda9f9b98bd97966efd6f07ca36041b3de5c3581ef330b3197a40c6939ab9c417a4d0b945b227c88c768ae,arr,Strength,"
2. ",125
e42d651bc09e986d20ae0dffeb058df1964cbd04280553237939209a47f80c069be38d31a79dea7654f05bca31b819bcad9acfb0d1bbc047de61fe954a420162,arr,Strength,"
2. ",234
7dbcd742049303889db6f12347d88a7912d218b2a8f4c46461d34e401289e1f2915c0c04a40554ac567d9329dbcc4583af7403160ba74de14c697269927219a2,arr,Strength,This paper tests the performance of the proposed indicator on a variety of tasks and achieved good results on some of them. ,115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136
53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9,arr,Strength,The proposed parallel corpus is valuable and make great contributions to Livonian NMT. ,64 65 66 67 68 69 70 71 72 73 74 75 76
40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f,arr,Strength,"- First attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.
",292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,"-A model with SOTA performance.
",98 99 100 101 102
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Strength,The paper is well written and easy to follow. ,114 115 116 117 118 119 120 121 122
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Strength,The authors evaluate their methods on multiple text classification datasets 2. ,172 173 174 175 176 177 178 179 180 181 182
fb3b9aa95ddf49e8c7dde3292ed0a7f5aa84862ac8fa8ce482dd03bb23b412c9c99d8268b47ebcee72e4ced81f48c81d9e4fe03e640e096b46c86623737620f4,arr,Strength, ,
a4d284a7d3c4ce822d168c01f209a7b5eaa16a30952d0d3321b51e9997abbc9fde9f6d37dd53a0afd9519480279c75f831fa38e7fbc0bbd7aabeecd03f5b8e8e,arr,Strength,Several reasons to accept this paper in ACL special theme track: + Understanding the challenges of cross-cultural and multicultural NLP can improve the NLP systems to serve the users in a more inclusive world. ,58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91
ee5e4ca21e0a5335fdb764ce2fe1636d41f84b13ddb546252f94075398b80fb071e33f60d189833f839aa8eaceff519c009e91e1c79ba5ec08a2c632894cc69f,arr,Strength, ,
7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f,arr,Strength,1. ,77
3b51e3d3b5c133b47458ca30f3c4de26bd880108776f3ad26f73d6053855640b3ec45a3effeb3975aa4203a5e7bc2574ca800cadcb69019305109f12f53176e0,arr,Strength,"The authors define clearly the contributions, motivation, and experiments conducted. ",71 72 73 74 75 76 77 78 79 80
4a1c1a54db4c8630e04e4e5f045f69749e7bf8d6b6bf7fe1b5abc8f64b63aac51dbe6e0e4f0a4a667815ef7b8e80d00ca2eac00026243514c420f95834081e42,arr,Strength,The paper identified only a small number of parameters are enough to fine-tune the CLIP few-shot learner. ,94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110
93f2dbcf1adfb64891da4b3d647b5b93e5bc9bef019adfe68983a764eafa5ce16f7b16a14cc54a8522b5c9c7534ef42d0a763a4a2c949645aec3f8303fa466c4,arr,Strength, ,
f3f751ba8b21e054b0fd4d27d2f966fab26cf382c0a8f51d2c6ec4be6b17b050fe248fb2fb091fcae6f0e79231a9bd3c7b696da7961e1310f79bf4638586a896,arr,Strength,The paper is generally well-written. ,192 193 194 195 196
e226035b46a2b2286c61a62ba7d567c1de36ee507bc11d502316f5b531df65379be5e519183e6243575f237e0dcdedc1d0e8853ca7383aadc9f14c1af20e9d18,arr,Strength,"- The work shows that the performance of summarization can be slightly improved by selecting the summary that lays in the ""centroid"" of the pool of generated summaries. ",163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Strength,It may be useful for nested NER studies for that language and also for low-resource languages as a comparison. ,89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107
90e04379fb077ffb95194774c8c4d6f2e74a1d3828f2518769ab00f35a80d69327a9545b72f18a23ff9dbf51959a971024bf998443b25750975d7b78aa0e8edb,arr,Strength,"-A dataset for the new task.
",92 93 94 95 96 97
b1a87aee239b1301e7f158ea20fa7511d5cd1f71f6d8619ce88dcd3244eccb1e72527779ea511b0e4f44f8d5917451213f80ea53973faba39940047771b675dd,arr,Strength,"
2. ",75
c6ac27ad9dd330a6c0d139fea8c0115c634caee678a5868fef6c613fe519c0457b25bfe2df08741630166891caaebcbac86f624ad1b6207df4192f30d25f0a3f,arr,Strength,The paper demonstrate improvement from using proposed text smoothing method. ,28 29 30 31 32 33 34 35 36 37
de80fb5dcb7742d5deac72ad17f784d4f2402d16ce8127f954e5aed45500453a2562ebf5590b2fd934a95b4a4a38458099f90408c9bf145080d1a3131b9088bd,arr,Strength,"The authors work in a low-resource setting, and their work is very valuable and could greatly help linguistic fieldworkers with (semi-)automatic segmentation of either recorded speech or transcripts. ",102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129
a1e3d5b8b31ba97f2b2a0d19d6bf1da01b1caeb7ebb1cfc2ec0a8654fae797bd669adea6bc97b08cbe9a15381733c14d3803ad76d0457d7d4a88b7c921772932,arr,Strength,"The methodology described is mostly appropriate, which makes the conclusions more reliable. ",281 282 283 284 285 286 287 288 289 290 291 292
6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640,arr,Strength, ,
b6471bd64d652cce2aab51eb4eaa7a36bf8b0f53e71692c95a15a293914fbfa710f8ee33d85e431dba9cdc510218ccf0102fde0a9dbafb93e4a02a904b78a554,arr,Strength," I expect that the details necessary for re-implementation are relatively clear.
",270 271 272 273 274 275 276 277 278 279 280
879b13234d6d01374f7edbafbfd9606c21b5c808ab693460325731eba80fe52f1dfed62bbe466ebd526b0423037bc7ebd68668e33ae3a6115cfdee123ab8bc80,arr,Strength,A nested NER dataset with a wide coverage was compiled for the Thai language. ,66 67 68 69 70 71 72 73 74 75 76 77 78 79
c73cf33735ae5af24fdde2536e815b0464984a17fc23086a6b1205cf754731a3100135f13508f7eb265e6160a4c51095f0c7b38bbfc971edb010117ba3fa9918,arr,Strength,- Theoretical justification of the method ,487 488 489 490 491 492
7b9204699434ff8312efc0b85be09bc0e8b68ed3f9561594785ea7d884b0ea8646efc7d8e1a5e3cd17f8cb3226b6f2e3eadf5a2110a20637e7e000dc6cd83eda,arr,Strength,- Ablation studies and analyses are thorough. ,51 52 53 54 55 56 57
30d20ad4e80241740d806935042ffdb8b0cf0152b3b8c806b714ae4860d32a4981bd6158b950986ab97475e6f5276453181819cbebd8bc138ce1ea904d8ffa90,arr,Strength,I did not see papers that use OT to search similar data samples before. ,133 134 135 136 137 138 139 140 141 142 143 144 145 146
6fa9bce38a7d737b41586d8ddc0aa1e8962e82d241876d5bb9b07592de8e6aab2dba7abc8f3fd736e5539c64304e95cdee2e0c4c301a477133c370a101f9f912,arr,Strength,"Experiments are comprehensive, and the appendixes contain a lot of information and analysis for reference. ",207 208 209 210 211 212 213 214 215 216 217 218 219 220 221
6267cc0fb878ff34bdebf321ebde58ed5769d12cebf2f4620ea6634f15bbe0a64b13d12070b8fec26de185fec8ba105e4df074009b5fbd4d2101e39db53a343d,arr,Strength,-The proposed tasks provide a complementary view to the 10 already existing task of SUPERB  ,164 165 166 167 168 169 170 171 172 173 174 175 176 177 178
ebec57333f46f2bffc75b6573895650584ed72eaefcf54ab44394a50013760eb2db229be9aea5935ec4a0e98e42e2934a0eba90151207b3b968ba1b49cdafa54,arr,Strength,"
3. ",146
cb1c7a25620a6ec79b6929eca97da3113719a73a0b5b513709b8ee66ba8914b405dd9df438a79fe7f7ea4b59dccba72584ce1b95ee19dcd55ff249ee0e8a4d49,arr,Strength,"- A new model for event and argument detection and typing that uses distant supervision signals in the form of additional prompt templates.
",152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174
aa6b6ff5226b0789a70bcf2ab038b9a89465cfe5ad981bef382ae7a1f352e0be4cd9caeaa18dbc82bb1bfc5e11e9ea276fb72c8184fa12f54398b2be1c70e449,arr,Strength,"-The experimental paradigms are simple (both rely on comparisons of Euclidean distance in an embedding space), but novel in their choice of which quantities to compare.
",237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262
31ffabcd4514d0e9d752684467f1a8b81ce5a6e875bb8a39ac20fcda680c141881857b67fd91827b7cf658c231d5b66efb01ddbc9505c3e5bd5e6a5db35e82e9,arr,Strength,"Moreover, the new evaluating dataset proposed in this paper is also very useful; it enables future work to evaluate their models across several domains. ",222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245
324a61be0ca93af3fd62304b21836f355ccb20245c616b23c2d22b62de33b64e253756efcd07b651c95dcabda1345aa9800d6ffa22ba96060c7adb455f14d561,arr,Strength,-The paper shows through evaluation on a suite of benchmarks that the proposed method is superior. ,250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265
05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e,arr,Strength, ,
7c0a758d59caeaedb368c857bc3a695af2f04d314c12228f0c5e970d6b975ca00df45df67b9ee9585e02f1f78d72bfacac95f9bf8bf0f8f1eaf0e6f4c5391199,arr,Strength,"
3. ",72
d4b6a18e476d8e6bbc82a16af3be25ab35ab591e6d762377cd3c7a461fb6c5dfae0df4cab91a186fa68d4d0dcbe88c11f30a461bfd96fc392bfd976f35d7cda0,arr,Strength,"
2. ",129
98e038cc6cfd29e7ea20df44c6679583f02d10f368158c5f52945f252874c7a1453526c6a69c7d68a194962c05c0a3f09cb6f1b7f84df268a22cd5db11d0f2a7,arr,Strength,"Overall, I think there is enough to learn from this, given it is a short paper. ",211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226
46d7f10cad6e3fbe1637657cc3bc345496a13b80b025b50840df9488b039d43cb71304e5729e20ccb69837b052332160687b67f517e7083834a301124be36cd0,arr,Strength,The paper presents the model performance on this new cross-domain benchmark and provides a reasonable analysis of the results. ,139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
22d03e07f270cb7d246ddfa1364aa54f68ec658e0cdb7979d63c4afcfaadca4646fa4ae846e99647874dfa339718baf9e9a7b6a22b03a558013c39ecd70245a8,arr,Strength,1. ,47
49cb81c274f23110d2cdd4961637e7730446d6deaa51193c052e5080395742611ff31f35a5e37607cabeda122d7d3273017b3a1fad0dd7b75ebd00fb6e641d5a,arr,Strength,"They use a system based on that of Cai et al. (2018) which is a bit old now (surpassed by many other systems in other benchmarks), but it is still good baseline. ",425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456
c1af730b370c44b11d64851ee9d2f5ea9eb336b8c04301c2681c8d1bfdf213c74db334a970ae2b248018ee30be7a033c695c8c021292d26e3f53ccac0f23ec28,arr,Strength,"-Detailed discussion is also provided for different datasets to further analyze the effectiveness of the proposed method with respect to informativeness, diversity of the constructed phrases, and the source of phrase semantics. ",108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
a6f82cf1b57c8583edc2f577a981c611737147123a0d7938a14b18effdeef61e7a661ded347656f6a6ddf9ab69c25c5e6a56f25a4df9c814a9ece60fc02ebcee,arr,Strength,"
   * The use of the same methods (direct reuse of prompts and using prompts as initialization) in different settings (cross task transfer with the same model and cross model transfer with the same task) and similar results in each demonstrate the robustness of the method. ",671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715
9f320459a1665d8d0d4fd148e378270f6dcd498d505a6f2f475a0de31f62931889ab7d137afb7349bf74a57ad9d75223fdaa1a26431d93140d4489848e20eff8,arr,Strength,A zip file has been attached to reproduce results. ,154 155 156 157 158 159 160 161 162
267d8cc21e6494de3e7f8dae6c4dac07596c44639abf6652d7d3ae071e4fb97395f8715a3ca6b660ea2aa51bd4f0a8a98d8d2059b958e941eab0e23eb1975655,arr,Strength,The paper introduces some interesting modifications to the existing approaches (Mahalanobis distance and DPP Monte Carlo dropout) and the authors are able to show that the proposed modifications lead to state-of-the-art performance in most of the selected tasks. ,134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171
f5d14391b40ef9e869292686627ae5faec18d78b9d435160d007bffe2a8ff9c81af1cb18c0dd694d75685fba6500e824421b6e8b6433e6210275268381c13291,arr,Strength,"-The introduced momentum sampling strategy is interesting and can be useful for multi-task training.
",87 88 89 90 91 92 93 94 95 96 97 98 99 100
ed6a448153d21c5e87700a26686a8bc5c1f967ef8e12c2d42787ac5d1b0b5f08beb12de91b6038d5a330fab97a5da343759b8e3ebe07fc958d1a32ab6cb23290,arr,Strength,"
+ They experimented the proposed method with various types of tasks. ",63 64 65 66 67 68 69 70 71 72 73
bf02e6a3f5c823ead06f01e0ee0a11317b7a8a6f6d4ded461af62d5380a91e25108a020db545f21b64a0a636f9e4e37df65e1007d6c0a718b93b53a43bffe768,arr,Strength,-Strong results across numerous tasks ,74 75 76 77 78
9916122c21008d2809d79170fd22af33b3db6005fa54fc02e83857b0c09d300dec25122a30df4d2c5f9b170d03107ef2a40c9165542a47a2a4c4ee2f298ea9f5,arr,Strength,"The exposition is clear, which makes the experiments easy to replicate for a reader. ",336 337 338 339 340 341 342 343 344 345 346 347 348 349
e825a3c26bb00f83fc361f1ba4a9855a49ca997af474f34abdfe94c969eccbe694bff9837526c04191321ca6c266d33260d33287967aff28805da237a4dbb70f,arr,Strength,The discussion of the limitation of the present language models is rich and this work provides an important understanding about SOTA language models in the way different from other language model evaluation papers. ,129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
bf6b83670f48614949712d64e3e745e1031c30ca34f2e6cdf285147af2b918d31f957440e1398e7051360fa613b9b36636eb0126804664c8d97153126378174a,arr,Strength,The assigning procedure is solid and can thus benefit the following studies. ,243 244 245 246 247 248 249 250 251 252 253 254
e59cf68e846cef32b4bd1a1156957394e1650a4efa1704ec26a15e98466601456d3c79dc40b96046a46efe1206287ef8f1acbe1984b1c218d09880b0acf0ad06,arr,Strength,"The reader would benefit from reading the theory and methods in this paper.
",156 157 158 159 160 161 162 163 164 165 166 167 168
7bd274f90b74323501513a52410d7c58b8629cb10f9396a73e0b9acb30c62c06109a30503eeb22875b1ebd3cc2f6e4afcf2a9052020d18d30fa2a2192f56df03,arr,Strength,"
3. ",139
edeb6b73f5e1cd110d9fcf8979ad3bb447374e25885ac475b989d86003ce7ab9dd829cf7a3030c3dce84f990563e1b6e53dce8b8d8c9c12a8bc012551c41c85d,arr,Strength,"- Evaluation is through, and includes ablations and experiments with automatic metrics and humans ",200 201 202 203 204 205 206 207 208 209 210 211 212 213
3509a36805c40e4daeb6764d44ec941ce2ce3aa3c0c60a392aa14260ac722032ad7ea98de5ebb67addc506cd978eb4241a1d3079302ccde45397f1dfa2a1cf59,arr,Strength,"The paper is well written.
",210 211 212 213 214
05bb7fb6c2f67986bb57b62cc394f8f195da4af9698e6062b6102bea1dc2fa1a83dc2ee06d1ef4a1953933e8401643b026d63246ad4449320230d22536fead18,arr,Strength,"
3. ",233
8eecd9d9385a645627d2a6dc5dfb99a9f0adff93a88e823da7c6daa9fb72238b4d05705185bd11eba3b6dec1ff93a1c18736f66f630f4e4674deaa2109450f8e,arr,Strength,The authors carry out an extensive analysis of explanations in out-of-domain settings considering various datasets and models. ,53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69
08892a69fdac49d5f25fbbeffbc337678709c630149dcd0d04a9ecdcee4570471144cc3f53651dfd68492a0d63e448bef3ed5c51b2765e40d3a2e1e908916e31,arr,Strength,-The results are convincing on the BEIR benchmark ,55 56 57 58 59 60 61 62
9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b,arr,Strength,"In addition, hype can potentially impact early researchers' understanding of progress in NLP. ",113 114 115 116 117 118 119 120 121 122 123 124 125
4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39,arr,Strength,The work or its variants (unsupervised version) may be extended to other cross-lingual/multilingual applications. ,132 133 134 135 136 137 138 139 140 141 142 143 144 145
e4ac3556d3516a52885850d0aefd91a4d53eb84f9686b4896f9ced9e9fb4bc3a9cf69127e23e965b27264c491b1c1ced150cc994fe7734b373f96bbd1a67da3a,arr,Strength,I still wonder whether it is necessary to conduct visual grounding on pixel level. ,70 71 72 73 74 75 76 77 78 79 80 81 82 83
29b4b4ffced31f175c39dd09eb38b5d8fcbb8543641322dc87442f102fb354f48017201834d7e24d64832f7aea4fa4f5fc892898e767d19ebf974a2f372cd73e,arr,Strength,1. ,52
1731e84e1beb6d679ca8de876b0d9db91db12fd5433e655c6fc2d0884a5e5c60329fd204f2b50f81c4af09ba4f3f53521b5c9426463a6af3283d8b2dbffad7d5,arr,Strength,"
2. ",48
3d9bd4f696a0ffd93f440373203719609023010bd34a2c59a8cff858a5fa2f8173fef25fa6a9e50b96b725b1123e71585fb385d91e0d0b1b203a048ffbded8ce,arr,Strength,"The topic is highly relevant for the special theme of this year, and the issue of cross-cultural NLP is a new and interesting perspective. ",294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317
da3c75eabf392377ac87f8a824fc74a96de1a193ae8b5b549decdf44cc11150c2340a91584f025dc2b71f02707dae76bb9a0192b85eeda5b980d5ac7271f74e4,arr,Strength,"From the perspective of this paper, one can easily notice unexplored areas of the research manifold, thus I believe this paper is helpful to the community to become more diverse. ",124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153
b62bb422efa894574ec90254ce8f2101fa9faa7241129ab055cf5a1bb98c83c2b80958259c78f17880f3a5c08a430599dbef877bab17d345bd53653ec9a5daec,arr,Strength,The idea of jointly training inference and interpretation is interesting. ,152 153 154 155 156 157 158 159 160 161
aa58d6b301c8f7acc508015e36d7e9b0fc06eb7af2007afe19aac58699718a360f1087554638b6ebc805c25666ac67359ec09e505418c3fa623b2cf1ba8d7b8b,arr,Strength,"The numerical-reasoning-aware pretraining outperforms SOTA by large margin in three representative tasks.
",81 82 83 84 85 86 87 88 89 90 91 92
a870e0cbe442bebd391baff19abed2b42a7d8f14cc88a0606769c78e8f41709da3cad6054a0d78f2df052c2e6a680deb626b0378618025a5b3b95cbf1cf3c640,arr,Strength,"
4. ",240
ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd,arr,Strength,"• The paper shows a performance gap in the translate-train model (a common baseline in multilingual ToD) when the data contains local context.
",270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292
e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb,arr,Strength,"-The proposed method also achieves good performance in the few-shot setting, which makes it more useful in real practice. ",103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
